<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>trabajo_grado – Vladimir Sanchez Tenjo</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>.my-large-equation { font-size: 24px; }</style>
<style>.my-small-equation { font-size: 12px; }</style>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar docked nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Vladimir Sanchez Tenjo</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html"> 
<span class="menu-text">Principal</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./about.html"> 
<span class="menu-text">Acerca de Mí</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-recursos-de-aprendizaje" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Recursos de aprendizaje</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-recursos-de-aprendizaje">    
        <li>
    <a class="dropdown-item" href="./Recursos1.html">
 <span class="dropdown-text">Libros de Texto</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./Recursos2.html">
 <span class="dropdown-text">Recursos de Multimedia</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./Recursos3.html">
 <span class="dropdown-text">Otros</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-programas-prueba" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Programas prueba</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-programas-prueba">    
        <li>
    <a class="dropdown-item" href="./Series_Tesuvr.html">
 <span class="dropdown-text">Test UVR</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./R_Tutorial_01.html">
 <span class="dropdown-text">RStudio Básico</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./Recursos3.html">
 <span class="dropdown-text">Computación</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./Trabajo_Grado.html">
 <span class="dropdown-text">Trabajo Grado</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-pasatiempo-prueba" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Pasatiempo prueba</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-pasatiempo-prueba">    
        <li>
    <a class="dropdown-item" href="./Literatura.qmd">
 <span class="dropdown-text">Literatura</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./Podcast.html">
 <span class="dropdown-text">Podcast</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./Arte.qmd">
 <span class="dropdown-text">Arte</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./Trabajo_Grado.html">
 <span class="dropdown-text">Musica</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./Trabajo_Grado.html">
 <span class="dropdown-text">Filosofía</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./Libros_02.html">
 <span class="dropdown-text">Libros</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./Peliculas.html">
 <span class="dropdown-text">Películas</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./Trabajo_Grado.html">Trabajo Grado</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Series_Tesuvr.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Test UVR</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./R_Tutorial_01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">RStudio Básico</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Recursos3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Computación</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Trabajo_Grado.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Trabajo Grado</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#teoría-de-distribución-de-rachas-y-patrones-y-sus-aplicaciones.-un-enfoque-de-incrustación-de-cadenas-de-markov-finitas." id="toc-teoría-de-distribución-de-rachas-y-patrones-y-sus-aplicaciones.-un-enfoque-de-incrustación-de-cadenas-de-markov-finitas." class="nav-link active" data-scroll-target="#teoría-de-distribución-de-rachas-y-patrones-y-sus-aplicaciones.-un-enfoque-de-incrustación-de-cadenas-de-markov-finitas.">Teoría de distribución de Rachas y Patrones y sus aplicaciones. Un enfoque de Incrustación de Cadenas de Markov Finitas.</a>
  <ul class="collapse">
  <li><a href="#prologo" id="toc-prologo" class="nav-link" data-scroll-target="#prologo">Prologo</a></li>
  <li><a href="#introdución" id="toc-introdución" class="nav-link" data-scroll-target="#introdución">Introdución</a></li>
  <li><a href="#capitulo-2-incrustación-de-cadenas-de-markov-finitas" id="toc-capitulo-2-incrustación-de-cadenas-de-markov-finitas" class="nav-link" data-scroll-target="#capitulo-2-incrustación-de-cadenas-de-markov-finitas">Capitulo 2: Incrustación de Cadenas de Markov Finitas</a></li>
  <li><a href="#capitulo-3-rachas-y-patrones-en-una-sucesión-de-ensayos-de-dos-estados" id="toc-capitulo-3-rachas-y-patrones-en-una-sucesión-de-ensayos-de-dos-estados" class="nav-link" data-scroll-target="#capitulo-3-rachas-y-patrones-en-una-sucesión-de-ensayos-de-dos-estados">Capitulo 3: Rachas y Patrones en una sucesión de ensayos de dos estados</a></li>
  <li><a href="#capitulo-4-rachas-y-patrones-en-ensayos-multi-estados" id="toc-capitulo-4-rachas-y-patrones-en-ensayos-multi-estados" class="nav-link" data-scroll-target="#capitulo-4-rachas-y-patrones-en-ensayos-multi-estados">Capitulo 4: Rachas y Patrones en ensayos Multi-Estados</a></li>
  <li><a href="#capitulo-5-distribucines-de-tiempo-de-espera" id="toc-capitulo-5-distribucines-de-tiempo-de-espera" class="nav-link" data-scroll-target="#capitulo-5-distribucines-de-tiempo-de-espera">Capitulo 5: Distribucines de tiempo de espera</a></li>
  <li><a href="#bibliografia" id="toc-bibliografia" class="nav-link" data-scroll-target="#bibliografia">Bibliografia:</a></li>
  </ul></li>
  <li><a href="#rachas-y-escaners-con-aplicaciones" id="toc-rachas-y-escaners-con-aplicaciones" class="nav-link" data-scroll-target="#rachas-y-escaners-con-aplicaciones">Rachas y Escaners con Aplicaciones</a>
  <ul class="collapse">
  <li><a href="#prefacio" id="toc-prefacio" class="nav-link" data-scroll-target="#prefacio">Prefacio</a></li>
  <li><a href="#introducción-y-comentarios-históricos" id="toc-introducción-y-comentarios-históricos" class="nav-link" data-scroll-target="#introducción-y-comentarios-históricos">Introducción y comentarios históricos</a></li>
  <li><a href="#para-qué-sirven-las-rachas" id="toc-para-qué-sirven-las-rachas" class="nav-link" data-scroll-target="#para-qué-sirven-las-rachas">¿Para qué sirven las rachas?</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">




<section id="teoría-de-distribución-de-rachas-y-patrones-y-sus-aplicaciones.-un-enfoque-de-incrustación-de-cadenas-de-markov-finitas." class="level2">
<h2 class="anchored" data-anchor-id="teoría-de-distribución-de-rachas-y-patrones-y-sus-aplicaciones.-un-enfoque-de-incrustación-de-cadenas-de-markov-finitas.">Teoría de distribución de Rachas y Patrones y sus aplicaciones. Un enfoque de Incrustación de Cadenas de Markov Finitas.</h2>
<section id="prologo" class="level3">
<h3 class="anchored" data-anchor-id="prologo">Prologo</h3>
<p>
El propósito de este libro es ofrecer una introducción rigurosa y exhaustiva a la técnica de <em>Incrustación de Cadenas de Markov Finitas (ICMF)</em> para estudiar las distribuciones de <em>Rachas</em> y <em>Patrones</em> desde un punto de vista unificado e intuitivo, alejado de las líneas tradicionales de la combinatoria. A lo largo de las dos últimas décadas, se han obtenido mediante este enfoque un número considerable de nuevos resultados relacionados con las distribuciones de rachas y patrones.
</p>
<p>
</p><p>El tema central de la Incrustación de Cadenas de Markov Finitas (ICMF), como su nombre indica, es incrustar adecuadamente las variables aleatorias de interés en el marco de una cadena de Markov finita, y las representaciones resultantes de las distribuciones subyacentes son compactas y muy susceptibles de un estudio más profundo de las propiedades asociadas. En este libro, el concepto de <em>ICMF</em> se desarrolla sistemáticamente y se ilustra su utilidad mediante aplicaciones prácticas a diversos campos, como la fiabilidad de los sistemas de ingeniería, la comprobación de hipótesis, el control de calidad y la medición de la continuidad en el sector sanitario.</p>
<p>
</p><p>
</p><p>Este libro está restringido a espacios muestrales discretos, una restricción que sirve para que este trabajo sea accesible a una audiencia más amplia al simplificar los resultados teóricos y sus aplicaciones. Las rachas y patrones considerados aquí se definen en gran medida en sucesiones de ensayos Markov-Dependientes de dos o múltiples estados, con aplicaciones prácticas en mente; los definidos sobre permutaciones aleatorias de números enteros, como los números de Eulerian y Simon Newcomb, también se tratan utilizando un procedimiento de inserción adicional. El contenido de este libro está orientado principalmente a los investigadores que utilizan la teoría de la distribución de rachas y patrones en diversos ámbitos aplicados de la estadística, la probabilidad y la combinatoria, pero también podría servir de base de un curso de temas especiales de un semestre de duración en cuarto curso de licenciatura o a nivel de primer año de posgrado.<br>
</p>
<p>
</p><p>
Deseamos agradecer la ayuda de Y. M. Chang y B. C. Johnson en la corrección de los primeros borradores del libro, así como el aliento de nuestros colegas de la Universidad de Manitoba y la Universidad de Toronto.
</p>
<p>
También estamos en deuda con nuestras familias por su inagotable apoyo. Por último, queremos agradecer a la Sra. E. H. Chionh, de World Scientific Publishing Co.&nbsp;por su paciencia y apoyo administrativo.
</p>
</section>
<section id="introdución" class="level3">
<h3 class="anchored" data-anchor-id="introdución">Introdución</h3>
<p>La ocurrencia de <em>rachas</em> y <em>patrones</em> en una sucesión de resultados de ensayos discretos o permutaciones aleatorias es un concepto importante en diversas áreas de la ciencia, como la ingeniería de confiabilidad, el control de calidad, la psicología, la sociología, la comparación de <em>secuencias de ADN</em> y la comprobación de hipótesis. Resultados de las distribuciones de probabilidad de rachas y patrones elementales se obtuvieron esporádicamente en la literatura hasta aproximadamente la década de 1940, cuando se publicaron una serie de estudios pioneros sobre rachas y patrones más complejos: por ejemplo, <em>Wishart e Hirshfeld (1936), Cochran (1938), Mood (1940), Wald y Wolfowitz (1940), Mosteller (1941) y Wolfowitz (1943).</em> La mayoría de estos estudios se centraron en hallar la distribución condicional de las rachas de éxito dado el número total de éxitos en una sucesión de ensayos de dos estados. Un libro reciente reciente de <em>Balakrishnan y Koutras (2002)</em>, ofrece una buena revisión exhaustiva de los avances históricos y actuales en la teoría de la distribución de rachas y las estadísticas de escaneo.</p>
<p>Tradicionalmente, las distribuciones de rachas y patrones se estudiaban mediante análisis combinatorio. Por ejemplo, Mood (1940) escribió: <em>“El problema de la distribución es, por supuesto, combinatorio, y todo el desarrollo depende de algunas identidades del análisis combinatorio”.</em> Sin embargo, encontrar las identidades combinatorias apropiadas para derivar las distribuciones de probabilidad puede ser difícil, si no imposible, para rachas y patrones complejos, y quizá sea ésta la razón por la que las distribuciones exactas de muchos estadísticos comunes definidos en rachas y patrones siguen siendo desconocidas. Además las identidades requeridas a menudo difieren incluso para rachas y patrones similares, y por lo tanto, incluso en el caso más sencillo de ensayos independientes e idénticamente distribuidas <em>(i.i.d.)</em> de dos estados (los llamados <em>“ensayos de Bernoulli”</em>), cada nuevo problema de distribución generalmente tiene que estudiarse caso por caso utilizando el enfoque combinatorio. Por ejemplo, sólo hace relativamente poco tiempo <em>Philippou y Makri (1986) e Hirano (1986)</em>, de forma independiente y mediante análisis combinatorio, obtuvieron la distribución exacta de la estadística de racha tradicional <span class="math inline">\(\small{N_{n,k}}\)</span>, del número de rachas de <span class="math inline">\(k\)</span> éxitos consecutivos no-solapados en una secuencia de <span class="math inline">\(n\)</span> ensayos Bernoulli:</p>
<!---Ecuación 1.1--->
<div class="math">
<span class="math display">\[\begin{equation}
\mathbb{P}(N_{n,k}=x)=\sum_{m=0}^{k-1}\sum_{x_1+x_2+\cdots+\\
kx_k=n-m-km}\binom{x_1+x_2+\cdots+x_k+x}{x_1,x_2,\cdots,x_k,x}p^n\Big(\frac{q}{p}\Big)^{x_1+x_2+\cdots+x_k}
\end{equation}\]</span>
</div>
<p>para <span class="math inline">\(x=0,1,\ldots,[n/k]\)</span>, con probabilidades de éxito y fracaso denotadas por <span class="math inline">\(p\)</span> y <span class="math inline">\(q=1-p\)</span>, respectivamente. <span style="background-color:#CBEFF9;">Otro método para determinar una distribución de probabilidad exacta consiste en derivar la función generadora <span class="math inline">\(\small{\varphi(s)}\)</span> para la variable aleatoria entera no negativa <span class="math inline">\(\small{X_n(\Lambda)}\)</span> asociada con el patrón <span class="math inline">\(\small{\Lambda}\)</span> (por ejemplo, <span class="math inline">\(\small{X_n(\Lambda)}\)</span> podría ser el número de apariciones del patrón <span class="math inline">\(\small{\Lambda}\)</span> en <span class="math inline">\(n\)</span> ensayos) y, a continuación, diferenciar <span class="math inline">\(\small{\varphi(s)}\)</span> <span class="math inline">\(x\)</span> veces para obtener la función de distribución de probabilidad <em>(fdp)</em> dada por <span class="math inline">\(\small{\mathbb{P}(X_n(\Lambda) = x)}\)</span> este enfoque fue introducido por Feller (1968) utilizando la teoría de los sucesos recurrentes. Por ejemplo, para la función generadora del tiempo de espera <span class="math inline">\(\small{W(\Lambda)}\)</span>, el número de ensayos Bernoulli hasta la primera aparición del patrón <span class="math inline">\(\small{\Lambda}\)</span> consistente en <span class="math inline">\(k\)</span> éxitos consecutivos, fue dada por Feller como:</span></p>
<!---Ecuación 1.2--->
<div class="math">
<span class="math display">\[\begin{equation}
\varphi_{W}(s)=\frac{p^ks^k(1-ps)}{1-s+qp^ks^{k+1}}
\end{equation}\]</span>
</div>
<p>Para rachas y patrones más complejos, las funciones generadoras pueden ser difíciles de diferenciar un gran número de veces y es posible que sea necesario emplear técnicas de aproximación. Feller utilizó el método de expansión de fracciones parciales, que puede requerir métodos numéricos eficientes para calcular raíces de polinomios. A traves del libro estudiaremos problemas de distribución de rachas y patrones desde un punto de vista, en nuestra opinión, más unificado e intuitivo, alejado de las líneas de la combinatoria tradicional. <span style="background-color:#FAFAD9;">El enfoque adoptado consiste en incrustar adecuadamente la variable aleatoria <span class="math inline">\(\small{X_n(\Lambda)}\)</span> en una cadena de Markov finita <span class="math inline">\(\small{\{Y_t\}}\)</span>, de modo que la probabilidad de <span class="math inline">\(\small{X_n(\Lambda)}=x\)</span> pueda expresarse en términos de la probabilidad de que el estado de la cadena de Markov al momento <span class="math inline">\(\small{n}\)</span>, <span class="math inline">\(\small{Y_n}\)</span>, se encuentre en un subconjunto <span class="math inline">\(\small{C_x}\)</span> del espacio de estados, es decir:</span></p>
<!---Ecuación 1.3--->
<div class="math">
<span class="math display">\[\begin{equation}
\mathbb{P}\{X_n(\Lambda)=x\}=\mathbb{P}(Y_n \in C_x)
\end{equation}\]</span>
</div>
<p><span style="background-color:#FAFAD9;">donde la probabilidad del lado derecho se puede calcular fácilmente mediante las matrices de probabilidad de transición de la cadena de Markov.</span> Esta representación de la distribución subyacente de <span class="math inline">\(\small{X_n(\Lambda)}\)</span> es compacta, fácil de calcular y bastante susceptible de análisis posteriores. El método depende en gran medida de la capacidad de construir una cadena de Markov adecuada asociada con la variable aleatoria <span class="math inline">\(\small{X_n(\Lambda)}\)</span>, pero una vez construida la cadena, la linealidad de la cadena de Markov reduce la complejidad computacional a menudo asociada con técnicas combinatorias y de funciones generadoras para calcular los <em>fdp’s</em> exactas de rachas y patrones.</p>
<p>Los primeros resultados de la teoría de la distribución de rachas y patrones se derivaron casi exclusivamente bajo el supuesto de ensayos Bernoulli o ensayos <em>i.i.d.</em> multiestados. Una gran ventaja de la técnica de incrustación de cadenas finitas de Markov es que se puede aplicar no sólo a casos de ensayos <em>i.i.d.</em> , también para ensayos multiestado Markov-dependientes, eso si, con poco esfuerzo adicional. Independientemente de los procedimientos de conteo especificados para patrones superpuestos (conteo superpuesto versus no superpuesto); también se puede extender a varios tipos de rachas y patrones en permutaciones aleatorias. Recientemente, este método ha sido adoptado por varios investigadores para estudiar diversas distribuciones de rachas y patrones: por ejemplo, <em>Antzoulakos (1999, 2001), Boutsikas y Koutras (2000a,b), Doi y Yamamoto (1998), Fu (1985, 1986, 1996), Pu y Koutras (1994), Fu y Lou (2000a,b), Han y Aki (2000a,b), Johnson (2002), Koutras (1996a,b, 1997a,b, 2003), Koutras y Alexandrou (1995), Lou (1996, 2000, 2001) y Nishimura y Sibuya (1997)</em>. Tocaremos algunos de estos trabajos recientes, pero nuestras formulaciones correspondientes pueden diferir ligeramente para tratar todos los problemas utilizando un enfoque de incrustación común.</p>
<p>Este libro no es una revisión de la teoría de rachas y patrones, ni pretende ser utilizado principalmente como un libro de texto de curso; está dirigido principalmente a investigadores en estadística aplicada y probabilidad que estén interesados en utilizar la técnica de incrustación de cadenas finitas de Markov para estudiar las distribuciones de rachas y patrones que surgen en aplicaciones específicas. El contenido del libro se basa en gran medida en desarrollos recientes en esta área, pero se presenta de una manera que no requiere conocimiento de conceptos avanzados en matemáticas o probabilidad; Se supone que se tiene experiencia en teoría de la probabilidad, al nivel de, por ejemplo, el libro de Feller (1968) <em>“Una introducción a la teoría de la probabilidad y sus aplicaciones, Volumen I”.</em> El libro está organizado como sigue. En el <strong>Capítulo 2</strong>, presentamos las ideas y técnicas básicas de incrustación de cadenas finitas de Markov. Este capítulo sienta las bases para calcular los <em>fdp’s</em> de rachas y patrones, incluidas las distribuciones de tiempo de espera. El <strong>Capítulo 3</strong> examina las distribuciones de rachas y patrones asociados con los ensayos de dos estados, y en el <strong>Capítulo 4</strong>, se trata la extensión a los ensayos de múltiples estados a través del <em>principio de avance y retroceso</em>. El <strong>Capítulo 5</strong> estudia principalmente las distribuciones de tiempo de espera de patrones simples y compuestos, así como sus funciones generadoras y aproximaciones de grandes desviaciones. En el <strong>Capítulo 6</strong>, la técnica de incrustación de cadenas finitas de Markov se extiende al estudio de distribuciones de patrones en permutaciones aleatorias de números enteros, centrándose en detalle en los números de <em>Euler y Simon Newcomb</em>. El <strong>Capítulo 7</strong> cubre varias aplicaciones de la teoría de la distribución de rachas y patrones en las áreas de confiabilidad de sistemas de ingeniería, pruebas de hipótesis, medición de continuidad en atención médica y control de calidad.</p>
</section>
<section id="capitulo-2-incrustación-de-cadenas-de-markov-finitas" class="level3">
<h3 class="anchored" data-anchor-id="capitulo-2-incrustación-de-cadenas-de-markov-finitas">Capitulo 2: Incrustación de Cadenas de Markov Finitas</h3>
<section id="cadena-de-markov-finita" class="level4">
<h4 class="anchored" data-anchor-id="cadena-de-markov-finita">2.1 Cadena de Markov Finita</h4>
<p>Sea <span class="math inline">\(\small{\Omega=\{1,2,\ldots,m\}}\quad(m&lt;\infty)\)</span> un espacio de estados finito, y <span class="math inline">\(\small{\mathcal{Y_t}=\{Y_0,Y_1,\ldots,Y_t,\ldots\}}\)</span> una familia de variables aleatorias definidas sobre <span class="math inline">\(\small{\Omega}\)</span>.<span style="background-color:#F0F8CD;">(proceso estocástico).</span></p>
<p><strong>Definición 2.1</strong> Decimos que la familia/colección de variables aleatorias <span class="math inline">\(\small{\{\mathcal{Y_t}\}}\)</span> es cadena de Markov si, para toda sucesión <span class="math inline">\(\small{\{Y_0=i_0,Y_1=i_1,\ldots,Y_{t-1}=i_{t-1},Y_t=i_t\}},\)</span> con <span class="math inline">\(\small{t\in \{1,2,\cdots\}}\)</span>, se tiene que:</p>
<!---Ecuación 2.1--->
<div class="math">
<span class="math display">\[\begin{equation}
\mathbb{P}(Y_t=i_t \mid Y_{t-1}=i_{t-1},\ldots,Y_0=i_0)=\mathbb{P}(Y_t=i_t \mid Y_{t-1}=i_{t-1})
\end{equation}\]</span>
</div>
<p>En otras palabras, la sucesión de variables aleatorias es una cadena de Markov si la probabilidad de que el sistema entre en el estado <span class="math inline">\(\small{i_t}\)</span> en el momento <span class="math inline">\(\small{t}\)</span> depende sólo del estado inmediatamente anterior <span class="math inline">\(\small{i_{t-i}}\)</span> en el momento <span class="math inline">\(\small{t-1}\)</span>. O más sucintamente, visto desde el estado en el momento <span class="math inline">\(\small{t- 1}\)</span>, el futuro es independiente del pasado. Las probabilidades condicionales.</p>
<!---Ecuación 2.2--->
<div class="math">
<span class="math display">\[\begin{equation}
\mathbb{P}(Y_t=j \mid Y_{t-1}=i)\equiv p_{ij}
\end{equation}\]</span>
</div>
<p><span class="math inline">\(\small{i,j \in \Omega}\)</span>, se denominan probabilidades de transición de un paso para el sistema en el momento <span class="math inline">\(t\)</span>. Las probabilidades de transición <span class="math inline">\(\small{p_{ij}(t), 1 \leq i,j \leq m}\)</span>, pueden representarse como una matriz <span class="math inline">\(m\times m\)</span></p>
<!---Ecuación 2.2.1--->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{M_t}=(p_{ij(t)})=\begin{pmatrix}
p_{11}(t) &amp; p_{12}(t) &amp; \cdots &amp; p_{1m}(t)\\
p_{21}(t) &amp; p_{22}(t) &amp; \cdots &amp; p_{2m}(t)\\
\vdots &amp; \ddots &amp; \ddots &amp; \cdots\\
p_{m1}(t) &amp;p_{m2}(t) &amp; \cdots &amp; p_{mm}(t)\\
\end{pmatrix}_{m\times m}
\end{equation}\]</span>
</div>
<p>Las matrices <span class="math inline">\(\small{\boldsymbol{M_t},\,\, t=1,2,\ldots,}\)</span> son llamadas <em>matrices de probabilidades de transición de un paso</em> o simplemente <em>matrices de transición de un paso</em>.</p>
<p><strong>Proposición.</strong> La matriz de probabilidades de transición <span class="math inline">\(\small{\boldsymbol{M_t}=(p_{ij}(t))}\)</span> cumplen las siguientes propiedades, para cada tiempo <span class="math inline">\(\small{t}\)</span>:</p>
<ol type="1">
<li><span class="math inline">\(\small{(p_{ij(t)}) \geq 0}\)</span> para todo <span class="math inline">\(\small{t}\)</span>.</li>
<li><span class="math inline">\(\small{\displaystyle\sum_{j}p_{ij}=1}\)</span>, es decir, en cada momento del tiempo <span class="math inline">\(\small{t}\)</span>, el proceso cambia de estado (puede ser permanecer en el mismo estado) con probabibilidad <span class="math inline">\(\small{1}\)</span>.</li>
</ol>
<p><strong>Definición 2.2:</strong> Una cadena de Markov <span class="math inline">\(\small{\{Y_0,Y_1,\dots\}}\)</span>, es <em>homogenea</em> si las probabilidades de transición son constantes en el tiempo, <em>i.e</em> <span class="math inline">\(\small{\mathbb{P}(Y_t=j \mid Y_{t-1}=i)}=p_{ij}\)</span> para todo par <span class="math inline">\(\small{(i,j)\in \Omega \times \Omega=\Omega^2}\)</span> y todo <span class="math inline">\(\small{t=1,2,\ldots}\)</span></p>
<p>Esta definición equivale a decir que las matrices de probabilidad de transición de una cadena de Markov homogénea pueden representarse mediante la única matriz:</p>
<!-- Equación (2.2.2) -->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{M=M_t}=(p_{ij}(t)), \quad \text{para todo } t=1,2,\ldots
\end{equation}\]</span>
</div>
<p>en donde las probabilidades de transición <span class="math inline">\(\small{p_{ij}}\)</span> son independientes del índice del tiempo <span class="math inline">\(\small{t}\)</span>.</p>
<p>El conjunto de probabilidades en el momento <span class="math inline">\(\small{0}\)</span>, denotada como <span class="math inline">\(\small{\mathbb{P}(Y_0 = i)}\)</span> para <span class="math inline">\(i = 1,\ldots,m\)</span> se conoce como la <em>distribución inicial</em> de la cadena de Markov. Dada una distribución de probablidad inicial y las probabilidades de transición de una cadena de Markov, la <em>distribución conjunta</em> de la cadena se puede calcular de la siguiente manera:</p>
<!-- Equación (2.3) -->
<div class="math">
<span class="math display">\[\begin{equation}
\begin{split}
\mathbb{P}(Y_n=i_n,\ldots,Y_1=i_1,Y_0=i_0) = &amp;  \mathbb{P}(Y_n=i_n \mid Y_{n-1}=i_{n-1})\cdots \\
&amp; \cdots \mathbb{P}(Y_1=i_1 \mid Y_0=i_0)\mathbb{P}(Y_{0}=i_{0}).
\end{split}
\end{equation}\]</span>
</div>
<p>Las cadenas de Markov se han utilizado en el modelado de una gran cantidad de aplicaciones. Aquí damos dos ejemplos simples que se ven a menudo en la teoría de probabilidad aplicada:</p>
<p><strong>Ejemplo 2.1</strong> (El problema de la ruina del jugador). Considere un jugador que gana y pierde un dólar con probabilidades <span class="math inline">\(p\)</span> y <span class="math inline">\(q = 1-p\)</span>, respectivamente. Supongamos que el jugador tiene un capital inicial de <span class="math inline">\(\small{a}\)</span> dólares. El jugador deja de jugar cuando se queda sin capital (“arruinado”) o cuando alcanza una fortuna de <span class="math inline">\(\small{a + b}\)</span> dólares (con ganancia neta <span class="math inline">\(\small{b &gt; 0}\)</span>).</p>
<p>La sucesión del monto de capital del jugador, <span class="math inline">\(\small{\{Y_t: t = 0,1,2, \ldots\}}\)</span>, forma una cadena de Markov <em>homogénea</em> con espacio de estados <span class="math inline">\(\small{\Omega= \{0,1, 2, \ldots, a-1,a,a + 1,\ldots, a + b}\}\)</span> y las siguientes probabilidades de transición:</p>
<!-- Equación (2.3.1) -->
<div class="math">
<span class="math display">\[\begin{equation}
p_{ij}=\begin{cases}
p\quad \text{si } j=i+1\\
q\quad \text{si } j=i-1
\end{cases}
\end{equation}\]</span>
</div>
<p>para <span class="math inline">\(\small{i=1,2,\ldots,a+b-1,\, p_{00}=p_{a+b,a+b}=1}\)</span> y cero en cualquier otro caso. Los estados <span class="math inline">\(\small{0}\)</span> y <span class="math inline">\(\small{a+b}\)</span> se denominan <em>absorbentes</em>, ya que, una vez alcanzados nunca se sale de estos. La Cadena de Markov tine la matriz de problabilidades de transición:</p>
<!---Matriz de probabilidades de transición del problema de la ruina del jugador-->
<!-- Equación (2.3.2) -->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{M}=\begin{array}{cc} &amp;
\begin{array}{cccccccc}
\end{array}
\\
\begin{array}{ccc}
0 \\
1 \\
\vdots\\
\cdot \\
a-1 \\
a\\
a+1\\
\vdots\\
a+b
\end{array}
&amp;
\left(
\begin{array}{cccccccc}
1 &amp; 0 &amp; 0 &amp; 0 &amp;  &amp;  &amp;   &amp;   \\
q &amp; 0 &amp; p &amp; 0 &amp;  &amp;  &amp;   &amp;  \\
&amp; \ddots &amp; \ddots &amp; \ddots &amp;   &amp;   &amp;\boldsymbol{0}   &amp;  \\
&amp;  &amp;  \ddots &amp; \ddots &amp; \ddots &amp;   &amp;   &amp;   \\
&amp;  &amp;   &amp;  q &amp; 0&amp; p &amp;  &amp;   \\
&amp; \boldsymbol{0} &amp;  &amp;   &amp;   \ddots &amp; \ddots &amp; \ddots &amp; \\
&amp;  &amp;  &amp;  &amp;  &amp; q &amp; 0 &amp; p \\
&amp;  &amp;  &amp;  &amp;  &amp; 0 &amp; 0 &amp; 1 \\
\end{array}
\right)
\end{array}
\end{equation}\]</span>
</div>
<p>en donde <span class="math inline">\({\mathbf{0}}\)</span> representa un matriz de ceros y la cadena tiene distribución de probabilidad inicial <span class="math inline">\(\small{\mathbb{P}(Y_0=a)=1}\)</span>.</p>
<p><strong>Ejemplo 2.2</strong> (Modelo de Urnas). Considere una sucesión de ensayos independientes, cada uno de los cuales consiste en insertar una bola al azar en una de <span class="math inline">\(\small{k}\)</span> urnas. Decimos que el sistema <span class="math inline">\(\small{\{Y_t : t = 0,1,\ldots\}}\)</span> está en estado <span class="math inline">\(\small{i}\)</span>, si exactamente <span class="math inline">\(\small{i}\)</span> urnas están ocupadas. Este sistema forma una cadena de Markov en el espacio de estados <span class="math inline">\(\small{\Omega = \{0,1,\ldots, k\}}\)</span> con probabilidades de transición</p>
<!-- Equación (2.3.3) -->
<div class="math">
<span class="math display">\[\begin{equation}
p_{ij}=\begin{cases}
\frac{i}{k}  \quad\quad  \text{si } j=i\\
\frac{k-i}{k}\quad \text{ si } j=i+1\\
0 \quad \quad \text{en otro caso}
\end{cases}
\end{equation}\]</span>
</div>
<p>para <span class="math inline">\(\small{i=0,1,\ldots,k}\)</span> y distribución de probabilidad inicial <span class="math inline">\(\small{\mathbb{P}(Y_0=0)=1}\)</span>. La matriz de probabilidades de transición esta dada por: <!-- Equación (2.3.4) --></p>
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{M}=\begin{array}{cc} &amp;
\begin{array}{ccccccc}
\end{array}
\\
\begin{array}{ccc}
0 \\
1 \\
\\
\vdots\\
i\\
\vdots\\
k-1\\
k
\end{array}
&amp;
\left(
\begin{array}{ccccccc}
0 &amp; 1 &amp; 0 &amp;   &amp;  &amp;  &amp;     \\
0 &amp; \frac{1}{k} &amp; \frac{k-1}{k}  &amp; 0 &amp;  &amp; \boldsymbol{0} &amp;      \\
&amp;  &amp; \ddots &amp; \ddots &amp;   &amp;   &amp;      \\
&amp;  &amp;        &amp; \frac{i}{k} &amp; \frac{k-i}{k} &amp;   &amp;       \\
&amp;   &amp;   &amp;  &amp; \ddots&amp; \ddots &amp;    \\
&amp;   &amp; \boldsymbol{0} &amp;   &amp;   &amp; \frac{k-1}{k} &amp; \frac{1}{k}  \\
&amp;   &amp;  &amp;   &amp;   &amp; 0 &amp; 1
\end{array}
\right)
\end{array}
\end{equation}\]</span>
</div>
<p>Se pueden encontrar más ejemplos de este tipo en <em>Feller (1968)</em> y <em>Ross (2000)</em>. Por supuesto, también habrá muchos más ejemplos de cadenas de Markov en secciones posteriores de este libro.</p>
</section>
<section id="ecuación-de-chapman-kolmogorov" class="level4">
<h4 class="anchored" data-anchor-id="ecuación-de-chapman-kolmogorov">2.2 Ecuación de Chapman-Kolmogorov</h4>
<p>Para una cadena de Markov no homogénea <span class="math inline">\(\small{\{Y_t\}}\)</span>, las probabilidades de transición de <span class="math inline">\(\small{n}\)</span> pasos <span class="math inline">\(\small{\mathbb{P}(Y_t= j \mid Y_{t-n} = i) = p_{ij}^{(n)}(t)}\)</span> se pueden obtener a partir de las probabilidades de transición de un paso por una identidad importante conocida como <em>Ecuación de Chapman-Kolmogorov</em>. Si <span class="math inline">\(\small{n = 2}\)</span>, tenemos, para <span class="math inline">\(\small{t \geq 2}\)</span>,</p>
<!--Ecuación (2.4): Chapman Kolmogorov-->
<div class="math">
<span class="math display">\[\begin{equation}
p_{ij}^{(2)}(t) = \sum_{k\in \Omega}\mathbb{P}(Y_{t-1}=k \mid  Y_{t-2}=i)\mathbb{P}(Y_{t}=j \mid  Y_{t-1}=k)=\sum_{k\in \Omega} p_{ik}(t-1)^{}p_{kj}^{}(t)
\end{equation}\]</span>
</div>
<p>que corresponde a sumar todos los posibles <span class="math inline">\(\small{k}\)</span> estados intermedios en la transición del estado <span class="math inline">\(\small{i}\)</span> al estado <span class="math inline">\(\small{j}\)</span>.</p>
<p>Si <span class="math inline">\(\small{\{Y_t\}}\)</span> es una cadena de Markov homogénea, entonces la ecuación anterior (2.4) genera las probabilidades de transición de dos pasos <span class="math inline">\(\small{(n = 2)}\)</span></p>
<!--Ecuación (2.5): Chapman Kolmogorov HOMO-->
<div class="math">
<span class="math display">\[\begin{equation}
p_{ij}^{(2)} = \sum_{ k \in \Omega}\mathbb{P}(Y_{t-1}=k  \mid  Y_{t-2}=i)\mathbb{P}(Y_{t}=j \mid  Y_{t-1}=k)=\sum_{k\in \Omega} p_{ik}p_{kj}
\end{equation}\]</span>
</div>
<p>las cuales son independientes de <span class="math inline">\(\small{t}\)</span>. Por lo tanto, de la ecuación (2.5), la matriz de probabilidades de transición de dos pasos <span class="math inline">\(\small{\boldsymbol{M}^{(2)} = (p_{ij}^{(2)})}\)</span> satisface la identidad <span class="math inline">\(\small{\boldsymbol{M}^{(2)}= \boldsymbol{M}^2}\)</span>. De manera analoga, para las probabilidades de transición de <span class="math inline">\(\small{n}\)</span> pasos de una cadena de <em>Markov homogénea</em>, la identidad de Chapman-Kolmogorov:</p>
<!-- Ec. (2.6) Chapman- Kolmogorov n-pasos --->
<div class="math">
<span class="math display">\[\begin{equation}
p_{ij}^{(n)} = \sum_{k \in \Omega} p_{ik}^{(s)}p_{kj}^{(n-s)}
\end{equation}\]</span>
</div>
<p>se mantiene para cada paso intermedio <span class="math inline">\(\small{s = 1,\ldots, n -1}\)</span>. Se deduce de las ecuaciones. (2.5) y arterior-(2.6) que</p>
<!--Ec. (2.7) Chapman- Kolmogorov Matricial--->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{M}^{(n)}= \boldsymbol{M}^{(s)}\boldsymbol{M}^{(n-s)}=\boldsymbol{M}^{n}
\end{equation}\]</span>
</div>
<p>Para una cadena de Markov homogénea <span class="math inline">\(\small{\{Y_t\}}\)</span>, y cualquier subconjunto <span class="math inline">\(\small{{C}}\)</span> del espacio de estados <span class="math inline">\(\small{\Omega}\)</span>, se deduce de la Ec.(2.7) que la probabilidad condicional del sistema <span class="math inline">\(\small{Y_n}\)</span> resida en <span class="math inline">\(\small{{C}}\)</span> en el índice de tiempo <span class="math inline">\(\small{n}\)</span>, dada la distribución de probabilidad inicial <span class="math inline">\(\small{\boldsymbol{\mathbf{\xi}}_0 = \big(\mathbb{P}(Y_0 = 1), \cdots,P(Y_0 = m)\big)}\)</span> es:</p>
<!-- Equación (2.8) -->
<div class="math">
<span class="math display">\[\begin{equation}
\mathbb{P}(Y_n \in {C} \mid \boldsymbol{\mathbf{\xi}}_0)=\boldsymbol{\mathbf{\xi}}_0 \boldsymbol{M}^{n}\boldsymbol{\mathbf{U}'}({C})
\end{equation}\]</span>
</div>
<p>en donde <span class="math inline">\(\small{\boldsymbol{\mathbf{U}'}({C})}\)</span> es la traspuesta de <span class="math inline">\(\small{\boldsymbol{\mathbf{U}}({C})}\)</span>, con <span class="math inline">\(\small{\boldsymbol{\mathbf{U}}( {C})=\displaystyle\sum_{i \in C}e_i}\)</span> y <span class="math inline">\(\small{\boldsymbol{e}_i=(0,\ldots,1,\ldots,0)_{1\times m}}\)</span> es un vector canónico con un <span class="math inline">\(\small{1}\)</span> correspondiente al <span class="math inline">\(i\)</span>-ésimo estado y cero en los otros. De manera más general, si <span class="math inline">\(\small{\{Y_t\}}\)</span> es una cadena de Markov no homogénea, se puede demostrar (ver, <em>Feller 1968</em>) que la probabilidad condicional de <span class="math inline">\(\small{Y_n \in {C} }\)</span> dado <span class="math inline">\(\small{\boldsymbol{\xi}_0}\)</span> se puede expresar simplemente como</p>
<!-- Equación (2.9) -->
<div class="math">
<span class="math display">\[\begin{equation}
\mathbb{P}(Y_n \in  {C} \mid \boldsymbol{\mathbf{\xi}}_0)=\boldsymbol{\mathbf{\xi}}_0 \Big(\prod_{t=1}^{n}\boldsymbol{M_t}\Big)\boldsymbol{\mathbf{U}'}({C})
\end{equation}\]</span>
</div>
<p>Las ecuaciones (2.8) y (2.9) son dos herramientas indispensables para evaluar las probabilidades de diversos eventos asociados con cadenas de Markov homogéneas y no homogéneas, respectivamente.</p>
</section>
<section id="cadena-de-markov-con-estructura-de-árbol." class="level4">
<h4 class="anchored" data-anchor-id="cadena-de-markov-con-estructura-de-árbol.">2.3 Cadena de Markov con estructura de árbol.</h4>
<p>Con el fin de ampliar las posibles aplicaciones, es útil considerar una extensión simple de la metodología anterior a cadenas de Markov definidas en espacios de estados de diferentes tamaños. Sea <span class="math inline">\(\small\{Y_t\}\)</span> una sucesión de variables aleatorias definidas en una familia de espacios de estados <span class="math inline">\(\small{\{\Omega_t\}}\)</span>, respectivamente. La sucesión <span class="math inline">\(\small{\{Y_t\}}\)</span> se denomina <em>cadena de Markov con estructura de árbol</em> si <span class="math inline">\(\small{\{Y_t\}}\)</span> es una cadena de Markov con matrices de transición</p>
<!-- Equación (2.9.1) -->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{M_t}=(p_{ij}(t)), \quad \text{para todo } t=1,2,\ldots,
\end{equation}\]</span>
</div>
<p>en donde, para cada <span class="math inline">\(\small{i \in {\Omega}_{t-1}}\)</span> y <span class="math inline">\(\small{j \in {\Omega}_{t}}\)</span></p>
<!-- Equación (2.9.2) -->
<div class="math">
<span class="math display">\[\begin{equation}
p_{ij}(t)=\mathbb{P}(Y_t=j\mid Y_{t-1}=i).
\end{equation}\]</span>
</div>
<p>Obsérvese que los espacios de estados de la colección <span class="math inline">\(\small{\{\Omega_t\}}\)</span> pueden tener tamaños diferentes, las matrices de transición <span class="math inline">\(\small{\boldsymbol{M_t}}\)</span> pueden ser rectangulares en lugar de cuadradas; es decir, <span class="math inline">\(\small{\boldsymbol{M_t},\, t = 1, 2, \ldots,}\)</span> son matrices de orden <span class="math inline">\(\small{\text{card}(\Omega_{t-1}) \times \text{card}(\Omega_{t})}\)</span>, donde <span class="math inline">\(\small{\text{card}(\Omega)}\)</span> representa el número cardinal del espacio de estados <span class="math inline">\(\small{\Omega}\)</span>. La sucesión de matrices de probabilidad de transición <span class="math inline">\(\small{\{\boldsymbol{M_t}}\}\)</span> sigue determinando la cadena de Markov <span class="math inline">\(\small\{{Y_t}\}\)</span> estructurada en árbol, y la ecuación de <em>Chapman-Kolmogorov</em> sigue siendo aplicable.</p>
<p>Para cualquier subconjunto <span class="math inline">\(\small{ {C}\subseteq \Omega_n}\)</span>, la probabilidad condicional de <span class="math inline">\(\small{Y_n\in {C}}\)</span> dada la distribución de probabilidad inicial <span class="math inline">\(\small{\boldsymbol{\xi}_0}\)</span>, puede calcularse vía:</p>
<!-- Equación (2.10) -->
<div class="math">
<span class="math display">\[\begin{equation}
\mathbb{P}(Y_n \in {C} \mid \boldsymbol{\mathbf{\xi}}_0)=\boldsymbol{\mathbf{\xi}}_0 \Big(\prod_{t=1}^{n}\boldsymbol{M_t}\Big)\boldsymbol{\mathbf{U}'}_{n}({C})
\end{equation}\]</span>
</div>
<p>siendo <span class="math inline">\(\small{\boldsymbol{\mathbf{U}}_{n}({C})=\displaystyle\sum_{i \in C}\boldsymbol{e}_i}\)</span> y <span class="math inline">\(\small{\boldsymbol{e}_i=(0,\ldots,1,\ldots,0)_{1\times card(\Omega_n)}}\)</span> es un vector unitario de tamaño <span class="math inline">\(\small{1\times card(\Omega_n)}\)</span> con un <span class="math inline">\(\small{1}\)</span> asociado al <span class="math inline">\(i\)</span>-ésimo estado. Si todo los espacios de estados son iguales <span class="math inline">\(\small{(\Omega_1=\cdots=\Omega_n)}\)</span>,entonces la <em>Eq. (2.10)</em> se reduce a <em>Eq. (2.9)</em>.</p>
</section>
<section id="rachas-y-patrones" class="level4">
<h4 class="anchored" data-anchor-id="rachas-y-patrones">2.4 Rachas y Patrones</h4>
<p>Tradicionalmente, dentro de una sucesión de ensayos Bernoulli (i.i.d. éxito-fracaso), una <em>racha</em> denota una sucesión de éxitos o fracasos consecutivos. Por ejemplo una racha de éxitos de tamaño 4 implica el patrón <span class="math inline">\(\small{SSSS}\)</span>. Varias de las estadísticas de <em>rachas</em> que se utilizan a menudo en estadística y probabilidad aplicada para una sucesión de <span class="math inline">\(n\)</span> ensayos Bernoulli son:</p>
<p><em>(i)</em> <span class="math inline">\(\small{N_{n,k}}\)</span> el número rachas de <span class="math inline">\(\small{k}\)</span> éxitos consecutivos no solapados, en el sentido del conteo de Feller (1968);</p>
<p><em>(ii)</em> <span class="math inline">\(\small{M_{n,k}}\)</span> el número de rachas de <span class="math inline">\(\small{k}\)</span> éxitos consecutivos solapados;</p>
<p><em>(iii)</em> <span class="math inline">\(\small{E_{n,k}}\)</span> el número de rachas de éxitos de tamaño exactamente igual a <span class="math inline">\(\small{k}\)</span>, en el sentido del conteo de <em>Mood (1940)</em>;</p>
<p><em>(iv)</em> <span class="math inline">\(\small{G_{n,k}}\)</span> el número de rachas de éxitos de tamaño mayor o igual que <span class="math inline">\(\small{k}\)</span> ;</p>
<p><em>(v)</em> <span class="math inline">\(\small{L_{n}(S)}\)</span> el tamaño de la racha de éxitos más larga.</p>
<p>Quizás la forma más sencilla de comprender las definiciones dadas de estas estadísticas de rachas y el procedimiento de conteo de solapado/no solapado, sea mediante el siguiente ejemplo. Supongamos que hay <span class="math inline">\(\small{n = 10}\)</span> ensayos de Bernoulli, con realización <span class="math inline">\(\small{SSFSSSSFFF}\)</span>. Entonces <span class="math inline">\(\small{L_{10}(S) = 4}\)</span>, y para <span class="math inline">\(\small{k = 2}\)</span>, tenemos <span class="math inline">\(\small{N_{10,2} = 3, M_{10,2} = 4, E_{10,2} = 1}\)</span> y <span class="math inline">\(\small{G_{10,2} = 2}\)</span></p>
<p>De las definiciones de estas estadísticas de rachas, se deduce por inspección que las siguientes relaciones siempre son verdaderas:</p>
<!-- Equación (2.10.1) -->
<div class="math">
<span class="math display">\[\begin{equation}
E_{n,k}\leq G_{n,k} \leq N_{n,k} \leq M_{n,k}\\
E_{n,k} = G_{n,k} - G_{n,k+1}\\
L_n(S)&lt;k\quad\text{si y solo si }N_{n,k}=0
\end{equation}\]</span>
</div>
<p><span style="background-color:#FBF9C9;">Para ampliar las definiciones de rachas, consideremos una sucesión de <span class="math inline">\(\small{n}\)</span> ensayos multiestados <span class="math inline">\(\small{\{{X}\}_{t=1}^{n}}\)</span>, cada una de las cuales tiene <span class="math inline">\(\small{m \geq 2}\)</span> estados o símbolos como posibles resultados. Estos símbolos se denotan por <span class="math inline">\(\small{b_1,b_2,\ldots,b_m}\)</span> y ocurren con probabilidades <span class="math inline">\(\small{p_1,p_2,\ldots,p_m}\)</span>, respectivamente. A continuación, definimos tres tipos de patrones generales: un <em>patrón simple</em>, un <em>patrón compuesto</em> y un <em>patrón en serie</em>.</span></p>
<p><span style="background-color:#FEFF5B;"><strong>Definición 2.3</strong> Decimos que <span class="math inline">\(\small{\Lambda}\)</span> es un <em>patron simple</em>, si esta conformado por una determinada serie de <span class="math inline">\(\small{k}\)</span> símbolos, <em>i.e</em>, <span class="math inline">\(\small{\Lambda=b_{i_1}b_{i_2}\cdots b_{i_k}}\)</span> con <span class="math inline">\(\small{i_j\in \{1,2,\ldots,m\}}\)</span>, para todo <span class="math inline">\(\small{j=1,\dots,k}\)</span>. La longitud del patrón es fija y los símbolos en el patrón puede repetirse.</span></p>
<p>Las rachas de éxito y fracaso de tamaño <span class="math inline">\(\small{k}\)</span> son por tanto patrones simples según esta definición, y de hecho cualquier sucesión de éxitos y fracasos de longitud fija, digamos <span class="math inline">\(\small{\Lambda =SSFSF}\)</span>, puede considerarse un patrón simple dentro de una sucesión de de <span class="math inline">\(\small{n}\)</span> ensayos de dos estados <span class="math inline">\(\small{(m = 2)}\)</span>.</p>
<p>Ahora, sean <span class="math inline">\(\small{\Lambda_1}\)</span> y <span class="math inline">\(\small{\Lambda_2}\)</span> dos patrones simples de longitudes/tamaños <span class="math inline">\(\small{k_1}\)</span> y <span class="math inline">\(\small{k_2}\)</span> , respectivamente. Decimos que <span class="math inline">\(\small{\Lambda_1}\)</span> y <span class="math inline">\(\small{\Lambda_2}\)</span> son <em>distintos</em> si ni <span class="math inline">\(\small{\Lambda_1}\)</span> incluye a <span class="math inline">\(\small{\Lambda_2}\)</span> ni <span class="math inline">\(\small{\Lambda_2}\)</span> incluye a <span class="math inline">\(\small{\Lambda_1}\)</span>. Definimos <span class="math inline">\(\small{\Lambda_1 \cup\Lambda_2}\)</span> como la ocurrencia de uno de los dos patrón <span class="math inline">\(\small{\Lambda_1}\)</span> o <span class="math inline">\(\small{\Lambda_2}\)</span> , y definimos <span class="math inline">\(\small{\Lambda_1 \ast\Lambda_2}\)</span> como la ocurrencia de patrón <span class="math inline">\(\small{\Lambda_1}\)</span> seguido del patrón <span class="math inline">\(\small{\Lambda_1}\)</span> (quizás con una separación entre ellos).</p>
<p><strong>Definición 2.4</strong> Decimos que <span class="math inline">\(\small{\Lambda}\)</span> es un <em>patrón compuesto</em> si es la unión de <span class="math inline">\(\small{1 &lt; l &lt;\infty}\)</span> patrones simples distintos solapados/no solapados, es decir, <span class="math inline">\(\small{\Lambda=\displaystyle\bigcup_{i=1}^{l}\Lambda_i}\)</span>.</p>
<p><strong>Definición 2.5</strong> Decimos <span class="math inline">\(\small{\Lambda}\)</span> es un <em>patrón en serie</em> si <span class="math inline">\(\small{\Lambda}\)</span> está compuesto por una sucesión ordenada de <span class="math inline">\(\small{1 &lt; l &lt;\infty}\)</span> patrones simples distintos no superpuestos <span class="math inline">\(\small{\Lambda_i}\)</span>, es decir, <span class="math inline">\(\small{\Lambda=\Lambda_1 \ast\Lambda_2\ast\cdots\Lambda_l}\)</span></p>
<p><span style="background-color:#B7F7E9;">A lo largo de este libro, la variable aleatoria <span class="math inline">\(\small{X_n(\Lambda)}\)</span> representa el número de ocurrencias del patrón <span class="math inline">\(\small{\Lambda}\)</span> en una sucesión de <span class="math inline">\(\small{n}\)</span> ensayos multiestado, utilizando el recuento con solapamiento o sin solapamiento</span>. Para aclarar las tres definiciones de patrones y los dos métodos de recuento para los ensayos multiestado, presentamos el siguiente ejemplo.</p>
<p><strong>Ejemplo 2.3</strong> Sea <span class="math inline">\(\small{\{X_t\}_{t=1}^{16}}\)</span> una sucesión de dieciséis ensayos de un proceso de cuatro estados, en donde los resultados posibles para cada ensayo son <span class="math inline">\(\small{A, G, C}\)</span> y <span class="math inline">\(\small{T}\)</span>. Sea <span class="math inline">\(\small{\Lambda_1=AGAG}\)</span> y <span class="math inline">\(\small{\Lambda_2=AGT}\)</span> dos patrones simples distintos, <span class="math inline">\(\small{\Lambda=\Lambda_1 \cup\Lambda_2}\)</span> un patrón compuesto y <span class="math inline">\(\small{\Lambda^{\ast}=\Lambda_1 \ast\Lambda_2}\)</span> un <em>patron en serie</em>. Supongamos que la realización de esta sucesión de dieciséis ensayos es <span class="math inline">\(\small{TAGAGAGTCAGAGTCC}\)</span>, entonces:</p>
<p><em>(i)</em> <span class="math inline">\(\small{X_{16}(\Lambda_1)}\)</span> es <span class="math inline">\(\small{3}\)</span> con <em>conteo solapado</em> y es <span class="math inline">\(\small{2}\)</span> con <em>conteo no solapado</em>,</p>
<p><em>(ii)</em> <span class="math inline">\(\small{X_{16}(\Lambda)}\)</span> es <span class="math inline">\(\small{5}\)</span> con <em>conteo solapado</em> y es <span class="math inline">\(\small{3}\)</span> con <em>conteo no solapado</em>,</p>
<p><em>(iii)</em> <span class="math inline">\(\small{X_{16}(\Lambda^{\ast})}\)</span> es igual a <span class="math inline">\(\small{1}\)</span>.</p>
<p><em>(iv)</em> <span class="math inline">\(\small{X_{16}(\Lambda_2)}\)</span> es <span class="math inline">\(\small{2}\)</span>.</p>
<p>Las definiciones anteriores de rachas y patrones en una sucesión de ensayos de múltiples estados también se pueden extender a <em>permutaciones aleatorias</em> <span class="math inline">\(\small{\{\pi : \pi=(\pi (1),\ldots,\pi(n)) \}}\)</span> de <span class="math inline">\(\small{n}\)</span> enteros <span class="math inline">\(\small{\{1, 2, \ldots, n\}}\)</span>. Por ejemplo, el número Euleriano <span class="math inline">\(\small{E(\pi, n)}\)</span>, el número de aumentos en una permutación aleatoria <span class="math inline">\(\small{\pi}\)</span> (ver Carlitz 1964, Tanny 1973 y Worpitzky 1883), podría verse como una variable aleatoria <span class="math inline">\(\small{X_n(\Lambda)}\)</span> con el patrón <span class="math inline">\(\small{\Lambda}\)</span> siendo un aumento. Matemáticamente, el número de Euler se puede definir como</p>
<!-- Equación (2.10.2) -->
<div class="math">
<span class="math display">\[\begin{equation}
E(\pi,n)=X_n(\Lambda)=\displaystyle \sum_{i=0}^{n-1}I(\pi,i),
\end{equation}\]</span>
</div>
<p>en donde <!-- Equación (2.10.3) --></p>
<div class="math">
<span class="math display">\[\begin{equation}
I(\pi,i)=\begin{cases}
1 \quad \text{si }\pi(i)&lt;\pi(i+1) \\
0 \quad \text{en otro caso }
\end{cases}
\end{equation}\]</span>
</div>
<p><span class="math display">\[I(\pi,i)=\begin{cases}
1 \quad \text{si }\pi(i)&lt;\pi(i+1) \\
0 \quad \text{en otro caso,}
\end{cases}\]</span></p>
<p>para <span class="math inline">\(\small{i=1,\ldots,n-1}\)</span>, con <span class="math inline">\(\small{I(\pi,i)=1}\)</span> por convención (la <em>brecha</em> inicial que precede a la primera permutación siempre se considera un aumento). Por ejemplo, el número de aumentos <span class="math inline">\(\small{E(\pi, 9)}\)</span> en la permutación aleatoria <span class="math inline">\(\small{\pi = (321459768)}\)</span> de 9 números enteros son 5.</p>
<p>En vista de las definiciones y ejemplos anteriores, uno debería esperar que la distribución exacta de la variable aleatoria <span class="math inline">\(\small{X_n(\Lambda)}\)</span> dependa en gran medida de tres factores importantes:</p>
<p><span style="background-color:#CCFFCC;">(a) la estructura del patrón <span class="math inline">\(\small{\Lambda}\)</span> ,</span></p>
<p><span style="background-color:#FFFFCC;"> (b) la estructura de la sucesión <span class="math inline">\(\small{\{{X}\}_{t=1}^{n}}\)</span> de <span class="math inline">\(n\)</span> ensayos (o permutaciones aleatorias),</span></p>
<p> <span style="background-color:#E8EAF6;">(c) el procedimiento de conteo (conteo superpuesto o no superpuesto).</span></p>
<p>Debido a estos factores, la determinación analítica de distribuciones exactas mediante enfoques tradicionales como la combinatoria puede ser bastante desafiante y generalmente compleja, involucrando identidades especiales y un álgebra extensa. En consecuencia, las distribuciones exactas de muchas estadísticas utilizadas en aplicaciones prácticas nunca se han estudiado utilizando tales métodos, especialmente cuando los ensayos subyacentes no son <em>i.i.d.</em> (por ejemplo, Markov-dependientes).</p>
<p><span style="background-color:#EFDCFB;">En la siguiente subsección, describimos una técnica que permite obtener una representación matricial compacta para la distribución exacta de una manera relativamente simple y universal al incorporar la variable aleatoria <span class="math inline">\(\small{X_n(\Lambda)}\)</span> en una cadena de Markov finita; la expresión resultante también es muy adecuada para un análisis más detallado de propiedades estadísticas, para el desarrollo de aproximaciones de grandes desviaciones y para una implementación numérica eficiente para el cálculo de probabilidades exactas.</span></p>
</section>
<section id="incrustación-de-cadenas-de-markov-finitas" class="level4">
<h4 class="anchored" data-anchor-id="incrustación-de-cadenas-de-markov-finitas">2.5 Incrustación de Cadenas de Markov Finitas</h4>
<p>La técnica de Incrustación de Cadenas de Markov Finitas (ICMF) para encontrar la distribución de la variable aleatoria <span class="math inline">\(\small{X_n(\Lambda)}\)</span> tiene sus orígenes en una serie de artículos de <em>Fu (1985, 1986)</em>, <em>Fu</em> y <em>Hu (1987)</em>, <em>Chao</em> y <em>Fu (1989, 1991)</em>, y <em>Fu</em> y <em>Lou (1991)</em>. El término <em>“Cadena de Markov Finita Incrustable”</em> para describir una variable aleatoria fue introducido formalmente por <em>Fu y Koutras (1994)</em>.</p>
<p>Sea <span class="math inline">\(\small{\Gamma_n=\{0,1\ldots,n\}}\)</span> un conjunto de indices, y <span class="math inline">\(\small{\Omega=\{a_1,a_2,\ldots,a_m\}}\)</span> un espacio de estados finito.</p>
<p><strong>Definicion 2.6</strong> La variable aleatoria no negativa de valores enteros <span class="math inline">\(\small{X_n(\Lambda)}\)</span>, es una <em>cadena de Markov finita incrustable</em> si:</p>
<p>(a). Existe una cadena de Markov finita <span class="math inline">\(\small{\{Y_t:t\in \Gamma\}}\)</span> definida sobre un espacio de estados <span class="math inline">\(\small{\Omega}\)</span> finito, con vector de probabilidades inicial <span class="math inline">\(\small{\boldsymbol{\xi}_0}\)</span>.</p>
<p>(b). Existe una partición finita <span class="math inline">\(\small{\{C_x:x=0,1,\ldots,l_n\}}\)</span> sobre el espacio de estado <span class="math inline">\(\small{\Omega}\)</span>.</p>
<p>(c). Para todo <span class="math inline">\(\small{x=0,1,\ldots,l_m}\)</span> tenemos: <span class="math display">\[\small{\mathbb{P}\{X_n(\Lambda)=x\}=\mathbb{P}\{Y_n\in C_x \mid \boldsymbol{\xi}_0\}.}\]</span> Sea <span class="math inline">\(\small{\{\boldsymbol{M}_t\}_{t=1}^{n}}\)</span> una sucesión de matrices de probabilidades de transición de orden <span class="math inline">\(\small{m\times m}\)</span> de una cadena finita de Markov <span class="math inline">\(\small{\{Y_t\}}\)</span> definida sobre un espacio de estados <span class="math inline">\(\small{\Omega}\)</span> con distribución de probablidad inicial <span class="math inline">\(\small{\boldsymbol{\xi}_0=\big(\mathbb{P}\{Y_0=a_1\},\mathbb{P}\{Y_0=a_2\},\ldots,\mathbb{P}\{Y_0=a_m\}\big)}\)</span></p>
<p><strong>Teorema 2.1</strong> Si <span class="math inline">\(\small{X_n(\Lambda)}\)</span> es una <em>cadena finita de Markov incrustable</em>, entoces</p>
<!-- Equación (2.11) -->
<div class="math">
<span class="math display">\[\begin{equation}
\mathbb{P}\{ X_n(\Lambda)=x\}=\boldsymbol{\mathbf{\xi}}_0 \Big(\prod_{t=1}^{n}\boldsymbol{M}_t\Big)\boldsymbol{\mathbf{U}'}({C_x})
\end{equation}\]</span>
</div>
<p>siendo <span class="math inline">\(\small{\boldsymbol{\mathbf{U}}({C_x})=\displaystyle\sum_{r: a_r\in C_x}\boldsymbol{e}_r}\)</span> y <span class="math inline">\(\small{\boldsymbol{e}_r=(0,\ldots,1,\ldots,0)_{1\times m}}\)</span> es un vector unitario de tamaño <span class="math inline">\(\small{1\times m}\)</span> con un <span class="math inline">\(\small{1}\)</span> asociado al estado <span class="math inline">\(\small{a_r}\)</span> e <span class="math inline">\(\small{\boldsymbol{\mathbf{\xi}}_0}\)</span> vector de probabilidades iniciales, y <span class="math inline">\(\small{\boldsymbol{M}_t\,,\,\,t=1,\dots,n}\)</span> son las matrices de probabilidades de transición de la cadena de Markov incrustada.</p>
<p><strong>Prueba:</strong> Dado que <span class="math inline">\(\small{X_n(\Lambda)}\)</span> es una cadena de Markov finita incrustable, se deduce de <em>Definición 2.6(a)</em> de que existe una cadena de Markov finita <span class="math inline">\(\small{\{Y_t : t\in \Gamma_n \}}\)</span> con probabilidades iniciales <span class="math inline">\(\small{\boldsymbol{\mathbf{\xi}}_0}\)</span>. Luego por la <em>ecuación de Chapman-Kolmogorov</em> descrita en Sección 2.2, para cada <span class="math inline">\(\small{a_r\in \Omega}\)</span>, tenemos</p>
<!-- Equación (2.11.1)-->
<div class="math">
<span class="math display">\[\begin{equation}
\mathbb{P}(Y_n =a_r \mid \boldsymbol{\mathbf{\xi}}_0)=\boldsymbol{\mathbf{\xi}}_0 \Big(\prod_{t=1}^{n}\boldsymbol{M}_t\Big)\boldsymbol{e_r'}
\end{equation}\]</span>
</div>
<p>Además, de las Definiciones <em>2.6(b)</em> y <em>(c)</em> se deduce que, para cada <span class="math inline">\(\small{x =0,1\ldots,l_n}\)</span>,</p>
<!-- Equación (2.11.2)-->
<div class="math">
<span class="math display">\[\begin{equation}
\begin{split}
\mathbb{P}\{ X_n(\Lambda)=x\} &amp; =  \mathbb{P}(Y_n \in C_x \mid \boldsymbol{\mathbf{\xi}}_0) \\
&amp; = \sum_{a_r\in C_x}\mathbb{P}\{Y_n=a_r\mid \boldsymbol{\mathbf{\xi}_0}\}\\
&amp; = \sum_{a_r\in C_x} \boldsymbol{\mathbf{\xi}}_0 \Big(\prod_{t=1}^{n}\boldsymbol{M}_t\Big)\boldsymbol{e_r'}\\
&amp; = \boldsymbol{\mathbf{\xi}}_0 \Big(\prod_{t=1}^{n}\boldsymbol{M}_t\Big)\boldsymbol{\mathbf{U}'}( {C_x})\quad \quad \quad \quad \quad \Box
\end{split}
\end{equation} \Box\]</span>
</div>
<p>El <span class="math inline">\(\small{k-}ésimo\)</span> momento <span class="math inline">\(\small{\mathbb{E}\{X_n^k(\Lambda)\},\,\,k=1,2,\ldots,}\)</span> puede expresarse como:</p>
<!-- Equaciín 2.12-->
<div class="math">
<span class="math display">\[\begin{equation}
\mathbb{E}\{X_n^k(\Lambda)\}=\boldsymbol{\mathbf{\xi}}_0 \Big(\prod_{t=1}^{n}\boldsymbol{M}_t\Big)\boldsymbol{{V}_k'}
\end{equation}\]</span>
</div>
<p>en donde</p>
<!-- Equación (2.12.1)-->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{{V}_k'}=\sum_{x=0}^{l_n}x^{k}\boldsymbol{U}(\mathbf{C_x})
\end{equation}\]</span>
</div>
<p>De manera ánaloga la <em>función generadora de probabilidad</em> de la variable aleatoria <span class="math inline">\(\small{X_n(\Lambda)}\)</span> puede escribirse como:</p>
<!-- Equación 2.13-->
<div class="math">
<span class="math display">\[\begin{equation}
\psi(s)= \boldsymbol{\mathbf{\xi}}_0 \Big(\prod_{t=1}^{n}\boldsymbol{M}_t\Big)\boldsymbol{W'}(s)
\end{equation}\]</span>
</div>
<p>en donde <!-- Equación (2.13.1)--></p>
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{W}(s)=\sum_{x=0}^{l_n}s^{x}\boldsymbol{U}(\mathbf{C_x})
\end{equation}\]</span>
</div>
<p>Los funciones generadoras de probabilidad y de momentos se discutirán dentro del contexto de aplicaciones específicas en secciones posteriores.</p>
<p><strong>Ejemplo 2.4</strong> (Número de parejas de resultados sucesivos idénticos). Sea <span class="math inline">\(\small{\{X_t:t = 0,1,\ldots, n\}}\)</span> una sucesión de <span class="math inline">\(\small{n}\)</span> ensayos Markov-dependientes homogéneos con <span class="math inline">\(\small{m}\)</span> estados y matriz de probabilidad de transición <span class="math inline">\(\small{\boldsymbol{A}_{m\times m} = \big(P_{ij}\big)}\)</span> y una distribución de probabilidad inicial <span class="math inline">\(\small{\boldsymbol{\xi}_0=\big(\mathbb{P}\{X_0=1\},\mathbb{P}\{X_0=2\},\ldots,\mathbb{P}\{X_0=m\}\big)=(1/m,1/m,\ldots,1/m)}\)</span>. Definiendo una sucesión de funciones indicadoras</p>
<!-- Equación (2.13.2)-->
<div class="math">
<span class="math display">\[\begin{equation}
I_i=\begin{cases}
1 \quad \text{si }X_t=X_{t-1}\\
0 \quad \text{en otro caso}
\end{cases}
\end{equation}\]</span>
</div>
<p>para todo <span class="math inline">\(\small{t=1,\ldots,n}\)</span></p>
<p>En este ejemplo, nos interesa el número de veces que un resultado particular (uno de <span class="math inline">\(\small{m}\)</span> resultados posibles) en un ensayo determinado se repite en el ensayo inmediatamente siguiente. En términos matemáticos, definimos el patrón <span class="math inline">\(\small{\Lambda}\)</span> para denotar dicho resultado repetido, un patrón que está presente en el índice de tiempo <span class="math inline">\(\small{1 \leq t \leq n}\)</span> si <span class="math inline">\(\small{X_{t-1} = X_t}\)</span> o, de manera equivalente en términos de la función indicadora anterior, si <span class="math inline">\(\small{I_t = 1}\)</span>. La estadística de rachas:</p>
<!-- Equación (2.13.3)-->
<div class="math">
<span class="math display">\[\begin{equation}
X_n(\Lambda)= \sum_{t=1}^{n}I_t
\end{equation}\]</span>
</div>
<p>corresponde al número de veces que ocurrió el patrón <span class="math inline">\(\small{\Lambda}\)</span> en la sucesión <span class="math inline">\(\small{\{X\}_{t=0}^{n}}\)</span> de <span class="math inline">\(\small{n}\)</span> ensayos Markov-dependientes con <span class="math inline">\(\small{m}\)</span> estados. En el sector sanitario, por ejemplo, la estadística <span class="math inline">\(\small{X_n(\Lambda)/n}\)</span> se conoce como <span class="math inline">\(SECON\)</span> y forma la medida principal de continuidad secuencial en una serie de <span class="math inline">\(\small{n}\)</span> visitas de pacientes a <span class="math inline">\(\small{m}\)</span> posibles proveedores de atención sanitaria ( <em>Steinwachs 1979</em>).</p>
<p>Una dificultad aquí es que las variables aleatorias <span class="math inline">\(\small{\{I_t\}}\)</span> no son independientes y no conforman una cadena de Markov, incluso si la sucesión <span class="math inline">\(\small{\{X\}_{t=0}^{n}}\)</span> se extrajera de ensayos <em>i.i.d.</em> de <span class="math inline">\(\small{m}\)</span> estados. De hecho, se puede demostrar que las variables aleatorias <span class="math inline">\(\small{\{I_t\}}\)</span> son dependientes y están correlacionadas positivamente probando que <span class="math inline">\(\small{Cov(I_i, I_j) &gt; 0}\)</span> para todo <span class="math inline">\(\small{i}\)</span> y <span class="math inline">\(\small{j}\)</span>, con <span class="math inline">\(\small{Cov(I_i, I_j) \rightarrow 0}\)</span> cuando <span class="math inline">\(\small{\mid i-j \mid\rightarrow 0}\)</span>. Sin embargo, como se indica a continuación, la distribución exacta aún se puede obtener fácilmente utilizando la técnica de incrustación de cadenas de Markov finitas.</p>
<p>Primero, descomponemos la matriz de probabilidad de transición <span class="math inline">\(\small{\boldsymbol{A}}\)</span> en dos matrices <span class="math inline">\(\small{\boldsymbol{G}}\)</span> y <span class="math inline">\(\small{\boldsymbol{D}}\)</span>, donde la matriz <span class="math inline">\(\small{\boldsymbol{D}}\)</span> contiene sólo los elementos diagonales de <span class="math inline">\(\small{\boldsymbol{A}}\)</span>; es decir:</p>
<!-- Equación (2.13.4)-->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{A}_{m\times m}=\boldsymbol{G}_{m\times m}+\boldsymbol{D}_{m\times m}
\end{equation}\]</span>
</div>
<p>en donde: <!-- Equación (2.13.5)--></p>
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{G}_{m\times m}=
\begin{pmatrix}
0 &amp; p_{ij} &amp; \cdots \\
  &amp; \ddots &amp;        \\
\cdots &amp; p_{ij} &amp; 0
\end{pmatrix}
\quad \text{y} \quad

\boldsymbol{D}_{m\times m}=
\begin{pmatrix}
p_{11} &amp;  &amp; \boldsymbol{0} \\
  &amp; \ddots &amp;        \\
\boldsymbol{0} &amp;   &amp; p_{mm}
\end{pmatrix}
\end{equation}\]</span>
</div>
<p>Sea <span class="math inline">\(\small{\Omega=\{(u,v): u = 0,\ldots,n, \text{ y }v = 1,2,\ldots, m\}}\)</span> el espacio de estados que contiene un total de <span class="math inline">\(\small{(n+1)m}\)</span> estados. Dado <span class="math inline">\(\small{n}\)</span>, se define una cadena de Markov homogénea y finita <span class="math inline">\(\small{\{Y_t: t\in \Gamma\}}\)</span> en el espacio de estados <span class="math inline">\(\small{\Omega}\)</span> como</p>
<!-- Equación (2.13.6)-->
<div class="math">
<span class="math display">\[\begin{equation}
Y_t=\begin{cases}
\Big(\displaystyle\sum_{i=1}^{t}I_i, X_t \Big) \quad \text{si } 1 \leq t \leq n\\
\big(0,X_0\big) \quad t=0
\end{cases}
\end{equation}\]</span>
</div>
<p>con matriz de probabilidades de transición:</p>
<!-- Equación (2.13.7)-->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{M}=\begin{pmatrix}
\boldsymbol{G} &amp; \boldsymbol{D} &amp; \boldsymbol{O} &amp; \cdots &amp; \boldsymbol{O}\\
\boldsymbol{O} &amp; \boldsymbol{G} &amp; \boldsymbol{D} &amp; \cdots &amp; \boldsymbol{O} \\
\vdots &amp; \ddots &amp; \ddots &amp; \ddots &amp; \vdots \\
\boldsymbol{O} &amp; \cdots &amp; \cdots &amp; \boldsymbol{G}&amp; \boldsymbol{D}\\
\boldsymbol{O} &amp; \boldsymbol{O} &amp; \cdots &amp; \boldsymbol{O}&amp; \boldsymbol{I}\\
\end{pmatrix}
\end{equation}\]</span>
</div>
<p>donde <span class="math inline">\(\small{\boldsymbol{M}}\)</span> es una matriz <span class="math inline">\(\small{(n + 1)m \times (n + 1)m}\)</span>, <span class="math inline">\(\small{\boldsymbol{O}}\)</span> representa la matriz cero <span class="math inline">\(\small{m\times m}\)</span> e <span class="math inline">\(\small{\boldsymbol{I}}\)</span> es la matriz identidad <span class="math inline">\(\small{m\times m}\)</span>. Los estados en <span class="math inline">\(\small{\boldsymbol{M}}\)</span> están ordenados en orden lexicográfico (diccionario). Por último, defininiendo la partición <span class="math inline">\(\small{\{C_x: x=0,1,2,\ldots,n\}}\)</span> en el espacio de estados <span class="math inline">\(\small{\boldsymbol{\Omega}}\)</span> como</p>
<!-- Equación (2.13.8)-->
<div class="math">
<span class="math display">\[\begin{equation}
C_x=\{(x,v): v=1,2,\ldots,m\}
\end{equation}\]</span>
</div>
<p>Dadas las definiciones anteriores para la cadena de Markov <span class="math inline">\(\small\{Y_t\}\)</span>, la variable aleatoria <span class="math inline">\(\small{X_n(\Lambda)}\)</span> es, según la Definición 2.6, una cadena de Markov finita incrustable y su distribución exacta se desprende del <em>Teorema 2.1</em>: para <span class="math inline">\(\small{0 \leq x \leq n}\)</span>,</p>
<!--Equación 2.14-->
<div class="math">
<span class="math display">\[\begin{equation}
\mathbb{P}\{X_n(\Lambda)=x\}=\boldsymbol{\xi_0}\begin{pmatrix}
\boldsymbol{G} &amp; \boldsymbol{D} &amp; \boldsymbol{O} &amp; \cdots &amp; \boldsymbol{O}\\
\boldsymbol{O} &amp; \boldsymbol{G} &amp; \boldsymbol{D} &amp; \cdots &amp; \boldsymbol{O} \\
\vdots &amp; \ddots &amp; \ddots &amp; \ddots &amp; \vdots \\
\boldsymbol{O} &amp; \cdots &amp; \cdots &amp; \boldsymbol{G}&amp; \boldsymbol{D}\\
\boldsymbol{O} &amp; \boldsymbol{O} &amp; \cdots &amp; \boldsymbol{O}&amp; \boldsymbol{I}\\
\end{pmatrix}^{n}\boldsymbol{U'}(C_x)
\end{equation}\]</span>
</div>
<p>donde <span class="math inline">\(\small{\boldsymbol{\xi_0}(\pi_0,0,\ldots,0)_{(n+1)\times m}}\)</span> es la distribución inicial del vector de estado <span class="math inline">\(\small{Y_0}\)</span>, y <span class="math inline">\(\small{\boldsymbol{U'}(C_x): (0,\ldots, 0, \underbrace{1, 1, ..., 1}_{C_x}, 0,\ldots,0)}\)</span> es un vector de fila <span class="math inline">\(\small{1 \times(n+1)m}\)</span> con <span class="math inline">\(\small{1}\)</span> en las coordenadas asociadas con los estados en <span class="math inline">\(\small{C_x}\)</span> y cero en otros posiciones. En el <em>Capítulo 7</em> se darán más detalles y un ejemplo numérico de este problema.</p>
<p><em>Koutras y Alexandrou (1995)</em> introdujeron la noción de variables incrustables en cadenas finitas de Markov de tipo binomial <em>(MVBS)</em>, y muchas estadísticas comunes para rachas y patrones caen en esta categoría especial. Sea la partición <span class="math inline">\(\small{ \{C_x\}=\{[(x, v): v=1,...,r], \text{ para } x = 0, 1,\ldots, l_n\}}\)</span>, la partición del espacio de estados <span class="math inline">\(\small{\Omega}\)</span>.</p>
<p><strong>Definición 2.7</strong> Una variable aleatoria <span class="math inline">\(\small{X_n(\Lambda)}\)</span> es una cadena de Markov finita incrustable de tipo binomial si:</p>
<p><em>(i)</em> <span class="math inline">\(\small{X_n(\Lambda)}\)</span> es una cadena de Markov finita incrustable como en la <em>Definición 2.6</em>.</p>
<p><em>(ii)</em> <span class="math inline">\(\small{\mathbb{P}\{Y_t=(y,j) \mid Y_{t-1} =(x,i)\} \equiv 0}\)</span> para todo <span class="math inline">\(\small{y\neq x}\)</span> o <span class="math inline">\(\small{x + 1}\)</span>.</p>
<p>Para cualquier <span class="math inline">\(\small{MVB}\)</span>, introduzca dos matrices de probabilidad de transición <span class="math inline">\(\small{r\times r}\)</span>:</p>
<!-- Equación (2.14.1)-->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{A_t}(x) = \big(a_{ij}(t)\big) = \Big(\mathbb{P}\{Y_t = (x,j)\mid Y_{t−1} = (x, i)\}\Big)
\end{equation}\]</span>
</div>
<p>y <!-- Equación (2.14.2)--></p>
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{B_t}(x) = \big(b_{ij}(t)\big) = \Big(\mathbb{P}\{Y_t = (x+1,j)\mid Y_{t−1} = (x, i)\}\Big)
\end{equation}\]</span>
</div>
<p>Por tanto las matrices de probabilidad de transición <span class="math inline">\(\small{\boldsymbol{M_t}}\)</span> de la cadena de Markov incrustada tienen la siguiente forma: <!-- Equación (2.15)--></p>
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{M}=\begin{pmatrix}

\boldsymbol{A}_t(0) &amp; \boldsymbol{B}_t(0) &amp; \boldsymbol{O} &amp; \cdots &amp;\cdots  &amp; \boldsymbol{O} \\

\boldsymbol{O} &amp;\boldsymbol{A}_t(1) &amp; \boldsymbol{B}_t(1)  &amp; \boldsymbol{O} &amp; \cdots  &amp; \boldsymbol{O}\\

\vdots &amp; \boldsymbol{O} &amp; \ddots &amp; \ddots &amp; \ddots &amp; \vdots \\
\vdots &amp; \ddots &amp; \boldsymbol{O}&amp; \ddots &amp; \ddots &amp; \boldsymbol{O} \\
\vdots &amp; \cdots &amp; \cdots &amp; \boldsymbol{O}&amp; \boldsymbol{A}_t(l_n-1) &amp; \boldsymbol{B}_t(l_n-1) \\
\boldsymbol{O} &amp; \boldsymbol{O} &amp; \cdots &amp;  \boldsymbol{O}&amp; \boldsymbol{O} &amp;  \boldsymbol{A}_t(l_n) \\
\end{pmatrix}
\end{equation}\]</span>
</div>
<p>para <span class="math inline">\(\small{t = 1,\ldots,n}\)</span>, en donde los estados están ordenados en orden lexicográfico (diccionario). Hay muchas estadísticas para rachas y patrones con matrices de transición que tienen esta forma, como, por ejemplo, las estadísticas de rachas <span class="math inline">\(\small{N_{n,k},\, M_{n,k}\, \text{y}\, G_{n,k}}\)</span> introducidas en la <em>Sección 2.4</em> (y estudiadas más a fondo en el Capítulo 3).</p>
<p>Para <span class="math inline">\(\small{MVB´s}\)</span>, se puede derivar una ecuación recursiva eficiente para la distribución de <span class="math inline">\(\small{X_n(\Lambda)}\)</span>, que aprovecha parcialmente la estructura de bandas de las matrices de probabilidad de transición <span class="math inline">\(\small{\boldsymbol{M}_t}\)</span>. Sea el vector fila <span class="math inline">\(\small{\boldsymbol{\alpha}_t(x)=\big(\mathbb{P}\{Y_t=(x,1)\},\ldots, \mathbb{P}\{Y_t=(x,1)\}\big)}\)</span> , para <span class="math inline">\(\small{t= 1,\ldots, n}\)</span>, de modo que la probabilidad de <span class="math inline">\(\small{X_n(\Lambda)=x}\)</span> se puede representar como</p>
<!-- Equación 2.16-->
<div class="math">
<span class="math display">\[\begin{equation}
\mathbb{P}\{X_n(\Lambda)=x \mid \boldsymbol{\xi}_0\}=
\boldsymbol{\alpha}_n(x)\boldsymbol{1}', \, \text{para toda}\,\,
x=0,1,\dots,l_n
\end{equation}\]</span>
</div>
<p>donde <span class="math inline">\(\small{\boldsymbol{1}'=(1,\ldots,1)'}\)</span>. Descomponga <span class="math inline">\(\small{\boldsymbol{M}_t}\)</span> como <span class="math inline">\(\small{\boldsymbol{M}_t=\boldsymbol{K}_t+\boldsymbol{H}_t}\)</span>, donde <span class="math inline">\(\small{\boldsymbol{K}_t}\)</span> es una matriz diagonal con componentes <span class="math inline">\(\small{\boldsymbol{A}_t(x)}\)</span>, para <span class="math inline">\(\small{x = 0,1,\ldots,l_n}\)</span>, y <span class="math inline">\(\small{\boldsymbol{H}_t}\)</span> es una matriz diagonal superior con componentes <span class="math inline">\(\small{\boldsymbol{B}_t(x)}\)</span>, para <span class="math inline">\(\small{x = 0,1,\ldots,l_{n-1}}\)</span>. A partir de la multiplicación hacia atrás, <span class="math inline">\(\small{\boldsymbol{\mathbf{\xi}}_0 \Big(\displaystyle\prod_{j=1}^{t}\boldsymbol{M}_j\Big)=\boldsymbol{\mathbf{\xi}}_0 \Big(\displaystyle\prod_{j=1}^{t-1}\boldsymbol{M}_j\Big)\boldsymbol{M}_t=\boldsymbol{\mathbf{\xi}}_0 \Big(\displaystyle\prod_{j=1}^{t-1}\boldsymbol{M}_j\Big)\big(\boldsymbol{K}_t+\boldsymbol{H}_t\big)}\)</span>, puede demostrarse que se cumplen las siguientes ecuaciones recursivas:</p>
<!--Equación 2.17--->
<div class="math">
<span class="math display">\[\begin{align*}
\boldsymbol{\alpha_t}(0)&amp;=\boldsymbol{\alpha_{t-1}}(0)\boldsymbol{A_t}(0) \\
\boldsymbol{\alpha_t}(X)&amp;=
\boldsymbol{\alpha_{t-1}}(x-1)\boldsymbol{B_{t-1}}(t-1)+\boldsymbol{\alpha_{t-1}}(x)\boldsymbol{A_t}(x),\, x=1,\ldots,l_n.
\end{align*}\]</span>
</div>
<p>La <em>ecuación (2.17)</em> proporciona un algoritmo eficiente para calcular las probabilidades <span class="math inline">\(\small{ \mathbb{P}\{X_n(\Lambda)=x \mid\boldsymbol{\xi}_0\}=\boldsymbol{\alpha}_n(x)\boldsymbol{1}', \, \text{para toda }\, x=0,1,\dots,l_n}\)</span>, y esto es especialmente importante cuando la dimensión de las matrices de transición <span class="math inline">\(\small{\boldsymbol{M_t}}\)</span> es grande y el esfuerzo computacional para calcular ingenuamente <span class="math inline">\(\small{\boldsymbol{\mathbf{\xi}}_0 \Big(\displaystyle\prod_{t=1}^{n}\boldsymbol{M}_t\Big)\boldsymbol{U'}(C_x)}\)</span> se vuelve prohibitivo. A partir de la multiplicación hacia atrás, la técnica de incrustación de cadenas finitas de Markov a menudo proporciona una ecuación recursiva en una forma similar a la <em>ecuación (2.17)</em>, una forma que, en general, no puede obtenerse tan fácilmente mediante los métodos combinatorios o de renovación tradicionales.</p>
</section>
<section id="estados-absorbentes" class="level4">
<h4 class="anchored" data-anchor-id="estados-absorbentes">2.6 Estados Absorbentes</h4>
<p>En esta sección se derivan algunas expresiones útiles para la probabilidad de entrar en un estado absorbente. Para mayor claridad de la exposición, nos centraremos en las cadenas de Markov homogéneas, pero las ideas pueden generalizarse fácilmente a casos no homogéneos.</p>
<p>Un estado <span class="math inline">\(\small{\alpha \in \Omega}\)</span> se llama estado absorbente si, una vez que el sistema entra en el estado <span class="math inline">\(\small{\alpha}\)</span>, nunca sale; es decir, <span class="math inline">\(\small{p_{\alpha\alpha}\equiv 1}\)</span> (y <span class="math inline">\(\small{p_{\alpha\beta}\equiv 0}\)</span> para cualquier <span class="math inline">\(\small{\alpha\neq\beta}\)</span>). Sea <span class="math inline">\(\small{A=\{\alpha_1,\ldots,\alpha_k\}}\)</span> el conjunto de todos los estados absorbentes de una cadena de Markov homogénea <span class="math inline">\(\small{\{Y_t\}}\)</span> con una matriz de probabilidad de transición <span class="math inline">\(\small{\boldsymbol{M}}\)</span>. Bajo una disposición apropiada del espacio de estados, la matriz de probabilidad de transición <span class="math inline">\(\small{\boldsymbol{M}}\)</span> siempre se puede escribir de la siguiente forma:</p>
<!---Ecuación. (2.18) --->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{M}=\left(\begin{array}{c|c}
\boldsymbol{N}_{(m-k)\times (m-k)} &amp; \boldsymbol{C}_{(m-k)\times (m-k)}\\
\hline  
\boldsymbol{O}_{k\times (m-k)} &amp; \boldsymbol{1}_{k \times k}
\end{array}\right)
\end{equation}\]</span>
</div>
<p>donde <span class="math inline">\(\small{m}\)</span> y <span class="math inline">\(\small{k}\)</span> <span class="math inline">\(\small{(m&gt;k)}\)</span> son los números de estados en <span class="math inline">\(\small{\Omega}\)</span> y <span class="math inline">\(\small{A}\)</span>, respectivamente. La matriz <span class="math inline">\(\small{\boldsymbol{N}}\)</span> definida por la ecuación. (2.18) se conoce como la <em>submatriz de probabilidad de transición esencial de la cadena de Markov</em>. Desempeña un papel importante en el estudio de las distribuciones exactas de <em>variables aleatorias incrustables en cadenas de Markov</em>, especialmente para las distribuciones asociadas de tiempos de espera.</p>
<p>Sea <span class="math inline">\(\small{\boldsymbol{\xi_{0}}=\big(\boldsymbol{\xi}:\boldsymbol{0}\big)_{1\times m}}\)</span> la distribución inicial, donde <span class="math inline">\(\small{\boldsymbol{\xi}=(\xi_1,\ldots,\xi_{m-k}), \, \boldsymbol{0}=(0,\ldots,0)_{1\times k}}\)</span> y <span class="math inline">\(\small{\displaystyle{\sum_{i=1}^{m-k}\xi_i=1}}\)</span> y sea <span class="math inline">\(\small{\big(\boldsymbol{1:0}\big)_{1\times m}}\)</span> un vector fila, en donde <span class="math inline">\(\small{\boldsymbol{1}=(1,\ldots,1)_{1\times (m-k)}}\)</span> La razón por la que suponemos que la distribución inicial tiene la forma <span class="math inline">\(\small{\big(\boldsymbol{\xi_0}:\boldsymbol{0}\big)}\)</span> es estrictamente por razones prácticas, ya que la mayoría de los sistemas siempre comienzan en un estado no absorbente.</p>
<p><strong>Teorema 2.2</strong> Dada una matriz de probabilidad de transición <span class="math inline">\(\small{\boldsymbol{M}}\)</span> de una cadena de Markov homogénea <span class="math inline">\(\small{\{Y_t\}}\)</span> en la forma de la <em>ecuación (2.18)</em>, la probabilidad para el índice de tiempo <span class="math inline">\(\small{n}\)</span> cuando el sistema ingresa por primera vez al conjunto de estados absorbentes puede ser obtenida como:</p>
<!--Equación 2.19 -->
<div class="math">
<span class="math display">\[\begin{equation}
\mathbb{P}\big(Y_n\in A,Y_{n-1}\notin A,\ldots,  Y_1\notin A \mid \boldsymbol{\xi_0}\big)=\boldsymbol{\xi N}^{n-1}\boldsymbol{(I-N)1'}
\end{equation}\]</span>
</div>
<p><strong>Demostración:</strong> Dado que <span class="math inline">\(\small{\boldsymbol{M}}\)</span> tiene la forma de la <em>Equación 2.18</em>, se sigue que:</p>
<!--Equación 2.20 -->
<div class="math">
<span class="math display">\[\begin{equation}
\mathbf{M}^{n-1}=\left(\begin{array}{c|c}
\boldsymbol{N}^{n-1} &amp; \boldsymbol{K}_{n-1}\\
\hline  
\boldsymbol{O} &amp; \boldsymbol{I}
\end{array}\right)
\end{equation}\]</span>
</div>
<p>en donde <span class="math inline">\(\small{\boldsymbol{K}_{n-1}=\big( \boldsymbol{I}+\boldsymbol{N}+\cdots+\boldsymbol{N}^{n-2}\big)\boldsymbol{C}}\)</span>. Además, como todos los estados en <span class="math inline">\(\small{\boldsymbol{A}}\)</span> son estados absorbentes, de la ecuación de Chapman-Kolmogorov se deduce que:</p>
<!---Ecuación 2.21--->
<div class="math">
<span class="math display">\[\begin{align*}
\mathbb{P}\big(Y_{n-1}\notin A,\cdots,  Y_1\notin A \mid \boldsymbol{\xi_0}\big) &amp; =\mathbb{P}\big(Y_{n-1}\in \Omega-A\mid \boldsymbol{\xi_0}\big)\\
&amp; =\big(\boldsymbol{\xi_0}:\boldsymbol{0}\big) \boldsymbol{ M}^{n-1}\big(\boldsymbol{1}:\boldsymbol{0}\big)'.
\end{align*}\]</span>
</div>
<p>Luego la ecuación (2.19) puede entonces deducirse utilizando las ecuaciones (2.20) y (2.21) a traves de:</p>
<!---Ecuación (2.20) y (2.21) --->
<div class="math">
<span class="math display">\[\begin{align*}
&amp; \quad \, \, \mathbb{P}\big(Y_n\in A,Y_{n-1}\notin A,\ldots,  Y_1\notin A \mid \boldsymbol{\xi_0}\big)\\
&amp; =\mathbb{P}\big(Y_{n-1}\notin A,\ldots,  Y_1\notin A \mid \boldsymbol{\xi_0}\big)-\mathbb{P}\big(Y_n\notin A,Y_{n-1}\notin A,\ldots,  Y_1\notin A \mid \boldsymbol{\xi_0}\big)\\
&amp; = \big(\boldsymbol{\xi_0}:\boldsymbol{0}\big) \boldsymbol{ M}^{n-1}\big(\boldsymbol{I-M}\big)\big(\boldsymbol{1}:\boldsymbol{0}\big)' \\
&amp; =\boldsymbol{\xi N}^{n-1}\boldsymbol{(I-N)1'}.\hspace{8cm} \Box
\end{align*}\]</span>
</div>
<p>En vista de las <em>Ecs. (2.20) y (2.21)</em>, los siguientes teoremas son inmediatos.</p>
<p><strong>Teorema 2.3</strong> Para todo estado <span class="math inline">\(\small{i\in \Omega-A}\)</span></p>
<!--Equación 2.22-->
<div class="math">
<span class="math display">\[\begin{align*}
\mathbb{P}\big(Y_{n-1}=i,Y_{n-2}\notin A,\ldots,  Y_1\notin A \mid \boldsymbol{\xi_0}\big)= \boldsymbol{\xi N}^{n-1}\boldsymbol{e_i'}.
\end{align*}\]</span>
</div>
<p><strong>Prueba</strong>. Utilizando los mismos argumentos que en la demostración del <em>Teorema 2.2</em> y reemplazando <span class="math inline">\(\small{\boldsymbol{1'}}\)</span> por <span class="math inline">\(\small{\boldsymbol{e_i'}}\)</span>, la <em>Ec. (2.22)</em> se sigue directamente de las ecuaciones <em>(2.20) y (2.21)</em>. <span class="math inline">\(\hspace{1cm} \Box\)</span></p>
<p><strong>Teorema 2.4</strong> Para cualquier estado absorbente <span class="math inline">\(\small{j \in A}\)</span>, la probabilidad del sistema para llegar por primera vez al estado absorbente <span class="math inline">\(\small{j}\)</span> en el <span class="math inline">\(\small{n}-\)</span>ésimo ensayo es:</p>
<!--Equación 2.23-->
<div class="math">
<span class="math display">\[\begin{align*}
\mathbb{P}\big(Y_{n}=j,Y_{n-1}\notin A,\ldots,  Y_1\notin A \mid \boldsymbol{\xi_0}\big)= \boldsymbol{\xi N}^{n-1}{C_j'}.
\end{align*}\]</span>
</div>
<p>en donde, <span class="math inline">\(\small{C_j'}\)</span> es la <span class="math inline">\(\small{j}-\)</span>ésima columna de la matriz <span class="math inline">\(\small{\boldsymbol{C}}\)</span>.</p>
<p><strong>Prueba:</strong> Para cualquier <span class="math inline">\(\small{j \in A}\)</span>, de la definición de la cadena de Markov y del <em>Teorema 2.3</em> se deduce que:</p>
<!--Prueba teorema 2.4-->
<div class="math">
<span class="math display">\[\begin{align*}
&amp; \quad \, \mathbb{P}\big(Y_{n-1}=j,Y_{n-1}\notin A,\ldots,  Y_1\notin A \mid \boldsymbol{\xi_0}\big)\\
&amp; = \sum_{i\in \Omega-A}\mathbb{P}\big(Y_{n-1}=i,Y_{n-2}\notin A,\ldots,  Y_1\notin A \mid \boldsymbol{\xi_0}\big)\times \mathbb{P}\big( Y_n=j\mid Y_{n-1}=i \big)\\
&amp;= \sum_{i\in \Omega-A}\boldsymbol{\xi N}^{n-1}{e_i'}p_{ij}\\
&amp;= \boldsymbol{\xi N}^{n-1}\sum_{i\in \Omega-A}{e_i'}p_{ij}\\
&amp;= \boldsymbol{\xi N}^{n-1}{C_j'}\hspace{8cm}
\end{align*}\]</span>
</div>
<p>Para ilustrar los <em>teoremas 2.2</em> a <em>2.4</em> y sus relaciones, proporcionamos el siguiente ejemplo sencillo.</p>
<p><strong>Ejemplo 2.5</strong> Sea <span class="math inline">\(\small{\{Y_t\}}\)</span> una cadena de Markov homogénea definida en el espacio de estados <span class="math inline">\(\small{\{1, 2, 3, 4\}}\)</span> con distribución inicial <span class="math inline">\(\small{\boldsymbol{\xi_0}=\big(\xi : 0 \big)=(1,0:0,0)}\)</span> y matriz de probabilidad de transición</p>
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{M}=\begin{array}{cccc}&amp;
\begin{array}{cccc}
\end{array}
\\
\begin{array}{ccc}
1 \\
2 \\
3\\
4\\
\end{array}
&amp;
\left(
\begin{array}{cc|cc}
1/2 &amp; 1/4 &amp; 1/4  &amp;  0 \\
1/3 &amp; 1/3 &amp; 0 &amp;  1/3 \\
\hline
0&amp; 0  &amp;  1 &amp; 0 \\
0&amp;  0 &amp; 0 &amp;  1
\end{array}
\right)
\end{array}
\end{equation}\]</span>
</div>
<p>en donde <span class="math inline">\(\small{A=\{3,4\}}\)</span> es el conjunto de estados absorbentes. Para <span class="math inline">\(\small{n = 3}\)</span> (tercer ensayo), las probabilidades de entrada del sistema en los estados absorbentes <span class="math inline">\(\small{3}\)</span> y <span class="math inline">\(\small{4}\)</span> son, respectivamente:</p>
<!--Ejemplo 2.5.3-->
<div class="math">
<span class="math display">\[\begin{equation}
\mathbb{P}\big(Y_{3}=3,Y_{2}\notin A,Y_1\notin A \mid \boldsymbol{\xi_0}\big)=(0,1)
\left(\begin{array}{cc}
1/2 &amp; 1/4\\
1/3 &amp; 1/3\\
\end{array} \right)^{2}
\left(\begin{array}{c}
1/4\\
0\\
\end{array} \right)=\frac{1}{12}
\end{equation}\]</span>
</div>
<p>y <!--Ejemplo 2.5.3--></p>
<div class="math">
<span class="math display">\[\begin{equation}
\mathbb{P}\big(Y_{3}=4,Y_{2}\notin A,Y_1\notin A \mid \boldsymbol{\xi_0}\big)=(0,1)
\left(\begin{array}{cc}
1/2 &amp; 1/4\\
1/3 &amp; 1/3\\
\end{array} \right)^{2}
\left(\begin{array}{c}
0\\
1/3\\
\end{array} \right)=\frac{5}{72}.
\end{equation}\]</span>
</div>
<p>Además, por el <em>Teorema 2.2</em>, la probabilidad de que el sistema entre por primera vez en el subconjunto <span class="math inline">\(\small{A=\{3,4\}}\)</span> en el tercer ensayo es</p>
<!--Ejemplo 2.5.4-->
<div class="math">
<span class="math display">\[\begin{align*}
&amp; \quad \,\, \mathbb{P}\{Y_3\in A,Y_{2}\notin A,Y_1\notin A \mid \boldsymbol{\xi_0}\}\\
&amp;=\boldsymbol{\xi N}^{3-1}\boldsymbol{(I-N)1'}\\
&amp;=(0,1)
\left(\begin{array}{cc}
1/2 &amp; 1/4\\
1/3 &amp; 1/3\\
\end{array} \right)^{2}
\left[
\left(\begin{array}{cc}
1 &amp; 0\\
0 &amp; 1\\
\end{array} \right)-
\left(\begin{array}{cc}
1/2 &amp; 1/4\\
1/3 &amp; 1/3\\
\end{array} \right)
\right]
\left(\begin{array}{c}
1\\
1\\
\end{array} \right)\\
&amp; =\frac{11}{72}
\end{align*}\]</span>
</div>
<p>Como verificación de los resultados anteriores, observemos que:</p>
<!--Ejemplo 2.5.5-->
<div class="math">
<span class="math display">\[\begin{align*}
\mathbb{P}\big(Y_3\in A,Y_{2}\notin A,Y_1\notin A \mid \boldsymbol{\xi_0}\big)&amp; =
\mathbb{P}\big(Y_3= 3,Y_{2}\notin A,Y_1\notin A \mid \boldsymbol{\xi_0} \big)\\
&amp;+ \mathbb{P}\big(Y_3= 4,Y_{2}\notin A,Y_1\notin A \mid \boldsymbol{\xi_0}\\
&amp;= \frac{11}{72} \hspace{5cm}\Diamond
\end{align*}\]</span>
</div>
<p>De forma más general, puesto que para cada <span class="math inline">\(\small{i\in \Omega-A}\)</span></p>
<div class="math">
<span class="math display">\[\begin{align*}
\sum_{j\in A}p_{ij}= 1- \sum_{j \in \Omega- A}p_{il}
\end{align*}\]</span>
</div>
<p>luego se deduce que <span class="math inline">\(\small{\displaystyle\sum_{j\in A}C_j'=\boldsymbol{(I-N)1'}}\)</span>, y por tanto</p>
<!--Ecuación 2.24-->
<div class="math">
<span class="math display">\[\begin{align*}
\sum_{j\in A}\boldsymbol{\xi N}^{n-1}C_j'=\boldsymbol{\xi N}^{n-1}\boldsymbol{(I-N)1'}
\end{align*}\]</span>
</div>
</section>
<section id="probabilidad-de-entrada-inicial-probabilidades-de-primera-visita" class="level4">
<h4 class="anchored" data-anchor-id="probabilidad-de-entrada-inicial-probabilidades-de-primera-visita">2.7 Probabilidad de entrada inicial // Probabilidades de primera visita**</h4>
<p>Utilizando las ideas de la <em>sección 2.6</em>, podemos encontrar la probabilidad de que se produzca la primera entrada para cualquier subconjunto <span class="math inline">\(\small{B\subset \Omega}\)</span>. Dado el subconjunto <span class="math inline">\(\small{B}\)</span>, la matriz de probabilidad de transición <span class="math inline">\(\small{\boldsymbol{M}}\)</span> de una cadena de Markov <span class="math inline">\(\small{\{Y_t\}}\)</span> homogénea siempre puede disponerse de la siguiente forma:</p>
<!--Ecuación 2.25-->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{M}=
\begin{array}{cc}
{\Omega-B} \\B \end{array}
\left(\begin{array}{c|c}
\boldsymbol{N} &amp; \boldsymbol{B}\\
\hline
\boldsymbol{J} &amp;  \boldsymbol{Q}
\end{array}
\right)
\end{equation}\]</span>
</div>
<p><strong>Teorema 2.5</strong> Sea <span class="math inline">\(\small{\{Y_t\}}\)</span> una cadena de Markov homogénea con matriz de probabilidad de transición <span class="math inline">\(\small{\boldsymbol{M}}\)</span>, en la forma de la <em>ecuación (2.25)</em>, y con distribución inicial <span class="math inline">\(\small{\boldsymbol{\xi=(1:0)}}\)</span>. Entonces, para un subconjunto <span class="math inline">\(\small{B}\)</span> de tamaño <span class="math inline">\(\small{k}\)</span> contenido en el espacio de estados <span class="math inline">\(\small{\Omega}\)</span> de tamaño <span class="math inline">\(\small{m}\)</span>, se cumplen las siguientes relaciones:</p>
<p><em>(i)</em> Para todo <span class="math inline">\(\small{j \in B}\)</span></p>
<!--Ecuación 2.26-->
<div class="math">
<span class="math display">\[\begin{equation}
\mathbb{P}\big(Y_n =j,Y_{n-1}\notin B,\cdots,Y_1\notin B \mid \boldsymbol{\xi_0}\big)=\boldsymbol{\xi N}^{n-1}\boldsymbol{B_j'},
\end{equation}\]</span>
</div>
<p>en donde <span class="math inline">\(\small{B_j'}\)</span> es la <span class="math inline">\(\small{j}-\)</span>ésima columna de la matriz <span class="math inline">\(\small{\boldsymbol{B}_{(m-k)\times k}}\)</span> y</p>
<p><em>(ii)</em></p>
<div class="math">
<!--Ecuación 2.27-->
<span class="math display">\[\begin{align*}
&amp; \quad \,\, \mathbb{P}\big(Y_n \in B,Y_{n-1}\notin B,\cdots,Y_1\notin B \mid \boldsymbol{\xi_0}\big)\\
&amp;=\boldsymbol{\xi N}^{n-1}\boldsymbol{(I-N)1'}\\
&amp;=\sum_{j\in B}\boldsymbol{\xi N}^{n-1}{B'}_j,
\end{align*}\]</span>
</div>
<p><strong>Prueba.</strong> Defina una nueva cadena de Markov <span class="math inline">\(\small{\{Z_t\}}\)</span> en el espacio de estados <span class="math inline">\(\small{\Omega}\)</span>, donde <span class="math inline">\(\small{\{Z_t\}}\)</span> es igual a <span class="math inline">\(\small{\{Y_t\}}\)</span>para todos los estados <span class="math inline">\(\small{i \in \Omega-B}\)</span> y donde todos los estados <span class="math inline">\(\small{j \in B}\)</span> se toman como estados absorbentes. Entonces la matriz de probabilidad de transición <span class="math inline">\(\small{\boldsymbol{M^{\star}}}\)</span> para la cadena de Markov <span class="math inline">\(\small{\{Z_t\}}\)</span> tiene la forma</p>
<!--Ecuación/Prueba-teorema 2.5.1-->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{M}^{\star}=\big(p_{ij}^{\ast}\big)=
\left(\begin{array}{c|c}
\boldsymbol{N} &amp; \boldsymbol{B}   \\
\hline
\boldsymbol{O} &amp;  \boldsymbol{I}
\end{array}
\right).
\end{equation}\]</span>
</div>
<p>Dado que, para cada <span class="math inline">\(\small{n}\)</span> <!--Ecuación/Prueba-teorema 2.5.2--></p>
<div class="math">
<span class="math display">\[\begin{equation}
\mathbb{P}\big(Y_n =j,Y_{n-1} \notin B,\cdots, Y_1\notin B,Y_1\notin B \mid \boldsymbol{\xi_0}\big)=\mathbb{P}\big(Z_n =j,Z_{n-1} \notin B,\cdots, Y_1\notin B,Z_1\notin B \mid \boldsymbol{\xi_0}\big),
\end{equation}\]</span>
</div>
<p>El resultado <em>(i)</em> se desprende del <em>teorema 2.4.</em> De manera similar, el <em>resultado (ii)</em> se sigue inmediatamente a partir de <em>(i)</em> y el hecho de que <span class="math inline">\(\small{\boldsymbol{(I-N)1'}=\displaystyle\sum_{j\in B}{B'}_j}\)</span>. <span class="math inline">\(\hspace{1cm}\Box\)</span></p>
<p>La prueba anterior está guiada por el hecho de que todos los estados en <span class="math inline">\(\small{B}\)</span> son estados absorbentes con respecto a la nueva cadena de Markov <span class="math inline">\(\small{\{Z_t\}}\)</span> y, por lo tanto, por ejemplo, para cada <span class="math inline">\(\small{i \in \Omega-B}\)</span>, la probabilidad <span class="math inline">\(\small{\mathbb{P}(Z_{n-1}=i)}\)</span> se puede dividir en dos partes de la siguiente manera:</p>
<!--Ecuación/Prueba-teorema 2.5.3-->
<div class="math">
<span class="math display">\[\begin{align*}
\mathbb{P}\big(Z_{n-1} = i \mid \boldsymbol{\xi_0}\big) &amp; =
\mathbb{P}\big(Z_{n-1} =i, Z_{n-2} \notin B,\cdots, Z_1\notin B \mid \boldsymbol{\xi_0}\big)\\
&amp; + \mathbb{P}\big(Z_{n-1} =i \text{ y por lo menos uno de } Z_{n-2},\cdots ,Z_1 \text{ esta dentro de } B \mid \boldsymbol{\xi_0}\big)
\end{align*}\]</span>
</div>
<p>en donde la segunda parte es siempre cero (ya que <span class="math inline">\(\small{i \in \Omega-B}\)</span> y <span class="math inline">\(\small{p_{ij}^{\ast}\equiv 0}\)</span> para todos <span class="math inline">\(\small{j \in B}\)</span>). Tenga en cuenta que, en el <em>teorema 2.5</em>, asumimos la distribución inicial <span class="math inline">\(\small{(\boldsymbol{\xi:0})}\)</span>), lo que equivale a decir <span class="math inline">\(\small{\mathbb{P}\big(Y_0\in B\big)\equiv 1}\)</span>. En consecuencia, la probabilidad <span class="math inline">\(\small{\mathbb{P}\big(Y_n \in B,Y_{n-1}\notin B,\cdots,Y_1 \notin B \mid \boldsymbol{\xi_0}\big)}\)</span> se conoce como probabilidad de primera entrada.</p>
<p><strong>Ejemplo 2.6</strong> Sea <span class="math inline">\(\small{\{Y_t\}}\)</span> una cadena de Markov homogénea definida en el espacio de estados <span class="math inline">\(\small{\Omega=\{1,2,3,4,5\}}\)</span> con matriz de probabilidad de transición</p>
<!--Ecuación/Ejemplo 2.6.1-->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{M}=
\begin{array}{ccccc}&amp;
\begin{array}{ccccc}
\end{array}
\\
\begin{array}{ccccc}
1 \\
2 \\
3\\
4\\
5
\end{array}
&amp;
\left(
\begin{array}{ccccc}
1/2 &amp; 1/4 &amp; 1/4  &amp; 0 &amp;  0 \\
1/4 &amp; 1/2  &amp; 0  &amp;  1/4 &amp; 0 \\
1/4 &amp; 1/4  &amp;  0 &amp; 0 &amp; 1/2 \\
0&amp;  0 &amp; 0 &amp;  1 &amp;0 \\
0&amp;  0 &amp; 0 &amp;  0 &amp; 1 \\
\end{array}
\right)
\end{array}
\end{equation}\]</span>
</div>
<p>Supongamos que <span class="math inline">\(\small{B = \{3, 4\}}\)</span>, entonces la matriz de probabilidad de transición de <span class="math inline">\(\small{B = \{Y_t\}}\)</span> se puede reorganizar como:</p>
<!--Ecuación/Ejemplo 2.6.2-->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{M}=
\begin{array}{ccccc}&amp;
\begin{array}{ccccc}
\end{array}
\\
\begin{array}{ccccc}
1 \\
2 \\
3\\
4\\
5
\end{array}
&amp;
\left(
\begin{array}{ccc|cc}
1/2 &amp; 1/4 &amp; 0  &amp; 1/4 &amp;  0 \\
1/4 &amp; 1/2  &amp; 0  &amp;  0 &amp; 1/4 \\
0 &amp; 0 &amp;  1 &amp; 0 &amp; 0 \\
\hline
1/4 &amp;  1/4 &amp; 1/2 &amp;  0 &amp; 0 \\
0&amp;  0 &amp; 0 &amp;  0 &amp; 1 \\
\end{array}
\right)
\end{array}
\end{equation}\]</span>
</div>
<p>Dada una distribución inicial de <span class="math inline">\(\small{Y_0}\)</span>, digamos <span class="math inline">\(\small{\mathbb{P}(Y_0=1)=1}\)</span>, la probabilidad de primera entrada para <span class="math inline">\(\small{Y_n=3}\)</span>, es</p>
<!--Ecuación/Ejemplo 2.6.3-->
<div class="math">
<span class="math display">\[\begin{align*}
&amp; \quad \,\mathbb{P}\big(Y_n =3,Y_{n-1} \notin B,\cdots,Y_1\notin B \mid Y_0 = 1\big)
\\
&amp; =(0,0,1)
\left(\begin{array}{ccc}
1/2 &amp; 1/4 &amp; 0\\
1/4 &amp; 1/2 &amp; 0\\
0 &amp; 0 &amp; 1
\end{array} \right)^{n-1}
\left(\begin{array}{c}
1/4\\
0\\
0
\end{array} \right)\\
\end{align*}\]</span>
</div>
<p>Para <span class="math inline">\(\small{n = 3}\)</span>, obtenemos que <span class="math inline">\(\small{\mathbb{P}\big(Y_n =3,Y_{3} \notin B,Y_1\notin B \mid Y_0 = 1\big)=5/64}\)</span>. Tenga en cuenta que dado que el estado “<span class="math inline">\(\small{5}\)</span>” es un estado absorbente, los cálculos se pueden reducir aún más a:</p>
<!--Ecuación/Ejemplo 2.6.4-->
<div class="math">
<span class="math display">\[\begin{equation}
\mathbb{P}\big(Y_n =3,Y_{n-1} \notin B,\cdots,Y_1\notin B \mid Y_0 = 1\big)=(1,0)
\left(\begin{array}{ccc}
1/2 &amp; 1/4 \\
1/4 &amp; 1/2
\end{array} \right)^{n-1}
\left(\begin{array}{c}
1/4\\
0
\end{array} \right) \hspace{5cm}\Diamond
  \end{equation}\]</span>
</div>
<p>Sea <span class="math inline">\(\small{A}\)</span> el conjunto que contenga todos los estados absorbentes de <span class="math inline">\(\small{\{Y_t\}}\)</span> y sea <span class="math inline">\(\small{B^{\ast}= A \cup B}\)</span>. La matriz de probabilidad de transición <span class="math inline">\(\small{\boldsymbol{M^{*}}}\)</span> , correspondiente a la cadena de Markov asociada <span class="math inline">\(\small{\{Z_t\}}\)</span> en la que todos los estados en <span class="math inline">\(\small{B^{\ast}}\)</span> se toman como estados absorbentes, puede entonces reordenarse como:</p>
<!--Ecuación/Ejemplo 2.6.5-->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{M^{\ast}}=
\begin{array}{cc}
{\Omega-B^{\ast}} \\B^{\ast} \end{array}
\left(\begin{array}{c|c}
\boldsymbol{N^{\ast}} &amp; \boldsymbol{B^{\ast}}\\
\hline
\boldsymbol{J} &amp;  \boldsymbol{Q}
\end{array}
\right)
\end{equation}\]</span>
</div>
<p>en donde <span class="math inline">\(\small{\boldsymbol{N^{*}}}\)</span> es la submatriz esencial de <span class="math inline">\(\small{\boldsymbol{M^{*}}}\)</span>, y <span class="math inline">\(\small{\boldsymbol{B^{*}}}\)</span> es la matriz formada a partir de <span class="math inline">\(\small{\boldsymbol{M^{*}}}\)</span> mediante la eliminación de todas las columnas asociadas con los estados en <span class="math inline">\(\small{\Omega-B^{*}}\)</span> y de todas las filas asociadas con los estados en <span class="math inline">\(\small{B^{*}}\)</span>. Entonces se cumple el siguiente corolario.</p>
<p><strong>Colorario:</strong> Para todo <span class="math inline">\(\small{j\in B}\)</span></p>
<!--Ecuación 2.28--->
<div class="math">
<span class="math display">\[\begin{equation}
\mathbb{P}\big(Y_n =j,Y_{n-1} \notin B,\cdots,Y_1\notin B \mid (\boldsymbol{\xi}:\boldsymbol{0}) \big)= \boldsymbol{\xi^{\ast}}(\boldsymbol{N^{\ast}})^{n-1}B_{j}^{*'},
\end{equation}\]</span>
</div>
<p>siendo <span class="math inline">\(\small{B_{j}^{*'}}\)</span> la <span class="math inline">\(j-\)</span>ésima columna de la matriz <span class="math inline">\(\small{\boldsymbol{B^{\ast}}}\)</span></p>
<p>La prueba del corolario anterior es sencilla y se deja en manos del lector. Tenga en cuenta que el tamaño de la matriz <span class="math inline">\(\small{\boldsymbol{N^{\ast}}}\)</span> es menor o igual que el tamaño de <span class="math inline">\(\small{\boldsymbol{N}}\)</span>.</p>
</section>
</section>
<section id="capitulo-3-rachas-y-patrones-en-una-sucesión-de-ensayos-de-dos-estados" class="level3">
<h3 class="anchored" data-anchor-id="capitulo-3-rachas-y-patrones-en-una-sucesión-de-ensayos-de-dos-estados">Capitulo 3: Rachas y Patrones en una sucesión de ensayos de dos estados</h3>
<section id="introducción" class="level4">
<h4 class="anchored" data-anchor-id="introducción">3.1 Introducción:</h4>
<p>Aunque las rachas y patrones en una sucesión de ensayos de Bernoulli son casos especiales de los ensayos multiestados, merecen un capítulo aparte debido a su larga historia, la gran cantidad de resultados asociados y su amplia aplicación a numerosos campos. El enfoque de este capítulo será derivar las distribuciones para las estadísticas de rachas más comunes y útiles en ensayos de Bernoulli mediante la técnica de <em>incrustación de cadenas finitas de Markov</em>, y también en extender estos resultados a secuencias de ensayos de dos estados dependientes de Markov. También se presentan técnicas para obtener ecuaciones recursivas y funciones generadoras de probabilidad de estadísticas de rachas a través del enfoque de incrustación de cadenas finitas de Markov. Estas herramientas pueden ser muy útiles para estudiar ciertas características de las distribuciones de rachas, como la media, la varianza y los momentos superiores.</p>
<p>En este capítulo se tratan las siguientes estadísticas de rachas, definidas tradicionalmente en una secuencia de <span class="math inline">\(\small{n}\)</span> ensayos de Bernoulli:</p>
<p><em>(i)</em> <span class="math inline">\(\small{N_{n,k}}\)</span> el número de <span class="math inline">\(\small{k}\)</span> éxitos consecutivos no superpuestos;</p>
<p><em>(ii)</em> <span class="math inline">\(\small{G_{n,k}}\)</span> el número de rachas exitosas de tamaño mayor o igual a <span class="math inline">\(\small{k}\)</span>.</p>
<p><em>(iii)</em> <span class="math inline">\(\small{M_{n,k}}\)</span> el número de <span class="math inline">\(\small{k}\)</span> éxitos consecutivos solapados.</p>
<p><em>(iv)</em> <span class="math inline">\(\small{E_{n,k}}\)</span> el número de rachas de exctamente <span class="math inline">\(\small{k}\)</span> éxitos.</p>
<p><em>(v)</em> <span class="math inline">\(\small{L_{n,k}}\)</span> el tamaño de la racha de exitos más larga;</p>
<p><em>(vi)</em> <span class="math inline">\(\small{S_{n,k}}\)</span> el número total de éxitos en rachas exitosas de longitud mayor o igual a <span class="math inline">\(\small{k}\)</span> .</p>
<p>También se trata la distribución del tiempo de espera de una racha de éxitos y se incluyen algunos resultados numéricos para las distribuciones de las estadísticas de las rachas anteriores.</p>
</section>
<section id="número-de-smallk-éxitos-consecutivos-no-superpuestos" class="level4">
<h4 class="anchored" data-anchor-id="número-de-smallk-éxitos-consecutivos-no-superpuestos">3.2 Número de <span class="math inline">\(\small{k}\)</span> éxitos consecutivos no superpuestos</h4>
<p>El número de rachas de <span class="math inline">\(\small{k}\)</span> éxitos consecutivos no superpuestos, <span class="math inline">\(\small{N_{n,k}}\)</span>, en una secuencia de <span class="math inline">\(\small{n}\)</span> ensayos de Bernoulli es probablemente la estadística de ejecuciones más importante, no sólo por su amplia aplicación a diversas áreas sino también por su conexión con otras estadísticas de rachas; En teoría de la distribución, la distribución de <span class="math inline">\(\small{N_{n,k}}\)</span> se conoce como distribución binomial de orden <span class="math inline">\(\small{k}\)</span>. <em>Philippou</em> y <em>Makri (1986)</em> e <em>Hirano (1986)</em> dieron de forma independiente una fórmula para la distribución exacta de <span class="math inline">\(\small{N_{n,k}}\)</span> en una secuencia de <span class="math inline">\(\small{n}\)</span> ensayos de Bernoulli como:</p>
<!--Ecuación 3.1--->
<div class="math">
<span class="math display">\[\begin{equation}
\mathbb{P}(N_{n,k}=x)=\sum_{m=0}^{k-1}\sum_{x_1+x_2+\cdots+\\
kx_k=n-m-km}\binom{x_1+x_2+\cdots+x_k+x}{x_1,x_2,\cdots,x_k,x}p^n\Big(\frac{q}{p}\Big)^{x_1+x_2+\cdots+x_k},
\end{equation}\]</span>
</div>
<p>en donde, <span class="math inline">\(\small{x=0,1,\ldots,[n/k]}\,\)</span> (<span class="math inline">\(\small{[n/k]}\)</span> la parte entera de <span class="math inline">\(\small{n/k}\)</span>) y con probabilidades de éxito <span class="math inline">\(\small{p}\)</span> y fracaso <span class="math inline">\(\small{p=1-p}\)</span>. <em>Godbole (1990)</em> dio una fórmula alternativa para la función de probabilidad de <span class="math inline">\(\small{N_{n,k}}\)</span> con <span class="math inline">\(\small{k&gt;1}\)</span>:</p>
<!--Ecuación 3.2--->
<div class="math">
<span class="math display">\[\begin{align*}
\mathbb{P}(N_{n,k}=x) &amp;=\sum_{[(n-kx)/k]\leq y \leq n-kx} \binom{y+x}{x}q^yp^{n-y}\\
&amp; \times \sum_{0 \leq j \leq  [(n-kx-y)/k]}(-1)^j \binom{y+1}{j} \binom{n-kx-jk}{y},
\end{align*}\]</span>
</div>
<p>para <span class="math inline">\(\small{x=0,1,\ldots,[n/k]}\,\)</span>. La fórmula (3.2) tiene la ventaja sobre la (3.1) de que es más fácil de evaluar por computadora para <span class="math inline">\(\small{n}\,\)</span> grande. <em>Hirano</em> y <em>Aki (1987, 1993)</em> estudiaron algunas propiedades de esta distribución y ampliaron los resultados al caso de ensayos de Markov dependientes de dos estados.</p>
<p>Para comenzar nuestro estudio de <span class="math inline">\(\small{N_{n,k}}\)</span> utilizando el método de incrustación de cadenas finitas de Markov, consideremos el espacio de estados</p>
<!--Partición de espacios de estados --->
<div class="math">
<span class="math display">\[\begin{equation}
\Omega =\{(x,i):x=0,1,\cdots,l_n\, \text{y}\, 0,1,\cdots,k-1\},
\end{equation}\]</span>
</div>
<p>en donde, <span class="math inline">\(\small{l_n=[n/k]}\,\)</span> es el número máximo de rachas exitosas no superpuestas de longitud <span class="math inline">\(\small{k}\)</span> que pueden ocurrir en <span class="math inline">\(\small{n}\)</span> ensayos. Ahora definamos la Cadena de Markov finita homogenea <span class="math inline">\(\small{\{Y_t:t=0,1,\ldots,n\}}\,\)</span> sobre <span class="math inline">\(\small{\Omega}\,\)</span> como sigue:</p>
<!--Equacion 3.3--->
<div class="math">
<span class="math display">\[\begin{equation}
Y_t=(N_{t,k},E_{t}),\quad \text{para }1\leq t \leq n,
\end{equation}\]</span>
</div>
<p>donde <span class="math inline">\(\small{N_{n,k}}\)</span> es el número de <span class="math inline">\(\small{k}\)</span> éxitos consecutivos no superpuestos que ocurrieron durante los primeros <span class="math inline">\(\small{t}\)</span> ensayos <span class="math inline">\(\small{X_1,X_2,\ldots,X_n}\)</span>. El “bloque final” <span class="math inline">\(\small{E_t}\)</span> es igual a <span class="math inline">\(\small{m}\)</span> módulo <span class="math inline">\(\small{k}\)</span>, donde <span class="math inline">\(\small{m}\)</span> representa el número de éxitos finales (posiblemente cero) que existen en la sucesión después de las primeros <span class="math inline">\(\small{t}\)</span> ensayos:</p>
<!--Equacion 3.3.1-->
<div class="math">
<span class="math display">\[\begin{equation}
FFSSF\underbrace{SS\cdots S}_{m}.
\end{equation}\]</span>
</div>
<p>Observemos que <span class="math inline">\(\small{E_t=0}\)</span> si <span class="math inline">\(\small{m}\)</span> es un múltiplo positivo de <span class="math inline">\(\small{k}\)</span> o si el <span class="math inline">\(\small{t-}\)</span>ésimo resultado es <span class="math inline">\(\small{F}\)</span>. Esta variable de bloque final realiza un seguimiento del número de éxitos en una posible racha parcial asociada con en el <span class="math inline">\(\small{t-}\)</span>ésimo ensayo. Por ejemplo, dados <span class="math inline">\(\small{n=10}\)</span> ensayos de Bernoulli con resultados <span class="math inline">\(\small{\{FSFFSSSFSS\}}\)</span> y una duración de ejecución exitosa elegida de <span class="math inline">\(\small{k=2}\)</span>, la realización de la cadena de Markov incorporada <span class="math inline">\(\small{\{Y_t: t = 1,2,\ldots, 10\}}\)</span> con respecto a estos diez resultados es: <span class="math inline">\(\small{\{Y_1=(0,0), Y_2 = (0, 1), Y_3=(0,0), Y_4=(0,0),Y_5= (0,1),Y_6 = (1,0), Y_7=(1, 1), Y_8=(1,0),Y_9=(1,1), Y_{10}=(2,0)\}}\)</span>. Tenga en cuenta que para una secuencia dada de resultados <span class="math inline">\(\small{\{FS\cdots SF\}}\)</span>, la realización de <span class="math inline">\(\small{\{Y_t\}}\)</span> es siempre única.</p>
<p>Definir los subconjuntos</p>
<!--Equación 3.4--->
<div class="math">
<span class="math display">\[\begin{equation}
C_x =\{(x,i): i=0,1,\cdots,k-1\},\quad 0\leq x \leq l_n
\end{equation}\]</span>
</div>
<p>La colección de subconjuntos <span class="math inline">\(\small{\{C_x:x = 0,1,\ldots,l_n\}}\)</span> forma una partición del espacio de estados <span class="math inline">\(\small{\Omega}\)</span>. Dado que <span class="math inline">\(\small{\{X_t\}}\)</span> es, por el momento, una sucesión de ensayos Bernoulli, de las definiciones anteriores se deduce que <span class="math inline">\(\small{Y_t}\)</span> tiene una matriz de probabilidad de transición <span class="math inline">\(\small{\boldsymbol{M_t} = (p_{(x,i)(y,j)})}\)</span> para todo <span class="math inline">\(\small{t=1,2,\ldots,n}\)</span>, con las probabilidades de transición <span class="math inline">\(\small{(p_{(x,i)(y,j)})}\)</span> dadas por la siguiente ecuación: para <span class="math inline">\(\small{1 \leq t \leq n}\)</span> y <span class="math inline">\(\small{0 \leq x \leq l_n}\)</span> <!--Ecuacion  3.5--></p>
<div class="math">
<span class="math display">\[\begin{align*}
p_{(x,i)(y,j)} &amp; = \mathbb{P}\big(Y_t=(y,j)\mid Y_{t-1}=(x,i)\big)\\
&amp; =\begin{cases}
q \quad \text{si }y=x\,\text{y }j=0,\,\text{para }i=0,1,\ldots, k-1
\\
p \quad \text{si }y=x\,\text{y }j=i+1,\,\text{para }i=0,1,\ldots, k-2
\\
p \quad \text{si }y=x+1\,\text{y }j=0,\,\text{para }i=k-1\,\text{y },x=0,1,\ldots, l_{n}-1
\\
1 \quad \text{si }y=x=l_{n}\,\text{y }j=i=k-1
\\
0 \quad \text{en otro caso}
\end{cases}
\end{align*}\]</span>
</div>
<p>A modo de ilustración, la matriz de probabilidad de transición <span class="math inline">\(\small{\boldsymbol{M_t}}\)</span> de la cadena de Markov incrustada <span class="math inline">\(\small{{Y_t}}\)</span> asociada con la variable aleatoria <span class="math inline">\(\small{N_{5,2}}\)</span> viene dada por</p>
<!----Ecuación 3.6--->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{M}=
\begin{array}{cccccc}&amp;
\begin{array}{cccccc}
\end{array}
\\
\begin{array}{cccccc}
(0,0)\\
(0,1)\\
(1,0)\\
(1,1)\\
(2,0)\\
(2,1)
\end{array}
&amp;
\left(
\begin{array}{cc|cc|cc}
q&amp;p&amp;0&amp;0&amp;0&amp;0\\
q&amp;0&amp;p&amp;0&amp;0&amp;0\\
\hline
0&amp;0&amp;q&amp;p&amp;0&amp;0\\
0&amp;0&amp;q&amp;0&amp;p&amp;0\\
\hline
0&amp;0&amp;0&amp;0&amp;q&amp;p\\
0&amp;0&amp;0&amp;0&amp;0&amp;1\\
\end{array}
\right)
\end{array}_{6\times6}
\end{equation}\]</span>
</div>
<p>para <span class="math inline">\(\small{1\leq t \leq 5.}\)</span></p>
<p>Para el caso donde <span class="math inline">\(\small{\{X_t\}}\)</span> es una sucesión de ensayos de dos estados independientes pero no idénticamente distribuidos con probabilidades <span class="math inline">\(\small{\mathbb{P}(X_t=S)=p_t}\)</span> y <span class="math inline">\(\small{\mathbb{P}(X_t=F)=q_t}\)</span> , para <span class="math inline">\(\small{t=1,2,\ldots,n}\)</span>, las matrices de transición <span class="math inline">\(\small{\boldsymbol{M_t}}\)</span> para la cadena de Markov incrustada <span class="math inline">\(\small{\{Y_t\}}\)</span> permanece sin cambios excepto que la probabilidad <span class="math inline">\(\small{p}\)</span> se reemplaza por <span class="math inline">\(\small{p_t}\)</span> y <span class="math inline">\(\small{q}\)</span> se reemplaza por <span class="math inline">\(\small{q_t}\)</span>. En general, para ensayos de dos estados independientes pero no idénticamente distribuidos, las matrices de probabilidad de transición se pueden escribir como</p>
<!----Ecuación 3.7--->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{M_t}(N_{n,k})=
\left(\begin{array}{cccc}
\boldsymbol{A_t}&amp;\boldsymbol{B_t}&amp;&amp;&amp;\boldsymbol{0}\\
&amp;&amp;\ddots&amp;\ddots&amp;\\
\boldsymbol{0}&amp;&amp;&amp;\boldsymbol{A_t}&amp;\boldsymbol{B_t}\\
&amp;&amp;&amp;&amp;\boldsymbol{A_{t}^{\ast}}\\
\end{array}\right)_{d\times d},
\end{equation}\]</span>
</div>
<p>para <span class="math inline">\(\small{t=1,2,\dots,n}\)</span>, en donde:</p>
<!----Ecuación 3.7.1--->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{A_t}=
\left(\begin{array}{ccccc}
q_t&amp;p_t&amp;0&amp;\cdots&amp;0\\
q_t&amp;0&amp;p_t&amp;\cdots&amp;0\\
\vdots&amp; &amp;\ddots&amp;\ddots&amp;\\
\vdots&amp; &amp; &amp;\ddots&amp;p_t\\
q_t&amp;0&amp;0&amp;\cdots&amp;0\\
\end{array}\right)_{k\times k},
\end{equation}\]</span>
</div>
<p><span class="math inline">\(\small{\boldsymbol{B_t}}\)</span> es una matriz <span class="math inline">\(\small{k\times k}\)</span> que tiene <span class="math inline">\(\small{p_t}\)</span> en la entrada <span class="math inline">\(\small{(k,1)}\)</span> y cero en el resto, <span class="math inline">\(\small{\boldsymbol{A_t}^{\ast}}\)</span> es igual que <span class="math inline">\(\small{\boldsymbol{A_t}}\)</span> excepto que su última fila se reemplaza con <span class="math inline">\(\small{(0,0,...,0,1)}\)</span>, y la dimensión de <span class="math inline">\(\small{\boldsymbol{M_t}(N_{n,k})}\)</span> viene dado por <span class="math inline">\(\small{d = k(l_n+1)}\)</span>. Por tanto, en virtud del <em>teorema 2.1</em>, podemos afirmar que</p>
<!----Ecuación 3.8--->
<div class="math">
<span class="math display">\[\begin{equation}
\small{\mathbb{P}\big( N_{n,k}=x\big)=\boldsymbol{\mathbf{\xi}}_0 \Big(\prod_{t=1}^{n}\boldsymbol{M}_t(N_{n,k})\Big)\boldsymbol{\mathbf{U}'}(\mathbf{C_x})},\,\,  x=1,2,\ldots,l_n,
\end{equation}\]</span>
</div>
<p>en donde, <span class="math inline">\(\small{\boldsymbol{\mathbf{\xi}}_0=(1,0,\ldots,0)_{1\times d}}\)</span> y <span class="math inline">\(\small{\boldsymbol{\mathbf{U}'}({C_x})}\)</span> es la transpuesta del vector <span class="math inline">\(\small{\boldsymbol{\mathbf{U}'}({C_x})=(0,\ldots,0, 1,\ldots, 1, 0,\ldots,0)}\)</span> con unos en las ubicaciones asociadas con los estados en <span class="math inline">\(\small{C_x}\)</span>. La <em>ecuación (3.8)</em> representa la distribución exacta de <span class="math inline">\(\small{N_{n,k}}\)</span> para ensayos independientes de dos estados distribuidos tanto de forma idéntica como no idéntica. En vista de la matriz de probabilidad de transición en la <em>ecuación (3.7)</em>, <span class="math inline">\(\small{N_{n,k}}\)</span> es una cadena finita de Markov incrustable de tipo binomial en el sentido de la Definición 2.7 <em>(Koutras y Alexandrou 1995)</em>.</p>
<p>Si <span class="math inline">\(\small{\{X_t\}}\)</span> es una Cadena de Markov no homogenea com matriz de probabilidades de transición:</p>
<!----Ecuación 3.8.1--->
<div class="math">
<span class="math display">\[\begin{equation}
\left(\begin{array}{cc}
p_{FF}(t)&amp;p_{SS}(t)\\
p_{FF}(t)&amp;p_{SS}(t)
\end{array}\right),
\end{equation}\]</span>
</div>
<p>entonces, es necesaria una modificación menor en el procedimiento de incrustación para obtener la distribución de <span class="math inline">\(\small{N_{n,k}}\)</span>. Dado que el resultado de <span class="math inline">\(\small{X_{t+1}}\)</span>, y por tanto también de <span class="math inline">\(\small{Y_{t+1}}\)</span>, ahora depende de <span class="math inline">\(\small{X_t}\)</span>, cada estado de la cadena de Markov <span class="math inline">\(\small{Y_t}\)</span> debe implicar un cierto resultado de <span class="math inline">\(\small{X_t}\)</span>. Este ya es el caso en nuestra definición anterior de <span class="math inline">\(\small{Y_t}\)</span>, salvo para los estados con un bloque final de <span class="math inline">\(\small{E_t=0}\)</span>, que puede surgir para cualquier resultado de <span class="math inline">\(\small{X_t}\)</span>. Para resolver esta ambigüedad, definimos un estado de bloque final adicional, <span class="math inline">\(\small{E_t=\gamma}\)</span>, para corresponder al caso donde la serie de éxitos finales es un múltiplo distinto de cero de <span class="math inline">\(\small{k}\)</span> éxitos, y reservamos el estado <span class="math inline">\(\small{E_t=0}\)</span> para el caso donde el resultado <span class="math inline">\(\small{t-}\)</span>ésimo es un fracaso. La cadena de Markov incrustada se define entonces de la siguiente manera:</p>
<!----Ecuación 3.8.2--->
<div class="math">
<span class="math display">\[\begin{equation}
Y_t =
\begin{cases}
(x,\gamma) &amp; \begin{array}{l} \text{Si existen } x \text{ rachas de } k \text{ aciertos} \\
\text{consecutivos en los primeros } t \\
\text{ensayos con } m &gt; 0 \text{ aciertos finales}\\
\text{tales que } m \equiv k \pmod{k} \end{array} \\
\\
(x,0) &amp; \begin{array}{l}\text{Si existen } x \text{ rachas de } k \text{ aciertos}\\
\text{consecutivos en los primeros } t\text{ ensayos} \\ \text{con } m = 0 \text{ aciertos finales} \text{ (}X_t=F\text{)} \end{array}
\end{cases}
\end{equation}\]</span>
</div>
<p>y <span class="math inline">\(\small{Y_t=(x,i)}\)</span>, para <span class="math inline">\(\small{i=1,2,\ldots,k-1}\)</span> se define como se indica en la <em>ecuación (3.3)</em>. La diferencia entre los estados <span class="math inline">\(\small{(x,\gamma)}\)</span> y <span class="math inline">\(\small{ (x,0)}\)</span> se puede ver en el siguiente ejemplo: para una racha exitosa de longitud <span class="math inline">\(\small{k=2}\)</span>, <span class="math inline">\(\small{Y_8=(SFFFSSSS) = (2,\gamma)}\)</span> y <span class="math inline">\(\small{Y_8=(SFSSFSSF)= (2,0)}\)</span>. Tenga en cuenta que el bloque final <span class="math inline">\(\small{E_t}\)</span> ahora contiene no solo la información requerida sobre los subpatrones sino que también implica el resultado de <span class="math inline">\(\small{X_t}\)</span>, lo que permite la asignación de probabilidades de transición para la Cadena de Markov incustada.</p>
<p>Las matrices de probabilidad de transición correspondientes a estas definiciones pueden deducirse fácilmente. La cadena de Markov incrustada asociada con la variable aleatoria <span class="math inline">\(\small{N_{5,2}}\)</span> como se considera en la <em>Ecuación (3.6)</em> para ensayos de Bernoulli, tiene las siguientes matrices de transición <span class="math inline">\(\small{\boldsymbol{M_t^{\ast}}}\)</span> bajo ensayos dependientes de Markov no homogéneos: para <span class="math inline">\(\small{t=1,2,\ldots,n}\)</span></p>
<!----Equación 3.8.3----->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{M_t^*}(N_{5,2})=
\begin{array}{cc}
\begin{array}{c}
(0,0)\\
(0,1)\\
(1,c)\\
(1,0)\\
(1,1)\\
(2,c)\\
(2,1)\\
(2,1)
\end{array}&amp;
\left(
\begin{array}{cc|ccc|ccc}
p_{FF}(t)&amp;p_{FS}(t)&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\
p_{FS}(t)&amp;0&amp;p_{SS}(t)&amp;0&amp;0&amp;0&amp;0&amp;0\\
\hline
0&amp;0&amp;0&amp;p_{SF}(t)&amp;p_{SS}(t)&amp;0&amp;0&amp;0\\
0&amp;0&amp;0&amp;p_{FF}(t)&amp;p_{FS}(t)&amp;0&amp;0&amp;0\\
0&amp;0&amp;0&amp;p_{SF}(t)&amp;0&amp;p_{SS}(t)&amp;0&amp;0\\
\hline
0&amp;0&amp;0&amp;0&amp;0&amp;&amp;p_{SF}(t)&amp;p_{SS}(t)\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;p_{FF}(t)&amp;p_{FS}(t)\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;1\\
\end{array}
\right)
\end{array}
\end{equation}\]</span>
</div>
<p>Note que la estructura de “franja/banda” de <span class="math inline">\(\small{\boldsymbol{M_t^{\ast}}(N_{5,2})}\)</span> es similar con <span class="math inline">\(\small{\boldsymbol{M_t}(N_{5,2})}\)</span> de la <em>ecuación (3.6)</em> para ensayos de Bernoulli. Como es sencillo derivar la forma general de <span class="math inline">\(\small{\boldsymbol{M_t^{\ast}}(N_{n,k})}\)</span> análoga a la ecuación (3.7), esto lo dejamos al lector interesado.</p>
<p>Cuando la secuencia <span class="math inline">\(\small{\{X_t\}}\)</span> es i.i.d., la distribución inicial <span class="math inline">\(\small{\boldsymbol{\xi}_0}\)</span> puede definirse como <span class="math inline">\(\small{\mathbb{P}\big(Y_0=(0,0)\big)=1}\)</span>, y luego para <span class="math inline">\(\small{k&gt;1}\)</span>, las probabilidades de transición <span class="math inline">\(\small{\mathbb{P}\big(Y_1=(0,1)\mid Y_0=(0,0)\big)=p}\)</span> y <span class="math inline">\(\small{\mathbb{P}\big(Y_1=(0,0)\mid Y_0=(0,0)\big)=q=(1-p)}\)</span>. Sin embargo, cuando <span class="math inline">\(\small{\{X_t\}}\)</span> es una sucesión de variables aleatorias Markov-Dependientes , se debe tener cuidado al asumir <span class="math inline">\(\small{\mathbb{P}\big(Y_0=(0,0)\big)=1}\)</span>, lo que implicaría que las probabilidades de transición entre <span class="math inline">\(\small{Y_0}\)</span> e <span class="math inline">\(\small{Y_1}\)</span> están dadas por <span class="math inline">\(\small{\mathbb{P}\big(Y_1=(0,1)\mid Y_0=(0,0)\big)=p_{FS}(1)}\)</span> y <span class="math inline">\(\small{\mathbb{P}\big(Y_1=(0,0)\mid Y_0=(0,0)\big)=p_{FF}=1}\)</span>, independiente de <span class="math inline">\(\small{p_{SF}}\)</span> y <span class="math inline">\(\small{p_{FF}}\)</span>. Para evitar este tipo de sesgo, es útil crear un estado ficticio <span class="math inline">\(\small{\emptyset}\)</span> como estado inicial para <span class="math inline">\(\small{Y_0}\)</span>. Luego definimos <span class="math inline">\(\small{\mathbb{P}\big(Y_0=\emptyset\big)=1}\)</span>, y las probabilidades de transición <span class="math inline">\(\small{\mathbb{P}\big(Y_1=(0,1)\mid Y_0=\emptyset\big)=p_{s}}\)</span>, y <span class="math inline">\(\small{\mathbb{P}\big(Y_1=(0,0)\mid Y_0=\emptyset\big)=p_{f}}\)</span>. Por tanto, para <span class="math inline">\(\small{N_{5,2}}\)</span> la correspondiente cadena de Markov incrustada <span class="math inline">\(\small{\{Y_t\}}\)</span> se define en el espacio de estados expandido <span class="math inline">\(\small{\Omega=\{\emptyset,(0,0),(0,1),(1,0),\ldots\}}\)</span> con matrices de probabilidad de transición:</p>
<!--Ecuación 3.8.4-->
<div class="math">
<span class="math display">\[\begin{equation}
\begin{array}{cc} &amp;
\begin{array}{cccccc}(0,0)&amp;(0,1)&amp;(1,c)&amp;(1,0)&amp;(1,1)&amp;\cdots
\end{array}\\
\begin{array}{cccccccc}
\end{array}
&amp;
\left(
\begin{array}{c|ccccc}
0 &amp;  p_{f}  &amp; p_{s} &amp;  0  &amp;   0 &amp; \cdots \\
\hline
\, 0&amp;&amp;&amp;&amp;&amp;\\
0&amp;&amp;&amp;\boldsymbol{M_t}^{\ast}(N_{5,2})&amp;&amp;\\
0&amp;&amp;&amp;&amp;&amp;\\
\end{array}
\right)\end{array}
\end{equation}\]</span>
</div>
<p>Tenga en cuenta que el procedimiento de incrustación de cadenas finitas de Markov utilizado para obtener la distribución exacta de <span class="math inline">\(\small{N_{n,k}}\)</span> sigue siendo el mismo, excepto por diferencias menores en las matrices de probabilidad de transición, independientemente de si la secuencia de ensayos <span class="math inline">\(\small{\{X_t\}}\)</span> es <em>i.i.d.</em>, independiente pero no idéntica distribuida o si es Markov-Dependiente.</p>
</section>
<section id="número-de-rachas-exitosas-de-longitud-mayor-o-igual-a-smallk" class="level4">
<h4 class="anchored" data-anchor-id="número-de-rachas-exitosas-de-longitud-mayor-o-igual-a-smallk">3.3 Número de rachas exitosas de longitud mayor o igual a <span class="math inline">\(\small{k}\)</span></h4>
<p>Para una sucesión de ensayos de dos estados, la variable aleatoria <span class="math inline">\(\small{G_{n,k}}\)</span> se define como el número de rachas exitosas de longitud mayor o igual a <span class="math inline">\(\small{G_{n,k}}\)</span>. Consideremos una cadena de Markov finita <span class="math inline">\(\small{\{Y_t:t=0,1,2,\ldots,n\}}\)</span> definida en el espacio de estados:</p>
<!--Partición de espacios de estados 3.3.1--->
<div class="math">
<span class="math display">\[\begin{equation}
\Omega =\{(x,i):x=0,1,\cdots,l_n\,\, \text{y}\,\, i= \gamma,0,1,\cdots,k-1\}-{\{(0,\gamma)\}},
\end{equation}\]</span>
</div>
<p>en donde, <span class="math inline">\(\small{l_n=[(n+1)/(k+1)]}\)</span>. Para una sucesión de resultados de los primeros <span class="math inline">\(\small{t}\)</span> ensayos con <span class="math inline">\(\small{m}\)</span> éxitos finales, digamos <span class="math inline">\(\small{FS \cdots F \underbrace{SS \cdots}_{m}S}\)</span>, definimos la cadena de Markov:</p>
<!-- Ecuación 3.9--->
<div class="math">
<span class="math display">\[\begin{equation}
Y_t=(G_{n,k},E_t) \quad 1\leq t\leq n,
\end{equation}\]</span>
</div>
<p>donde <span class="math inline">\(\small{G_{n,k}}\)</span>, es el número de rachas exitosas de longitud mayor o igual a <span class="math inline">\(\small{k}\)</span> en la sucesión <span class="math inline">\(\small{\{X_t\}}\)</span>, y <span class="math inline">\(\small{E_t}\)</span> es la variable del bloque final con <span class="math inline">\(\small{E_t=m}\)</span> si <span class="math inline">\(\small{m=0,1,2,\ldots,k-1}\)</span>, y <span class="math inline">\(\small{E_t=\gamma}\)</span> si <span class="math inline">\(\small{m\geq k}\)</span>. Para ilustrar esta definición, considere una longitud de racha mínima de <span class="math inline">\(\small{k=2}\)</span> y los siguientes doce resultados, de un ensayo de dos estados: <span class="math inline">\(\small{FSFFSSFSSSFS}\)</span>, para los cuales <span class="math inline">\(\small{G_{12,2}=2}\)</span>. Se deduce de la <em>Ec.(3.9)</em> que la realización de la Cadena de Markov <span class="math inline">\(\small{\{Y_t:t=0,1,2,\ldots,14\}}\)</span> es : <span class="math inline">\(\small{\{Y_1=(0,0),Y_2=(0,1),Y_3=(0,0),Y_4=(0,0),Y_5=(0,1),Y_6=(1,\gamma),Y_7=(1,0),Y_8=(1,1),Y_9=(2,\gamma),Y_{10}=(2,\gamma),Y_{11}=(2,0),Y_{12}=(2,0)\}}\)</span>. Note que el bloque final <span class="math inline">\(\small{E_t=\gamma}\)</span> puede ocurrir sólo cuando hay al menos <span class="math inline">\(\small{k}\)</span> éxitos finales, en cuyo caso <span class="math inline">\(\small{G_{n,k}\geq k}\)</span> por esta razón, el estado <span class="math inline">\(\small{(0,\gamma)}\)</span> fue excluido en la definición anterior del espacio de estados <span class="math inline">\(\small{\Omega}\)</span>.</p>
<p>De la definición de la cadena de Markov incrustada dada por la <em>Ecu. (3.9)</em>, las probabilidades de transición de un paso en <span class="math inline">\(\small{\boldsymbol{M_t}(G_{n,k})}\)</span> para ensayos independientes pero no identicamente distribuidos se especifican mediante la siguiente ecuación: para <span class="math inline">\(\small{t=1,2,\ldots,n}\)</span></p>
<!----Ecuación 3.10--->
<div class="math">
<span class="math display">\[\begin{equation}
p_{(x,i)(y,i)}(t) =
\begin{cases}
q_t &amp; \begin{array}{l} \text{Si}\,\, y=x \,\, \text{y}\,\, j=0 \,\,\text{para}\,\, x=0,1,\ldots,l_n \,\text{y}\, i=\gamma,0,1,\ldots,k-1  \end{array} \\
p_t &amp; \begin{array}{l} \text{Si}\,\, y=x \,\, \text{y}\,\, j=i=\gamma\,\,\text{para}\,\, x=0,1,\ldots,l_n  \end{array}
\\
p_t &amp; \begin{array}{l} \text{Si}\,\, y=x \,\, \text{y}\,\, j=i+1\,\,\text{para}\,\, x=0,1,\ldots,l_n \,\text{y}\, i=\gamma,0,1,\ldots,k-2  \end{array}
\\
p_t &amp; \begin{array}{l} \text{Si}\,\, y=x+1,\,i=k-1 \,\, \text{y}\, j=\gamma \,\,\text{para}\,\, x=0,1,\ldots,l_n-1  \end{array}
\\
1 &amp; \begin{array}{l} \text{Si}\,\, y=x=l_n,\,j=x=k-1\end{array} \\
0 &amp; \begin{array}{l} \text{Otro caso} \end{array}
\end{cases}\\
\end{equation}\]</span>
</div>
<p>En el caso especial de <span class="math inline">\(\small{n=5}\)</span> y <span class="math inline">\(\small{k=2}\)</span> la matriz de probabilidades de transición <span class="math inline">\(\small{\boldsymbol{M_t}(G_{n,k})}\)</span> esta dada por:</p>
<!----Ecuación 3.10.1--->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{M_t}(G_{5,2})=
\begin{array}{cc}&amp;
\begin{array}{cccccc}
\end{array}
\\
\begin{array}{cccccc}
(0,0)\\
(0,1)\\
(1,\gamma)\\
(1,0)\\
(1,1)\\
(2,\gamma)\\
(2,0)\\
(2,1)
\end{array}
&amp;
\left(
\begin{array}{cc|c|cc|c|cc}
q_t&amp;p_t&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\
q_t&amp;0&amp;p_t&amp;0&amp;0&amp;0&amp;0&amp;0\\
\hline
0&amp;0&amp;p_t&amp;q_t&amp;0&amp;0&amp;0\\
\hline
0&amp;0&amp;0&amp;q_t&amp;p_t&amp;0&amp;0&amp;0\\
0&amp;0&amp;0&amp;q_t&amp;0&amp;p_t&amp;0&amp;0\\
\hline
0&amp;0&amp;0&amp;0&amp;0&amp;p_t&amp;q_t&amp;0\\
\hline
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;q_t&amp;p_t\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;1\\
\end{array}
\right)
\end{array}
\end{equation}\]</span>
</div>
<p>para <span class="math inline">\(\small{t=1,2,\ldots,5}\)</span>. En general <span class="math inline">\(\small{\boldsymbol{M_t}(G_{n,k})}\)</span> es una matriz bidiagonal de bloques de la forma: <!----Ecuación 3.11---></p>
<div class="math">
<span class="math display">\[\begin{equation}
\left(
\begin{array}{ccccccc}
\boldsymbol{A_t}&amp;p_t\boldsymbol{e_k'}&amp;&amp;&amp;&amp;&amp;\boldsymbol{O}\\
&amp;p_t&amp;q_t\boldsymbol{e_1}&amp;&amp;\boldsymbol{O}&amp;&amp;\\
&amp;&amp;\boldsymbol{A_t}&amp;p_t\boldsymbol{e_k'}&amp;&amp;&amp;\\
&amp;&amp;&amp;\ddots&amp;\ddots&amp;&amp;\\
&amp;&amp;&amp;&amp;\ddots&amp;\ddots&amp;\\
&amp;&amp;\boldsymbol{O}&amp;&amp;&amp;p_t&amp;q_t\boldsymbol{e_1}\\
\boldsymbol{O}&amp;&amp;&amp;&amp;&amp;&amp;\boldsymbol{A_t^{\ast}}\\
\end{array}
\right)
\end{equation}\]</span>
</div>
<p>en donde <span class="math inline">\(\small{\boldsymbol{e_1}=(1,0,\ldots,0)}\)</span> y <span class="math inline">\(\small{\boldsymbol{e_1}=(0,\ldots,0,1)}\)</span> son vectores fila unitarios <span class="math inline">\(\small{1\times k}\)</span>, y <span class="math inline">\(\small{\boldsymbol{A_t}}\)</span> es dada por:</p>
<!----Ecuación 3.11.1--->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{A_t} =\left(
\begin{array}{ccccc}
q_t &amp; p_t &amp; 0  &amp; \ldots &amp;  0 \\
\vdots &amp; \ddots &amp; \ddots  &amp;    &amp;   \\
\vdots &amp;  &amp;  \ddots&amp; \ddots &amp;   \\
\vdots&amp;  &amp;   &amp;  \ddots &amp;p_t \\
q_t&amp;  0 &amp; 0 &amp;  \cdots &amp; 1 \\
\end{array}
\right)
\end{equation}\]</span>
</div>
<p>La matriz de probabilidad de transición <span class="math inline">\(\small{\boldsymbol{A_t}}\)</span>, en el contexto de la demografía, a menudo se denomina matriz de Leslie o, más generalmente, matriz de tipo renovación (véase <em>Seneta, 1981</em>). La dimensión de <span class="math inline">\(\small{\boldsymbol{A_t}(G_{n,k})}\)</span> es igual a <span class="math inline">\(\small{(l_n+1)(k+1)-1}\)</span>. La matriz <span class="math inline">\(\small{\boldsymbol{A_t^{\ast}}}\)</span> en la <em>Ec. (3.11)</em> es igual que <span class="math inline">\(\small{\boldsymbol{A_t}}\)</span> excepto por la última fila, que se reemplaza por <span class="math inline">\(\small{(0,\ldots,0,1)}\)</span></p>
<p>Si definimos la partición <span class="math inline">\(\small{\{C_x:i=0,1,2,\ldots,l_n\}}\)</span> sobre <span class="math inline">\(\small{\Omega}\)</span></p>
<!----Ecuación 3.11.2--->
<div class="math">
<span class="math display">\[\begin{align*}
C_0&amp;=\{(0,i):i=0,1,\ldots,k-1\} \\
C_x&amp;=\{(0,i):i=\gamma,0,1,\ldots,k-1\},\,\text{para}\, x=1,2,\ldots,l_n
\end{align*}\]</span>
</div>
<p>y en consecuencia <span class="math inline">\(\small{\mathbb{P}\big(G_{n,k}=x\big)=\mathbb{P}\big(Y_n \in C_x \big)}\)</span> para todo <span class="math inline">\(\small{x=0,1,2,\ldots,l_n}\)</span>. La función de distribución, los momentos y la función generadora de probabilidad ahora se pueden calcular fácilmente mediante las ecuaciones (2.11), (2.12) y (2.13), respectivamente.</p>
<p>Para el caso de ensayos <em>i.i.d.</em>, todas las probabilidades de transición serían constantes y se podría llevar a cabo una extensión a los ensayos de Markov-Dependientes como se describe para el estadístico <span class="math inline">\(\small{N_{n,k}}\)</span> en la sección anterior; En el resto de este capítulo sobre ensayos en dos Estados, nos centraremos principalmente en el caso de ensayos independientes pero no idénticamente distribuidos.</p>
</section>
<section id="número-de-smallk-éxitos-consecutivos-solapados" class="level4">
<h4 class="anchored" data-anchor-id="número-de-smallk-éxitos-consecutivos-solapados">3.4 Número de <span class="math inline">\(\small{k}\)</span> éxitos consecutivos solapados</h4>
<p>La variable aleatoria <span class="math inline">\(\small{M_{n,k}}\)</span> se define como el número <span class="math inline">\(\small{k}\)</span> de éxitos consecutivos superpuestos en una sucesión de <span class="math inline">\(\small{n}\)</span> ensayos independientes de dos estados. La cadena de Markov incrustada <span class="math inline">\(\small{\{Y_t:t=0,1,2,\ldots,n\}}\)</span> asociada a <span class="math inline">\(\small{M_{n,k}}\)</span> puede definirse como</p>
<!----Ecuación 3.12--->
<div class="math">
<span class="math display">\[\begin{align*}
Y_t=(M_{t,k},E_t),\quad t=1,2,\ldots,n
\end{align*}\]</span>
</div>
<p>sobre el espacio de estados</p>
<!----Ecuación 3.12.1--->
<div class="math">
<span class="math display">\[\begin{align*}
\Omega &amp;=\{(x,i):x=0,1,\cdots,l_n-1\,\, \text{e}\,\, i=\gamma, 0,1,\cdots,k-1\} \\
&amp; \cup \{(l_n,\gamma)\}-\{(0,\gamma)\},
\end{align*}\]</span>
</div>
<p>donde <span class="math inline">\(\small{l_n=n-k+1,\, M_{n,k}}\)</span> es el número de <span class="math inline">\(\small{k}\)</span> éxitos consecutivos superpuestos en las primeros <span class="math inline">\(\small{t}\)</span> ensayos, y <span class="math inline">\(\small{E_t}\)</span> es la <em>variable del bloque final</em> que lleva la cuenta del número <span class="math inline">\(\small{m}\)</span> de éxitos finales:</p>
<!--Eciación 3.13--->
<div class="math">
<span class="math display">\[\begin{equation}
E_t=\begin{cases}
\gamma &amp; \text{si}\, m\geq k\\
m &amp; \text{si}\, m=0,1,\ldots,k-1.
\end{cases}
\end{equation}\]</span>
</div>
<p>Con conteo superpuesto, es fácil verificar que las probabilidades para las matrices de probabilidad de transición <span class="math inline">\(\small{\boldsymbol{M_t}=p_{(x,i)(y,j)}(t)}\)</span> se pueden obtener a partir de la siguiente ecuación:</p>
<!----Ecuación 3.14--->
<div class="math">
<span class="math display">\[\begin{equation}
p_{(x,i)(y,j)}(t) =
\begin{cases}
q_t &amp; \begin{array}{l} \text{Si}\,\, y=x \,\, \text{y}\,\, j=0 \,\,\text{para}\,\, x=0,1,\ldots,l_n \,\,\text{e}\, i=\gamma,0,1,\ldots,k-1 \end{array} \\
p_t &amp; \begin{array}{l} \text{Si}\,\, y=x \,\, \text{y}\,\, j=i+1\,\,\text{para}\,\, x=0,1,\ldots,l_n \,\, \text{e}\,\,i=0,1,\ldots,k-2 \end{array}
\\
p_t &amp; \begin{array}{l} \text{Si}\,\, y=x+1 \,\, \text{y}\,\, j=\gamma\,\,\text{e}\,\,i=k-1,\,\text{para}\,\, x=0,1,\ldots,l_n-1 \end{array}
\\
p_t &amp; \begin{array}{l} \text{Si}\, y=x+1,\,j=i=\gamma\,\,\text{para}\,\, x=0,1,\ldots,l_n-1  \end{array}
\\
1 &amp; \begin{array}{l} \text{Si} \,\, y=x=l_n,\,\text{y}\ j=i=\gamma\end{array} \\
0 &amp; \begin{array}{l} \text{Otro caso} \end{array}
\end{cases}\\
\end{equation}\]</span>
</div>
<p>La partición correspondiente del espacio de estados <span class="math inline">\(\small{\Omega}\)</span> se puede especificar de la siguiente manera:</p>
<!----Ecuación 3.14.1--->
<div class="math">
<span class="math display">\[\begin{align*}
C_0 &amp;=\{(x,i):i=0,1,\cdots,k-1\}\\
C_x &amp;=\{(x,i):i=\gamma,0,1,\cdots,k-1\},\, x=1,\cdots,l_n,\\
C_{l_n} &amp;= \{(l_n,\gamma)\}
\end{align*}\]</span>
</div>
<p>Como ejemplo considerese, <span class="math inline">\(\small{n=4}\)</span> y <span class="math inline">\(\small{k=2}\)</span>, luego las matrices de probabilidades de transición <span class="math inline">\(\small{\boldsymbol{M_t}(M_{4,2})}\)</span> para <span class="math inline">\(\small{t=1,2,3,4}\)</span> son:</p>
<!----Ecuación 3.15--->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{M_t}(M_{4,2})=
\begin{array}{cc}&amp;
\begin{array}{cccccc}
\end{array}
\\
\begin{array}{cccccc}
(0,0)\\
(0,1)\\
(1,\gamma)\\
(1,0)\\
(1,1)\\
(2,\gamma)\\
(2,0)\\
(2,1)\\
(3,\gamma)
\end{array}
&amp;
\left(
\begin{array}{cc|c|cc|c|cc|c}
q_t&amp;p_t&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\
q_t&amp;0&amp;p_t&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\
\hline
0&amp;0&amp;0&amp;q_t&amp;0&amp;p_t&amp;0&amp;0&amp;0\\
\hline
0&amp;0&amp;0&amp;q_t&amp;p_t&amp;0&amp;0&amp;0&amp;0\\
0&amp;0&amp;0&amp;q_t&amp;0&amp;p_t&amp;0&amp;0&amp;0\\
\hline
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;q_t&amp;0&amp;p_t\\
\hline
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;q_t&amp;p_t&amp;0\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;q_t&amp;0&amp;p_t\\
\hline
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;1\\
\end{array}
\right)
\end{array}
\end{equation}\]</span>
</div>
<p>En general para <span class="math inline">\(\small{n}\)</span> y <span class="math inline">\(\small{k}\)</span> arbitrareos, las matrices de probabilidad de transición continúan teniendo una forma de bandas similar a <span class="math inline">\(\small{\boldsymbol{M_t}(M_{4,2})}\)</span> en la <em>ecuación (3.15)</em>, y son de dimensión <span class="math inline">\(\small{l_n(k+1)}\)</span>. La distribución y los momentos de la variable aleatoria <span class="math inline">\(\small{M_{n,k}}\)</span> se pueden calcular nuevamente mediante las ecuaciones (2.11) y (2.12), respectivamente.</p>
</section>
<section id="número-de-rachas-de-exactamente-smallk-éxitos." class="level4">
<h4 class="anchored" data-anchor-id="número-de-rachas-de-exactamente-smallk-éxitos.">3.5 Número de Rachas de exactamente <span class="math inline">\(\small{k}\)</span> éxitos.</h4>
<p>La Cadena de Markov incrustada <span class="math inline">\(\small{\{Y_t\}}\)</span> asociada con la variable aleatoria, <span class="math inline">\(\small{E_{n,k}}\)</span>, del número de rachas exitosas de tamaño exactamente <span class="math inline">\(\small{k}\)</span> en <span class="math inline">\(\small{n}\)</span> ensayos independientes de dos estados, se define por:</p>
<!--Ecuación 3.16-->
<div class="math">
<span class="math display">\[\begin{equation}
Y_t=(E_{t,k},E_t)
\end{equation}\]</span>
</div>
<p>sobre el espacio de estados:</p>
<!--Ecuación 3.16.1--->
<div class="math">
<span class="math display">\[\begin{equation}
\Omega =\{(x,i):x=0,1,\cdots,l_n\,\, \text{e}\,\, i=\beta,\gamma,0,1,\cdots,k-1\}-\{(0,\gamma)\},
\end{equation}\]</span>
</div>
<p>en donde, <span class="math inline">\(\small{l_n=[(n+1)/(k+1)]}\)</span>, <span class="math inline">\(\small{E_{t,k}}\)</span> es el número de rachas éxitosas de longitud igual a <span class="math inline">\(\small{k}\)</span> en los primeros <span class="math inline">\(\small{t}\)</span> ensayos, y el <em>bloque final</em> <span class="math inline">\(\small{E_{t}}\)</span> se define en función del número de éxitos finales <span class="math inline">\(\small{m}\)</span>, en los primeros <span class="math inline">\(\small{t}\)</span> ensayos de la siguiente manera:</p>
<!---Ecuación 3.17--->
<div class="math">
<span class="math display">\[\begin{equation}
E_t=\begin{cases}
m &amp; \text{Si}\,\, m=0,1,\ldots,k-1\\
\gamma &amp; \text{Si}\,\, m = k\\
\beta &amp; \text{Si}\,\, m&gt;k
\end{cases}
\end{equation}\]</span>
</div>
<p>Los dos estados del bloque final <span class="math inline">\(\small{\beta}\)</span> e <span class="math inline">\(\small{\gamma}\)</span> tienes la siguiente interpretación:</p>
<p><em>(i)</em> Estado de espera <span class="math inline">\(\small{(x,\gamma),\,\,x=1,2,\dots,l_n}\)</span>:</p>
<p><span class="math inline">\(\small{ Y_t=(x,\gamma)}\)</span> significa que <span class="math inline">\(\small{m=k}\)</span> y que <span class="math inline">\(\small{x-}\)</span>ésima racha exitosa de tamaño <span class="math inline">\(\small{k}\)</span> ha ocurrido en el <span class="math inline">\(\small{t-}\)</span>ésimo ensayo, y</p>
<p><em>(ii)</em> Estado de desbordamiento <span class="math inline">\(\small{(x,\beta),\,\,x=1,2,\dots,l_n}\)</span>:</p>
<p><span class="math inline">\(\small{ Y_t=(x,\beta)}\)</span> significa que <span class="math inline">\(\small{m&gt;k}\)</span> y que exactamente <span class="math inline">\(\small{x}\)</span> rachas exitosas de tamaño <span class="math inline">\(\small{k}\)</span> han aparecido antes de los últimos <span class="math inline">\(\small{m+1}\)</span> resultados <span class="math inline">\(\small{(F\underbrace{S\cdots S}_{m})}\)</span>.</p>
<p>Con estos bloques finales en mente, podemos construir fácilmente la partición para el espacio de estados <span class="math inline">\(\small{\Omega:\, C_0=\{(0,i):i=\beta,0,1,\ldots, k-1\} }\)</span> y <span class="math inline">\(\small{C_x=\{(x,i):i=\gamma,\beta,0,1,\ldots, k-1\} }\)</span>, para <span class="math inline">\(\small{x=1,\ldots,l_n}\)</span>.</p>
<p>Las probabilidades para las matrices de transición <span class="math inline">\(\small{\boldsymbol{M_t}(E_{t,k})}\)</span> de la cadena de Markov incrustada <span class="math inline">\(\small{\{Y_t\}}\)</span>, se especifican mediante la siguiente ecuación:</p>
<!----Ecuación 3.18--->
<div class="math">
<span class="math display">\[\begin{equation}
p_{(x,i)(y,j)}(t) =
\begin{cases}
q_t &amp; \begin{array}{l} \text{Si}\,\, y=x \,\, \text{y}\,\, j=0 \,\,\text{para}\,\, x=0,1,\ldots,l_n \,\,\text{e}\,\, i=\gamma,\beta,0,1,\ldots,k-1 \end{array} \\
p_t &amp; \begin{array}{l} \text{Si}\,\, y=x \,\, \text{y}\,\, j=i+1\,\,\text{para}\,\, x=0,1,\ldots,l_n \,\, \text{e}\,\,i=0,1,\ldots,k-2 \end{array}
\\
p_t &amp; \begin{array}{l} \text{Si}\,\, y=x+1 \,\, \text{y}\,\, j=\gamma\,\,\text{e}\,\,i=k-1,\,\text{para}\,\, x=0,1,\ldots,l_n-1 \end{array}
\\
p_t &amp; \begin{array}{l} \text{Si}\,\, y=x-1,\,\,j=\beta\,\, \,\,\text{e}\,\, i=\gamma\,\,\text{para}\,\, x=0,1,\ldots,l_n  \end{array}
\\
p_t &amp; \begin{array}{l} \text{Si}\,\, y=x,\,\,\text{e}\,\, j=i=\beta\,, \,\,\text{para}\,\, x=0,1,\ldots,l_n  \end{array}
\\
1 &amp; \begin{array}{l} \text{Si} \,\, y=x=l_n\,\,\text{y}\,\, j=i=k-1\end{array} \\
0 &amp; \begin{array}{l} \text{Otro caso}. \end{array}
\end{cases}\\
\end{equation}\]</span>
</div>
<p>A modo de ilustración, consideremos el caso <span class="math inline">\(\small{n=5}\)</span> y <span class="math inline">\(\small{k=2}\)</span>, para lo cual tenemos las matrices de probabilidad de transición:</p>
<!----Ecuación 3.19--->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{M_t}(E_{5,2})=
\begin{array}{cc}&amp;
\begin{array}{c}
(0,\beta)\\
(0,0)\\
(0,1)\\
(1,\gamma)\\
(1,\beta)\\
(1,0)\\
(1,1)\\
(2,\gamma)\\
(2,\beta)\\
(2,0)\\
(2,1)
\end{array}
&amp;
\left(
\begin{array}{c|cc|cc|cc|cc|cc}
q_t&amp;p_t&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\
\hline
0&amp;q_t&amp;p_t&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\
0&amp;q_t&amp;0&amp;p_t&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\
\hline
p_t&amp;0&amp;0&amp;0&amp;0&amp;q_t&amp;0&amp;0&amp;0&amp;0&amp;0\\
0&amp;0&amp;0&amp;0&amp;p_t&amp;q_t&amp;0&amp;0&amp;0&amp;0&amp;0\\
\hline
0&amp;0&amp;0&amp;0&amp;0&amp;q_t&amp;p_t&amp;0&amp;0&amp;0&amp;0\\
0&amp;0&amp;0&amp;0&amp;0&amp;q_t&amp;0&amp;p_t&amp;0&amp;0&amp;0\\
\hline
0&amp;0&amp;0&amp;0&amp;p_t&amp;0&amp;0&amp;0&amp;0&amp;q_t&amp;0\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;p_t&amp;q_t&amp;0\\
\hline
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;q_t&amp;p_t\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;1\\
\end{array}
\right)
\end{array}
\end{equation}\]</span>
</div>
<p>En general, las matrices de probabilidad de transición de la cadena de Markov <span class="math inline">\(\small{\{Y_t\}}\)</span> asociadas con <span class="math inline">\(\small{E_{n,k}}\)</span> tienen la forma dada por la <em>ecuación (3.19</em>) con dimensión <span class="math inline">\(\small{(l_n + 1)(k+1)+l_n}\)</span>.</p>
</section>
<section id="la-distribución-de-la-racha-de-éxitos-más-larga" class="level4">
<h4 class="anchored" data-anchor-id="la-distribución-de-la-racha-de-éxitos-más-larga">3.6 La distribución de la Racha de éxitos más larga</h4>
<p>Sea <span class="math inline">\(\small{L_n(S)}\)</span>, la duración de la racha exitosa más larga en una sucesión de ensayos de dos estados. Para el caso de <span class="math inline">\(\small{n}\)</span> lanzamientos independientes de una moneda justa, sea <span class="math inline">\(\small{A_n(k)}\)</span> el número de secuencias de longitud <span class="math inline">\(\small{n}\)</span> en las que la racha más larga de éxitos (cara) es menor o igual a <span class="math inline">\(\small{k}\)</span>. Dado que todas las sucesiones son igualmente probables con probabilidad <span class="math inline">\(\small{(1/2)^n}\)</span>, la distribución del racha más largo es:</p>
<!--Ecuación 3.20--->
<div class="math">
<span class="math display">\[\begin{equation}
\mathbb{P}\big(L_n(S)\leq k\big)=2^{-n}A_n(k)
\end{equation}\]</span>
</div>
<p>donde <span class="math inline">\(\small{A_n(k)}\)</span> satisface la ecuación recursiva <em>(Schilling 1990)</em></p>
<!--Ecuación 3.21--->
<div class="math">
<span class="math display">\[\begin{equation}
A_n(k)=\begin{cases}
\displaystyle\sum_{j=0}^{k}A_{n-1-j}(k) &amp; \text{si}\, n &gt; k\\
2^{n} &amp; \text{si}\,\, n \leq k\\
1 &amp; \text{si}\,\, k = 0\\
\end{cases}
\end{equation}\]</span>
</div>
<p>Para monedas sesgadas <span class="math inline">\(\small{(p\neq1/2)}\)</span>, el análisis combinatorio es:</p>
<!--Ecuación 3.22--->
<div class="math">
<span class="math display">\[\begin{equation}
\mathbb{P}\big(L_n(S)\leq k\big)=\displaystyle\sum_{x=0}^{k}C_{n}^{(x)}(k)p^{x}q^{n-x},
\end{equation}\]</span>
</div>
<p>para <span class="math inline">\(\small{1 \leq k \leq n}\)</span>, y <span class="math inline">\(\small{\mathbb{P}\big(L_n(S)=0 \big)=q^{-n}}\)</span>, donde <span class="math inline">\(\small{C_n^{(x)}(k)}\)</span> es el número de secuencias de longitud <span class="math inline">\(\small{n}\)</span> en las que ocurren exactamente <span class="math inline">\(\small{x}\)</span> éxitos, pero en las que no más de <span class="math inline">\(\small{k}\)</span> de estos éxitos ocurren consecutivamente. <span class="math inline">\(\small{C_n^{(x)}(k)}\)</span> se puede obtener a través de la ecuación recursiva:</p>
<!--Ecuación 3.23--->
<div class="math">
<span class="math display">\[\begin{equation}
C_n^{(x)}(k)=\begin{cases}
\displaystyle\sum_{j=0}^{k}C_{n-1-j}^{x-j}(k) &amp; \text{si}\,\,  k&lt;x&lt;n\\
\binom{n}{x} &amp; \text{si}\,\,  x \leq k \leq n\\
\, 0 &amp; \text{si}\,\,k&lt;x= n\\
\end{cases}
\end{equation}\]</span>
</div>
<p>De manera más general, supongamos que las probabilidades de éxito y fracaso podrían ser diferentes en cada ensayo, iguales a <span class="math inline">\(\small{p_t}\)</span> y <span class="math inline">\(\small{q_t}\)</span>, respectivamente, para <span class="math inline">\(\small{t=1,2,\ldots,n}\)</span>. El siguiente teorema deriva la distribución de <span class="math inline">\(\small{L_n(S)}\)</span>:</p>
<p><strong>Teorema 3.1</strong> Para <span class="math inline">\(\small{0\leq k\leq n}\)</span>,</p>
<!--Ecuación 3.24--->
<div class="math">
<span class="math display">\[\begin{equation}
\mathbb{P}\big(L_n(S)\leq k\big)=\boldsymbol{\mathbf{\xi}} \Big(\prod_{t=1}^{n}\boldsymbol{N}_t\Big)\boldsymbol{\mathbf{1}'}_{1 \times(k+1)}
\end{equation}\]</span>
</div>
<p>en donde <span class="math inline">\(\small{\boldsymbol{\mathbf{\xi}}=(1,0,\ldots,0)}\)</span> es un vector fila unitario de tamaño <span class="math inline">\(\small{1\times (k+1)}\)</span> y <span class="math inline">\(\small{\boldsymbol{N_t}}\)</span> es como se indica a continuación, la <em>submatriz esencial</em> <span class="math inline">\(\small{(k+1)\times (k+1)}\)</span> de la matriz de probabilidades de transición:</p>
<!--Ecuación 3.25--->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{M_t}=
\begin{array}{cc}&amp;
\begin{array}{c}
0\\
1\\
\vdots\\
\vdots\\
k\\
\alpha
\end{array}
&amp;\left(
\begin{array}{ccccc|c}
q_t&amp;p_t&amp;0&amp;\cdots&amp;0&amp;0\\
q_t&amp;0&amp;p_t&amp;\cdots&amp;0&amp;0\\
\vdots&amp;&amp;\ddots&amp;\ddots&amp;&amp;\vdots\\
\vdots&amp;&amp;\ddots&amp;\ddots&amp;\ddots&amp;\vdots\\
q_t&amp;0&amp;\cdots&amp;\cdots&amp;0&amp;p_t\\
\hline
0&amp;0&amp;\cdots&amp;\cdots&amp;0&amp;1\\
\end{array}
\right)_{(k+2) \times (k+2)}
\end{array}=\left(\begin{array}{c|c}
\boldsymbol{N_t} &amp;  {C_t}\\
\hline
\boldsymbol{0}&amp;  {1}\\
\end{array}
\right)
\end{equation}\]</span>
</div>
<p><strong>Demostración:</strong> La racha exitosa más larga en una sucesión de ensayos de dos estados está relacionada con las estadísticas de ejecución <span class="math inline">\(\small{N_{n,k}}\)</span>, <span class="math inline">\(\small{G_{n,k}}\)</span> y <span class="math inline">\(\small{M_{n,k}}\)</span> de la siguiente manera sencilla:</p>
<!--Ecuación 3.25.1--->
<div class="math">
<span class="math display">\[\begin{equation}
L_n(S)\leq k \,\, \text{si y solo si}\,\, N_{n,k+1} = G_{n,k+1}=M_{n,k+1}=0
\end{equation}\]</span>
</div>
<p>Por tanto, <span class="math inline">\(\small{\mathbb{P}\big(L_n(S)\leq k\big)=\mathbb{P}\big(N_{n,k+1}=0\big)}\)</span>, y podemos completar la demostración considerando la <em>Ecuación (3.8)</em> para <span class="math inline">\(\small{\mathbb{P}\big(N_{n,k+1}=x\big)}\)</span> con <span class="math inline">\(\small{x=0}\)</span>. Cambiando los estados <span class="math inline">\(\small{(0,0),(0,1),\ldots,(0,k)}\)</span> en esta aplicación de la <em>Ecuación (3.8)</em> a los estados <span class="math inline">\(\small{0,1,2,\ldots,k}\)</span> respectivamente, y combinando todos los demás estados en el estado absorbente <span class="math inline">\(\small{\alpha}\)</span>, obtenemos:</p>
<!--Ecuación 3.25.2--->
<div class="math">
<span class="math display">\[\begin{equation}
\mathbb{P}\big(L_n(S)\leq k\big)=\mathbb{P}\big(N_{n,k+1}=0\big)=\boldsymbol{\mathbf{\xi}_0} \Big(\prod_{t=1}^{n}\boldsymbol{M}_t\Big)(1,\ldots,1,0)'
\end{equation}\]</span>
</div>
<p>en donde <span class="math inline">\(\small{\boldsymbol{\xi_0}=(1,0\ldots,0)_{1\times(k+2)}=(\boldsymbol{\xi}:0)}\)</span>. Con la notación <span class="math inline">\(\small{(1,\ldots,1,0)_{1\times(k+2)}=(\boldsymbol{1}:0)}\)</span> y haciendo uso del hecho que las matrices de transición de probabilidad tienen la forma:</p>
<!--Ecuación 3.25.3--->
<div class="math">
<span class="math display">\[\begin{equation}
\prod_{t=1}^{n}\boldsymbol{M_t}=
\left(
\begin{array}{c|c}
\displaystyle\prod_{t=1}^{n}\boldsymbol{N_t}&amp; C_t(n)\\
\hline
\boldsymbol{0}&amp;1
\end{array}
\right)
\end{equation}\]</span>
</div>
<p>luego, el teorema se sigue inmediatamente. <span class="math inline">\(\hspace{3cm}\Box\)</span></p>
<p><strong>Colorario</strong> Dados <span class="math inline">\(\small{1 \leq k \leq n}\)</span> se satisface la siguiente ecuación recursiva:</p>
<!--Ecuación 3.26--->
<div class="math">
<span class="math display">\[\begin{equation}
\mathbb{P}\big(L_n(S)\leq k\big)=q_n\cdot\mathbb{P}\big(L_{n-1}(S)\leq k\big)+\displaystyle\sum_{i=1}^{k}q_{n-i} \prod_{j=n-i+1}^{n}p_{j}\cdot\mathbb{P}\big(L_{n-i-1}(S)\leq k\big)
\end{equation}\]</span>
</div>
<p>con <span class="math inline">\(\small{\mathbb{P}\big(L_n(S)=0\big)=\displaystyle\prod_{j=1}^{n}q_j}\)</span> y <span class="math inline">\(\small{\mathbb{P}\big(L_n(S)\leq n\big)\equiv1}\)</span> para <span class="math inline">\(\small{k=m}.\)</span></p>
<p><strong>Demostración</strong> De la estructuradada dada por la Ec.(3.25) para las matrices de probabilidades de transición <span class="math inline">\(\small{\boldsymbol{M_t}}\)</span>, se sigue que:</p>
<!--Ecuación 3.26.1--->
<div class="math">
<span class="math display">\[\begin{align*}
\text{(i)}\,\, \boldsymbol{M_te_0'} &amp;=q_t(1,\ldots,1,0)'_{1\times(k+2)}\,\, \text{y} \\
\text{(ii)}\,\,\boldsymbol{M_te_i'} &amp;=p_t\boldsymbol{e_{i-1}'},\,\,\text{para}\,\, i=1,2,\ldots,k,
\end{align*}\]</span>
</div>
<p>en donde <span class="math inline">\(\small{\boldsymbol{e_i}=(0,\ldots,0,1,0,\ldots,0)}\)</span> es un vector fila unitario con un uno en la coordenada asociada al estado <span class="math inline">\(\small{i}\)</span>, para <span class="math inline">\(\small{i=0,1,2,\ldots,k}\)</span>.</p>
<p>Dado que <span class="math inline">\(\small{\displaystyle\sum_{i=0}^{k}\boldsymbol{e_i'}}\)</span>, nuestro resultado es una consecuencia directa de (i),(ii) y multiplicaciones hacia atrás de la <em>ecuación (3.24)</em>.</p>
<p>Tomando <span class="math inline">\(\small{p_t=q_t=1/2}\)</span> para todo <span class="math inline">\(\small{t=1,2,\ldots,n}\)</span> y multiplicando <span class="math inline">\(\small{\mathbb{P}\big(L_n(S)\leq k\big)=1}\)</span> por <span class="math inline">\(\small{2^n}\)</span>, la ecuación (3.26) produce la ecuación recursiva (3.21) para <span class="math inline">\(\small{A_n(k)}\)</span>. El teorema 3.1 también se puede extender para la rachas de falla más larga <span class="math inline">\(\small{L_n(F)}\)</span> y a la estadística de racha más larga <span class="math inline">\(\small{L_n = \max\{L_n(S), L_n(F)\}}\)</span>. Para el caso <em>i.i.d.</em> y para <span class="math inline">\(\small{n}\)</span> grande, hay varios resultados sobresalientes sobre la duración de la racha exitosa más larga. <em>Rényi (1970), Csörgö (1979)</em>, Erdös y Rényi (1970) y Erdös y Révész (1975) muestran que, cuando <span class="math inline">\(\small{n \rightarrow \infty}\)</span></p>
<!--Ecuación 3.26.2--->
<div class="math">
<span class="math display">\[\begin{equation}
\frac{L_n(S)}{\log_{1/p}(n)} \xrightarrow{a.s} 1
\end{equation}\]</span>
</div>
<p>A este resultado se le suele denominar la nueva ley de los grandes números.</p>
<p>En el Capítulo 5, desarrollaremos una aproximación de grande desviación para la probabilidad de <span class="math inline">\(\small{L_n(S)}\)</span> bajo ensayos <em>i.i.d.</em> (y Markov-Dependientes homogéneos):</p>
<!--Ecuación 3.26.3--->
<div class="math">
<span class="math display">\[\begin{equation}
\mathbb{P}\big(L_n(S)\leq  k\big)\sim \exp\{-n\beta\}
\end{equation}\]</span>
</div>
<p>en donde <span class="math inline">\(\small{\beta=-\log(\lambda_{[1]})}\)</span> y <span class="math inline">\(\small{\lambda_{[1]}}\)</span> es el valor propio más grande de la submatriz de probabilidad de transición esencial <span class="math inline">\(\small{\boldsymbol{N_t}}\)</span> (con <span class="math inline">\(\small{p_t}\)</span> y <span class="math inline">\(\small{q_t}\)</span> constantes) dada por la <em>ecuación (3.25)</em>.</p>
</section>
<section id="distribución-del-tiempo-de-espera-de-una-racha-exitosa" class="level4">
<h4 class="anchored" data-anchor-id="distribución-del-tiempo-de-espera-de-una-racha-exitosa">3.7 Distribución del tiempo de espera de una Racha Exitosa</h4>
<p>Sea <span class="math inline">\(\small{\Lambda=S\cdots S}\)</span> el patrón simple de <span class="math inline">\(\small{k}\)</span> éxitos consecutivos y defina la variable aleatoria <span class="math inline">\(\small{W(\Lambda)}\)</span> como el tiempo de espera para que ocurra el patrón <span class="math inline">\(\small{\Lambda}\)</span>, es decir <!--Ecuación 3.26.3---></p>
<div class="math">
<span class="math display">\[\begin{equation}
W(\Lambda)=\inf\{n:X_{n-k+1}=X_{n-k+2}=\cdots=X_{n}=S\}.
\end{equation}\]</span>
</div>
<p>Por ejemplo, dado <span class="math inline">\(\small{k=3}\)</span>, <span class="math inline">\(\small{W(\Lambda)=6}\)</span> significa que el patrón <span class="math inline">\(\small{SSS}\)</span> ocurre por primera vez después de seis intentos, como en <span class="math inline">\(\small{SFFSSS}\)</span>. La distribución de <span class="math inline">\(\small{W(\Lambda)}\)</span> para los ensayos de Bernoulli a menudo se denomina distribución geométrica de orden <span class="math inline">\(\small{k}\)</span> (ver Aki 1985 e Hirano 1986).</p>
<p><strong>Teorema 3.2</strong> Dado un patrón de longitud <span class="math inline">\(\small{k\geq 1}\)</span> y una sucesión de ensayos Bernoulli <span class="math inline">\(\small{\{X_t\}}\)</span>, la distribución de <span class="math inline">\(\small{W(\Lambda)}\)</span> esta dada por:</p>
<!--Ecuación 3.27.0--->
<div class="math">
<span class="math display">\[\begin{equation}
\mathbb{P}\big(W(\Lambda)=n\big)=\boldsymbol{\xi} \boldsymbol{N_t}^{n-1}(\Lambda)\big(\boldsymbol{I-N}(\Lambda)\big)\boldsymbol{1'}
\end{equation}\]</span>
</div>
<p>en donde <span class="math inline">\(\small{\boldsymbol{\xi}=(1,0,\ldots,0)}\)</span> es un vector fila <span class="math inline">\(\small{1\times k}\)</span> y <span class="math inline">\(\small{\boldsymbol{N}(\Lambda)}\)</span> es la submatriz de probabilidades de transición esencial:</p>
<!--Ecuación 3.28--->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{M}(\Lambda)=
\begin{array}{cc}&amp;
\begin{array}{c}
0\\
1\\
\vdots\\
\vdots\\
k-1\\
\alpha
\end{array}
&amp;\left(
\begin{array}{ccccc|c}
p&amp;q&amp;0&amp;\cdots&amp;0&amp;0\\
q&amp;0&amp;p&amp;\cdots&amp;0&amp;0\\
\vdots&amp; &amp;\ddots&amp;\ddots&amp;&amp;\vdots\\
\vdots&amp;&amp;\ddots&amp;\ddots&amp;\ddots&amp;\vdots\\
q&amp;0&amp;\cdots&amp;\cdots&amp;0&amp;p\\
\hline
0&amp;0&amp;\cdots&amp;\cdots&amp;0&amp;1\\
\end{array}
\right)_{(k+1)\times(k+1)}
\end{array}=
\left(
\begin{array}{c|c}
\boldsymbol{N}(\Lambda)&amp;C\\
\hline
\boldsymbol{0} &amp; 1
\end{array}\right)
\end{equation}\]</span>
</div>
<p>Se deduce además que la función generadora de probabilidad de <span class="math inline">\(\small{W(\Lambda)}\)</span> está dada por:</p>
<!---Ecuación 3.29--->
<div class="math">
<span class="math display">\[\begin{equation}
\varphi_{W}(s)=\frac{p^ks^k(1-ps)}{1-s+qp^ks^{k+1}}
\end{equation}\]</span>
</div>
<p><strong>Prueba.</strong> Dados <span class="math inline">\(\small{\Lambda}\)</span>,<span class="math inline">\(\small{}\)</span> y <span class="math inline">\(\small{k \leq n}\)</span>, de la definición de <span class="math inline">\(\small{W(\Lambda)}\)</span> y <span class="math inline">\(\small{N_{n,k}}\)</span>, se deduce que estas dos variables aleatorias tienen la siguiente relación:</p>
<!---Ecuación 3.29.1--->
<div class="math">
<span class="math display">\[\begin{equation}
W(\Lambda) \leq n \quad \text{si y solo si}\quad N_{n,k}\geq 1 \,\,\text{para todo }\, n \geq k.
\end{equation}\]</span>
</div>
<p>Por tanto <span class="math inline">\(\small{\mathbb{P}\big(W(\Lambda)\leq n\big)=\mathbb{P}\big(N_{n,k}\geq 1\big)}\)</span> y</p>
<!---Ecuación 3.30--->
<div class="math">
<span class="math display">\[\begin{align*}
\mathbb{P}\big(W(\Lambda)\leq n\big) &amp;= \mathbb{P}\big(N_{n,k}\geq 1\big)-\mathbb{P}\big(N_{n-1,k}\geq 1\big), \\
&amp;=  \mathbb{P}\big(N_{n-1,k}= 0\big)-\mathbb{P}\big(N_{n,k}= 0\big).
\end{align*}\]</span>
</div>
<p>Puesto que sólo necesitamos el resultado general de <span class="math inline">\(\small{\mathbb{P}\big(N_{n,k}= 0\big)}\)</span> para completar la prueba, podemos, como en la sección anterior sobre la racha exitosa más larga, reemplazar los estados <span class="math inline">\(\small{(0,0),\cdots,(0,k-1)}\)</span> definidos en la <em>Sección 3.2</em> por los estados <span class="math inline">\(\small{0,1,2,\ldots,k-1}\)</span> y combinar todos los demás estados en un estado absorbente <span class="math inline">\(\small{\alpha}\)</span>. Bajo este espacio de estados reducido, la matriz de probabilidad de transición <span class="math inline">\(\small{\boldsymbol{M_t}(N_{n,k})}\)</span> se simplifica a <span class="math inline">\(\small{\boldsymbol{M}(\Lambda)}\)</span>. La ecuación (3.27) del teorema 3.2 es entonces una consecuencia inmediata de las ecuaciones (3.8), (3.30) y Teorema 3.1.</p>
<p>Note que, para <span class="math inline">\(\small{0\leq i\leq k-1,}\)</span></p>
<!---Ecuación 3.30.1--->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{e_iN}(\Lambda)=q\boldsymbol{e_0}+p\boldsymbol{e_{i+1}}.
\end{equation}\]</span>
</div>
<p>Dado <span class="math inline">\(\small{\boldsymbol{\xi=e}_0}\)</span>, y usando del resultado de multiplicación hacia adelante obtenemos la siguiente ecuación recursiva:</p>
<!---Ecuación 3.31--->
<div class="math">
<span class="math display">\[\begin{align*}
\mathbb{P}\big(W(\Lambda)= n\big) &amp;= \boldsymbol{\xi N}^{n-1}(\Lambda)\big(\boldsymbol{I-N}(\Lambda)\big)\boldsymbol{1'} \\
&amp;= \sum_{i=1}^{k}qp^{i-1}\mathbb{P}\big(W(\Lambda)=n-i\big).
\end{align*}\]</span>
</div>
<p>La anterior ecuación recursivay la condición de frontera <span class="math inline">\(\small{\mathbb{P}\big(W(\Lambda)=k\big)=p^{k}}\)</span> conducen a la siguiente ecuación recursiva para la función generadora de probabilidad <span class="math inline">\(\small{\varphi_{W}(s)}\)</span>:</p>
<!---Ecuación 3.31.1--->
<div class="math">
<span class="math display">\[\begin{equation}
\varphi_{W}(s)= s^kp^k+\sum_{i=1}^{k}qp^{i-1}s^{i}\varphi_{W}(s)
\end{equation}\]</span>
</div>
<p>Sumando las series de potencias finitas se obtiene el resultado explícito para <span class="math inline">\(\small{\varphi_{W}(s)}\)</span> dado en la Ec. (3.29), resultado que fue derivado por primera vez por Feller (1968) utilizando la teoría de la renovaciones.<span class="math inline">\(\hspace{3cm}\Box\)</span></p>
<p>Si definimos las matrices:</p>
<!---Ecuación 3.31.2--->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{A}=\left(
\begin{array}{ccccc}
q&amp;p&amp;0&amp;\cdots&amp;0\\
q&amp;0&amp;p&amp; &amp;0\\
\vdots&amp; &amp;\ddots&amp;\ddots&amp; \\
q&amp; &amp; &amp;0&amp;p\\
q&amp;0&amp;\cdots&amp;&amp;0\\
\end{array}
\right)_{k\times k},\,
\boldsymbol{B}=\left(
\begin{array}{ccccc}
0&amp;0&amp;0&amp;\cdots&amp;0\\
0&amp;0&amp;0&amp; &amp;\\
\vdots&amp; &amp;\ddots&amp;\ddots&amp; \\
0&amp; &amp; &amp;0&amp;0\\
p&amp;0&amp;\cdots&amp;&amp;0\\
\end{array}
\right)_{k\times k}
\end{equation}\]</span>
</div>
<!---Ecuación 3.31.1--->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{A}^{\ast}=(1)_{1\times 1}\,\, \text{y}\,\, \boldsymbol{B}^{\ast}=(0\,\,0\,\,\cdots \, 0\,\,p)'_{k\times 1}
\end{equation}\]</span>
</div>
<p>y sea <span class="math inline">\(\small{W(m,\Lambda)}\)</span> el tiempo de espera para la <span class="math inline">\(\small{m-}\)</span>ésima racha de <span class="math inline">\(\small{k}\)</span> éxitos consecutivos (sin solapamiento). De forma similar al desarrollo anterior para <span class="math inline">\(\small{W(\Lambda)}\)</span>, la distribución de la variable aleatoria <span class="math inline">\(\small{W(m,\Lambda)}\)</span> puede ser obtenida usando la Ecuación (3.27) al remplazar la matriz de probabilidades de transición <span class="math inline">\(\small{W(\Lambda)}\)</span>, por:</p>
<!---Ecuación 3.31.3--->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{W}(m,\Lambda)=\left(
\begin{array}{ccccc}
\boldsymbol{A}&amp;\boldsymbol{A}&amp; &amp;\boldsymbol{O}&amp;\\
&amp;\ddots &amp; \ddots&amp; &amp;\\
&amp; &amp;\boldsymbol{A}&amp;\boldsymbol{B}&amp; \\
&amp;\boldsymbol{O} &amp;&amp;\boldsymbol{A}&amp;\boldsymbol{B^{\ast}}\\
&amp; &amp; &amp;&amp;\boldsymbol{A^{\ast}}\\
\end{array}
\right)_{(mk+1)\times (mk+1)}
\end{equation}\]</span>
</div>
<p>Obsérvese que la matriz de probabilidad de transición <span class="math inline">\(\small{\boldsymbol{M}(\Lambda)}\)</span> de la <em>Ec. (3.28)</em> es el caso especial de <span class="math inline">\(\small{\boldsymbol{M}(m,\Lambda)}\)</span> con <span class="math inline">\(\small{m=1}\)</span>. Puesto que <span class="math inline">\(\small{W(m,\Lambda)=\displaystyle\sum_{i=1}^{m}W_i(\Lambda)}\)</span>, donde <span class="math inline">\(\small{W_i(\Lambda)}\)</span> representa el tiempo de espera desde la <span class="math inline">\(\small{(i-1)-}\)</span>ésima ocurrencia hasta la <span class="math inline">\(\small{(i)-}\)</span>ésima ocurrencia del patrón <span class="math inline">\(\small{\Lambda}\)</span>, y puesto que las variables aleatorias <span class="math inline">\(\small{W(\Lambda)}\)</span> son <em>i.i.d.</em>, se deduce de la Ec. (3.29) que la función generadora de probabilidad de <span class="math inline">\(\small{W(m,\Lambda)}\)</span> es:</p>
<!---Ecuación 3.32--->
<div class="math">
<span class="math display">\[\begin{equation}
\varphi_{W(m,\Lambda)}^{m}(s)=\varphi_{W}^{m}(s)=\Bigg(\frac{p^ks^k(1-ps)}{1-s+qp^ks^{k+1}}\Bigg)^{m}.
\end{equation}\]</span>
</div>
<p>La función generadora de probabilidad <span class="math inline">\(\small{\varphi_{W}(s)}\)</span> siempre existe para todo <span class="math inline">\(\small{|s| \leq 1}\)</span></p>
<p>Esto se desprende de su definición y del hecho de que:</p>
<!---Ecuación 3.32.1--->
<div class="math">
<span class="math display">\[\begin{equation}
|\varphi_{W}(s)|\leq\sum_{n=1}^{\infty}|s^{n}|\cdot\mathbb{P}(W=n)\leq\sum_{n=1}^{\infty}\mathbb{P}(W=n)=1.
\end{equation}\]</span>
</div>
<p>Sin embargo, la función generadora de probabilidad <span class="math inline">\(\small{\varphi_{W}(s)}\)</span> puede existir más allá de la región <span class="math inline">\(\small{|s| \leq 1}\)</span>. La región exacta varía de un problema a otro. Volveremos a discutir la mayor región de existencia de <span class="math inline">\(\small{\varphi_{W}(s)}\)</span> en la sección 5.7.</p>
<p>La distribución de <span class="math inline">\(\small{W(m,\Lambda)}\)</span> también puede obtenerse mediante la ecuación</p>
<!---Ecuación 3.32.2--->
<div class="math">
<span class="math display">\[\begin{equation}
\mathbb{P}\big(W(m,\Lambda)=n\big)=\frac{1}{n!}\frac{d^{n}}{ds^{n}}\varphi_{W(m,\Lambda)}(s)\Bigr|_{s=0}.
\end{equation}\]</span>
</div>
<p>enfoque que puede obtenerse más fácilmente utilizando software de manipulación simbólica (por ejemplo, MAPLE o MATLAB). En el capítulo 5 se ofrece un tratamiento más detallado de las distribuciones de tiempo de espera para patrones simples y compuestos en ensayos <em>i.i.d.</em> y Markov-Dependientes multiestado.</p>
</section>
<section id="ejemplos-numéricos" class="level4">
<h4 class="anchored" data-anchor-id="ejemplos-numéricos">3.8 Ejemplos numéricos</h4>
<p>Antes de estudiar estadísticas de rachas más complejas, en esta sección proporcionamos algunos resultados numéricos para las estadísticas de rachas y los tiempos de espera descritos en las secciones anteriores con el fin de ilustrar los resultados teóricos. Dada la matriz (o matrices) de probabilidad de transición de la cadena de Markov incrustada <span class="math inline">\(\small{\{Y_t\}}\)</span> , en general sólo necesitamos dos tipos de fórmulas, en las formas de las <em>Ecs. (3.8)</em> y <em>(3.27)</em>, para evaluar las distribuciones de <span class="math inline">\(\small{X_n(\Lambda)}\)</span> y <span class="math inline">\(\small{W(\Lambda)}\)</span>, respectivamente. Las fórmulas son sencillas y eficientes desde el punto de vista computacional, adecuadas incluso para <span class="math inline">\(\small{n}\)</span> muy grandes. Los resultados numéricos que aquí se presentan también pueden servir para comprobar los propios cálculos de programación. En todos los ejemplos considerados, el tiempo de cálculo para obtener cada distribución es mínimo, una fracción de segundo en un PC actual.</p>
<p>En la <em>Tabla 3.1</em> se presentan las distribuciones exactas y las medias de las variables aleatorias <span class="math inline">\(\small{E_{15,2},\, G_{15,2},\,N_{15,2},\, M_{15,2}}\)</span> y <span class="math inline">\(\small{L_{15}(S)}\)</span> bajo el supuesto de que <span class="math inline">\(\small{\{X_t\}}\)</span>es una secuencia de ensayos independientes de dos estados con probabilidades <span class="math inline">\(\small{p_t=1/(t+1)}\)</span> para <span class="math inline">\(\small{t=1,2,\ldots,15}\)</span>.</p>
<p>La <em>Tabla 3.2</em> muestra las distribuciones del tiempo de espera de la primera racha con éxito de longitud <span class="math inline">\(\small{k}\)</span>, para varios valores de <span class="math inline">\(\small{k}\)</span> y probabilidades de estado <span class="math inline">\(\small{p_t}\)</span>. En los capítulos 5 y 7 se ofrecen más resultados numéricos sobre las distribuciones del tiempo de espera.</p>
</section>
<section id="número-de-éxitos-en-rachas-éxitosas-de-longitud-mayor-o-igual-que-smallk." class="level4">
<h4 class="anchored" data-anchor-id="número-de-éxitos-en-rachas-éxitosas-de-longitud-mayor-o-igual-que-smallk.">3.9 Número de éxitos en rachas éxitosas de longitud mayor o igual que <span class="math inline">\(\small{k}\)</span>.</h4>
<p>Sea <span class="math inline">\(\small{S_{n,k}}\)</span> el número total de éxitos en rachas de éxitos de longitud mayor o igual que <span class="math inline">\(\small{}\)</span>, para <span class="math inline">\(\small{k=1,2,\ldots,n}\)</span>. Puede escribirse como</p>
<!---Ecuación 3.33--->
<div class="math">
<span class="math display">\[\begin{equation}
S_{n,k}=\sum_{i=k}^{n}iR_n(i),
\end{equation}\]</span>
</div>
<p>en donde <span class="math inline">\(\small{R_n(i)}\)</span>, para <span class="math inline">\(\small{i=k,\ldots,n}\)</span> es el número de rachas éxitosas de longitud exactamente igual a <span class="math inline">\(\small{i}\)</span> en una sucesión <span class="math inline">\(\small{\{X_t\}}\)</span>. Para <span class="math inline">\(\small{k=1}\)</span>, la Ec. (3.33) es equivalente al número total de éxitos en la sucesión <span class="math inline">\(\small{\{X_t\}}\)</span>, es decir:</p>
<!---Ecuación 3.33.1--->
<div class="math">
<span class="math display">\[\begin{equation}
S_{n,1}=\sum_{i=k}^{n}I_{X_i},
\end{equation}\]</span>
</div>
<p>en donde <span class="math inline">\(\small{I_{X_i}=1}\)</span> cuando el <span class="math inline">\(\small{i-}\)</span>ésimo ensayo es éxito y cero en otro caso. Si <span class="math inline">\(\small{\{X_t\}}\)</span> es una sucesión de ensayos Bernoulli, entonces <span class="math inline">\(\small{S_{n,1}}\)</span> tiene distribuciones binomial exacta y normal en el límite, respectivamente. De manera más general, para el caso <span class="math inline">\(\small{\{X_t\}}\)</span> es una sucesión de variables aleatorias Markov-Dependientes, la estadística <span class="math inline">\(\small{S_{n,k}}\)</span> también tiene una distrubución límite normal, como determino <em>Nagaev (1957)</em> para <span class="math inline">\(\small{k=1}\)</span> y <em>Fu, Lou, Bai y Li (2002)</em> para <span class="math inline">\(\small{k \geq 2}\)</span>. En esta sección, sólo estudiamos la distribución exacta de <span class="math inline">\(\small{S_{n,k}}\)</span> con <span class="math inline">\(\small{k \geq 2}\)</span>.</p>
<p>Sea <span class="math inline">\(\small{L_j}\)</span>, para <span class="math inline">\(\small{j \geq 2}\)</span>, la longitud de la racha de éxitos situada entre el <span class="math inline">\(\small{(j-1)-}\)</span>ésimo y el <span class="math inline">\(\small{j-}\)</span> ésimo fallo en la sucesión <span class="math inline">\(\small{\{X_t\}}\)</span>, con <span class="math inline">\(\small{L_1=0}\)</span> si el primer ensayo es un fallo y <span class="math inline">\(\small{L_1=l}\)</span> si los primeros <span class="math inline">\(\small{l}\)</span> ensayos son éxitos y el <span class="math inline">\(\small{(j+1)-}\)</span>ésimo ensayo es un fallo. Para un índice de tiempo <span class="math inline">\(\small{t}\)</span> dado, sea <span class="math inline">\(\small{m_t}\)</span> el número de fracasos en la subsecuencia <span class="math inline">\(\small{X_1, X_2,\ldots, X_t}\)</span> y sea <span class="math inline">\(\small{L_t^{\star}}\)</span> el número de éxitos que se producen después del <span class="math inline">\(\small{m_t-}\)</span>ésimo fracaso en esta subsecuencia. Nótese que <span class="math inline">\(\small{0 \leq L_{t}^{\star} \leq t}\)</span> y <span class="math inline">\(\small{0\leq L_t^{\star} \leq L_{m_t+1}}\)</span>. Por otra parte, <span class="math inline">\(\small{S_{t,k}}\)</span>, tal como se define en la <em>Ec. (3.33)</em>, también se puede escribir como:</p>
<!---Ecuación 3.34--->
<div class="math">
<span class="math display">\[\begin{equation}
S_{t,k}=\sum_{j=1}^{m_t}L_{j}(k)+L_t^{\star}(t),
\end{equation}\]</span>
</div>
<p>con <!---Ecuación 3.35---></p>
<div class="math">
<span class="math display">\[\begin{equation}
L_{j}(k)=L_j\cdot I_{\{L_j\geq k\}}\quad \text{y}\quad L_{j}^{\star}(k)=L_j^{\star}\cdot I_{\{L_j^{\star} \geq k\}}.
\end{equation}\]</span>
</div>
<p>Acá <span class="math inline">\(\small{I_{\{L_j \geq k\}}}\)</span>, es la función indicadora del evento <span class="math inline">\(\small{\{L_j \geq k\}}\)</span>, es decir, es igual a uno cuando (<span class="math inline">\(\small{I_{\{L_j^{\star} \geq k\}}}\)</span>, se define de manera análoga) Para capturar la información relevante en la subsucesión <span class="math inline">\(\small{\{X_1,X_2,\cdots, X_t\}}\)</span> definimos una nueva sucesión de variables aleatorias en la forma del vector de dos componentes</p>
<!---Ecuación 3.36--->
<div class="math">
<span class="math display">\[\begin{equation}
Y_t=\big( S_{t,k},E_{t}(t)\big),\,\, t=1,2,\ldots,n,
\end{equation}\]</span>
</div>
<p>en donde <span class="math inline">\(\small{S_{t,k}}\)</span> indica el número total de éxitos en rachas exitosas de longitud mayor o igual a <span class="math inline">\(\small{k}\)</span> en los primeros <span class="math inline">\(\small{t}\)</span> ensayos, y <span class="math inline">\(\small{E_{t}(k)}\)</span> es la variable aleatoria de <em>bloque final</em> dada por:</p>
<!---Ecuación 3.35--->
<div class="math">
<span class="math display">\[\begin{equation}
E_{t}(k)= L_{t}^{\star}\big(1-I_{\{L_j^{\star}\geq k\}}\big)+k^{+}\cdot I_{\{L_j^{\star} \geq k\}}.
\end{equation}\]</span>
</div>
<p>En esta expresión, el símbolo <span class="math inline">\(\small{k^{+}}\)</span> representa el estado donde <span class="math inline">\(\small{L_t}\)</span> es mayor o igual que <span class="math inline">\(\small{k}\)</span>.</p>
<p>El bloque final <span class="math inline">\(\small{E_t(k)}\)</span> representa la longitud de la racha de éxitos contando hacia atrás desde el <span class="math inline">\(\small{t-}\)</span>ésimo ensayo, con <span class="math inline">\(\small{E_t(k)=0}\)</span> si el <span class="math inline">\(\small{t-}\)</span>ésimo ensayo es un fracaso y <span class="math inline">\(\small{E_t(k)=k^{+}}\)</span> si la longitud es mayor o igual a <span class="math inline">\(\small{k}\)</span>. Más específicamente, considere que desde el 1 <span class="math inline">\(\small{ m_t-}\)</span>ésimo (o más reciente) fracaso <span class="math inline">\(\small{F}\)</span> hasta el final de la subsucesión <span class="math inline">\(\small{\{X_1,X_2,\cdots, X_t\}}\)</span> sólo podemos tener los siguientes resultados posibles: <span class="math inline">\(\small{\{F,FS,\cdots,FS\cdots S,\,\text{or}\, S\cdots S\, \text{si } m_t = 0\}}\)</span>; la variable aleatoria <span class="math inline">\(\small{E_t(k)}\)</span> es igual al número de éxitos en estos resultados si el número es menor que <span class="math inline">\(\small{k}\)</span>, y <span class="math inline">\(\small{E_t(k)=k^{+}}\)</span> si es igual o mayor que <span class="math inline">\(\small{k}\)</span>. Este bloque final de los primeros <span class="math inline">\(\small{t}\)</span> ensayos proporciona información esencial sobre las probabilidades de transición de <span class="math inline">\(\small{Y_t}\)</span> a <span class="math inline">\(\small{Y_{t+1}}\)</span>.</p>
<p>Definimos el espacio de estados</p>
<!--Ecuación 3.37------>
<div class="math">
<span class="math display">\[\begin{equation}
\Omega =\{(u,v):u=0,k,\cdots,n-1,n\,\, \text{y}\,\, v=0,1,\cdots,k-1,k^{+}\},
\end{equation}\]</span>
</div>
<p>con tamaño <span class="math inline">\(\small{d=\text{card}(\Omega)=(n-k+2)(k+1)}\)</span>, y consideraremos aquí el caso en que la sucesión <span class="math inline">\(\small{\{X_t\}}\)</span> es una cadena de Markov homogénea con probabilidades de transición <span class="math inline">\(\small{p_{FF},p_{Fs},p_{SF}}\)</span> y <span class="math inline">\(\small{p_{SS}}\)</span>. En nuestro procedimiento de recuento, la sucesión de vectores aleatorios <span class="math inline">\(\small{Y_t=\big( S_{t,k},E_{t}(t)\big),\,\, t=1,2,\ldots,n,}\)</span> definida en <span class="math inline">\(\small{\Omega}\)</span> obedece las siguientes reglas:</p>
<p><em>(i)</em> Dado <span class="math inline">\(\small{Y_{t-1}=(x,0)}\)</span>, entonces <span class="math inline">\(\small{Y_{t}=(x,0)}\)</span> con probabilidad <span class="math inline">\(\small{p_{FF}}\)</span> si el resultado del <span class="math inline">\(\small{t-}\)</span>ésimo ensayo es <span class="math inline">\(\small{F}\)</span>, e <span class="math inline">\(\small{Y_{t}=(x,1)}\)</span> con probabilidad <span class="math inline">\(\small{p_{FS}}\)</span> si el resultado del <span class="math inline">\(\small{t-}\)</span>ésimo ensayo es <span class="math inline">\(\small{S}\)</span>.</p>
<p><em>(ii)</em> Dado <span class="math inline">\(\small{Y_{t-1}=(x,y)}\)</span> para <span class="math inline">\(\small{1\leq y \leq k-2}\)</span> entonces <span class="math inline">\(\small{Y_{t}=(x,0)}\)</span> con probabilidad <span class="math inline">\(\small{p_{SF}}\)</span> si el resultado del <span class="math inline">\(\small{t-}\)</span>ésimo ensayo es <span class="math inline">\(\small{F}\)</span>, e <span class="math inline">\(\small{Y_{t}=(x,y+1)}\)</span> con probabilidad <span class="math inline">\(\small{p_{SS}}\)</span> si el resultado del <span class="math inline">\(\small{t-}\)</span>ésimo ensayo es <span class="math inline">\(\small{S}\)</span>.</p>
<p><em>(iii)</em> Dado <span class="math inline">\(\small{Y_{t-1}=(x,k-1)}\)</span>, entonces <span class="math inline">\(\small{Y_{t}=(x,0)}\)</span>, con probabilidad <span class="math inline">\(\small{p_{SF}}\)</span> si el resultado del <span class="math inline">\(\small{t-}\)</span>ésimo ensayo es <span class="math inline">\(\small{F}\)</span>, e <span class="math inline">\(\small{Y_{t-1}=(x+k,k^{+})}\)</span>, con probabilidad <span class="math inline">\(\small{p_{SS}}\)</span> si el resultado del <span class="math inline">\(\small{t-}\)</span>ésimo ensayo es <span class="math inline">\(\small{S}\)</span>.</p>
<p><em>(iv)</em> Dado <span class="math inline">\(\small{Y_{t-1}=(x,k^{+})}\)</span>, entonces <span class="math inline">\(\small{Y_{t}=(x,0)}\)</span> con probabilidad <span class="math inline">\(\small{p_{SF}}\)</span> si el resultado del <span class="math inline">\(\small{t-}\)</span>ésimo ensayo es <span class="math inline">\(\small{F}\)</span>, e <span class="math inline">\(\small{Y_{t}=(x+1,k^{+})}\)</span> con probabilidad <span class="math inline">\(\small{p_{SS}}\)</span> si el resultado del <span class="math inline">\(\small{t-}\)</span>ésimo prueba es <span class="math inline">\(\small{S}\)</span>.</p>
<p>A la vista de nuestra construcción, la sucesión <span class="math inline">\(\small{\{Y_t = \big( S_{t,k}, E_t(k) \big) : t = 1, 2,..., n\}}\)</span> forma una cadena de Markov homogénea con matriz de probabilidad de transición:</p>
<!---Ecuación 3.37.7--->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{M}=\big( p_{(x,y)\times(u,v)}\big)_{d\times d}
\end{equation}\]</span>
</div>
<p>donde las probabilidades de transición <span class="math inline">\(\small{p_{(x,y)\times(u,v)}}\)</span>, bajo orden lexicográfico de los estados <span class="math inline">\(\small{(\cdot,\cdot)}\)</span>, se pueden especificar explícitamente de la siguiente manera. Dado <span class="math inline">\(\small{(x,y)\in \Omega}\)</span>,</p>
<!----Ecuación 3.38--->
<div class="math">
<span class="math display">\[\begin{equation}
p_{(x,y)(u,v)}(t) =
\begin{cases}
p_{FF} &amp; \begin{array}{l} \text{Si}\,\, y=v=0 \,\, \text{y}\,\, u=x, \end{array} \\
p_{FS} &amp; \begin{array}{l} \text{Si}\,\, y=0,\,v=1 \,\, \text{y}\,\, u=x, \end{array}
\\
p_{SF} &amp; \begin{array}{l} \text{Si}\,\, y\neq 0,\,v=0\,\, \text{y}\,\, u=x, \end{array}
\\
p_{SS} &amp; \begin{array}{l} \text{Si}\,\, 1 \leq y \leq k-2,\,\,v=y+1\,\, \,\,\text{e}\,\, u=x,\\
\text{o si}\,\, y=k-1,\,\, v=k^{+}\,\,\text{e}\,\, u=x+k,\\
\text{o si}\,\, y=k^{+},\,\, v=k^{+}\,\,\text{e}\,\, u=x+1\\
\end{array}
\\
1 &amp; \begin{array}{l} \text{Si} \,\, y=v\,\,\text{y}\,\, u=x=n\end{array} \\
0 &amp; \begin{array}{l} \text{Otro caso}. \end{array}
\end{cases}
\end{equation}\]</span>
</div>
<p>Por lo tanto, la variable aleatoria <span class="math inline">\(\small{S_{n,k}}\)</span> es una Cadena de Markov incrustable y las probabilidades exactas se pueden obtener de:</p>
<!---Ecuación 3.39--->
<div class="math">
<span class="math display">\[\begin{equation}
\mathbb{P}\big(S_{n,k}= x\big) = \boldsymbol{\xi_0 M}^{n-1}\boldsymbol{U}(C_x),\,\, x=0,k,\ldots,n
\end{equation}\]</span>
</div>
<p>donde el vector fila <span class="math inline">\(\small{\boldsymbol{\xi_0}=(q_0,p_0,0,\ldots,0)_{1 \times d}}\)</span> es la distribución inicial de <span class="math inline">\(\small{Y_1}\)</span>, la partición <span class="math inline">\(\small{\{C_x\}}\)</span> se define como:</p>
<!---Ecuación 3.37.7--->
<div class="math">
<span class="math display">\[\begin{equation}
C_x =\{(x,y):y=0,1,\cdots,k-1,k^{+}\},\,\,x=0,k,\cdots,n,
\end{equation}\]</span>
</div>
<p>y <span class="math inline">\(\small{\boldsymbol{U}'(C_x)}\)</span> es la transposición del vector fila <span class="math inline">\(\small{\boldsymbol{U}(C_x)=(0,\ldots,0,1,\ldots,1,0,\ldots,0)}\)</span> con unos en las coordenadas correspondientes a los estados de <span class="math inline">\(\small{C_x}\)</span>.</p>
<p>Para comprender mejor los efectos de los distintos parámetros, en la Figura 3.1 se muestran gráficamente las distribuciones de <span class="math inline">\(\small{S_{n,k}}\)</span> para algunos casos representativos con <span class="math inline">\(\small{n=15,30,60}\)</span>, en los que se supone la distribución inicial <span class="math inline">\(\small{\boldsymbol{\xi_0}=(1,0,\ldots,0)}\)</span>. Cuando <span class="math inline">\(\small{p_{SS}}\)</span> es pequeño (por ejemplo, <span class="math inline">\(\small{p_{SS}=0.2}\)</span>), los efectos de los parámetros sobre la distribución son menos pronunciados, por lo que en la Figura 3.1 sólo se presentan casos con valores grandes de <span class="math inline">\(\small{p_{SS}\,(=0.8)}\)</span>. A efectos de comparación, también se incluyen las esperanzas.</p>
<p>Para <span class="math inline">\(\small{n}\)</span> fijo, el efecto de <span class="math inline">\(\small{k}\)</span> y <span class="math inline">\(\small{p_{FS}}\)</span> puede resumirse como sigue. Para <span class="math inline">\(\small{k}\)</span> pequeño <span class="math inline">\(\small{(k=2)}\)</span> , la distribución de <span class="math inline">\(\small{S_{n,k}}\)</span> se suaviza y adquiere forma de campana a medida que aumenta <span class="math inline">\(\small{n}\)</span> (de la Figura 3.1(a) a (d) a (g)), y esta tendencia se amplifica con valores mayores de <span class="math inline">\(\small{p_{FS}}\)</span>. A medida que <span class="math inline">\(\small{k}\)</span> aumenta, las distribuciones se alejan de la forma normal y se vuelven muy sesgadas hacia la derecha (por ejemplo, de la Figura 3.1(d) a (e) a (f)). La distribución de <span class="math inline">\(\small{S_{n,k}}\)</span> sólo puede aproximarse a una distribución normal cuando <span class="math inline">\(\small{k}\)</span> es mucho menor que <span class="math inline">\(\small{n}\)</span>, y las aproximaciones normales deben utilizarse con precaución. En <em>Fu, Lou, Bai y Li (2002)</em> se ofrecen más detalles sobre la distribución límite de <span class="math inline">\(\small{S_{n,k}}\)</span>.</p>
</section>
</section>
<section id="capitulo-4-rachas-y-patrones-en-ensayos-multi-estados" class="level3">
<h3 class="anchored" data-anchor-id="capitulo-4-rachas-y-patrones-en-ensayos-multi-estados">Capitulo 4: Rachas y Patrones en ensayos Multi-Estados</h3>
<section id="introducción-1" class="level4">
<h4 class="anchored" data-anchor-id="introducción-1">4.1 Introducción</h4>
<p>En el capítulo 3, analizamos las ideas clave de la técnica de Incrustación de Cadenas de Markov Finitas (ICMF) para obtener las distribuciones exactas del número de rachas y patrones con éxitos en una sucesión de ensayos de dos estados. El objetivo principal de este capítulo es ampliar la técnica de ICMF para estudiar el número de rachas y patrones en una secuencia de ensayos multiestado. Podría parecer que, en principio, la ampliación debería ser sencilla y requerir sólo pequeñas modificaciones. Sin embargo, no es así, especialmente cuando el patrón es complejo y la sucesión <span class="math inline">\(\small{\{X_t\}}\)</span> está formada por ensayos multiestado Markov-Dependientes. Las principales dificultades se deben a la complejidad de construir una cadena de Markov finita adecuada asociada a la variable aleatoria <span class="math inline">\(\small{X_n(\Lambda)}\)</span>, especialmente en el proceso de obtención de las probabilidades de transición. Para superar estas dificultades, introducimos el <em>principio de avance y retroceso</em>. En este capítulo nos centraremos en la utilización del <em>principio de avance y retroceso</em> para obtener las distribuciones de patrones simples y compuestos. De hecho, el <em>principio de avance y retroceso</em> desempeña un papel indispensable en la construcción de la Cadena de Markov Incrustada para casi todas las aplicaciones cubiertas por este libro.</p>
</section>
<section id="principio-de-avance-y-retroceso-con-recuento-sin-solapamiento" class="level4">
<h4 class="anchored" data-anchor-id="principio-de-avance-y-retroceso-con-recuento-sin-solapamiento">4.2 Principio de avance y retroceso con recuento sin solapamiento</h4>
<p>Comencemos con el caso simple de que <span class="math inline">\(\small{\{X_t\}_{t=1}^{n}}\)</span> es una secuencia de <em>i.i.d.</em> ensayos miltiestados. Cada ensayo tiene <span class="math inline">\(\small{m\,\, (m\geq 2)}\)</span> resultados posibles (estados o símbolos), etiquetados como <span class="math inline">\(\small{\mathscr{S} =\{b_1,\ldots, b_m\}}\)</span> y que ocurren con probabilidades <span class="math inline">\(\small{p_1,p_2,\ldots,p_m,}\)</span> respectivamente. Denotamos <span class="math inline">\(\small{X_n(\Lambda)}\)</span> al número de patrones simples <span class="math inline">\(\small{\Lambda}\)</span> <em>no-superpuestos</em> en la sucesión <span class="math inline">\(\small{\{X_t\}}\)</span>. Primero, nos gustaría presentar el <em>principio de avance y retroceso</em> para la técnica de incrustación de cadenas de Markov finitas, un principio que guiará la construcción de una cadena de Markov incrustada <span class="math inline">\(\small{\{Y_t\}}\)</span> y la determinación de sus matrices de probabilidad de transición. Para facilitar la discusión, el principio de avance y retroceso se introduce mediante el siguiente ejemplo.</p>
<p><strong>Ejemplo 4.1</strong> Consideremos el patrón simple <span class="math inline">\(\small{\Lambda=\{b_{1}b_{1}b_{2}\}}\)</span> en una sucesión de ensayos de tres estados (<span class="math inline">\(\small{\mathscr{S} =\{b_1,b_{2}, b_{3}\}}\)</span>).</p>
<p><em>(i)</em> Descompongamos el patrón <span class="math inline">\(\small{\Lambda=b_{1}b_{1}b_{2}}\)</span> en un conjunto de <em>subpatrones secuenciales</em> <span class="math inline">\(\small{\mathscr{S}(\Lambda) =\{b_1,b_{1}b_{1}, b_{1}b_{1}b_{2}\}}\)</span>. Definiendo</p>
<!---Ecuación 4.1--->
<div class="math">
<span class="math display">\[\begin{equation}
\mathscr{E}=\mathscr{S}\, \cup \,\mathscr{S}(\Lambda)=\{b_{1},b_{2},b_{3},b_{1}b_{1}, b_{1}b_{1}b_{2}\}
\end{equation}\]</span>
</div>
<p>como un conjunto de bloques finales inducidos por el patrón <span class="math inline">\(\small{ b_{1}b_{1}b_{2}}\)</span> con respecto a sucesión de ensayos <span class="math inline">\(\small{\{X_t\}}\)</span></p>
<p><em>(ii)</em> Sea <span class="math inline">\(\small{{\omega} =(x_{1},\ldots, x_n)}\)</span> una realización de una sucesión de <span class="math inline">\(\small{n}\)</span> ensayos de tres estados. Definiendo el espacio de estados:</p>
<!---Ecuación 4.2--->
<div class="math">
<span class="math display">\[\begin{equation}
\Omega =\{(u,v):u=0,1,\cdots,[n
/3],\,\, v\in \mathscr{E}\}\,\cup \,\{\emptyset\}\, -\,\{(0,b_{1}b_{1}b_{2})\}
\end{equation}\]</span>
</div>
<p>y una cadena de Markov</p>
<!---Ecuación 4.3--->
<div class="math">
<span class="math display">\[\begin{equation}
\big\{Y_t=\big(X_n(\Lambda), E_t\big),\,t=0,1,2,\ldots,n\big\}
\end{equation}\]</span>
</div>
<p>operando sobre <span class="math inline">\(\small{\omega}\)</span> como</p>
<!---Ecuación 4.3.1--->
<div class="math">
<span class="math display">\[\begin{equation}
Y_t(\omega)=(u,v),\,\, \text{para}\,\, t=1,\ldots,n
\end{equation}\]</span>
</div>
<p>en donde: <!---Ecuación 4.3.2---></p>
<div class="math">
<span class="math display">\[\begin{align*}
u &amp;=\begin{cases}
\begin{array}{l}
X_n(\Lambda)(\omega)=\,\text{el número total de patrones no-solapados}\,\Lambda\,\\
\text{en los primeros}\,\, t\,\, \text{ensayos contando hacia delante desde} \\
\text{el primer ensayo hasta el}\,\, t-ésimo\,\, \text{ensayo, y}
\end{array}
\end{cases}\\
\\
v &amp;=\begin{cases}
\begin{array}{l}
E_t(w) =\,\text{el bloque final más largo en}\ \mathscr{S},\\
\text{contando hacia atrás desde}\, X_t.
\end{array}
\end{cases}
\end{align*}\]</span>
</div>
<p>Las definiciones de <span class="math inline">\(\small{u}\)</span> y <span class="math inline">\(\small{v}\)</span> para la sucesión de los primeros <span class="math inline">\(\small{t}\)</span> ensayos se ilustran gráficamente en la figura 4.1. Para que la cadena de Markov incrustada <span class="math inline">\(\small{\{Y_t\}}\)</span> y el concepto de bloque final más largo sean más transparentes, consideremos la siguiente realización, <span class="math inline">\(\small{\omega=(b_{3}b_{1}b_{2}b_{1}b_{1}b_{2}b_{1})}\)</span>, de una sucesión de siete ensayos de tres estados. Aplicando el principio de avance y retroceso, la correspondiente del la cadena de Markov incrustada <span class="math inline">\(\small{\{Y_t\}}\)</span> sobre <span class="math inline">\(\small{\omega}\)</span> viene dada por <span class="math inline">\(\small{\{Y_{1}(\omega)=(0,b_{3}), Y_{2}(\omega)=(0, b_{1}), Y_{3}(\omega) = (0, b_{2}), Y_{4}(\omega)= (0, b_{1}), Y_{5}(\omega)=(0, b_{1}b_{1}), Y_{6}(\omega) = (1, b_{1}b_{1}b_{2})\,\text{y}\, Y_{7}(\omega)=(1, b_{1})\}}\)</span>. Tenga en cuenta que para cada <span class="math inline">\(\small{\omega}\)</span> dada, la realización de la cadena de Markov incrustada <span class="math inline">\(\small{Y_t(\omega) = (u, v)}\)</span> está determinada únicamente por lo anterior procedimientos <em>(i)</em> y <em>(ii)</em> bajo conteo sin superposición. En palabras sencillas, el el bloque final <span class="math inline">\(\small{v}\)</span> representa el estado de formación del siguiente patrón <span class="math inline">\(\small{\Lambda}\)</span> para el subsecuencia <span class="math inline">\(\small{\{{x_1,., ,x_t} \}}\)</span> que contiene <span class="math inline">\(\small{u}\)</span> patrones completos.</p>
<p><em>(iii)</em> La cadena de Markov incrustada <span class="math inline">\(\small{\{Y_t\}}\)</span> es homogénea y su matriz de probabilidad de transición <span class="math inline">\(\small{\boldsymbol{M_t}= \big(p_{(x,z),(u,v)}\big)}\)</span> puede determinarse del siguiente modo. Por ejemplo, dado <span class="math inline">\(\small{Y_5(\omega)=(0,b_{1}b_{1})}\)</span>, como <span class="math inline">\(\small{X_{6}}\)</span> sólo puede ser uno de los tres resultados posibles <span class="math inline">\(\small{b_{1}, b_{2}}\)</span> y <span class="math inline">\(\small{b_{3}}\)</span>, el procedimiento de recuento hacia delante y hacia atrás da como resultado</p>
<!---Ecuación 4.4--->
<div class="math">
<span class="math display">\[\begin{align*}
Y_{5}(\omega) &amp; \rightarrow \quad \quad Y_{6}(\omega)
\\
(0,b_{1}b_{1}) &amp;\rightarrow  \begin{cases}
\begin{array}{cl}
(0,b_{1}b_{1}) &amp; \text{si}\,\, X_6= b_{1}\,\,(\text{con probabilidad}\, p_{1})\\
(1,b_{1}b_{1}b_{2}) &amp; \text{si}\,\, X_6= b_{2}\,\,(\text{con probabilidad}\, p_{2})\\
(0,b_{3}) &amp; \text{si}\,\, X_6= b_{3}\,\,(\text{con probabilidad}\, p_{3}),
\end{array}
\end{cases}
\end{align*}\]</span>
</div>
<p>e <span class="math inline">\(\small{Y_5(\omega)}\)</span> pasa a cualquier otro estado con probabilidad cero. De esta forma se obtienen todas las probabilidades de transición <span class="math inline">\(\small{\mathbb{P}\big(Y_t=(u,v)\mid Y_{t-1}=(x,z)\big)}\)</span>. El estado ficticio <span class="math inline">\(\small{\emptyset}\)</span> se añadirá como estado inicial con <span class="math inline">\(\small{\mathbb{P}\big(Y_{0}=\emptyset\big)=1}\)</span> y con probabilidades de transición <span class="math inline">\(\small{\mathbb{P}\big(Y_{1}=b_{i}\mid Y_0=\emptyset\big)=p_{i}}\)</span> para <span class="math inline">\(\small{i=1,2,3}\)</span>. Obsérvese que el estado <span class="math inline">\(\small{(0,\Lambda=b_{1}b_{1}b_{2})}\)</span> se eliminó del espacio de estados, ya que siempre que el bloque final <span class="math inline">\(\small{v}\)</span> sea igual a <span class="math inline">\(\small{\Lambda}\)</span> debe haber al menos una ocurrencia de el patrón en la secuencia (es decir, <span class="math inline">\(\small{u\geq1}\)</span> si <span class="math inline">\(\small{v=\Lambda}\)</span>).</p>
<p><em>(iv)</em> Dado <span class="math inline">\(\small{n}\)</span>, tenemos la siguiente partición en el espacio de estados <span class="math inline">\(\small{\Omega}\)</span>:</p>
<!---Ecuación 4.5---->
<div class="math">
<span class="math display">\[\begin{align*}
\big\{C_{\emptyset} &amp;=[\emptyset], C_{0}=[(0,b_{1}),(0,b_{2}),(0,b_{3}),(0,b_{1}b_{1})], \\
&amp; \,\,\text{y}\,\,C_{x}=[(x,v),v\in \mathscr{E}],\, x=1,\ldots,[n/3] \big\}.
\end{align*}\]</span>
</div>
<p>Para <span class="math inline">\(\small{n=5}\)</span> y la probabilidad inicial <span class="math inline">\(\small{\mathbb{P}\big(Y_0=\emptyset \big)\equiv 1}\)</span>, se deduce de los procedimientos <em>(i)</em> a <em>(iv)</em> anteriores que la cadena de Markov incrustada <span class="math inline">\(\small{\{Y_t\}_{t=0}^{5}}\)</span> está definida en el espacio de estados <span class="math inline">\(\small{\Omega=\{\emptyset, (0, b_{1}), (0, b_{2}), (0, b_{3}), (0, b_{1}b_{1}), (1, b_{1}b_{1}b_{2}), (1, b_{1}), (1, b_{2}), (1, b_{3}), (1, b_{1}b_{1})\}}\)</span> con matriz de probabilidad de transición</p>
<!----Ecuación 4.6--->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{M}=
\begin{array}{cc}&amp;
\begin{array}{c}
\emptyset\\
(0,b_{1})\\
(0,b_{2})\\
(0,b_{3})\\
(0,b_{1}b_{1})\\
(1,b_{1}b_{1}b_{2})\\
(1,b_{1})\\
(1,b_{2})\\
(1,b_{3})\\
(1,b_{1}b_{1})
\end{array}
&amp;
\left(
\begin{array}{c|cccc|ccccc}
0&amp;p_{1}&amp;p_{2}&amp;p_{3}&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\
\hline
0&amp;0&amp;p_{2}&amp;p_{3}&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\
0&amp;p_{1}&amp;p_{2}&amp;p_{3}&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\
0&amp;p_{1}&amp;p_{2}&amp;p_{3}&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\
0&amp;0&amp;0&amp;p_{3}&amp;p_{1}&amp;p_{2}&amp;0&amp;0&amp;0\\
\hline
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;p_{1}&amp;p_{2}&amp;p_{3}&amp;0\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;p_{2}&amp;p_{3}&amp;p_{1}\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;p_{1}&amp;p_{2}&amp;p_{3}&amp;0\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;p_{1}&amp;p_{2}&amp;p_{3}&amp;0\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;1\\
\end{array}
\right)
\end{array}
\end{equation}\]</span>
</div>
<p>Las probabilidades <span class="math inline">\(\small{\mathbb{P}\big(X_n(\Lambda)=5\big)=\boldsymbol{\xi_0M}^5\boldsymbol{U'}(C_x),\, x=0,1,}\)</span>, pueden computarse facilmente.</p>
<p>Para demostrar la aplicabilidad del principio de avance y retroceso a los patrones compuestos, consideremos el siguiente ejemplo.</p>
<p><strong>Ejemplo 4.2</strong> Dado <span class="math inline">\(\small{n=4}\)</span> y un patrón compuesto <span class="math inline">\(\small{\Lambda= \Lambda_{1} \cup \Lambda_{2}}\)</span>, que consiste en la unión de dos patrones simples distintos <span class="math inline">\(\small{ \Lambda_{1}=b_{1}b_{2}}\)</span> y <span class="math inline">\(\small{ \Lambda_{1}=b_{3}b_{1}}\)</span>, estamos interesados en encontrar la distribución de la variable aleatoria <span class="math inline">\(\small{X_4(\Lambda)}\)</span>, el número de ocurrencias de <span class="math inline">\(\small{\Lambda_{1}}\)</span> o <span class="math inline">\(\small{\Lambda_{2}}\)</span> en una secuencia de cuatro ensayos <em>i.i.d.</em> de tres estados. Procediendo como en el ejemplo anterior, se obtiene la cadena de Markov incrustada <span class="math inline">\(\small{\{Y_t\}}\)</span> definida en el espacio de estados</p>
<!---Ecuación 4.7---->
<div class="math">
<span class="math display">\[\begin{align*}
\Omega &amp;=\big\{\emptyset,(0,b_{1}),(0,b_{2}),(0,b_{3}),(1,b_{1}b_{2}), (1,b_{3}b_{1}), \\
&amp; \quad \quad (1,b_{1}),(1,b_{2}),(1,b_{3}),(2,b_{1}b_{2}),(2,b_{3}b_{1})\big\}.
\end{align*}\]</span>
</div>
<p>con matriz de probabilidades de transición:</p>
<!----Ecuación 4.8--->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{M}=
\begin{array}{cc}&amp;
\begin{array}{c}
\emptyset\\
(0,b_{1})\\
(0,b_{2})\\
(0,b_{3})\\
(1,b_{1}b_{2})\\
(1,b_{3}b_{1})\\
(1,b_{1})\\
(1,b_{2})\\
(1,b_{3})\\
(2,b_{1}b_{2})\\
(2,b_{3}b_{1})
\end{array}
&amp;
\left(
\begin{array}{c|ccc|ccccc|cc}
0&amp;p_{1}&amp;p_{2}&amp;p_{3}&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\
\hline
0&amp;p_{1}&amp;0&amp;p_{3}&amp;p_{2}&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\
0&amp;p_{1}&amp;p_{2}&amp;p_{3}&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\
0&amp;0&amp;p_{2}&amp;p_{3}&amp;0&amp;p_{1}&amp;0&amp;0&amp;0&amp;0&amp;0\\
\hline
0&amp;0&amp;0&amp;0&amp;p_{1}&amp;0&amp;0&amp;p_{2}&amp;p_{3}&amp;0&amp;0\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;p_{1}&amp;p_{2}&amp;p_{3}&amp;0&amp;0\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;p_{1}&amp;0&amp;p_{3}&amp;p_{2}&amp;0\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;p_{1}&amp;p_{2}&amp;p_{3}&amp;0&amp;0\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;p_{2}&amp;p_{3}&amp;0&amp;p_{1}\\
\hline
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;1&amp;0\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;1\\
\end{array}
\right)
\end{array}
\end{equation}\]</span>
</div>
<p>Las probabilidades <span class="math inline">\(\small{\mathbb{P}\big(X_n(\Lambda)=4\big)=\boldsymbol{\xi_0M}^4\boldsymbol{U'}(C_x),\, x=0,1,2}\)</span>, pueden computarse facilmente.</p>
<p>El método también puede extenderse, con modificaciones simples, a la caso donde <span class="math inline">\(\small{\{X_t\}}\)</span> es una sucesión de ensayos multiestado Markov-Dependientes.</p>
<p><strong>Ejemplo 4.3</strong> Volvamos al Ejemplo 4.1, pero consideremos aquí que <span class="math inline">\(\small{\{X_t\}}\)</span> es una secuencia de ensayos de tres estados Markov-Dependientes con matriz de probabilidad de transición:</p>
<!----Ecuación 4.8.1--->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{A}=\left(
\begin{array}{ccc}
p_{11}&amp;p_{12}&amp;p_{13}\\
p_{21}&amp;p_{22}&amp;p_{23}\\
p_{31}&amp;p_{32}&amp;p_{33}\\
\end{array}
\right)
\end{equation}\]</span>
</div>
<p>Nuestro objetivo es determinar la distribución del patrón <span class="math inline">\(\small{\Lambda=b_{1}b_{1}b_{2}}\)</span> en una secuencia de cinco ensayos. De forma análoga al Ejemplo 4.1, las probabilidades de transición de la cadena de Markov incrustada pueden obtenerse para cada estado mediante el siguiente argumento. Dado <span class="math inline">\(\small{Y_3 = (0, b_{1}b_{1})}\)</span>, por ejemplo, tenemos:</p>
<!---Ecuación 4.9--->
<div class="math">
<span class="math display">\[\begin{align*}
Y_3 &amp; \rightarrow \quad \quad \, Y_{4}\\
(0,b_{1}b_{1}) &amp;\rightarrow  \begin{cases}
\begin{array}{cl}
(0,b_{1}b_{1}) &amp; \text{si}\,\, X_{4}= b_{1}\,\,(\text{con probabilidad}\, p_{11})\\
(1,b_{1}b_{1}b_{2}) &amp; \text{si}\,\, X_{4}= b_{2}\,\,(\text{con probabilidad}\, p_{12})\\
(0,b_{3}) &amp; \text{si}\,\, X_{4}= b_{3}\,\,(\text{con probabilidad}\, p_{13}).
\end{array}
\end{cases}
\end{align*}\]</span>
</div>
<p>Las ecuaciones (4.4) y (4.9) son equivalentes, salvo que las probabilidades <span class="math inline">\(\small{p_{1}}\)</span>,<span class="math inline">\(\small{p_{2}}\)</span> y <span class="math inline">\(\small{p_{3}}\)</span> se sustituyen por <span class="math inline">\(\small{p_{11}}\)</span>,<span class="math inline">\(\small{p_{12}}\)</span> y <span class="math inline">\(\small{p_{13}}\)</span> respectivamente. Por lo tanto, la cadena de Markov incrustada <span class="math inline">\(\small{\{Y_t\}}\)</span> se define aquí en el mismo espacio de estados <span class="math inline">\(\small{\Omega}\)</span> y con matriz de probabilidad de transición:</p>
<!----Ecuación 4.10--->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{M}=
\begin{array}{cc}&amp;
\begin{array}{c}
\emptyset\\
(0,b_{1})\\
(0,b_{2})\\
(0,b_{3})\\
(0,b_{1}b_{1})\\
(1,b_{1}b_{1}b_{2})\\
(1,b_{1})\\
(1,b_{2})\\
(1,b_{3})\\
(1,b_{1}b_{1})
\end{array}
&amp;
\left(
\begin{array}{c|cccc|ccccc}
0&amp;p_{1}&amp;p_{2}&amp;p_{3}&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\
\hline
0&amp;0&amp;p_{12}&amp;p_{13}&amp;p_{11}&amp;0&amp;0&amp;0&amp;0&amp;0\\
0&amp;p_{21}&amp;p_{22}&amp;p_{23}&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\
0&amp;p_{31}&amp;p_{32}&amp;p_{33}&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\
0&amp;0&amp;0&amp;p_{13}&amp;p_{11}&amp;p_{12}&amp;0&amp;0&amp;0\\
\hline
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;p_{21}&amp;p_{22}&amp;p_{23}&amp;0\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;p_{12}&amp;p_{13}&amp;p_{11}\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;p_{21}&amp;p_{22}&amp;p_{23}&amp;0\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;p_{31}&amp;p_{32}&amp;p_{33}&amp;0\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;1\\
\end{array}
\right)
\end{array}
\end{equation}\]</span>
</div>
<p>donde las probabilidades de transición <span class="math inline">\(\small{\mathbb{P}\big(Y_{t}(u,v)=Y_{t-1}(x,z)\big)}\)</span> se obtienen como se ilustra en la <em>Ec. (4.9).</em> Obsérvese que la matriz de probabilidades de transición de la <em>Ec. (4.10)</em> tiene exactamente la misma forma que la matriz de la <em>Ec. (4.6)</em> para el caso <em>i.i.d.</em>.</p>
<p>En vista de las transiciones de estado esbozadas por las <em>Ecs. (4.4) y (4.9)</em>, que conducen a las matrices de probabilidad de transición de los <em>Ejemplos 4.1 a 4.3</em>, dadas en las Ecs. (4.6), (4.8) y (4.10) respectivamente, definimos la siguiente notación: dado <span class="math inline">\(\small{Y_{t-1} = (x, z) \in \Omega}\)</span> y <span class="math inline">\(\small{X_t = j\in \mathscr{S}}\)</span>, <!--Ecu. 4.11--></p>
<div class="math">
<span class="math display">\[\begin{equation}
(u,v)\equiv &lt;(x,z),j&gt;_{\Omega}
\end{equation}\]</span>
</div>
<p>donde el estado <span class="math inline">\(\small{(u,v)\in \Omega}\)</span> es el resultado del recuento hacia delante y hacia atrás (no solapado) cuando se incluye un resultado adicional <span class="math inline">\(\small{X_t=j}\)</span>. Para cada <span class="math inline">\(\small{(x, z)\in \Omega}\)</span>, definimos también <span class="math inline">\(\small{L(z)\in \mathscr{S}}\)</span> como el último elemento del bloque final <span class="math inline">\(\small{z}\)</span>. Entonces, para el caso general, las probabilidades de transición de la cadena de Markov incrustada <span class="math inline">\(\small{Y_t}\)</span> se especifican mediante la siguiente ecuación:</p>
<!---Ec. 4.12--->
<div class="math">
<span class="math display">\[\begin{equation}
\mathbb{P}\big(Y_t=(u,v)\mid Y_{t-1}=(x,z)\big) =\begin{cases}
p_{ij} &amp; \quad
\begin{array}{l}
\text{si}\,\, X_{t}=j\in\mathscr{S},\, L(z)=i\\
\text{y}\,\,(u,v)= &lt;(x,z),j&gt;_{\Omega}
\end{array}\\
m &amp; \quad \text{en otro caso}
\end{cases}
\end{equation}\]</span>
</div>
<p>donde <span class="math inline">\(\small{p_{ij}}\)</span> son las probabilidades de transición de la cadena de Markov <span class="math inline">\(\small{\{X_t\}}\)</span>. Si <span class="math inline">\(\small{\{X_t\}}\)</span> es una secuencia de ensayos multiestado <em>i.i.d.</em>, la <em>Ec.(4.12)</em> se convierte en</p>
<!---Ec. 4.13--->
<div class="math">
<span class="math display">\[\begin{equation}
\mathbb{P}\big(Y_t=(u,v)\mid Y_{t-1}=(x,z)\big) =\begin{cases}
p_{j} &amp; \quad
\begin{array}{l}
\text{si}\,\, X_{t}=j\in\mathscr{S},\\
\text{y}\,\,(u,v)= &lt;(x,z),j&gt;_{\Omega}
\end{array}\\
0 &amp; \quad \text{en otro caso}
\end{cases}
\end{equation}\]</span>
</div>
<p><strong>Teorema 4.1</strong> Suponiendo que <span class="math inline">\(\small{\{X_t\}}\)</span> es una cadena de Markov homogénea con matriz de probabilidad de transición <span class="math inline">\(\small{\boldsymbol{A} = \big(p_{ij}\big)_{m\times m}}\)</span>, y <span class="math inline">\(\small{\Lambda=\displaystyle{\bigcup_{i=1}^{l}\Lambda_{i}}}\)</span> es un patrón compuesto generado por <span class="math inline">\(\small{l}\)</span> patrones simples distintos <span class="math inline">\(\small{\Lambda_{i}}\)</span> que tienen la misma longitud <span class="math inline">\(\small{k}\)</span>, entonces la cadena de Markov incrustada <span class="math inline">\(\small{\big\{Y_t=\big(X_{t}(\Lambda),E_{t} \big),\,t=1,2,\,\ldots,n\big\}}\)</span> correspondiente a la variable aleatoria <span class="math inline">\(\small{X_{n}(\Lambda)}\)</span></p>
<p><em>(i)</em> se define sobre el espacio de estados:</p>
<!---Ecuación 4.14---->
<div class="math">
<span class="math display">\[\begin{align*}\Omega &amp;=\{\emptyset\}\, \cup\,\{(x,z):x=0,1,\cdots,[n
/k],\,\, z\in \mathscr{E}\}\\
&amp;\quad- \{(0,\Lambda_{i}):i=1,\cdots,l\}
-\,\{([n/k],z):k[n/k]+z(k)&gt;n\},\end{align*}\]</span>
</div>
<p>en donde <span class="math inline">\(\small{\mathscr{E} =\mathscr{S}\,\cup\Bigg(\displaystyle\bigcup_{i=1}{\mathscr{S}(\Lambda_{i})\Bigg)}}\)</span> y <span class="math inline">\(\small{z(k)\equiv [\text{longitud de}\,z] \pmod k}\)</span></p>
<p><em>(ii)</em> tiene la matriz de probabilidades de transición: <!--Ec. 4.15----></p>
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{M}=\big(p_{(x,z)(u,v)}\big)_{d\times d}
\end{equation}\]</span>
</div>
<p>en donde las probabilidades de transición estan dadas por: <!--Ec. 4.16----></p>
<div class="math">
<span class="math display">\[\begin{equation}
p_{(x,z)(u,v)}=\begin{cases}
p_{j} &amp; \,\text{si}\, (x,z)=\emptyset,\,u=0,\,v=j,\, \text{para todo}\, j \in \mathscr{S}\\ \\
p_{ij} &amp;
\begin{array}{l}
\text{si}\,(u,v)=&lt;(x,z),j&gt;_{\Omega},\, x\leq [n/k],\, j\in \mathscr{S},\\
L(z)=i,\,\text{y}\,\, kx+z(k)&lt;n
\end{array} \\ \\
1 &amp;
\begin{array}{l}
\text{si}\,(u,v)= (x,z) ,\, x= [n/k]\\
\,\text{y}\,\, k[n/k]+z(k)=n
\end{array} \\\\
m &amp; \text{en otro caso.}
\end{cases}
\end{equation}\]</span>
</div>
<p>con <span class="math inline">\(\small{d=\text{card}(\Omega)}\)</span>, el tamaño del espacio de estados <span class="math inline">\(\small{\Omega}\)</span>, igual a:</p>
<!---Ecuación 4.17---->
<div class="math">
<span class="math display">\[\begin{align*}d =1 &amp; +([n/k]+1)\times \text{card}\big(\mathscr{E}\big)-l\\
&amp; -\text{card}\Big(\big\{([n/k],z):\,z \in \mathscr{E}, \,k[n/k]+z(k)&gt;n\big\}\big),\end{align*}\]</span>
</div>
<p>y <em>(iii)</em> se obtiene la distribución:</p>
<!---Ecuación 4.18---->
<div class="math">
<span class="math display">\[\begin{equation}
\mathbb{P}\big( X_n(\Lambda)=x\big)=\boldsymbol{\mathbf{\xi}}_0\boldsymbol{M}^{n}\boldsymbol{\mathbf{U}'}( {C_x}),\,\,  x=1,2,\ldots,[n/k],
\end{equation}\]</span>
</div>
<p>en donde <span class="math inline">\(\small{\boldsymbol{\xi}_0}\)</span> es la distribución inicial especificada por <span class="math inline">\(\small{\mathbb{P}\big(Y_{0}=\emptyset\big)\equiv 1}\)</span> y <!---Ec. 4.19----></p>
<div class="math">
<span class="math display">\[\begin{align*}
C_{\emptyset} &amp;=[\emptyset],\, C_{0}=[(0,z):z\in\mathscr{S}]-[(0,\Lambda_{i}):i=1,2,\ldots,l], \\
C_{x} &amp;=  [(x,z):z\in \mathscr{E}],\, 1\leq x \leq [n/k], \, \text{y}\\
C_{[n/x]}&amp;=[([n/k],z):z\in \mathscr{E},\,k[n/k]+z(k)\leq n]
\end{align*}\]</span>
</div>
<p>son las particiones del espacio de estados <span class="math inline">\(\small{\Omega}\)</span>.</p>
<p>Nótese que el espacio de estados <span class="math inline">\(\small{\Omega}\)</span> y su tamaño <span class="math inline">\(\small{d}\)</span> son funciones de <span class="math inline">\(\small{n}\)</span>, la estructura de los patrones <span class="math inline">\(\small{\Lambda_{i},\,i=1,\ldots,l}\)</span> y la longitud del patrón común <span class="math inline">\(\small{k}\)</span>. El lector puede comprobar que los resultados de los Ejemplos 4.1 a 4.3 se deducen directamente del Teorema 4.1.</p>
<p><strong>Demostración</strong>. Dado <span class="math inline">\(\small{n}\)</span>, como la longitud de cada patrón es <span class="math inline">\(\small{k}\)</span>, el número máximo de patrones es <span class="math inline">\(\small{[n/k]}\)</span> (bajo conteo no solapado). El conjunto <span class="math inline">\(\small{\mathscr{E} =\mathscr{S}\,\cup\Bigg(\displaystyle\bigcup_{i=1}{\mathscr{S}(\Lambda_{i})\Bigg)}}\)</span> contiene todos los posibles bloques finales generados por <span class="math inline">\(\small{\mathscr{S}}\)</span> y todos los patrones, y se deduce que para recuento hacia delante y hacia atrás sin solapamiento, el espacio de estados tiene la forma <span class="math inline">\(\small{\big\{(x,z): x=0,\ldots,[n/k]},\,z\in\mathscr{E}\big\}\)</span>. Los estados <span class="math inline">\(\small{\big\{(0,\Lambda_{i}): i=1,\ldots,l}\big\}\)</span> se eliminan porque si el bloque final es <span class="math inline">\(\small{\Lambda_{i}}\)</span>, entonces debe haber al menos un patrón <span class="math inline">\(\small{\Lambda_{i}}\)</span>, en la secuencia <span class="math inline">\(\small{(x\geq 1)}\)</span>, por lo que los estados <span class="math inline">\(\small{\big\{(0,\Lambda_{i})\big\}}\)</span> son inalcanzables; por la misma razón, los estados <span class="math inline">\(\small{\big\{([n/k],z):k[k/z]+z(k)&gt;n\big\}}\)</span> tampoco pueden darse y pueden eliminarse. Así, el espacio de estados <span class="math inline">\(\small{\Omega}\)</span> de la cadena de Markov incrustada tiene la forma dada por la <em>Ec. (4.14)</em>, y su tamaño <span class="math inline">\(\small{d}\)</span> viene determinado por la <em>Ec.(4.17).</em></p>
<p>Dados <span class="math inline">\(\small{(x,z)\in \Omega,\,0\leq x \leq [n/n]}\)</span>, y <span class="math inline">\(\small{kx + z(k) &lt; n}\)</span>, si <span class="math inline">\(\small{X_{t}=j\in \mathscr{S}}\)</span> y <span class="math inline">\(\small{(u, v) = &lt; (x, z), j &gt;_{\Omega}}\)</span> , entonces, como se describe en las Ecs. <em>(4.9)</em> y <em>(4.12)</em>, se deduce que</p>
<!---Ecu. 4.19.1--->
<div class="math">
<span class="math display">\[\begin{align*}
p_{(x,z)(u,v)}=\mathbb{P}\big(Y_t=(u,v)\mid Y_{t-1}=(x,z)\big)=p_{ij},
\end{align*}\]</span>
</div>
<p>donde <span class="math inline">\(\small{i=L(z)}\)</span>. Si <span class="math inline">\(\small{Y_{t-1}=([n/k], z) }\)</span>, y <span class="math inline">\(\small{[kn/k] + z(k) = n}\)</span> entonces <span class="math inline">\(\small{t-1\equiv n}\)</span>; por conveniencia, asignamos las probabilidades de transición para estos estados como <span class="math inline">\(\small{\mathbb{P}\big(Y_t=([n/k],z)\mid Y_{t-1}=([n/k],z)\big)\equiv1}\)</span> . Esto completa la construcción de la <em>Ec. (4.16)</em> y la matriz de probabilidad de transición <span class="math inline">\(\small{\boldsymbol{M}}\)</span> . Las particiones en el espacio de estados <span class="math inline">\(\small{\Omega}\)</span> , dadas por la <em>Ec. (4.19)</em>, son una consecuencia directa de la definición de la cadena de Markov incrustada introducida en la <em>Ec. (4.3)</em>. Por lo tanto, la distribución para el patrón compuesto <span class="math inline">\(\small{\Lambda}\)</span> en la Ec. (4.18) es una consecuencia inmediata del <em>Teorema 2.1</em>. Esto completa la demostración. <span class="math inline">\(\hspace{1cm}\Box\)</span></p>
<p>El <em>teorema 4.1</em> anterior también es válido para patrones simples, el caso especial cuando <span class="math inline">\(\small{l=1}\)</span> . Cuando las longitudes de los patrones <span class="math inline">\(\small{k_{i},\, i=1,\ldots,l}\)</span> no son todas iguales, el principio de avance y retroceso puede seguir utilizándose para hallar la distribución del patrón compuesto <span class="math inline">\(\small{\Lambda}\)</span> . En principio, el procedimiento de recuento de avance y retroceso es aplicable a cualquier número de patrones <span class="math inline">\(\small{l}\)</span> de tamaños <span class="math inline">\(\small{k_{i}}\)</span> variables, pero no es sencillo escribir la forma general del espacio de estados y la matriz de probabilidad de transición de la cadena de Markov incrusrada. Trataremos este problema en el capítulo 5 utilizando la relación de dualidad entre <span class="math inline">\(\small{X_{n}(\Lambda)}\)</span> y el tiempo de espera <span class="math inline">\(\small{W(\Lambda)}\)</span>.</p>
</section>
<section id="conteo-solapado" class="level4">
<h4 class="anchored" data-anchor-id="conteo-solapado">4.3 Conteo Solapado</h4>
<p>Consideremos que la secuencia <span class="math inline">\(\small{\{X_t\}}\)</span> es una cadena de Markov homogénea definida sobre el espacio de estados <span class="math inline">\(\small{\mathscr{S}=\{a, b, c\}}\)</span> con matriz de probabilidades de transición</p>
<!---Ec. 4.20---->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{A}=\big(p_{ij}\big),\, i,j=a,b,c
\end{equation}\]</span>
</div>
<p>Sea <span class="math inline">\(\small{\Lambda}\)</span> un patrón simple de longitud <span class="math inline">\(\small{k}\)</span>. La diferencia básica entre el recuento por solapamiento y el recuento sin solapamiento es que cuando se forma el patrón <span class="math inline">\(\small{\Lambda}\)</span>, una parte de A se contará para formar el siguiente patrón <span class="math inline">\(\small{\Lambda}\)</span> bajo el <em>recuento por solapamiento</em>, hasta los últimos <span class="math inline">\(\small{(k-1)}\)</span> ensayos.</p>
<p><strong>Definición 4.1</strong> Un bloque final <span class="math inline">\(\small{E^°}\)</span> generado por el patrón <span class="math inline">\(\small{\Lambda}\)</span> es el bloque final más largo <span class="math inline">\(\small{(E^{°} \neq \Lambda)}\)</span> que, después de cada aparición de <span class="math inline">\(\small{\Lambda}\)</span> bajo conteo superpuesto, se puede asignar como bloque final inicial para la siguiente aparición de <span class="math inline">\(\small{\Lambda}\)</span>. Escribimos <span class="math inline">\(\small{(E^{°} \cong \Lambda}\)</span> , con respecto al conteo de superposición.</p>
<p>Por ejemplo, bajo el conteo superpuesto:</p>
<ul>
<li>Si <span class="math inline">\(\small{\Lambda=aca}\)</span>, entonces <span class="math inline">\(\small{E^{°}=a}\)</span>,</li>
<li>Si <span class="math inline">\(\small{\Lambda=abcab}\)</span>, entonces <span class="math inline">\(\small{E^{°}=ab}\)</span>, y</li>
<li>Si <span class="math inline">\(\small{\Lambda=\underbrace{a\cdots a}_{k}}\)</span>, entonces <span class="math inline">\(\small{E^{°}=\underbrace{a\ldots a}_{k-1}}\)</span>.</li>
</ul>
<p>Para un patrón como <span class="math inline">\(\small{\Lambda=abc}\)</span>, no existe un <span class="math inline">\(\small{E^{°}}\)</span>, en cuyo caso el conteo superpuesto y no superpuesto es el mismo. Tenga en cuenta que bajo el conteo superpuesto, dado que el primer patrón requiere <span class="math inline">\(\small{k}\)</span> elementos y cada patrón adicional requiere solo <span class="math inline">\(\small{k-\text{Card}(E^{°})}\)</span> elementos, el mayor número posible de patrones <span class="math inline">\(\small{\Lambda}\)</span> que pueden ocurrir en <span class="math inline">\(\small{n (n \geq k)}\)</span> ensayos es</p>
<!----- Ec. 4.21 ----->
<div class="math">
<span class="math display">\[\begin{equation*}
l_{n}^{o}=1+\bigg[\frac{n-k}{k-\text{Card}(E^{°})}\bigg].
\end{equation*} \]</span>
</div>
<p>Para ilustrar las diferencias menores que surgen de los dos tipos de conteo, se proporciona el siguiente ejemplo.</p>
<p><strong>Ejemplo 4.4</strong> Consideremos el número de patrones <span class="math inline">\(\small{\Lambda=aca}\)</span> que ocurren en <span class="math inline">\(\small{n=5}\)</span> ensayos <em>i.i.d.</em> de tres estados. Bajo el conteo no superpuesto, la matriz de transición de probabilidades <span class="math inline">\(\small{\boldsymbol{M}}\)</span> asociada con la cadena de Markov incrustada</p>
<!----Ecuación 4.21.1--->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{M}=
\begin{array}{cc}&amp;
\begin{array}{c}
(0,a)\\
(0,b)\\
(0,c)\\
(0,ab)\\
(1,\Lambda)\\
(1,a)\\
(1,b)\\
(1,c)\\
(1,ac)\\
\end{array}
&amp;
\left(
\begin{array}{ccccccccc}
p_{a}&amp;p_{b}&amp;0&amp;p_{c}&amp;0&amp;0&amp;0&amp;0&amp;0\\
p_{a}&amp;p_{b}&amp;p_{c}&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\
p_{a}&amp;p_{b}&amp;p_{c}&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\
0&amp;p_{b}&amp;p_{c}&amp;0&amp;p_{a}&amp;0&amp;0&amp;0&amp;0\\
0&amp;0&amp;0&amp;0&amp;0&amp;p_{a}&amp;p_{b}&amp;p_{c}&amp;0\\
0&amp;0&amp;0&amp;0&amp;0&amp;p_{a}&amp;p_{b}&amp;0&amp;p_{c}\\
0&amp;0&amp;0&amp;0&amp;0&amp;p_{a}&amp;p_{b}&amp;p_{c}&amp;0\\
0&amp;0&amp;0&amp;0&amp;0&amp;p_{a}&amp;p_{b}&amp;p_{c}&amp;0\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;1\\
\end{array}
\right)
\end{array}
\end{equation}\]</span>
</div>
<p>donde <span class="math inline">\(\small{(1,\Lambda)\equiv (1,aca)}\)</span> . Bajo conteo de superpuesto, la matriz de probabilidad de transición <span class="math inline">\(\small{\boldsymbol{M^{°}}}\)</span> asociada con la cadena de Markov incrustada es</p>
<!----Ecuación 4.21.2--->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{M^{°}}=
\begin{array}{cc}&amp;
\begin{array}{c}
(0,a)\\
(0,b)\\
(0,c)\\
(0,ab)\\
(1,\Lambda)\\
(1,a)\\
(1,b)\\
(1,c)\\
(1,ac)\\
(2,\Lambda)
\end{array}
&amp;
\left(
\begin{array}{ccccc|cccc}
p_{a}&amp;p_{b}&amp;0&amp;p_{c}&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\
p_{a}&amp;p_{b}&amp;p_{c}&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\
p_{a}&amp;p_{b}&amp;p_{c}&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\
0&amp;p_{b}&amp;p_{c}&amp;0&amp;p_{a}&amp;0&amp;0&amp;0&amp;0&amp;0\\
\hline
0&amp;0&amp;0&amp;0&amp;0&amp;p_{a}&amp;p_{b}&amp;0&amp;p_{c}&amp;0\\
\hline
0&amp;0&amp;0&amp;0&amp;0&amp;p_{a}&amp;p_{b}&amp;0&amp;p_{c}&amp;0\\
0&amp;0&amp;0&amp;0&amp;0&amp;p_{a}&amp;p_{b}&amp;p_{c}&amp;0&amp;0\\
0&amp;0&amp;0&amp;0&amp;0&amp;p_{a}&amp;p_{b}&amp;p_{c}&amp;0&amp;0\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;p_{b}&amp;p_{c}&amp;0&amp;p_{a}\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;1&amp;0\\
\end{array}
\right)
\end{array}
\end{equation}\]</span>
</div>
<p>La principal diferencia entre las dos matrices surge después de que ha ocurrido el primer patrón. Con probabilidad <span class="math inline">\(\small{p_{c}}\)</span> , el estado <span class="math inline">\(\small{(1,\Lambda)}\)</span> pasa al estado <span class="math inline">\(\small{(1,c)}\)</span> bajo conteo no superpuesto, mientras que <span class="math inline">\(\small{(1,\Lambda)}\)</span> pasa a <span class="math inline">\(\small{(1,ac)}\)</span> bajo conteo superpuesto, lo que también implica el estado adicional <span class="math inline">\(\small{l_{n}^{°}=(2,\Lambda)}\)</span>. <span class="math inline">\(\hspace{1cm}\Diamond\)</span></p>
<p>Si <span class="math inline">\(\small{\{X_t\}}\)</span> es una cadena de Markov homogénea con probabilidades de transición dadas por la Ecuación. (4.20), la matriz de probabilidad de transición <span class="math inline">\(\small{\boldsymbol{M^{°}}}\)</span> del anterior ejemplo (bajo conteo superpuesto) se convierte en:</p>
<!----Ecuación 4.21.3--->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{M^{°}}=
\begin{array}{cc}&amp;
\begin{array}{c}
\emptyset\\
(0,a)\\
(0,b)\\
(0,c)\\
(0,ab)\\
(1,\Lambda)\\
(1,a)\\
(1,b)\\
(1,c)\\
(1,ac)\\
(2,\Lambda)
\end{array}
&amp;
\left(
\begin{array}{cccccc|ccccc}
0&amp;p_{a}&amp;p_{b}&amp;p_{c}&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\
0&amp;p_{aa}&amp;p_{ab}&amp;0&amp;p_{ac}&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\
0&amp;p_{ba}&amp;p_{bb}&amp;p_{bc}&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\
0&amp;p_{ca}&amp;p_{cb}&amp;p_{cc}&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\
0&amp;0&amp;p_{bb}&amp;p_{bc}&amp;0&amp;p_{ab}&amp;0&amp;0&amp;0&amp;0&amp;0\\
\hline
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;p_{aa}&amp;p_{ab}&amp;0&amp;p_{ac}&amp;0\\
\hline
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;p_{aa}&amp;p_{ab}&amp;0&amp;p_{ac}&amp;0\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;p_{ba}&amp;p_{bb}&amp;p_{bc}&amp;0&amp;0\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;p_{ca}&amp;p_{cb}&amp;p_{cc}&amp;0&amp;0\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;p_{cb}&amp;p_{cc}&amp;0&amp;p_{ca}\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;1\\
\end{array}
\right)
\end{array}
\end{equation}\]</span>
</div>
<p>donde <span class="math inline">\(\small{p_{a},\, p_{b}}\)</span>, y <span class="math inline">\(\small{p_{c}}\)</span> son las probabilidades de transición dadas del estado <span class="math inline">\(\small{\emptyset}\)</span> a los estados <span class="math inline">\(\small{(0, a), (0,b)}\)</span> y <span class="math inline">\(\small{(0, c)}\)</span>, respectivamente. Nuevamente, la extensión de <em>i.i.d.</em> a los emnsayos Markov-Dependientes sigue siendo sencillo. El concepto considerado en el ejemplo anterior se puede extender al caso de superposición hasta los últimos <span class="math inline">\(\small{d}\)</span> ensayos <span class="math inline">\(\small{(1 \leq d \leq k − 1)}\)</span>, como lo introdujeron <em>Aki e Hirano (2000)</em>. Una ventaja significativa de la técnica de incrustación de cadenas finitas de Markov es que la extensión del conteo sin superposición al conteo superpuesto es directa y simple.</p>
</section>
<section id="patrones-en-serie" class="level4">
<h4 class="anchored" data-anchor-id="patrones-en-serie">4.4 Patrones en Serie</h4>
<p>La distribución del número de patrones en serie <span class="math inline">\(\small{\Lambda=\Lambda_{1}\ast\Lambda_{2}}\)</span> se puede obtener casi de la misma manera que para un patrón simple, con modificaciones menores en el estado después de que se haya producido el primer patrón <span class="math inline">\(\small{\Lambda_{1}}\)</span>.</p>
<p><strong>Ejemplo 4.5</strong> Consideremos una secuencia de <span class="math inline">\(\small{n=5}\)</span> ensayos <em>i.i.d.</em> de tres estados extraídos de <span class="math inline">\(\small{\mathscr{S}=\{a,b,c\}}\)</span>, y el patrón de serie <span class="math inline">\(\small{\Lambda}=ab\ast cc\)</span> generado por los dos patrones simples <span class="math inline">\(\small{\Lambda_{1}=ab}\)</span> y <span class="math inline">\(\small{\Lambda_{2}=cc}\)</span>. Definiendo el conjunto de bloques finales <span class="math inline">\(\small{\mathscr{E}=\{a,\bar{a},ab\ast,ab{\ast}c,ab{\ast}cc\}}\)</span> y el espacio de estados</p>
<!----Ecuación 4.21.4--->
<div class="math">
<span class="math display">\[\begin{equation}
\Omega=\{\emptyset,(0,a),(0,\bar{a}),(0,ab{\ast}),(0,ab{\ast}c),(1,ab{\ast}cc),(1,a),(1,\bar{a})\}
\end{equation}\]</span>
</div>
<p>donde <span class="math inline">\(\small{\bar{a}}\)</span> representa <span class="math inline">\(\small{b}\)</span> o <span class="math inline">\(\small{c}\)</span>, y <span class="math inline">\(\small{ab{\ast}}\)</span> representa <span class="math inline">\(\small{ab{\ast}a}\)</span> o <span class="math inline">\(\small{ab{\ast}b}\)</span>. La correspondiente cadena de Markov incrustada <span class="math inline">\(\small{\{Y_t\}}\)</span> tiene la matriz de probabilidad de transición <span class="math inline">\(\small{\boldsymbol{M}}\)</span> dada por:</p>
<!----Ecuación 4.21.5--->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{M}=
\begin{array}{cc}&amp;
\begin{array}{c}
\emptyset\\
(0,a)\\
(0,\bar{a})\\
(0,ab{\ast})\\
(0,ab{\ast}c)\\
(1,ab{\ast}cc)\\
(1,a)\\
(1,\bar{a})\\
\end{array}
&amp;
\left(
\begin{array}{cccccccc}
0&amp;p_{a}&amp;p_{b}+p_{c}&amp;0&amp;0&amp;0&amp;0&amp;0\\
0&amp;p_{a}&amp;p_{c}&amp;p_{b}&amp;0&amp;0&amp;0&amp;0\\
0&amp;p_{a}&amp;p_{b}+p_{c}&amp;0&amp;0&amp;0&amp;0&amp;0\\
0&amp;0&amp;0&amp;p_{a}+p_{b}&amp;p_{c}&amp;0&amp;0&amp;0\\
0&amp;0&amp;0&amp;p_{a}+p_{b}&amp;0&amp;p_{c}&amp;0&amp;0\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;p_{a}&amp;p_{b}+p_{c}\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;1&amp;0\\
0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;1\\
\end{array}
\right)
\end{array}
\end{equation}\]</span>
</div>
<p>Por lo tanto:</p>
<!---Ecuación 4.21.6 ---->
<div class="math">
<span class="math display">\[\begin{equation}
\mathbb{P}\big(X_{n}(\Lambda)=x\big)=\boldsymbol{\xi}_{0}\boldsymbol{M}^{5}\boldsymbol{U}(C_{x}),\,x=0,1.
\end{equation}\]</span>
</div>
<p>Obsérvese que si <span class="math inline">\(\small{\{Y_t\}}\)</span> está en el estado <span class="math inline">\(\small{(0, ab{\ast})}\)</span> o <span class="math inline">\(\small{(0,ab{\ast}c)}\)</span>, significa que el patrón <span class="math inline">\(\small{\Lambda_{1}=ab}\)</span> ha ocurrido antes o en el <span class="math inline">\(\small{t-}\)</span>ésimo ensayo. Ahora bien, si la realización de <span class="math inline">\(\small{X_{t+1}}\)</span> es <span class="math inline">\(\small{a}\)</span> o <span class="math inline">\(\small{b}\)</span> , entonces <span class="math inline">\(\small{Y_{t+1}}\)</span> tiene que estar en el estado <span class="math inline">\(\small{(0, ab{\ast})}\)</span>, suceso que ocurre con probabilidad de transición <span class="math inline">\(\small{p_{a}+p_{b}}\)</span> , y si la realización de <span class="math inline">\(\small{X_{t+1}}\)</span> es <span class="math inline">\(\small{c}\)</span>, entonces <span class="math inline">\(\small{Y_{t+1}}\)</span> avanza al estado <span class="math inline">\(\small{(0, ab{\ast}c)}\)</span> o <span class="math inline">\(\small{(1, ab{\ast}cc)}\)</span>, respectivamente, sucesos que ocurren con probabilidad de transición <span class="math inline">\(\small{p_{c}}\)</span>.</p>
<p>El ejemplo anterior pone de manifiesto las diferencias entre los patrones en series y los patrones simples en lo que respecta a sus matrices de probabilidad de transición de las cadenas de Markov incrustadas. Ampliando ligeramente el espacio de estados <span class="math inline">\(\small{\Omega}\)</span>, sustituyendo <span class="math inline">\(\small{(i,\bar{a}),\, i=0,1}\)</span>, por <span class="math inline">\(\small{(i,b)}\)</span> y <span class="math inline">\(\small{(i, c)}\)</span>, y sustituyendo <span class="math inline">\(\small{(0, ab{\ast})}\)</span> por <span class="math inline">\(\small{(0, ab{\ast}a)}\)</span> y <span class="math inline">\(\small{(0, ab{\ast}b)}\)</span>, el ejemplo anterior puede ampliarse fácilmente al caso de ensayos de tres estados Markov-Dependientes.</p>
</section>
<section id="distribución-conjunta" class="level4">
<h4 class="anchored" data-anchor-id="distribución-conjunta">4.5 Distribución conjunta</h4>
<p>Hallar la distribución conjunta de dos números de rachas, digamos <span class="math inline">\(\small{X_n(\Lambda_{1})}\)</span> y <span class="math inline">\(\small{X_n(\Lambda_{2})}\)</span> , en una secuencia de ensayos de dos o varios estados <span class="math inline">\(\small{\{X_t\}}\)</span> utilizando la técnica de incrustación de cadenas de Markov finitas es similar a hallar la distribución exacta de <span class="math inline">\(\small{X_n(\Lambda)}\)</span> introducida en la <em>Sección 4.2.</em> En general, la cadena de Markov incrustada <span class="math inline">\(\small{\{Y_t\}}\)</span> asociada a la distribución conjunta de <span class="math inline">\(\small{X_n(\Lambda_{1})}\)</span> y <span class="math inline">\(\small{X_n(\Lambda_{2})}\)</span> tiene la forma</p>
<!---Ecuación 4.22 ---->
<div class="math">
<span class="math display">\[\begin{equation}
Y_{t}=\big(X_{t}(\Lambda_{1}),X_{t}(\Lambda_{2}),E_{t}\big),\,t=1,2,\ldots,n.
\end{equation}\]</span>
</div>
<p>El espacio de estados <span class="math inline">\(\small{\Omega}\)</span> y el bloque final <span class="math inline">\(\small{E_{t}}\)</span> para <span class="math inline">\(\small{\{Y_t\}}\)</span> dependen en gran medida de la estructura de los patrones <span class="math inline">\(\small{\Lambda_{1}}\)</span> y <span class="math inline">\(\small{\Lambda_{2}}\)</span>. Las matrices de probabilidad de transición <span class="math inline">\(\small{\boldsymbol{M}_{t}}\)</span> de la cadena de Markov inscrustada pueden construirse utilizando los mismos principios descritos en secciones anteriores. A continuación, damos un ejemplo para demostrar el procedimiento para encontrar la distribución conjunta.</p>
<p><strong>Ejemplo 4.6</strong> Sea <span class="math inline">\(\small{X_{n}}\)</span> el número total de rachas de éxito <span class="math inline">\(\small{X_{n}(S)}\)</span> y de fracaso <span class="math inline">\(\small{X_{n}(S)}\)</span> en una secuencia de <span class="math inline">\(\small{n}\)</span> ensayos de dos estados. Para cada <span class="math inline">\(\small{X_{n} = X_{n}(S) + X_{n}(F)}\)</span>, y los números de rachas <span class="math inline">\(\small{X_{n}(S)}\)</span> y <span class="math inline">\(\small{X_{n}(F)}\)</span> están relacionados de la siguiente manera: si hay <span class="math inline">\(\small{x}\)</span> rachas de éxito, entonces sólo puede haber <span class="math inline">\(\small{x+1, x}\)</span>, o <span class="math inline">\(\small{x-1}\)</span> rachas de fracaso. De ello se deduce que sólo puede haber cuatro tipos de estados <span class="math inline">\(\small{Y_{t}=(X_{t}(S), X_{t}(F), E_{t})}\)</span>, donde el bloque final <span class="math inline">\(\small{E_{t}}\)</span> es <span class="math inline">\(\small{S}\)</span> o <span class="math inline">\(\small{F}\)</span> : (i) <span class="math inline">\(\small{(x, x-1, S)}\)</span>, (ii) <span class="math inline">\(\small{(x, x + 1, F)}\)</span>, (iii) <span class="math inline">\(\small{(x, x, S)}\)</span> y (iv) <span class="math inline">\(\small{(x, x, F)}\)</span>.</p>
<p>Consideremos los resultados de diez ensayos de dos estados <span class="math inline">\(\small{w = (SSFFSFSSSF)}\)</span>. La realización de la cadena de Markov imbricada <span class="math inline">\(\small{\{Y_t\}}\)</span> es <span class="math inline">\(\small{\{Y_{1}=(1,0, S), Y_{2}=(1,0,S), Y_{3}=(1,1,F), Y_{4}=(1,1,F), Y_{5}=(2,1,S), Y_{6}= (2,2,F),Y_{7}=(3,2,S),Y_{8}=(3,2, S),Y_{9}=(3,2,S), Y_{10} = (3,3, F)\}}\)</span>. El espacio de estados <span class="math inline">\(\small{\Omega}\)</span> tiene la forma <span class="math inline">\(\small{\Omega=\{(1,0,S), (0,1,F), (1,1,S), (1,1,F),\ldots, (l_{n},l_{n}S), (l_{n}, l_{n},F)\}}\)</span>, donde <span class="math inline">\(\small{l_{n}=[(n+1)/2]}\)</span>. Para el caso de ensayos de dos estados independientes pero no idénticamente distribuidos, la definición de <span class="math inline">\(\small{Y_{t}}\)</span> da como resultado las matrices de probabilidad de transición, para <span class="math inline">\(\small{t=2,3,\ldots,n,}\)</span></p>
<!----Ecuación 4.21.5--->
<div class="math">
<span class="math display">\[\begin{equation}
\boldsymbol{M_{t}}=
\begin{array}{cc}&amp;
\begin{array}{c}
(1,0,S)\\
(0,1,S)\\
(1,1,S)\\
(1,1,S)\\
\cdot\\
\cdot\\
\cdot\\
(l_{n},l_{n}-1,S)\\
(l_{n}-1,l_{n},F)\\
(l_{n},l_{n},S)\\
(l_{n},l_{n},F)\\
\end{array}
&amp;
\left(
\begin{array}{ccccccccccc}
p_{t}&amp;0&amp;0&amp;q_{t}&amp;&amp;&amp;&amp;&amp;&amp;&amp;\\
&amp;q_{t}&amp;p_{t}&amp;0&amp;0&amp;&amp;&amp;&amp;&amp;&amp;\\
&amp;&amp;p_{t}&amp;0&amp;0&amp;q_{t}&amp;&amp;&amp;&amp;&amp;\\
&amp;&amp;&amp;q_{t}&amp;p_{t}&amp;0&amp;0&amp;&amp;&amp;&amp;\\
&amp;&amp;&amp;&amp;\ddots&amp;\ddots&amp;\ddots&amp;\ddots&amp;&amp;&amp;\\
&amp;&amp;&amp;&amp;&amp;\cdot&amp;\cdot&amp;\cdot&amp;\cdot&amp;&amp;\\
&amp;&amp;&amp;&amp;&amp;&amp;\ddots&amp;\ddots&amp;\ddots&amp;\ddots&amp;\\
&amp;&amp;&amp;&amp;&amp;&amp;&amp;p_{t}&amp;0&amp;0&amp;q_{t}\\
&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;q_{t}&amp;p_{t}&amp;0\\
&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;1&amp;0\\
&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;1\\
\end{array}
\right)
\end{array}
\end{equation}\]</span>
</div>
<p>Dado <span class="math inline">\(\small{\boldsymbol{\xi}_{1}=(p_{1},q_{1},0,\ldots,0)}\)</span> , se deduce que la distribución conjunta de <span class="math inline">\(\small{X_n(S)}\)</span> y <span class="math inline">\(\small{X_n(F)}\)</span> está dada por:</p>
<!----Ecuación 4.24--->
<div class="math">
<span class="math display">\[\begin{equation}
\small{\mathbb{P}\big( X_{n}(S)=x,X_{n}(F)=y\mid \boldsymbol{\xi}_{1}\big)=\boldsymbol{\mathbf{\xi}}_{1} \Big(\prod_{t=1}^{n}\boldsymbol{M}_{t}\Big)\boldsymbol{\mathbf{U}'}(\mathbf{C}_{(x,y)})},
\end{equation}\]</span>
</div>
<p>donde, si <span class="math inline">\(\small{y= x+1}\)</span>, entonces <span class="math inline">\(\small{C_{(x,x+1)}=\{{(x, x + 1, F)}\}}\)</span>, si <span class="math inline">\(\small{y=x-1}\)</span>, entonces <span class="math inline">\(\small{C_{(x, x-1)}=\{(x, x-1, S)\}}\)</span>, si <span class="math inline">\(\small{y=x}\)</span> entonces <span class="math inline">\(\small{C_{(x,x)}=\{(x, x, S), (x, x, F)\}}\)</span>, y <span class="math inline">\(\small{C_{(x,y)}=\{\emptyset\}}\)</span> en cualquier otro caso.</p>
<p>Una vez más, con algunas modificaciones sencillas de las matrices de probabilidades de transición, los resultados anteriores también son válidos tanto para ensayos de dos estados <em>i.i.d.</em>, como Markov-Dependientes homogéneos y no homogéneos. Las distribuciones marginales de <span class="math inline">\(\small{X_{n}(S)}\)</span> y <span class="math inline">\(\small{X_{n}(F)}\)</span> pueden obtenerse proyectando la distribución conjunta sobre las particiones generadas por las variables aleatorias <span class="math inline">\(\small{X_{n}(S)}\)</span> y <span class="math inline">\(\small{X_{n}(F)}\)</span>, respectivamente. De forma más general, la distribución conjunta de <span class="math inline">\(\small{l&gt;2}\)</span> variables aleatorias <span class="math inline">\(\small{X_{n}(\Lambda_{1}),X_{n}(\Lambda_{2}),\ldots,X_{n}(\Lambda_{l})}\)</span> puede obtenerse del mismo modo con una cadena de Markov <span class="math inline">\(\small{(l+1)-}\)</span>dimensional <span class="math inline">\(\small{\{Y_{t} = \big(X_{t}(\Lambda_{1}),\cdots, X_{t}(\Lambda_{l}), E_{t}\big)\}}\)</span>.</p>
<p>Fin 05 de Nov</p>
</section>
</section>
<section id="capitulo-5-distribucines-de-tiempo-de-espera" class="level3">
<h3 class="anchored" data-anchor-id="capitulo-5-distribucines-de-tiempo-de-espera">Capitulo 5: Distribucines de tiempo de espera</h3>
</section>
<section id="bibliografia" class="level3">
<h3 class="anchored" data-anchor-id="bibliografia">Bibliografia:</h3>
<p>Abramson, M. and Moser, W. O. J. (1967). Permutations without rising or falling w-sequences. Annals of Mathematical Statistics 38, 1245-1254.</p>
<p>Aki, S. (1985). Discrete distributions of order k on a binary sequence. Annals of the Institute of Statistical Mathematics 37, 205-224.</p>
<p>Aki, S. (1997). On sooner and later problems between success and failure runs.Advances in Combinatorial Methods and Applications to Probability and Statistics (ed.&nbsp;N. Balakrishnan), Birkhäuser, Boston, 385-400.</p>
<p>Aki, S. (1999). Distributions of runs and consecutive systems on directed trees. Annals of the Institute of Statistical Mathematics 51, 1-15.</p>
<p>Aki, S., Balakrishnan, N. and Mohanty, S. G. (1996). Sooner and later waiting time problems for success and failure runs in higher order Markov dependent trials. Annals of the Institute of Statistical Mathematics 48, 773-787.</p>
<p>Aki, S. and Hirano, K. (1988). Some characteristics of the binomial distribution of order k and related distributions. Statistical Theory and Data Analysis II (ed.&nbsp;K. Matusita), North-Holland, Amsterdam, 211-222.</p>
<p>Aki, S. and Hirano K. (1999). Sooner and later waiting time problems for runs in Markov dependent bivariate trials. Annals of the Institute of Statistical Mathematics 51, 17-29.</p>
<p>Aki, S. and Hirano K. (2000). Numbers of success-runs of specified length until certain stopping time rules and generalized binomial distributions of order k. Annals of the Institute of Statistical Mathematics 52, 767-777.</p>
<p>Aki, S., Kuboki, H. and Hirano, K. (1984). On discrete distributions of order k. Annals of the Institute of Statistical Mathematics 36, 431-440.</p>
<p>Antzoulakos, D. L. (1999). On waiting time problems associated with runs in Markov dependent trials. Annals of the Institute of Statistical Mathematics 51, 323-330.</p>
<p>Antzoulakos, D. L. (2001). Waiting times for patterns in a sequence of multistate trials. Journal of Applied Probability 38, 508-518.</p>
<p>Balakrishnan, N. and Koutras, M. V. (2002). Runs and Scans with Applications, Wiley, New York</p>
<p>Balasubramanian, K., Viveros, R. and Balakrishnan, N. (1993). Sooner and later waiting time problems for Markovian Bernoulli trials. Statistics and Prob- ability Letters 18, 153–161.}</p>
<p>Barnard, G. A. (1959). Control charts and stochastic processes. Journal of the Royal Statistical Society, Series B 21, 239-271.</p>
<p>Barton, D. E. and David, F. N. (1958). Non-randomness in a sequence of two alternatives: II. Runs test. Biometrika 45, 253-256.</p>
<p>Bateman, G. (1948). On the power function of the longest run as a test for randomness in a sequence of alternatives. Biometrika 35, 97-112.</p>
<p>Boutsikas, M. V. and Koutras, M. V. (2000a). Generalized reliability bounds for coherent structures. Journal of Applied Probability 37, 778-794.</p>
<p>Boutsikas, M. V. and Koutras, M. V. (2000b). Reliability approximation for Markov chain imbeddable systems. Methodology and Computing in Applied Probability 2, 393-411.</p>
<p>Brook, D. and Evans, D. A. (1972). An approach to the probability distribution of cusum run length. Biometrika 59, 539-549.</p>
<p>Cai, J. (1994). Reliability of a large consecutive-k-out-of-r-from-n:F system with unequal component-reliability. IEEE Transactions on Reliability 43, 107– 111.</p>
<p>Carlitz, L. (1964). Extended Bernoulli and Eulerian numbers. Duke Mathematical Journal 31, 667-689.</p>
<p>Chao, M. T. (1999). Applications of Markov chains in quality-related matters. Statistical Process Monitoring and Optimization (eds.&nbsp;S. H. Park and G. G. Vining), Marcel Dekker, New York, 175-188.</p>
<p>Chao, M. T. and Fu, J. C. (1989). A limit theorem of certain repairable systems. Annals of the Institute of Statistical Mathematics 41, 809–818.</p>
<p>Chao, M. T. and Fu, J. C. (1991). The reliability of large series system under a Markovian structure. Advances in Applied Probability 23, 894-908.</p>
<p>Chao, M. T., Fu, J. C. and Koutras, M. V. (1995). Survey of reliability stud- ies of consecutive-k-out-of-n: F and related systems. IEEE Transactions on Reliability 44, 120-127.</p>
<p>Chao, M. T. and Lin, G. D. (1984). Economical design of large consecutive-k- out-of-n:F systems. IEEE Transactions on Reliability 33, 411-413.</p>
<p>Chen, J. and Glaz, J. (1997). Approximations and inequalities for the distribution of a scan statistic for 0-1 Bernoulli trials. Advances in the Theory and Practice of Statistics (eds.&nbsp;N. L. Johnson and N. Balakrishnan), Wiley, New York, 285-298.</p>
<p>Chen, J. and Glaz, J. (1999). Approximations for the distribution and the moments of discrete scan statistics. Scan Statistics and Applications (eds.&nbsp;J. Glaz and N. Balakrishnan), Birkhäuser, Boston, 27-66.</p>
<p>Cheung, L. K. W. (2002). Statistical Pattern Recognition in Genomic DNA Sequences. Ph.D.&nbsp;Dissertation, Department of Statistics, University of Manitoba, Canada.</p>
<p>Chiang, D. T. and Niu, S. C. (1981). Reliability of consecutive-k-out-of-n:F sys- tems. IEEE Transactions on Reliability 30, 87-89.</p>
<p>Chrysaphinou, O. and Papastavridis, S. (1988). A limit theorem on the number of overlapping appearances of a pattern in a sequence of independent trials. Probability Theory and Related Fields 79, 129-143.</p>
<p>Cochran, W. G. (1938). An extension of Gold’s method for examining the apparent persistence of one type of weather. Quarterly Journal of the Royal Meteorological Society 64, 631-634.</p>
<p>Csörgö, S. (1979). Erdös-Rényi laws. Annals of Statistics 7, 772-787. David, F. N. (1947). A power function for tests of randomness in a sequence of alternatives. Biometrika 34, 335-339.</p>
<p>David, F. N. and Barton, D. E. (1962). Combinatorial Chance, Hafner, New York. Derman, G., Lieberman, G. J. and Ross, S. M. (1982). On the consecutive-k-out- of-n:F system. IEEE Transactions on Reliability 31, 57-63.</p>
<p>Dillon, J. F. and Roselle, D. P. (1969). Simon Newcomb’s problem. SIAM Journal on Applied Mathematics 17, 1086-1093.</p>
<p>Doi, M. and Yamamoto, E. (1998). On the joint distribution of runs in a sequence of multi-state trials. Statistics and Probability Letters 39, 133-141.</p>
<p>Dwass, M. (1973). The number of increases in a random permutation. Journal of Combinatorial Theory, Series A 15, 192-199.</p>
<p>Ebneshahrashoob, M. and Sobel, M. (1990). Sooner and later problems for Bernoulli trials: frequency and run quotas. Statistics and Probability Letters 9, 5-11.</p>
<p>Erdös, P. and Rényi, A. (1970). On a new law of large numbers. Journal d’Analyse Mathématique 23, 103-111.</p>
<p>Erdös, P. and Révész, P. (1975). On the length of the longest head-run. Topics in Information Theory, Colloquia Mathematica Societatis János Bolyai, 16 (eds.&nbsp;I. Csiszar and P. Elias; Keszthely, Hungary), North-Holland, Amster- dam, 219-228.</p>
<p>Ewan, W. D. and Kemp, K. W. (1960). Sampling inspection of continuous pro- cesses with no autocorrelation between successive results. Biometrika 47, 363-380.</p>
<p>Feller, W. (1968). An Introduction to Probability Theory and Its Applications (Vol. I, 3rd ed.), Wiley, New York.</p>
<p>Fu, J. C. (1985). Reliability of consecutive-k-out-of-n:F system. IEEE Transac- tions on Reliability 34, 127-130.</p>
<p>Fu, J. C. (1986). Reliability of consecutive-k-out-of-n:F systems with (k-1) step Markov dependence. IEEE Transactions on Reliability 35, 602-606.</p>
<p>Fu, J. C. (1995). Exact and limiting distributions of the number of successions in a random permutation. Annals of the Institute of Statistical Mathematics 47, 435-446.</p>
<p>Fu, J. C. (1996). Distribution theory of runs and patterns associated with a sequence of multi-state trials. Statistica Sinica 6, 957-974.</p>
<p>Fu, J. C. (2001). Distribution of scan statistics for a sequence of bi-state trials Journal of Applied Probability 38, 1-9.</p>
<p>Fu, J. C. and Chang, Y. M. (2002). On probability generating functions for wait- ing time distributions of compound patterns in a sequence of multistate trials. Journal of Applied Probability 39, 70-80.</p>
<p>Fu, J. C. and Hu, B. (1987). On reliability of a large consecutive-k-out-of-n:F sys- tem with k-1 step Markov dependence. IEEE Transactions on Reliability 36, 75-77.</p>
<p>Fu, J. C. and Koutras, M. V. (1994). Distribution theory of runs: a Markov chain approach. Journal of the American Statistical Association 89, 1050-1058.</p>
<p>Fu, J. C. and Lou, W. Y. W. (1991). On reliabilities of certain large linearly connected engineering systems. Statistics and Probability Letters 12, 291-296.</p>
<p>Fu, J. C. and Lou, W. Y. W. (2000a). On the exact distribution of SECON and its application. Statistica Sinica 10, 999-1010.</p>
<p>Fu, J. C. and Lou, W. Y. W. (2000b). Joint distribution of rises and falls. Annals of the Institute of Statistical Mathematics 52, 415-425.</p>
<p>Fu, J. C., Lou, W. Y. W., Bai, Z. D. and Li, G. (2002). The exact and limiting distributions for the number of successes in success runs within a sequence of Markov-dependent two-state trials. Annals of the Institute of Statistical Mathematics 54, 719-730.</p>
<p>Fu, J. C., Lou, W. Y. W. and Chen, S. C. (1999). On the probability of pattern matching in nonaligned DNA sequences: a finite Markov chain imbedding approach. Scan Statistics and Applications (eds.&nbsp;J. Glaz and N. Balakrish- nan), Birkhäuser, Boston, 287-302.</p>
<p>Fu, J. C., Lou, W. Y. W. and Wang, Y. J. (1999). On the exact distributions of Eulerian and Simon Newcomb numbers associated with random permuta- tions. Statistics and Probability Letters 42, 115–125.</p>
<p>Fu, J. C., Shmueli, G. and Chang, Y. M. (2002). A unified Markov chain approach for computing the run length distribution for control charts with simple or compound rules. Technical Report, Department of Statistics, University of Manitoba.</p>
<p>Fu, J. C., Spiring, F. A. and Xie, H. (2002). On the average run lengths of quality control schemes using a Markov chain approach. Statistics and Probability Letters 56, 369-380.</p>
<p>Glaz, J. (1989). Approximations and bounds for the distribution of the scan statistic. Journal of the American Statistical Association 84, 560-566.</p>
<p>Glaz, J. (1992). Approximations for tail probabilities and moments of the scan statistic. Computational Statistics and Data Analysis 14, 213-227.</p>
<p>Glaz, J., Naus, J. I. and Wallenstein, S. (2001). Scan Statistics, Springer-Verlag, New York.</p>
<p>Godbole, A. P. (1990). Specific formulae for some success run distributions. Statistics and Probability Letters 10, 119-124.</p>
<p>Godbole, A. P. (1991). Poisson approximations for runs and patterns of rare events. Advances in Applied Probability 23, 851-865.</p>
<p>Goncharov, V. L. (1944). On the field of combinatory analysis. Isvestija Akad. Nauk. SSSR. Ser. Math. 8, 3-48 (in Russian); English translation: Translations of the AMS Ser. Math. 19 (1962), 1-46.</p>
<p>Goodman, L. A. (1958). Simplified runs tests and likelihood ratio tests for Markoff chains. Biometrika 45, 181-197.</p>
<p>Han, Q. and Aki, S. (1998). Formulae and recursions for the joint distributions of success runs of several lengths in a two-state Markov chain. Statistics and Probability Letters 40, 203-214.</p>
<p>Han, Q. and Aki, S. (2000a). Sooner and later waiting time problems based on a dependent sequence. Annals of the Institute of Statistical Mathematics 52, 407-414.</p>
<p>Han, Q. and Aki, S. (2000b). Waiting time problems in a two-state Markov chain. Annals of the Institute of Statistical Mathematics 52, 778-789.</p>
<p>Hirano, K. (1986). Some properties of the distributions of order k. Fibonacci Numbers and Their Applications (eds.&nbsp;A. N. Philippou, G. E. Bergum, and A. F. Horadam), Reidel, Dordrecht, 43-53.</p>
<p>Hirano, K. and Aki, S. (1987). Properties of the extended distributions of order k. Statistics and Probability Letters 6, 67-69.</p>
<p>Hirano, K. and Aki, S. (1993). One number of occurrences of success runs of specified length in a two-state Markov chain. Statistica Sinica 3, 313-320.</p>
<p>Huntington, R. J. and Naus, J. I. (1975). A simpler expression for kth nearest neighbor coincidence probabilities. Annals of Probability 3, 894-896.</p>
<p>Hwang, F. K. (1982). Fast solutions for consecutive-k-out-of-n:F system. IEEE Transactions on Reliability 31, 447-448.</p>
<p>Hwang, F. K. (1986). Simplified reliabilities for consecutive-k-out-of-n systems.SIAM Journal on Algebraic and Discrete Methods 7, 258-264.</p>
<p>Jackson, D. M. and Reilly, J. W. (1976). Permutations with a prescribed number of p-runs. Ars Combinatoria 1, 297-305.</p>
<p>Johnson, B. C. (2001). Distribution of increasing l-sequences in a random permutation. Methodology and Computing in Applied Probability 3, 35-49.</p>
<p>Johnson, B. C. (2002). The distribution of increasing 2-sequences in random per- mutations of arbitrary multi-sets. Statistics and Probability Letters 59, 67-74.</p>
<p>Johnson, B. C and Fu, J. C. (2000). The distribution of increasing l-sequences in random permutations: A Markov chain approach. Statistics and Probability Letters 49, 337-344.</p>
<p>Kaplansky, I. (1944). Symbolic solution of certain problems in permutations. Bul- letin of the American Mathematical Society 50, 906-914.</p>
<p>Karlin, S. and McGregor, J. (1959). Coincident probabilities. Pacific Journal of Mathematics 9, 1141-1164.</p>
<p>Kontoleon, J. M. (1980). Reliability determination of a r-successive-out-of-n:F system. IEEE Transactions on Reliability 29, 437.</p>
<p>Kossow, A. and Preuss, W. (1989). Reliability of consecutive-k-out-of-n:F system with nonidentical component reliabilities. IEEE Transaction on Reliability 38, 229-233.</p>
<p>Koutras, M. V. (1996a). On a Markov chain approach for the study of reliability structures. Journal of Applied Probability 33, 357-367.</p>
<p>Koutras, M. V. (1996b). On a waiting time distribution in a sequence of Bernoulli trials. Annals of the Institute of Statistical Mathematics 48, 789-806.</p>
<p>Koutras, M. V. (1997a). Waiting time distributions associated with runs of fixed length in two-state Markov chains. Annals of the Institute of Statistical Mathematics 49, 123-139.</p>
<p>Koutras, M. V. (1997b). Waiting times and number of appearances of events in a sequence of discrete random variables. Advances in Combinatorial Meth- ods and Applications to Probability and Statistics (ed.&nbsp;N. Balakrishnan), Birkhäuser, Boston, 363-384.</p>
<p>Koutras, M. V. (2003). Applications of Markov chains to the distribution the- ory of runs and patterns. Handbook of Statistics 21: Stochastic Processes, Modeling and Simulation (eds.&nbsp;D. N. Shanbhag and C. R. Rao), Elsevier, Amsterdam, in press.</p>
<p>Koutras, M. V. and Alexandrou, V. (1995). Runs, scans and urn model distributions: a unified Markov chain approach. Annals of the Institute of Statistical Mathematics 47, 743-766.</p>
<p>Koutras, M. V. and Alexandrou, V. (1997a). Non-parametric randomness tests based on success runs of fixed length. Statistics and Probability Letters 32, 393-404.</p>
<p>Koutras, M. V. and Alexandrou, V. (1997b). Sooner waiting time problems in a sequence of trinary trials. Journal of Applied Probability 34, 593–609.</p>
<p>Koutras, M. V. and Papastavridis, S. G. (1993). Application of the Stein-Chen method for bounds and limit theorems in the reliability of coherent struc- tures. Naval Research Logistics 40, 617-631.</p>
<p>Ling, K. D. (1992). A generalization of the sooner and later waiting time problems for Bernoulli trials: frequency quota. Statistics and Probability Letters 14, 401-405.</p>
<p>Ling, K. D and Low, T. Y. (1993). On the soonest and the latest waiting time distributions: succession quotas. Communications in Statistics Theory and Methods 22, 2207-2221.</p>
<p>Lou, W. Y. W. (1996). On runs and longest run tests: method of finite Markov chain imbedding. Journal of the American Statistical Association 91, 1595– 1601.</p>
<p>Lou, W. Y. W. (1997). An application of the method of finite Markov chain imbedding to runs tests. Statistics and Probability Letters 31, 155–161.</p>
<p>Lou, W. Y. W. (2000). The exact distribution of the continuity of care measure NOP. Statistics and Probability Letters 48, 361–368.</p>
<p>Lou, W. Y. W. (2001). The distribution of the usual provider continuity index under Markov dependence. Statistics and Probability Letters 54, 269–276.</p>
<p>Lou, W. Y. W. (2003). The exact distribution of the K-tuple statistic for sequence homology. Statistics and Probability Letters 1, 51-59.</p>
<p>Lucas, J. M. and Crosier, R. B. (1982). Fast initial response for CUSUM quality control schemes: Give your CUSUM a head start. Technometrics 24, 199-205.</p>
<p>MacMahon, P. A. (1915). Combinatory Analysis, Cambridge University Press, London.</p>
<p>Mohanty, S. G. (1994). Success runs of length k in Markov dependent trials. Annals of the Institute of Statistical Mathematics 46, 777-796.</p>
<p>Montgomery, D. C. (2001). Introduction to Statistical Quality Control (4th ed.). Wiley, New York.</p>
<p>Mood, A. M. (1940). The distribution theory of runs. Annals of Mathematical Statistics 11, 367–392.</p>
<p>Mosteller, F. (1941). Note on an application of runs to quality control charts. Annals of Mathematical Statistics 12, 228-232.</p>
<p>Muselli, M. (2000). Useful inequalities for the longest run distribution. Statistics and Probability Letters 46, 239-249.</p>
<p>Nagaev, S. V. (1957). Some limit theorems for stationary Markov chains. Theory of Probability and its Applications 2, 378-406.</p>
<p>Naus, J. I. (1965). The distribution of the size of the maximum cluster of points on a line. Journal of the American Statistical Association 60, 532-538.</p>
<p>Naus, J. I. (1974). Probabilities for a generalized birthday problem. Journal of the American Statistical Association 69, 810-815</p>
<p>Naus, J. I. (1982). Approximations for distributions of scan statistics. Journal of the American Statistical Association 77, 177-183.</p>
<p>Nishimura, K. and Sibuya, M. (1997). Extended Stirling family of discrete probability distributions. Communications in Statistics Theory and Methods 26, 1727-1744.</p>
<p>Papastavridis, S. G. (1988). A Weibull limit for the reliability of a consecutive k-within-m-out-of-n system. Advances in Applied Probability 20, 690-692.</p>
<p>Papastavridis, S. G. and Koutras, M. V. (1993). Bounds for reliability of consec- utive k-within-m-out-of-n:F systems. IEEE Transactions on Reliability 42, 156-160.</p>
<p>Philippou, A. N. (1986). Distributions and Fibonacci polynomials of order k, longest runs, and reliability of consecutive-k-out-of-n:F systems. Fibonacci Numbers and Their Applications (eds.&nbsp;A. N. Philippou, G. E. Bergum and A. F. Horadam), Reidel, Dordrecht, 203-227.</p>
<p>Philippou, A. N., Georghiou, C. and Philippou, G. N. (1983). A generalized geometric distribution and some of its properties. Statistics and Probability Letters 1, 171–175.</p>
<p>Philippou, A. N. and Makri, F. S. (1986). Success runs and longest runs. Statistics and Probability Letters 4, 211–215.</p>
<p>Pyke, R. (1961). Markov renewal processes: definitions and preliminary proper- ties. Annals of Mathematical Statistics 32, 1231-1242.</p>
<p>Reilly, J. W. and Tanny, S. M. (1979). Counting successions in permutations. Studies in Applied Mathematics 61, 73-81.</p>
<p>Rényi, A (1970). Probability Theory, American Elsevier Publishing Company Inc., New York.</p>
<p>Riordan, J. (1958). An Introduction to Combinatorial Analysis, Wiley, New York.</p>
<p>Roselle, D. P. (1968). Permutations by number of rises and successions. Proceed- ings of the American Mathematical Society 19, 8-16. Ross, S. M. (2000). Introduction to Probability Models (7th ed.), Academic Press, San Diego.</p>
<p>Rubin, G., McCulloch, C. E. and Shapiro, M. A. (1990). Multinomial runs tests to detect clustering in constrained free recall. Journal of the American Sta- tistical Association 85, 315-320.</p>
<p>Saperstein, B. (1972). The generalized birthday problem. Journal of the American Statistical Association 67, 425-428.</p>
<p>Schilling, M. F. (1990). The longest run of heads. The College Mathematics Jour- nal 21, 196-207.</p>
<p>Seneta, E. (1981). Non-negative Matrices and Markov Chains (2nd ed.), Springer- Verlag, New York.</p>
<p>Sheng, K. N. and Naus, J. I. (1994). Pattern matching between two non-aligned random sequences. Bulletin of Mathematical Biology 56, 1143-1162.</p>
<p>Steinwachs, D. M. (1979). Measuring provider continuity in ambulatory care. Medical Care 17, 551-565.</p>
<p>Swed, F. S. and Eisenhart, C. (1943). Tables for testing randomness of grouping in a sequence of alternatives. Annals of Mathematical Statistics 14, 66-87.</p>
<p>Tanny, S. (1973). A probabilistic interpretation of Eulerian numbers. Duke Math- ematical Journal 40, 717-722.</p>
<p>Tanny, S. M. (1976). Permutations and successions. Journal of Combinatorial Theory, Series A 21, 196-202.</p>
<p>Vaggelatou, E. (2003). On the length of the longest run in a multi-state Markov chain. Statistics and Probability Letters 62, 211–221.</p>
<p>Uchida, M. and Aki, S. (1995). Sooner and later waiting time problems in a two- state Markov chain. Annals of the Institute of Statistical Mathematics 47, 415-433</p>
<p>Wald, A. and Wolfowitz, J. (1940). On a test whether two samples are from the same population. Annals of Mathematical Statistics 11, 147-162.</p>
<p>Wigle, D. T. (1982). Prevalence of selected chronic diseases in Canada, 1978-1979. Chronic Disease in Canada 3, 9.</p>
<p>Wishart, J. and Hirshfeld, H. O. (1936). A theorem concerning the distribution of joins between line segments. Journal of the London Mathematical Society 11, 227-235.</p>
<p>Wolfowitz, J. (1943). On the theory of runs with some applications to quality control. Annals of Mathematical Statistics 14, 280-288.</p>
<p>Worpitzky, J. (1883). Studien über die Bernoullischen und Eulerschen Zahlen. Journal für die reine und angewandte Mathematik 94, 203-232.</p>
</section>
</section>
<section id="rachas-y-escaners-con-aplicaciones" class="level2">
<h2 class="anchored" data-anchor-id="rachas-y-escaners-con-aplicaciones">Rachas y Escaners con Aplicaciones</h2>
<section id="prefacio" class="level3">
<h3 class="anchored" data-anchor-id="prefacio">Prefacio</h3>
<p>El concepto de rachas se entiende fácilmente y los procedimientos inferenciales basados en rachas son a menudo heurísticamente simples de seguir e implementar. Sin embargo, un estudio teórico de rachas requiere cuidado y uso de una amplia gama de técnicas especiales. Este volumen proporciona una descripción completa y exhaustiva de varios desarrollos teóricos y aplicados sobre problemas que involucran rachas y escaners</p>
<p>Este volumen contiene doce capítulos y puede clasificarse en términos generales en tres partes: la <strong>Parte A</strong>, que comprende los <em>Capítulos 2 y 3</em>, y se ocupa principalmente del tiempo de espera para la primera aparición de rachas y sus aplicaciones; La <strong>Parte B</strong>, que comprende los <em>Capítulos 4 a 8</em>, se ocupa del tiempo de espera para la ocurrencia múltiple de rachas, el número de ocurrencia de rachas, problemas de tiempo de espera tardia y temprana relacionados con rachas, distribuciones de rachas multivariadas y sus aplicaciones; y la <strong>Parte C</strong>, que comprende los <em>Capítulos 9 a 12</em>, y se ocupa principalmente del tiempo de espera para el primer escaner, escaners múltiples, el número de escaners y sus aplicaciones.</p>
<p>La extensión de este volumen, así como la extensa bibliografía al final del mismo (la mayor parte de los últimos veinte años) proporciona un amplio testimonio del notable crecimiento que este tema de investigación ha experimentado en el pasado reciente. Aunque hemos analizado varias aplicaciones diferentes de estadistícas de rachas y escaneo (con tres capítulos dedicados a ellas),creemos que hay mucho más potencial para muchas más aplicaciones diversas y espero sinceramente que este volumen permita y anime a los investigadores aplicados en esta dirección. Para ayudar a los lectores interesados en este proceso, también hemos incluido en la Bibliografía algunas referencias adicionales que se relacionan con esta área de investigación pero que no han sido citadas directamente en el texto.</p>
<p>En un volumen de esta naturaleza y tamaño, inevitablemente habrá omisión de algunos resultados que deberían haberse incluido en este volumen. Aseguramos que tal omisión es sólo accidental y de ninguna manera se debe a una antipatía personal no científica.</p>
<p>Alentamos a los lectores a comentar sobre el contenido de este volumen y les agradecemos de antemano por informarnos sobre cualquier error, tergiversación u omisión.</p>
<p>Nos complace reconocer el apoyo y el aliento del <em>Sr.&nbsp;Steve Quigley</em> de <em>John Wiley &amp; Sons, Inc.</em>, durante todo el transcurso de este proyecto. Se agradece la ayuda administrativa y editorial brindada por la <em>Sra. Heather Haselkorn</em> y el <em>Sr.&nbsp;Andrew Prince</em> de <em>John Wiley &amp; Sons, Inc</em>. También agradecemos a la <em>Sra. Debbie Iscoe (Mississauga, Ontario, Canadá)</em> por componer todo el volumen, a la <em>Sra. Roza Garden (Atenas, Grecia)</em> por mecanografiar algunas partes del volumen y al <em>Dr.&nbsp;Michael Boutsikas</em> por ayudarnos a la preparación de figuras.</p>
<p>La redacción de este volumen comenzó en 1995 y concluyó en el verano de 2001. Durante este período bastante largo, disfrutamos del apoyo, la cooperación y la inmensa paciencia de nuestras familias. A todos ellos va nuestro agradecimiento muy especial.</p>
</section>
<section id="introducción-y-comentarios-históricos" class="level3">
<h3 class="anchored" data-anchor-id="introducción-y-comentarios-históricos">Introducción y comentarios históricos</h3>
<section id="qué-son-las-rachas" class="level4">
<h4 class="anchored" data-anchor-id="qué-son-las-rachas">¿QUÉ SON LAS RACHAS?</h4>
<p>El concepto y el uso potencial de las rachas se pueden explicar incluso a un principiante en estadística en términos simples, ya que el término <em>racha</em> se usa en el campo de la probabilidad y la estadística de la misma manera que se usa en el lenguaje común. Un significado no técnico comúnmente entendido del término <em>racha</em> es una <em>sucesión ininterrumpida</em> y así es exactamente como definiremos y usaremos las <em>rachas</em> en el libro. Concretamente, en un experimento que involucra diferentes elementos (o resultados), una <em>racha</em> de un determinado tipo de elemento(s) es una sucesión ininterrumpida de dichos elementos delimitada en cada extremo por otros tipos de elementos o por el principio o el final de la sucesión completa. Por ejemplo, en la secuencia binaria <span class="math inline">\(\small{1100011101}\)</span>, primero tenemos una racha de dos <span class="math inline">\(\small{1}'\)</span>s, luego una racha de tres <span class="math inline">\(\small{0}'\)</span>s, una racha de tres <span class="math inline">\(\small{1}'\)</span>s, una racha de un <span class="math inline">\(\small{0}\)</span> y finalmente una racha de un <span class="math inline">\(\small{1}\)</span>. Por tanto, tenemos cinco rachas en esa sucesión binaria.</p>
<p>Aunque aquí hemos ilustrado el número de rachas como una estadística, es posible, por supuesto, definir algunas otras estadísticas basadas en las rachas. Por ejemplo, podemos considerar la longitud máxima de racha (que es <span class="math inline">\(\small{3}\)</span>), o la longitud mínima de rachas (que es <span class="math inline">\(\small{1}\)</span>), o la diferencia entre el número de rachas de <span class="math inline">\(\small{1}'\)</span>s y de <span class="math inline">\(\small{0}'\)</span>s (que es <span class="math inline">\(\small{3 - 2 = 1}\)</span>)</p>
<p>La definición anterior de racha es simple y fácil de introducir con una sola forma de contar. Sin embargo, si consideramos rachas de una longitud específica (digamos, <span class="math inline">\(\small{2}\)</span>), es posible introducir diferentes formas de contar. Por ejemplo, si permitimos el conteo superpuesto, entonces la segunda racha de tres <span class="math inline">\(\small{0}'\)</span>s en la anterior sucesión binaria puede considerarse como dos rachas de dos <span class="math inline">\(\small{0}'\)</span>s. Por otro lado, si utilizamos un conteo no superpuesto, entonces la segunda rachas de tres <span class="math inline">\(\small{0}'\)</span>s puede considerarse como una única racha de <span class="math inline">\(\small{0}'\)</span>s.</p>
</section>
<section id="por-qué-rachas" class="level4">
<h4 class="anchored" data-anchor-id="por-qué-rachas">¿POR QUÉ RACHAS?</h4>
<p>Las rachas y los problemas asociados siempre han atraído la atención de probabilistas y estadísticos desde el principio. Ya en <span class="math inline">\(\small{1738}\)</span>, <em>De Moivre</em> discutió el siguiente problema: <em>¿Cuál es la probabilidad de obtener una racha de longitud</em> <span class="math inline">\({r}\)</span> o más en <span class="math inline">\(n\)</span> ensayos? Sin embargo, hubo un error en la fórmula de <em>De Moivre (</em><span class="math inline">\(\small{1738}\)</span>, Doctrine of Chance, Problema 88); pero <em>De Moivre</em> había utilizado la fórmula correcta en sus ejemplos numéricos. <em>Simpson (1740), Laplace (1812)</em> y <em>Todhunter (1865)</em> realizaron más debates sobre este problema. Curiosamente, <em>Marbe (1916, 1934)</em> utilizó observaciones sobre rachas para respaldar la teoría que propuso de que si una moneda da “cara” con mucha frecuencia, entonces la probabilidad de obtener “cruz” en el lanzamiento disminuye.</p>
<p>A pesar de que los problemas relacionados con las rachas se estaban discutiendo en probabilidad y combinatoria desde la publicación de <em>Doctrine of Chance</em> por <em>De Moivre</em> en <span class="math inline">\(\small{1738}\)</span>, se necesitaron más de dos siglos para desarrollar una buena aplicación de las rachas en estadística. <em>Wald</em> y <em>Wolfowitz (1940)</em> utilizaron rachas para establecer una prueba de dos muestras que es intuitivamente simple y puede explicarse fácilmente de la siguiente manera.</p>
<p>Sea <span class="math inline">\(\small{X_1,X_2,\ldots, X_m}\)</span> una muestra aleatoria de una población con función de distribución acumulativa <span class="math inline">\(\small{F_X(x)}\)</span>, y sea <span class="math inline">\(\small{Y_1, Y_2,..., Y_n}\)</span> otra muestra aleatoria independiente de una población con función de distribución acumulativa <span class="math inline">\(\small{F_Y(x)}\)</span>. El problema inferencial de interés es contrastar las hipótesis <span class="math inline">\(\small{H_0 : F_X(x) = F_Y(x)}\)</span> para todo <span class="math inline">\(x\)</span>, frente a la alternativa <span class="math inline">\(\small{H_a: F_X(x) \neq F_Y(x)}\)</span> para algún <span class="math inline">\(x\)</span>. <em>Wald</em> y <em>Wolfowitz (1940)</em> luego sugirieron combinar las dos muestras, organizar las observaciones <span class="math inline">\(\small{m+n}\)</span> en orden creciente de magnitud, reemplazar los valores ordenados por <span class="math inline">\(\small{0}\)</span> o <span class="math inline">\(1\)</span> dependiendo de si se originaron a partir de la muestra <span class="math inline">\(\small{X}\)</span> o la muestra <span class="math inline">\(\small{Y}\)</span>, respectivamente, y utilizar el número total de rachas en esa sucesión binaria como estadística de prueba. Dado que se espera que los valores de <span class="math inline">\(\small{X}\)</span> y <span class="math inline">\(\small{Y}\)</span> estén completamente mezclados entre sí bajo la hipótesis nula, lo que resulta en un valor grande para el número total de racha, Wald y Wolfowitz (1940) propusieron rechazar la hipótesis nula para valores pequeños del número total de rachas; los valores críticos se pueden determinar fácilmente para los valores dados de los tamaños de muestra <span class="math inline">\(m\)</span> y <span class="math inline">\(n\)</span> y el nivel deseado de significancia <span class="math inline">\(\small{\alpha}\)</span>. <em>Wald</em> y <em>Wolfowitz (1940)</em> lograron demostrar que esta prueba de rachas de dos muestras es, de hecho, consistente, lo que significa que la potencia de la prueba tiende a <span class="math inline">\(\small{1}\)</span> cuando los tamaños de muestra <span class="math inline">\(m\)</span> y <span class="math inline">\(n\)</span> tienden a <span class="math inline">\(\infty\)</span>.</p>
<p>Desde entonces, se han desarrollado con éxito una variedad de aplicaciones diferentes de rachas y estadísticas basadas en rachas en una amplia gama de áreas de la estadística, así como en disciplinas aplicadas. En este libro, nuestro objetivo es reunir varios desarrollos teóricos que se han realizado sobre rachas y estadísticas relacionadas y muchas aplicaciones diferentes de estos resultados. Una aplicación estadística significativa de las rachas, anterior al trabajo de <em>Wald y Wolfowitz (1940)</em>, se debe a <em>De Forest (1876)</em>, quien sugirió usar rachas en la sucesión de signos de los residuos para evaluar la adecuación de una curva ajustada a un conjunto de datos observados; Véase <em>Stigler (1978)</em> para algunos detalles sobre este tema.</p>
<p>Aunque esta sección ha proporcionado una breve reseña histórica del trabajo sobre rachas y sus aplicaciones, se presentarán más detalles en varios lugares pertinentes de este libro. Los lectores interesados también pueden consultar el artículo de <em>Weiss (1985)</em> y los libros de <em>Stigler (1986)</em> y <em>Hald (1990)</em> para obtener información adicional.</p>
</section>
</section>
<section id="para-qué-sirven-las-rachas" class="level3">
<h3 class="anchored" data-anchor-id="para-qué-sirven-las-rachas">¿Para qué sirven las rachas?</h3>
<p>Siguiendo la línea de la prueba de rachas de dos muestras descrita en la última sección, el número de rachas también se puede utilizar para desarrollar algunas pruebas de aleatoriedad. Específicamente, sean <span class="math inline">\(\small{X_1,X_2,\ldots,X_n}\)</span>, <span class="math inline">\(n\)</span> variables aleatorias con una función de distribución acumulativa conjunta <span class="math inline">\(\small{F(x_2,x_2,\ldots, x_n)}\)</span>. El problema de interés es probar la hipótesis <span class="math inline">\(\small{H_0: X_i's}\)</span> son independientes y están distribuidas idénticamente (i.i.d.), es decir, <span class="math inline">\(\small{F(x_1, ...,x_n) = \displaystyle\prod_{i=1}^{n}F ^{*}_i(x)}\)</span>, donde <span class="math inline">\(\small{F^{*}_i(x)}\)</span> es una función de distribución acumulativa univariada continua. Podemos considerar la secuencia de signos de las diferencias <span class="math inline">\(\small{X_2-X_2, X_3 - X_2,\ldots, X_n - X_{n-1}}\)</span> y definir una <em>racha positiva</em> como una racha de signos correspondientes a diferencias sucesivas positivas y una <em>racha negativa</em> como una racha de signos correspondientes a diferencias sucesivas negativas. Ahora se pueden proponer diferentes procedimientos de prueba en función del número de rachas positivas y negativas o de la longitud de estas. Dependiendo de la alternativa considerada, se puede elegir una región crítica apropiada. Por ejemplo, si el problema es probar la aleatoriedad frente a la alternativa de que hay una tendencia en <span class="math inline">\(\small{X_1, X_2,\ldots, X_n}\)</span>, será razonable rechazar <span class="math inline">\(\small{H_0}\)</span> si los números de rachas positivas y negativas son demasiado pequeñas. Si la alternativa fuera especificar la dirección de la tendencia, entonces podríamos optar por utilizar una de ellas (la que sea apropiada). Por otro lado, si el problema es probar la aleatoriedad frente a la alternativa de que hay muchos ciclos cortos presentes en <span class="math inline">\(\small{X_1,X_2,\ldots, X_n}\)</span>, entonces será razonable rechazar <span class="math inline">\(\small{H_0}\)</span> si el número de racahs positivas y negativas son demasiado grandes.</p>
<p>Otra aplicación de similar naturaleza surge en el control estadístico de calidad o monitoreo de procesos. Aquí, asumimos que tenemos una característica medible en los artículos que se producen y que esta característica tiene límites de control superior e inferior (a veces, solo uno de esos límites). Se supone que el proceso de producción está <em>bajo control</em> si produce muchos artículos conformes y se declara <em>fuera de control</em> si en cualquier momento se produce una cantidad inusualmente grande de artículos no conformes. En concreto, podemos considerar que el proceso de producción está fuera de control si, entre las mediciones realizadas en <span class="math inline">\(n\)</span> artículos consecutivos, la longitud máxima de racha positiva o negativa es demasiado grande. Por ejemplo, <em>Deming (1972)</em> ha sugerido una tolerancia hasta una longitud máxima de <span class="math inline">\(\small{6}\)</span> y más allá para concluir que el proceso de producción se está saliendo de control. <em>Deming (1972)</em> también ha planteado otro esquema de monitoreo de procesos en el que observamos la longitud máxima de la racha positiva y negativa respecto de la media, es decir, longitud de racha por encima y por debajo de la media, respestivamente. De manera similar, <em>Kitagawa</em> y <em>Seguchi</em> <em>(1956, 1957)</em> han señalado la importancia del estudio de las distribuciones relacionadas con rachas múltiples en relación con los métodos de control estadístico.</p>
<p>Con base en ideas similares, también se han utilizado el número y la longitud de las rachas para desarrollar pruebas no paramétricas de simetría de la distribución de la cual se obtuvieron datos de muestra; véanse, por ejemplo, <em>Cohen</em> y <em>Menjoge (1988)</em>, <em>McWilliams (1990)</em>, <em>Henze (1993)</em> y <em>Modarres</em> y <em>Gastwirth (1996, 1998)</em>. En este contexto, suponiendo que se conoce la <strong>mediana</strong> poblacional <span class="math inline">\(\small{\mu}\)</span> (y se toma como cero, sin pérdida de generalidad), los valores absolutos de las observaciones negativas y positivas se juntan, se hace un recuento de las rachas de valores de un mismo lado y luego se proponen las estadísticas de prueba en función de estas rachas. Sin embargo, observe una diferencia clave en este problema: el número de valores a un lado de la mediana es una variable aleatoria aunque el tamaño de la muestra <span class="math inline">\(n\)</span> en sí sea fijo. El trabajo de <em>Balakrishnan</em> y <em>Frattina (2000)</em> y <em>Balakrishnan</em> y <em>Ng (2001)</em> sobre pruebas de <em>precedencia máxima</em>, en las que dos muestras de unidades se someten a una prueba de vida útil y sólo se observan unos pocos fallos tempranos de las unidades en ambas muestras, también utilizan de manera similar el longitud máxima de racha (correspondiente a fallas de la muestra “control”) como estadística de prueba.</p>
<p>Las rachas también desempeñan un papel fundamental en las <em>pruebas de demostración iniciales</em> (start-up demonstration testing, en ingles). En esta experimentación, un dispositivo (como un generador de energía, una cortadora de césped o una batería de automóvil) se prueba repetidamente y después de cada ensayo simplemente se observa si ha tenido un aranque exitoso o no. El plan/diseño de muestreo de aceptación utilizado por el minorista (o el consumidor) puede aceptar ese equipo si se logra un número prescrito de arranques exitosos consecutivos (es decir, una rachas de éxitos) antes de una cierta cantidad de pruebas, y rechazar ese equipo en caso contrario; véase, por ejemplo, <em>Hahn</em> y <em>Gage (1983</em>).</p>
<p>Nuestra aplicación final es en sistemas de confiabilidad. Así como las estadísticas de orden son fundamentales para los <em>sistemas</em> <span class="math inline">\(k\)</span>-out-of-<span class="math inline">\(n:F\)</span>, las rachas(de hecho, la longitud de la racha más larga) son fundamentales para los sistemas <span class="math inline">\(k\)</span>-out-of-<span class="math inline">\(n:F\)</span> consecutivos. Imaginemos que tenemos un sistema que consta de <span class="math inline">\(n\)</span> componentes y todos los <span class="math inline">\(n\)</span> componentes funcionan de forma independiente. En cualquier momento sólo existen dos estados posibles para los componentes y para todo el sistema: operativo o averiado. Así, se dice que dicho sistema es un <em>sistema</em> <span class="math inline">\(k\)</span>-out-of-<span class="math inline">\(n:F\)</span>, consecutivo si falla sólo cuando al menos <span class="math inline">\(k\)</span> componentes consecutivos han fallado, y funcionará mientras no hayan fallado <span class="math inline">\(k\)</span> componentes sucesivos; véase, por ejemplo, <em>Chiang</em> y <em>Niu (1981)</em> o el artículo de revisión de <em>Chao, Fu</em> y <em>Koutras (1995)</em>.</p>
<section id="de-las-racha-a-los-escaners" class="level4">
<h4 class="anchored" data-anchor-id="de-las-racha-a-los-escaners">DE LAS RACHA A LOS ESCANERS</h4>
<p>En el análisis de ensayos experimentales cuyos resultados pueden clasificarse en dos categorías exclusivas, una pregunta que surge naturalmente es si se podrían establecer criterios razonables que proporcionen evidencia de agrupamiento de cualquiera de las dos categorías. Estos criterios podrían luego usarse para detectar cambios en el proceso subyacente que genera la serie de resultados.</p>
<p>Consideremos una sucesión <span class="math inline">\(\small{X_1,\cdots, X_n}\)</span> de <span class="math inline">\(n=lm\)</span> <span class="math inline">\(\small{(m \geq 2)}\)</span> y <span class="math inline">\(\small{l &gt; 1}\)</span> enteros) resultados binarios. El problema de interés es nuevamente probar la hipótesis nula de que <span class="math inline">\(\small{X_i}\)</span> son independientes con probabilidad de éxito constante. Un criterio simple y comúnmente utilizado es dividir los <span class="math inline">\(n\)</span> ensayos en <span class="math inline">\(l\)</span> grupos separados de <span class="math inline">\(m\)</span> ensayos consecutivos cada uno y observar el número de éxitos dentro de cada grupo. Si algún grupo tiene “demasiados” éxitos (digamos, <span class="math inline">\(k\)</span> o más), se recibirá una señal de que se ha producido un cambio en el proceso subyacente. Si <span class="math inline">\(k\)</span> es cercano a <span class="math inline">\(m\)</span>, entonces podemos denominar al grupo de <span class="math inline">\(m\)</span> ensayos consecutivos una racha de éxitos “casi perfecta”.</p>
<p>Otro criterio muy utilizado se basa en la superposición de grupos de <span class="math inline">\(m\)</span> ensayos sucesivos. Con esta configuración, en cada ensayo contamos el número de éxitos en los últimos <span class="math inline">\(m\)</span> ensayos, y la frecuente aparición de ventanas de rachas “casi perfectas” podría servir como un indicio de un cambio en el proceso subyacente. Es claro que el caso aquí discutido consiste en una generalización natural del concepto de racha; Además, ofrece una estadística de prueba alternativa eficiente y fascinante en una variedad de campos donde tradicionalmente se han utilizado los criterios clásicos de rachas.</p>
<p>Consideremos, por ejemplo, el siguiente modelo que tiene su origen en la biología molecular. Al estudiar secuencias de aminoácidos se utilizan varios esquemas de clasificación, incluido un alfabeto químico de ocho letras, un alfabeto funcional de cuatro letras, un alfabeto de carga de tres letras, etc.; véase, por ejemplo, <em>Karlin</em> y <em>Ghandour (1985)</em>, <em>Karlin</em> y <em>MacKen (1991)</em>, <em>Karlin</em> y <em>Altschul (1993)</em>, <em>Karlin</em> y <em>Cardon (1994)</em> y <em>Waterman (2000)</em>. Con el fin de desarrollar medidas cuantitativas para evaluar e interpretar las heterogeneidades genómicas entre diferentes especies o unidades sujetas a diferentes químicos infecciosos y/o varios niveles de corrupción, los biólogos moleculares comparan sus secuencias de ADN y buscan subsecuencias alineadas largas que coincidan en la mayoría de sus posiciones. Aparentemente, una coincidencia inusualmente larga, es decir, la ocurrencia de una racha “casi perfecto” o escaner, ofrece una fuerte evidencia de similitud entre los sujetos bajo inspección.</p>
<p>Con el objetivo de establecer un modelo matemático para aplicaciones de esta naturaleza, denotemos por <span class="math inline">\(\small{Z_{i1}, Z_{i2}, i = 1,2,\ldots}\)</span>, dos secuencias de aminoácidos de un alfabeto finito. Se dirá que las dos secuencias coinciden en posición (<span class="math inline">\(i\geq 1\)</span>) si <span class="math inline">\(\small{Z_{i1}= Z_{i1}}\)</span>, en cuyo caso dejamos que <span class="math inline">\(\small{X_i}\)</span> sea <span class="math inline">\(\small{1}\)</span> (y <span class="math inline">\(\small{0}\)</span> en caso contrario). Entonces, el número de coincidencias en una ventana de longitud <span class="math inline">\(m\)</span> se describe mediante el proceso de sumas móviles <span class="math inline">\(\small{S_i =}\tiny{\displaystyle\sum_{j=1}^{i+m-1}X_i}\)</span> con <span class="math inline">\(\small{i \in\{1,2,\ldots\}}\)</span> y la coincidencia “casi perfecta” en la posición <span class="math inline">\(\small{i}\)</span> se puede describir mediante el evento <span class="math inline">\(\small{S_i \geq k}\)</span> (<span class="math inline">\(\small{k}\)</span> es un número entero, lo suficientemente cercano a <span class="math inline">\(\small{m}\)</span>).</p>
<p>Los resultados teóricos sobre el tiempo de espera para la primera (o más generalmente, la <span class="math inline">\(r\)</span>-ésima) ocurrencia de tal evento, o el número de ocurrencias de ellos en una secuencia de tamaño dado, son de gran importancia práctica para establecer e investigar pruebas estadísticas apropiadas que detectarían la hipótesis nula de que las dos secuencias son idénticas; véanse, por ejemplo, <em>Karlin</em> y <em>Ost (1988)</em>, <em>Glaz</em> y <em>Naus (1991)</em> y <em>Glaz</em> y <em>Balakrishnan (1999)</em>.</p>
<p>Los escaners también desempeñan un papel fundamental en varias otras áreas científicas. Por ejemplo, en un modelo de confiabilidad que se introdujo recientemente con el nombre de sistema <span class="math inline">\(k-within-consecutive-out-of-n\)</span>, la ocurrencia de un escaner (ejecución “casi perfecta” de componentes fallidos) indica una falla del sistema; véase <em>Papastavridis</em> y <em>Koutras (1994)</em>. En la teoría del control de calidad estadístico, un modelo más sensible (en comparación con el modelo basado en rachas descrito anteriormente en la <code>Sección 1.3</code>) se obtiene al declarar que un proceso está fuera de control siempre que <span class="math inline">\(\small{k}\)</span> de <span class="math inline">\(\small{n}\)</span> puntos consecutivos caigan en la zona crítica; ver <em>Greenberg (1970)</em> y <em>Saperstein (1973)</em>. Del mismo modo, en las pruebas de demostración de inicio ( <em>startup demonstration testing</em>, en ingles), el concepto de escaner puede explotarse para establecer procedimientos eficientes de aceptación/rechazo para la unidad bajo inspección.</p>
<p>En este libro, además de presentar todos los detalles teóricos relacionados con rachas, escaners y estadísticas relacionadas, también consideraremos todas estas aplicaciones, elaboraremos metodologías apropiadas y las ilustraremos con muchos ejemplos numéricos. Mientras lo hacemos, también discutiremos algunas modificaciones, extensiones y generalizaciones de estos problemas que pueden hacerlos más útiles y aplicables a situaciones prácticas de la vida real.</p>
</section>
<section id="que-esperar" class="level4">
<h4 class="anchored" data-anchor-id="que-esperar">QUE ESPERAR</h4>
<p>Aunque todas las aplicaciones citadas en las dos últimas secciones se basan en rachas de diferentes maneras, está bastante claro que algunos problemas de tiempo de espera están asociados con todas ellas. También es evidente que las distribuciones de probabilidad de la variable tiempo de espera (hasta que ocurran algunas rachas de cierto tipo, por ejemplo) y el número de rachas están bastante relacionadas. Por lo tanto, es útil y revelador estudiar las distribuciones de los tiempos de espera asociados con las rachas y luego utilizar estas distribuciones para abordar los diversos problemas aplicados mencionados en las dos últimas secciones. Éste es precisamente el objetivo y propósito de este libro. Para facilitar la presentación de todos los desarrollos relevantes, el resto de este libro se ha dividido en tres partes naturales de la siguiente manera:</p>
<ul>
<li><p><strong>Parte A</strong>: incluye los <em>Capítulos 2</em> y <em>3</em> que se ocupa principalmente del tiempo de espera para la primera aparición de rachas y su aplicación a una variedad de problemas. En el <em>Capítulo 3</em> se detallan varias aplicaciones interesantes en áreas tan diversas como confiabilidad, control de calidad, estadística no paramétrica, meteorología y ciencias ambientales.</p></li>
<li><p><strong>Parte B</strong>: incluye los <em>Capítulos 4</em> a <em>8</em> y se centra principalmente en algunas extensiones y generalizaciones de los resultados discutidos en la <em>Parte A</em>. Específicamente, incluye discusiones detalladas sobre el tiempo de espera para la ocurrencia múltiple de rachas, sobre el número de ocurrencias de rachas, sobre problemas de tiempo de espera tardia y temprana que involucran racha y sobre distribuciones multivariadas relacionadas con la ocurrencia de rachas. Finalmente, se describen algunas aplicaciones diversas de estos resultados.</p></li>
<li><p><strong>Parte C</strong>: incluye los <em>capítulos 9</em> a <em>12</em> y se ocupa de las distribuciones relacionadas con las estadísticas de escaneo, que son generalizaciones naturales del principio de rachas. La organización de la <em>Parte C</em> es similar a la utilizada para la <em>Parte B</em>, es decir, comenzamos nuestra discusión con la distribución del tiempo de espera para la primera ocurrencia de escaners, procedemos a los problemas de tiempo de espera de múltiples escaners y finalmente discutimos la distribución del número de ocurrencias de escaners en un número fijo de resultados. El libro concluye con el <em>Capítulo 12</em>, donde se describen las aplicaciones de escaners a una variedad de problemas.</p></li>
</ul>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>