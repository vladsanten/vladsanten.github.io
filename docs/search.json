[
  {
    "objectID": "Trabajo_Grado.html",
    "href": "Trabajo_Grado.html",
    "title": "Vladimir Sanchez Tenjo",
    "section": "",
    "text": "El propósito de este libro es ofrecer una introducción rigurosa y exhaustiva a la técnica de Incrustación de Cadenas de Markov Finitas (ICMF) para estudiar las distribuciones de Rachas y Patrones desde un punto de vista unificado e intuitivo, alejado de las líneas tradicionales de la combinatoria. A lo largo de las dos últimas décadas, se han obtenido mediante este enfoque un número considerable de nuevos resultados relacionados con las distribuciones de rachas y patrones.\n\n\nEl tema central de la Incrustación de Cadenas de Markov Finitas (ICMF), como su nombre indica, es incrustar adecuadamente las variables aleatorias de interés en el marco de una cadena de Markov finita, y las representaciones resultantes de las distribuciones subyacentes son compactas y muy susceptibles de un estudio más profundo de las propiedades asociadas. En este libro, el concepto de ICMF se desarrolla sistemáticamente y se ilustra su utilidad mediante aplicaciones prácticas a diversos campos, como la fiabilidad de los sistemas de ingeniería, la comprobación de hipótesis, el control de calidad y la medición de la continuidad en el sector sanitario.\n\n\nEste libro está restringido a espacios muestrales discretos, una restricción que sirve para que este trabajo sea accesible a una audiencia más amplia al simplificar los resultados teóricos y sus aplicaciones. Las rachas y patrones considerados aquí se definen en gran medida en sucesiones de ensayos Markov-Dependientes de dos o múltiples estados, con aplicaciones prácticas en mente; los definidos sobre permutaciones aleatorias de números enteros, como los números de Eulerian y Simon Newcomb, también se tratan utilizando un procedimiento de inserción adicional. El contenido de este libro está orientado principalmente a los investigadores que utilizan la teoría de la distribución de rachas y patrones en diversos ámbitos aplicados de la estadística, la probabilidad y la combinatoria, pero también podría servir de base de un curso de temas especiales de un semestre de duración en cuarto curso de licenciatura o a nivel de primer año de posgrado.\n\n\n\nDeseamos agradecer la ayuda de Y. M. Chang y B. C. Johnson en la corrección de los primeros borradores del libro, así como el aliento de nuestros colegas de la Universidad de Manitoba y la Universidad de Toronto.\n\n\nTambién estamos en deuda con nuestras familias por su inagotable apoyo. Por último, queremos agradecer a la Sra. E. H. Chionh, de World Scientific Publishing Co. por su paciencia y apoyo administrativo.\n\n\n\n\nLa ocurrencia de rachas y patrones en una sucesión de resultados de ensayos discretos o permutaciones aleatorias es un concepto importante en diversas áreas de la ciencia, como la ingeniería de confiabilidad, el control de calidad, la psicología, la sociología, la comparación de secuencias de ADN y la comprobación de hipótesis. Resultados de las distribuciones de probabilidad de rachas y patrones elementales se obtuvieron esporádicamente en la literatura hasta aproximadamente la década de 1940, cuando se publicaron una serie de estudios pioneros sobre rachas y patrones más complejos: por ejemplo, Wishart e Hirshfeld (1936), Cochran (1938), Mood (1940), Wald y Wolfowitz (1940), Mosteller (1941) y Wolfowitz (1943). La mayoría de estos estudios se centraron en hallar la distribución condicional de las rachas de éxito dado el número total de éxitos en una sucesión de ensayos de dos estados. Un libro reciente reciente de Balakrishnan y Koutras (2002), ofrece una buena revisión exhaustiva de los avances históricos y actuales en la teoría de la distribución de rachas y las estadísticas de escaneo.\nTradicionalmente, las distribuciones de rachas y patrones se estudiaban mediante análisis combinatorio. Por ejemplo, Mood (1940) escribió: “El problema de la distribución es, por supuesto, combinatorio, y todo el desarrollo depende de algunas identidades del análisis combinatorio”. Sin embargo, encontrar las identidades combinatorias apropiadas para derivar las distribuciones de probabilidad puede ser difícil, si no imposible, para rachas y patrones complejos, y quizá sea ésta la razón por la que las distribuciones exactas de muchos estadísticos comunes definidos en rachas y patrones siguen siendo desconocidas. Además las identidades requeridas a menudo difieren incluso para rachas y patrones similares, y por lo tanto, incluso en el caso más sencillo de ensayos independientes e idénticamente distribuidas (i.i.d.) de dos estados (los llamados “ensayos de Bernoulli”), cada nuevo problema de distribución generalmente tiene que estudiarse caso por caso utilizando el enfoque combinatorio. Por ejemplo, sólo hace relativamente poco tiempo Philippou y Makri (1986) e Hirano (1986), de forma independiente y mediante análisis combinatorio, obtuvieron la distribución exacta de la estadística de racha tradicional \\(\\small{N_{n,k}}\\), del número de rachas de \\(k\\) éxitos consecutivos no-solapados en una secuencia de \\(n\\) ensayos Bernoulli:\n\n\n\\[\\begin{equation}\n\\mathbb{P}(N_{n,k}=x)=\\sum_{m=0}^{k-1}\\sum_{x_1+x_2+\\cdots+\\\\\nkx_k=n-m-km}\\binom{x_1+x_2+\\cdots+x_k+x}{x_1,x_2,\\cdots,x_k,x}p^n\\Big(\\frac{q}{p}\\Big)^{x_1+x_2+\\cdots+x_k}\n\\end{equation}\\]\n\npara \\(x=0,1,\\ldots,[n/k]\\), con probabilidades de éxito y fracaso denotadas por \\(p\\) y \\(q=1-p\\), respectivamente. Otro método para determinar una distribución de probabilidad exacta consiste en derivar la función generadora \\(\\small{\\varphi(s)}\\) para la variable aleatoria entera no negativa \\(\\small{X_n(\\Lambda)}\\) asociada con el patrón \\(\\small{\\Lambda}\\) (por ejemplo, \\(\\small{X_n(\\Lambda)}\\) podría ser el número de apariciones del patrón \\(\\small{\\Lambda}\\) en \\(n\\) ensayos) y, a continuación, diferenciar \\(\\small{\\varphi(s)}\\) \\(x\\) veces para obtener la función de distribución de probabilidad (fdp) dada por \\(\\small{\\mathbb{P}(X_n(\\Lambda) = x)}\\) este enfoque fue introducido por Feller (1968) utilizando la teoría de los sucesos recurrentes. Por ejemplo, para la función generadora del tiempo de espera \\(\\small{W(\\Lambda)}\\), el número de ensayos Bernoulli hasta la primera aparición del patrón \\(\\small{\\Lambda}\\) consistente en \\(k\\) éxitos consecutivos, fue dada por Feller como:\n\n\n\\[\\begin{equation}\n\\varphi_{W}(s)=\\frac{p^ks^k(1-ps)}{1-s+qp^ks^{k+1}}\n\\end{equation}\\]\n\nPara rachas y patrones más complejos, las funciones generadoras pueden ser difíciles de diferenciar un gran número de veces y es posible que sea necesario emplear técnicas de aproximación. Feller utilizó el método de expansión de fracciones parciales, que puede requerir métodos numéricos eficientes para calcular raíces de polinomios. A traves del libro estudiaremos problemas de distribución de rachas y patrones desde un punto de vista, en nuestra opinión, más unificado e intuitivo, alejado de las líneas de la combinatoria tradicional. El enfoque adoptado consiste en incrustar adecuadamente la variable aleatoria \\(\\small{X_n(\\Lambda)}\\) en una cadena de Markov finita \\(\\small{\\{Y_t\\}}\\), de modo que la probabilidad de \\(\\small{X_n(\\Lambda)}=x\\) pueda expresarse en términos de la probabilidad de que el estado de la cadena de Markov al momento \\(\\small{n}\\), \\(\\small{Y_n}\\), se encuentre en un subconjunto \\(\\small{C_x}\\) del espacio de estados, es decir:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\{X_n(\\Lambda)=x\\}=\\mathbb{P}(Y_n \\in C_x)\n\\end{equation}\\]\n\ndonde la probabilidad del lado derecho se puede calcular fácilmente mediante las matrices de probabilidad de transición de la cadena de Markov. Esta representación de la distribución subyacente de \\(\\small{X_n(\\Lambda)}\\) es compacta, fácil de calcular y bastante susceptible de análisis posteriores. El método depende en gran medida de la capacidad de construir una cadena de Markov adecuada asociada con la variable aleatoria \\(\\small{X_n(\\Lambda)}\\), pero una vez construida la cadena, la linealidad de la cadena de Markov reduce la complejidad computacional a menudo asociada con técnicas combinatorias y de funciones generadoras para calcular los fdp’s exactas de rachas y patrones.\nLos primeros resultados de la teoría de la distribución de rachas y patrones se derivaron casi exclusivamente bajo el supuesto de ensayos Bernoulli o ensayos i.i.d. multiestados. Una gran ventaja de la técnica de incrustación de cadenas finitas de Markov es que se puede aplicar no sólo a casos de ensayos i.i.d. , también para ensayos multiestado Markov-dependientes, eso si, con poco esfuerzo adicional. Independientemente de los procedimientos de conteo especificados para patrones superpuestos (conteo superpuesto versus no superpuesto); también se puede extender a varios tipos de rachas y patrones en permutaciones aleatorias. Recientemente, este método ha sido adoptado por varios investigadores para estudiar diversas distribuciones de rachas y patrones: por ejemplo, Antzoulakos (1999, 2001), Boutsikas y Koutras (2000a,b), Doi y Yamamoto (1998), Fu (1985, 1986, 1996), Pu y Koutras (1994), Fu y Lou (2000a,b), Han y Aki (2000a,b), Johnson (2002), Koutras (1996a,b, 1997a,b, 2003), Koutras y Alexandrou (1995), Lou (1996, 2000, 2001) y Nishimura y Sibuya (1997). Tocaremos algunos de estos trabajos recientes, pero nuestras formulaciones correspondientes pueden diferir ligeramente para tratar todos los problemas utilizando un enfoque de incrustación común.\nEste libro no es una revisión de la teoría de rachas y patrones, ni pretende ser utilizado principalmente como un libro de texto de curso; está dirigido principalmente a investigadores en estadística aplicada y probabilidad que estén interesados en utilizar la técnica de incrustación de cadenas finitas de Markov para estudiar las distribuciones de rachas y patrones que surgen en aplicaciones específicas. El contenido del libro se basa en gran medida en desarrollos recientes en esta área, pero se presenta de una manera que no requiere conocimiento de conceptos avanzados en matemáticas o probabilidad; Se supone que se tiene experiencia en teoría de la probabilidad, al nivel de, por ejemplo, el libro de Feller (1968) “Una introducción a la teoría de la probabilidad y sus aplicaciones, Volumen I”. El libro está organizado como sigue. En el Capítulo 2, presentamos las ideas y técnicas básicas de incrustación de cadenas finitas de Markov. Este capítulo sienta las bases para calcular los fdp’s de rachas y patrones, incluidas las distribuciones de tiempo de espera. El Capítulo 3 examina las distribuciones de rachas y patrones asociados con los ensayos de dos estados, y en el Capítulo 4, se trata la extensión a los ensayos de múltiples estados a través del principio de avance y retroceso. El Capítulo 5 estudia principalmente las distribuciones de tiempo de espera de patrones simples y compuestos, así como sus funciones generadoras y aproximaciones de grandes desviaciones. En el Capítulo 6, la técnica de incrustación de cadenas finitas de Markov se extiende al estudio de distribuciones de patrones en permutaciones aleatorias de números enteros, centrándose en detalle en los números de Euler y Simon Newcomb. El Capítulo 7 cubre varias aplicaciones de la teoría de la distribución de rachas y patrones en las áreas de confiabilidad de sistemas de ingeniería, pruebas de hipótesis, medición de continuidad en atención médica y control de calidad.\n\n\n\n\n\nSea \\(\\small{\\Omega=\\{1,2,\\ldots,m\\}}\\quad(m&lt;\\infty)\\) un espacio de estados finito, y \\(\\small{\\mathcal{Y_t}=\\{Y_0,Y_1,\\ldots,Y_t,\\ldots\\}}\\) una familia de variables aleatorias definidas sobre \\(\\small{\\Omega}\\).(proceso estocástico).\nDefinición 2.1 Decimos que la familia/colección de variables aleatorias \\(\\small{\\{\\mathcal{Y_t}\\}}\\) es cadena de Markov si, para toda sucesión \\(\\small{\\{Y_0=i_0,Y_1=i_1,\\ldots,Y_{t-1}=i_{t-1},Y_t=i_t\\}},\\) con \\(\\small{t\\in \\{1,2,\\cdots\\}}\\), se tiene que:\n\n\n\\[\\begin{equation}\n\\mathbb{P}(Y_t=i_t \\mid Y_{t-1}=i_{t-1},\\ldots,Y_0=i_0)=\\mathbb{P}(Y_t=i_t \\mid Y_{t-1}=i_{t-1})\n\\end{equation}\\]\n\nEn otras palabras, la sucesión de variables aleatorias es una cadena de Markov si la probabilidad de que el sistema entre en el estado \\(\\small{i_t}\\) en el momento \\(\\small{t}\\) depende sólo del estado inmediatamente anterior \\(\\small{i_{t-i}}\\) en el momento \\(\\small{t-1}\\). O más sucintamente, visto desde el estado en el momento \\(\\small{t- 1}\\), el futuro es independiente del pasado. Las probabilidades condicionales.\n\n\n\\[\\begin{equation}\n\\mathbb{P}(Y_t=j \\mid Y_{t-1}=i)\\equiv p_{ij}\n\\end{equation}\\]\n\n\\(\\small{i,j \\in \\Omega}\\), se denominan probabilidades de transición de un paso para el sistema en el momento \\(t\\). Las probabilidades de transición \\(\\small{p_{ij}(t), 1 \\leq i,j \\leq m}\\), pueden representarse como una matriz \\(m\\times m\\)\n\n\n\\[\\begin{equation}\n\\boldsymbol{M_t}=(p_{ij(t)})=\\begin{pmatrix}\np_{11}(t) & p_{12}(t) & \\cdots & p_{1m}(t)\\\\\np_{21}(t) & p_{22}(t) & \\cdots & p_{2m}(t)\\\\\n\\vdots & \\ddots & \\ddots & \\cdots\\\\\np_{m1}(t) &p_{m2}(t) & \\cdots & p_{mm}(t)\\\\\n\\end{pmatrix}_{m\\times m}\n\\end{equation}\\]\n\nLas matrices \\(\\small{\\boldsymbol{M_t},\\,\\, t=1,2,\\ldots,}\\) son llamadas matrices de probabilidades de transición de un paso o simplemente matrices de transición de un paso.\nProposición. La matriz de probabilidades de transición \\(\\small{\\boldsymbol{M_t}=(p_{ij}(t))}\\) cumplen las siguientes propiedades, para cada tiempo \\(\\small{t}\\):\n\n\\(\\small{(p_{ij(t)}) \\geq 0}\\) para todo \\(\\small{t}\\).\n\\(\\small{\\displaystyle\\sum_{j}p_{ij}=1}\\), es decir, en cada momento del tiempo \\(\\small{t}\\), el proceso cambia de estado (puede ser permanecer en el mismo estado) con probabibilidad \\(\\small{1}\\).\n\nDefinición 2.2: Una cadena de Markov \\(\\small{\\{Y_0,Y_1,\\dots\\}}\\), es homogenea si las probabilidades de transición son constantes en el tiempo, i.e \\(\\small{\\mathbb{P}(Y_t=j \\mid Y_{t-1}=i)}=p_{ij}\\) para todo par \\(\\small{(i,j)\\in \\Omega \\times \\Omega=\\Omega^2}\\) y todo \\(\\small{t=1,2,\\ldots}\\)\nEsta definición equivale a decir que las matrices de probabilidad de transición de una cadena de Markov homogénea pueden representarse mediante la única matriz:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M=M_t}=(p_{ij}(t)), \\quad \\text{para todo } t=1,2,\\ldots\n\\end{equation}\\]\n\nen donde las probabilidades de transición \\(\\small{p_{ij}}\\) son independientes del índice del tiempo \\(\\small{t}\\).\nEl conjunto de probabilidades en el momento \\(\\small{0}\\), denotada como \\(\\small{\\mathbb{P}(Y_0 = i)}\\) para \\(i = 1,\\ldots,m\\) se conoce como la distribución inicial de la cadena de Markov. Dada una distribución de probablidad inicial y las probabilidades de transición de una cadena de Markov, la distribución conjunta de la cadena se puede calcular de la siguiente manera:\n\n\n\\[\\begin{equation}\n\\begin{split}\n\\mathbb{P}(Y_n=i_n,\\ldots,Y_1=i_1,Y_0=i_0) = &  \\mathbb{P}(Y_n=i_n \\mid Y_{n-1}=i_{n-1})\\cdots \\\\\n& \\cdots \\mathbb{P}(Y_1=i_1 \\mid Y_0=i_0)\\mathbb{P}(Y_{0}=i_{0}).\n\\end{split}\n\\end{equation}\\]\n\nLas cadenas de Markov se han utilizado en el modelado de una gran cantidad de aplicaciones. Aquí damos dos ejemplos simples que se ven a menudo en la teoría de probabilidad aplicada:\nEjemplo 2.1 (El problema de la ruina del jugador). Considere un jugador que gana y pierde un dólar con probabilidades \\(p\\) y \\(q = 1-p\\), respectivamente. Supongamos que el jugador tiene un capital inicial de \\(\\small{a}\\) dólares. El jugador deja de jugar cuando se queda sin capital (“arruinado”) o cuando alcanza una fortuna de \\(\\small{a + b}\\) dólares (con ganancia neta \\(\\small{b &gt; 0}\\)).\nLa sucesión del monto de capital del jugador, \\(\\small{\\{Y_t: t = 0,1,2, \\ldots\\}}\\), forma una cadena de Markov homogénea con espacio de estados \\(\\small{\\Omega= \\{0,1, 2, \\ldots, a-1,a,a + 1,\\ldots, a + b}\\}\\) y las siguientes probabilidades de transición:\n\n\n\\[\\begin{equation}\np_{ij}=\\begin{cases}\np\\quad \\text{si } j=i+1\\\\\nq\\quad \\text{si } j=i-1\n\\end{cases}\n\\end{equation}\\]\n\npara \\(\\small{i=1,2,\\ldots,a+b-1,\\, p_{00}=p_{a+b,a+b}=1}\\) y cero en cualquier otro caso. Los estados \\(\\small{0}\\) y \\(\\small{a+b}\\) se denominan absorbentes, ya que, una vez alcanzados nunca se sale de estos. La Cadena de Markov tine la matriz de problabilidades de transición:\n\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\\begin{array}{cc} &\n\\begin{array}{cccccccc}\n\\end{array}\n\\\\\n\\begin{array}{ccc}\n0 \\\\\n1 \\\\\n\\vdots\\\\\n\\cdot \\\\\na-1 \\\\\na\\\\\na+1\\\\\n\\vdots\\\\\na+b\n\\end{array}\n&\n\\left(\n\\begin{array}{cccccccc}\n1 & 0 & 0 & 0 &  &  &   &   \\\\\nq & 0 & p & 0 &  &  &   &  \\\\\n& \\ddots & \\ddots & \\ddots &   &   &\\boldsymbol{0}   &  \\\\\n&  &  \\ddots & \\ddots & \\ddots &   &   &   \\\\\n&  &   &  q & 0& p &  &   \\\\\n& \\boldsymbol{0} &  &   &   \\ddots & \\ddots & \\ddots & \\\\\n&  &  &  &  & q & 0 & p \\\\\n&  &  &  &  & 0 & 0 & 1 \\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nen donde \\({\\mathbf{0}}\\) representa un matriz de ceros y la cadena tiene distribución de probabilidad inicial \\(\\small{\\mathbb{P}(Y_0=a)=1}\\).\nEjemplo 2.2 (Modelo de Urnas). Considere una sucesión de ensayos independientes, cada uno de los cuales consiste en insertar una bola al azar en una de \\(\\small{k}\\) urnas. Decimos que el sistema \\(\\small{\\{Y_t : t = 0,1,\\ldots\\}}\\) está en estado \\(\\small{i}\\), si exactamente \\(\\small{i}\\) urnas están ocupadas. Este sistema forma una cadena de Markov en el espacio de estados \\(\\small{\\Omega = \\{0,1,\\ldots, k\\}}\\) con probabilidades de transición\n\n\n\\[\\begin{equation}\np_{ij}=\\begin{cases}\n\\frac{i}{k}  \\quad\\quad  \\text{si } j=i\\\\\n\\frac{k-i}{k}\\quad \\text{ si } j=i+1\\\\\n0 \\quad \\quad \\text{en otro caso}\n\\end{cases}\n\\end{equation}\\]\n\npara \\(\\small{i=0,1,\\ldots,k}\\) y distribución de probabilidad inicial \\(\\small{\\mathbb{P}(Y_0=0)=1}\\). La matriz de probabilidades de transición esta dada por: \n\n\\[\\begin{equation}\n\\boldsymbol{M}=\\begin{array}{cc} &\n\\begin{array}{ccccccc}\n\\end{array}\n\\\\\n\\begin{array}{ccc}\n0 \\\\\n1 \\\\\n\\\\\n\\vdots\\\\\ni\\\\\n\\vdots\\\\\nk-1\\\\\nk\n\\end{array}\n&\n\\left(\n\\begin{array}{ccccccc}\n0 & 1 & 0 &   &  &  &     \\\\\n0 & \\frac{1}{k} & \\frac{k-1}{k}  & 0 &  & \\boldsymbol{0} &      \\\\\n&  & \\ddots & \\ddots &   &   &      \\\\\n&  &        & \\frac{i}{k} & \\frac{k-i}{k} &   &       \\\\\n&   &   &  & \\ddots& \\ddots &    \\\\\n&   & \\boldsymbol{0} &   &   & \\frac{k-1}{k} & \\frac{1}{k}  \\\\\n&   &  &   &   & 0 & 1\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nSe pueden encontrar más ejemplos de este tipo en Feller (1968) y Ross (2000). Por supuesto, también habrá muchos más ejemplos de cadenas de Markov en secciones posteriores de este libro.\n\n\n\nPara una cadena de Markov no homogénea \\(\\small{\\{Y_t\\}}\\), las probabilidades de transición de \\(\\small{n}\\) pasos \\(\\small{\\mathbb{P}(Y_t= j \\mid Y_{t-n} = i) = p_{ij}^{(n)}(t)}\\) se pueden obtener a partir de las probabilidades de transición de un paso por una identidad importante conocida como Ecuación de Chapman-Kolmogorov. Si \\(\\small{n = 2}\\), tenemos, para \\(\\small{t \\geq 2}\\),\n\n\n\\[\\begin{equation}\np_{ij}^{(2)}(t) = \\sum_{k\\in \\Omega}\\mathbb{P}(Y_{t-1}=k \\mid  Y_{t-2}=i)\\mathbb{P}(Y_{t}=j \\mid  Y_{t-1}=k)=\\sum_{k\\in \\Omega} p_{ik}(t-1)^{}p_{kj}^{}(t)\n\\end{equation}\\]\n\nque corresponde a sumar todos los posibles \\(\\small{k}\\) estados intermedios en la transición del estado \\(\\small{i}\\) al estado \\(\\small{j}\\).\nSi \\(\\small{\\{Y_t\\}}\\) es una cadena de Markov homogénea, entonces la ecuación anterior (2.4) genera las probabilidades de transición de dos pasos \\(\\small{(n = 2)}\\)\n\n\n\\[\\begin{equation}\np_{ij}^{(2)} = \\sum_{ k \\in \\Omega}\\mathbb{P}(Y_{t-1}=k  \\mid  Y_{t-2}=i)\\mathbb{P}(Y_{t}=j \\mid  Y_{t-1}=k)=\\sum_{k\\in \\Omega} p_{ik}p_{kj}\n\\end{equation}\\]\n\nlas cuales son independientes de \\(\\small{t}\\). Por lo tanto, de la ecuación (2.5), la matriz de probabilidades de transición de dos pasos \\(\\small{\\boldsymbol{M}^{(2)} = (p_{ij}^{(2)})}\\) satisface la identidad \\(\\small{\\boldsymbol{M}^{(2)}= \\boldsymbol{M}^2}\\). De manera analoga, para las probabilidades de transición de \\(\\small{n}\\) pasos de una cadena de Markov homogénea, la identidad de Chapman-Kolmogorov:\n\n\n\\[\\begin{equation}\np_{ij}^{(n)} = \\sum_{k \\in \\Omega} p_{ik}^{(s)}p_{kj}^{(n-s)}\n\\end{equation}\\]\n\nse mantiene para cada paso intermedio \\(\\small{s = 1,\\ldots, n -1}\\). Se deduce de las ecuaciones. (2.5) y arterior-(2.6) que\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}^{(n)}= \\boldsymbol{M}^{(s)}\\boldsymbol{M}^{(n-s)}=\\boldsymbol{M}^{n}\n\\end{equation}\\]\n\nPara una cadena de Markov homogénea \\(\\small{\\{Y_t\\}}\\), y cualquier subconjunto \\(\\small{{C}}\\) del espacio de estados \\(\\small{\\Omega}\\), se deduce de la Ec.(2.7) que la probabilidad condicional del sistema \\(\\small{Y_n}\\) resida en \\(\\small{{C}}\\) en el índice de tiempo \\(\\small{n}\\), dada la distribución de probabilidad inicial \\(\\small{\\boldsymbol{\\mathbf{\\xi}}_0 = \\big(\\mathbb{P}(Y_0 = 1), \\cdots,P(Y_0 = m)\\big)}\\) es:\n\n\n\\[\\begin{equation}\n\\mathbb{P}(Y_n \\in {C} \\mid \\boldsymbol{\\mathbf{\\xi}}_0)=\\boldsymbol{\\mathbf{\\xi}}_0 \\boldsymbol{M}^{n}\\boldsymbol{\\mathbf{U}'}({C})\n\\end{equation}\\]\n\nen donde \\(\\small{\\boldsymbol{\\mathbf{U}'}({C})}\\) es la traspuesta de \\(\\small{\\boldsymbol{\\mathbf{U}}({C})}\\), con \\(\\small{\\boldsymbol{\\mathbf{U}}( {C})=\\displaystyle\\sum_{i \\in C}e_i}\\) y \\(\\small{\\boldsymbol{e}_i=(0,\\ldots,1,\\ldots,0)_{1\\times m}}\\) es un vector canónico con un \\(\\small{1}\\) correspondiente al \\(i\\)-ésimo estado y cero en los otros. De manera más general, si \\(\\small{\\{Y_t\\}}\\) es una cadena de Markov no homogénea, se puede demostrar (ver, Feller 1968) que la probabilidad condicional de \\(\\small{Y_n \\in {C} }\\) dado \\(\\small{\\boldsymbol{\\xi}_0}\\) se puede expresar simplemente como\n\n\n\\[\\begin{equation}\n\\mathbb{P}(Y_n \\in  {C} \\mid \\boldsymbol{\\mathbf{\\xi}}_0)=\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\prod_{t=1}^{n}\\boldsymbol{M_t}\\Big)\\boldsymbol{\\mathbf{U}'}({C})\n\\end{equation}\\]\n\nLas ecuaciones (2.8) y (2.9) son dos herramientas indispensables para evaluar las probabilidades de diversos eventos asociados con cadenas de Markov homogéneas y no homogéneas, respectivamente.\n\n\n\nCon el fin de ampliar las posibles aplicaciones, es útil considerar una extensión simple de la metodología anterior a cadenas de Markov definidas en espacios de estados de diferentes tamaños. Sea \\(\\small\\{Y_t\\}\\) una sucesión de variables aleatorias definidas en una familia de espacios de estados \\(\\small{\\{\\Omega_t\\}}\\), respectivamente. La sucesión \\(\\small{\\{Y_t\\}}\\) se denomina cadena de Markov con estructura de árbol si \\(\\small{\\{Y_t\\}}\\) es una cadena de Markov con matrices de transición\n\n\n\\[\\begin{equation}\n\\boldsymbol{M_t}=(p_{ij}(t)), \\quad \\text{para todo } t=1,2,\\ldots,\n\\end{equation}\\]\n\nen donde, para cada \\(\\small{i \\in {\\Omega}_{t-1}}\\) y \\(\\small{j \\in {\\Omega}_{t}}\\)\n\n\n\\[\\begin{equation}\np_{ij}(t)=\\mathbb{P}(Y_t=j\\mid Y_{t-1}=i).\n\\end{equation}\\]\n\nObsérvese que los espacios de estados de la colección \\(\\small{\\{\\Omega_t\\}}\\) pueden tener tamaños diferentes, las matrices de transición \\(\\small{\\boldsymbol{M_t}}\\) pueden ser rectangulares en lugar de cuadradas; es decir, \\(\\small{\\boldsymbol{M_t},\\, t = 1, 2, \\ldots,}\\) son matrices de orden \\(\\small{\\text{card}(\\Omega_{t-1}) \\times \\text{card}(\\Omega_{t})}\\), donde \\(\\small{\\text{card}(\\Omega)}\\) representa el número cardinal del espacio de estados \\(\\small{\\Omega}\\). La sucesión de matrices de probabilidad de transición \\(\\small{\\{\\boldsymbol{M_t}}\\}\\) sigue determinando la cadena de Markov \\(\\small\\{{Y_t}\\}\\) estructurada en árbol, y la ecuación de Chapman-Kolmogorov sigue siendo aplicable.\nPara cualquier subconjunto \\(\\small{ {C}\\subseteq \\Omega_n}\\), la probabilidad condicional de \\(\\small{Y_n\\in {C}}\\) dada la distribución de probabilidad inicial \\(\\small{\\boldsymbol{\\xi}_0}\\), puede calcularse vía:\n\n\n\\[\\begin{equation}\n\\mathbb{P}(Y_n \\in {C} \\mid \\boldsymbol{\\mathbf{\\xi}}_0)=\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\prod_{t=1}^{n}\\boldsymbol{M_t}\\Big)\\boldsymbol{\\mathbf{U}'}_{n}({C})\n\\end{equation}\\]\n\nsiendo \\(\\small{\\boldsymbol{\\mathbf{U}}_{n}({C})=\\displaystyle\\sum_{i \\in C}\\boldsymbol{e}_i}\\) y \\(\\small{\\boldsymbol{e}_i=(0,\\ldots,1,\\ldots,0)_{1\\times card(\\Omega_n)}}\\) es un vector unitario de tamaño \\(\\small{1\\times card(\\Omega_n)}\\) con un \\(\\small{1}\\) asociado al \\(i\\)-ésimo estado. Si todo los espacios de estados son iguales \\(\\small{(\\Omega_1=\\cdots=\\Omega_n)}\\),entonces la Eq. (2.10) se reduce a Eq. (2.9).\n\n\n\nTradicionalmente, dentro de una sucesión de ensayos Bernoulli (i.i.d. éxito-fracaso), una racha denota una sucesión de éxitos o fracasos consecutivos. Por ejemplo una racha de éxitos de tamaño 4 implica el patrón \\(\\small{SSSS}\\). Varias de las estadísticas de rachas que se utilizan a menudo en estadística y probabilidad aplicada para una sucesión de \\(n\\) ensayos Bernoulli son:\n(i) \\(\\small{N_{n,k}}\\) el número rachas de \\(\\small{k}\\) éxitos consecutivos no solapados, en el sentido del conteo de Feller (1968);\n(ii) \\(\\small{M_{n,k}}\\) el número de rachas de \\(\\small{k}\\) éxitos consecutivos solapados;\n(iii) \\(\\small{E_{n,k}}\\) el número de rachas de éxitos de tamaño exactamente igual a \\(\\small{k}\\), en el sentido del conteo de Mood (1940);\n(iv) \\(\\small{G_{n,k}}\\) el número de rachas de éxitos de tamaño mayor o igual que \\(\\small{k}\\) ;\n(v) \\(\\small{L_{n}(S)}\\) el tamaño de la racha de éxitos más larga.\nQuizás la forma más sencilla de comprender las definiciones dadas de estas estadísticas de rachas y el procedimiento de conteo de solapado/no solapado, sea mediante el siguiente ejemplo. Supongamos que hay \\(\\small{n = 10}\\) ensayos de Bernoulli, con realización \\(\\small{SSFSSSSFFF}\\). Entonces \\(\\small{L_{10}(S) = 4}\\), y para \\(\\small{k = 2}\\), tenemos \\(\\small{N_{10,2} = 3, M_{10,2} = 4, E_{10,2} = 1}\\) y \\(\\small{G_{10,2} = 2}\\)\nDe las definiciones de estas estadísticas de rachas, se deduce por inspección que las siguientes relaciones siempre son verdaderas:\n\n\n\\[\\begin{equation}\nE_{n,k}\\leq G_{n,k} \\leq N_{n,k} \\leq M_{n,k}\\\\\nE_{n,k} = G_{n,k} - G_{n,k+1}\\\\\nL_n(S)&lt;k\\quad\\text{si y solo si }N_{n,k}=0\n\\end{equation}\\]\n\nPara ampliar las definiciones de rachas, consideremos una sucesión de \\(\\small{n}\\) ensayos multiestados \\(\\small{\\{{X}\\}_{t=1}^{n}}\\), cada una de las cuales tiene \\(\\small{m \\geq 2}\\) estados o símbolos como posibles resultados. Estos símbolos se denotan por \\(\\small{b_1,b_2,\\ldots,b_m}\\) y ocurren con probabilidades \\(\\small{p_1,p_2,\\ldots,p_m}\\), respectivamente. A continuación, definimos tres tipos de patrones generales: un patrón simple, un patrón compuesto y un patrón en serie.\nDefinición 2.3 Decimos que \\(\\small{\\Lambda}\\) es un patron simple, si esta conformado por una determinada serie de \\(\\small{k}\\) símbolos, i.e, \\(\\small{\\Lambda=b_{i_1}b_{i_2}\\cdots b_{i_k}}\\) con \\(\\small{i_j\\in \\{1,2,\\ldots,m\\}}\\), para todo \\(\\small{j=1,\\dots,k}\\). La longitud del patrón es fija y los símbolos en el patrón puede repetirse.\nLas rachas de éxito y fracaso de tamaño \\(\\small{k}\\) son por tanto patrones simples según esta definición, y de hecho cualquier sucesión de éxitos y fracasos de longitud fija, digamos \\(\\small{\\Lambda =SSFSF}\\), puede considerarse un patrón simple dentro de una sucesión de de \\(\\small{n}\\) ensayos de dos estados \\(\\small{(m = 2)}\\).\nAhora, sean \\(\\small{\\Lambda_1}\\) y \\(\\small{\\Lambda_2}\\) dos patrones simples de longitudes/tamaños \\(\\small{k_1}\\) y \\(\\small{k_2}\\) , respectivamente. Decimos que \\(\\small{\\Lambda_1}\\) y \\(\\small{\\Lambda_2}\\) son distintos si ni \\(\\small{\\Lambda_1}\\) incluye a \\(\\small{\\Lambda_2}\\) ni \\(\\small{\\Lambda_2}\\) incluye a \\(\\small{\\Lambda_1}\\). Definimos \\(\\small{\\Lambda_1 \\cup\\Lambda_2}\\) como la ocurrencia de uno de los dos patrón \\(\\small{\\Lambda_1}\\) o \\(\\small{\\Lambda_2}\\) , y definimos \\(\\small{\\Lambda_1 \\ast\\Lambda_2}\\) como la ocurrencia de patrón \\(\\small{\\Lambda_1}\\) seguido del patrón \\(\\small{\\Lambda_1}\\) (quizás con una separación entre ellos).\nDefinición 2.4 Decimos que \\(\\small{\\Lambda}\\) es un patrón compuesto si es la unión de \\(\\small{1 &lt; l &lt;\\infty}\\) patrones simples distintos solapados/no solapados, es decir, \\(\\small{\\Lambda=\\displaystyle\\bigcup_{i=1}^{l}\\Lambda_i}\\).\nDefinición 2.5 Decimos \\(\\small{\\Lambda}\\) es un patrón en serie si \\(\\small{\\Lambda}\\) está compuesto por una sucesión ordenada de \\(\\small{1 &lt; l &lt;\\infty}\\) patrones simples distintos no superpuestos \\(\\small{\\Lambda_i}\\), es decir, \\(\\small{\\Lambda=\\Lambda_1 \\ast\\Lambda_2\\ast\\cdots\\Lambda_l}\\)\nA lo largo de este libro, la variable aleatoria \\(\\small{X_n(\\Lambda)}\\) representa el número de ocurrencias del patrón \\(\\small{\\Lambda}\\) en una sucesión de \\(\\small{n}\\) ensayos multiestado, utilizando el recuento con solapamiento o sin solapamiento. Para aclarar las tres definiciones de patrones y los dos métodos de recuento para los ensayos multiestado, presentamos el siguiente ejemplo.\nEjemplo 2.3 Sea \\(\\small{\\{X_t\\}_{t=1}^{16}}\\) una sucesión de dieciséis ensayos de un proceso de cuatro estados, en donde los resultados posibles para cada ensayo son \\(\\small{A, G, C}\\) y \\(\\small{T}\\). Sea \\(\\small{\\Lambda_1=AGAG}\\) y \\(\\small{\\Lambda_2=AGT}\\) dos patrones simples distintos, \\(\\small{\\Lambda=\\Lambda_1 \\cup\\Lambda_2}\\) un patrón compuesto y \\(\\small{\\Lambda^{\\ast}=\\Lambda_1 \\ast\\Lambda_2}\\) un patron en serie. Supongamos que la realización de esta sucesión de dieciséis ensayos es \\(\\small{TAGAGAGTCAGAGTCC}\\), entonces:\n(i) \\(\\small{X_{16}(\\Lambda_1)}\\) es \\(\\small{3}\\) con conteo solapado y es \\(\\small{2}\\) con conteo no solapado,\n(ii) \\(\\small{X_{16}(\\Lambda)}\\) es \\(\\small{5}\\) con conteo solapado y es \\(\\small{3}\\) con conteo no solapado,\n(iii) \\(\\small{X_{16}(\\Lambda^{\\ast})}\\) es igual a \\(\\small{1}\\).\n(iv) \\(\\small{X_{16}(\\Lambda_2)}\\) es \\(\\small{2}\\).\nLas definiciones anteriores de rachas y patrones en una sucesión de ensayos de múltiples estados también se pueden extender a permutaciones aleatorias \\(\\small{\\{\\pi : \\pi=(\\pi (1),\\ldots,\\pi(n)) \\}}\\) de \\(\\small{n}\\) enteros \\(\\small{\\{1, 2, \\ldots, n\\}}\\). Por ejemplo, el número Euleriano \\(\\small{E(\\pi, n)}\\), el número de aumentos en una permutación aleatoria \\(\\small{\\pi}\\) (ver Carlitz 1964, Tanny 1973 y Worpitzky 1883), podría verse como una variable aleatoria \\(\\small{X_n(\\Lambda)}\\) con el patrón \\(\\small{\\Lambda}\\) siendo un aumento. Matemáticamente, el número de Euler se puede definir como\n\n\n\\[\\begin{equation}\nE(\\pi,n)=X_n(\\Lambda)=\\displaystyle \\sum_{i=0}^{n-1}I(\\pi,i),\n\\end{equation}\\]\n\nen donde \n\n\\[\\begin{equation}\nI(\\pi,i)=\\begin{cases}\n1 \\quad \\text{si }\\pi(i)&lt;\\pi(i+1) \\\\\n0 \\quad \\text{en otro caso }\n\\end{cases}\n\\end{equation}\\]\n\n\\[I(\\pi,i)=\\begin{cases}\n1 \\quad \\text{si }\\pi(i)&lt;\\pi(i+1) \\\\\n0 \\quad \\text{en otro caso,}\n\\end{cases}\\]\npara \\(\\small{i=1,\\ldots,n-1}\\), con \\(\\small{I(\\pi,i)=1}\\) por convención (la brecha inicial que precede a la primera permutación siempre se considera un aumento). Por ejemplo, el número de aumentos \\(\\small{E(\\pi, 9)}\\) en la permutación aleatoria \\(\\small{\\pi = (321459768)}\\) de 9 números enteros son 5.\nEn vista de las definiciones y ejemplos anteriores, uno debería esperar que la distribución exacta de la variable aleatoria \\(\\small{X_n(\\Lambda)}\\) dependa en gran medida de tres factores importantes:\n(a) la estructura del patrón \\(\\small{\\Lambda}\\) ,\n (b) la estructura de la sucesión \\(\\small{\\{{X}\\}_{t=1}^{n}}\\) de \\(n\\) ensayos (o permutaciones aleatorias),\n (c) el procedimiento de conteo (conteo superpuesto o no superpuesto).\nDebido a estos factores, la determinación analítica de distribuciones exactas mediante enfoques tradicionales como la combinatoria puede ser bastante desafiante y generalmente compleja, involucrando identidades especiales y un álgebra extensa. En consecuencia, las distribuciones exactas de muchas estadísticas utilizadas en aplicaciones prácticas nunca se han estudiado utilizando tales métodos, especialmente cuando los ensayos subyacentes no son i.i.d. (por ejemplo, Markov-dependientes).\nEn la siguiente subsección, describimos una técnica que permite obtener una representación matricial compacta para la distribución exacta de una manera relativamente simple y universal al incorporar la variable aleatoria \\(\\small{X_n(\\Lambda)}\\) en una cadena de Markov finita; la expresión resultante también es muy adecuada para un análisis más detallado de propiedades estadísticas, para el desarrollo de aproximaciones de grandes desviaciones y para una implementación numérica eficiente para el cálculo de probabilidades exactas.\n\n\n\nLa técnica de Incrustación de Cadenas de Markov Finitas (ICMF) para encontrar la distribución de la variable aleatoria \\(\\small{X_n(\\Lambda)}\\) tiene sus orígenes en una serie de artículos de Fu (1985, 1986), Fu y Hu (1987), Chao y Fu (1989, 1991), y Fu y Lou (1991). El término “Cadena de Markov Finita Incrustable” para describir una variable aleatoria fue introducido formalmente por Fu y Koutras (1994).\nSea \\(\\small{\\Gamma_n=\\{0,1\\ldots,n\\}}\\) un conjunto de indices, y \\(\\small{\\Omega=\\{a_1,a_2,\\ldots,a_m\\}}\\) un espacio de estados finito.\nDefinicion 2.6 La variable aleatoria no negativa de valores enteros \\(\\small{X_n(\\Lambda)}\\), es una cadena de Markov finita incrustable si:\n(a). Existe una cadena de Markov finita \\(\\small{\\{Y_t:t\\in \\Gamma\\}}\\) definida sobre un espacio de estados \\(\\small{\\Omega}\\) finito, con vector de probabilidades inicial \\(\\small{\\boldsymbol{\\xi}_0}\\).\n(b). Existe una partición finita \\(\\small{\\{C_x:x=0,1,\\ldots,l_n\\}}\\) sobre el espacio de estado \\(\\small{\\Omega}\\).\n(c). Para todo \\(\\small{x=0,1,\\ldots,l_m}\\) tenemos: \\[\\small{\\mathbb{P}\\{X_n(\\Lambda)=x\\}=\\mathbb{P}\\{Y_n\\in C_x \\mid \\boldsymbol{\\xi}_0\\}.}\\] Sea \\(\\small{\\{\\boldsymbol{M}_t\\}_{t=1}^{n}}\\) una sucesión de matrices de probabilidades de transición de orden \\(\\small{m\\times m}\\) de una cadena finita de Markov \\(\\small{\\{Y_t\\}}\\) definida sobre un espacio de estados \\(\\small{\\Omega}\\) con distribución de probablidad inicial \\(\\small{\\boldsymbol{\\xi}_0=\\big(\\mathbb{P}\\{Y_0=a_1\\},\\mathbb{P}\\{Y_0=a_2\\},\\ldots,\\mathbb{P}\\{Y_0=a_m\\}\\big)}\\)\nTeorema 2.1 Si \\(\\small{X_n(\\Lambda)}\\) es una cadena finita de Markov incrustable, entoces\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\{ X_n(\\Lambda)=x\\}=\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\prod_{t=1}^{n}\\boldsymbol{M}_t\\Big)\\boldsymbol{\\mathbf{U}'}({C_x})\n\\end{equation}\\]\n\nsiendo \\(\\small{\\boldsymbol{\\mathbf{U}}({C_x})=\\displaystyle\\sum_{r: a_r\\in C_x}\\boldsymbol{e}_r}\\) y \\(\\small{\\boldsymbol{e}_r=(0,\\ldots,1,\\ldots,0)_{1\\times m}}\\) es un vector unitario de tamaño \\(\\small{1\\times m}\\) con un \\(\\small{1}\\) asociado al estado \\(\\small{a_r}\\) e \\(\\small{\\boldsymbol{\\mathbf{\\xi}}_0}\\) vector de probabilidades iniciales, y \\(\\small{\\boldsymbol{M}_t\\,,\\,\\,t=1,\\dots,n}\\) son las matrices de probabilidades de transición de la cadena de Markov incrustada.\nPrueba: Dado que \\(\\small{X_n(\\Lambda)}\\) es una cadena de Markov finita incrustable, se deduce de Definición 2.6(a) de que existe una cadena de Markov finita \\(\\small{\\{Y_t : t\\in \\Gamma_n \\}}\\) con probabilidades iniciales \\(\\small{\\boldsymbol{\\mathbf{\\xi}}_0}\\). Luego por la ecuación de Chapman-Kolmogorov descrita en Sección 2.2, para cada \\(\\small{a_r\\in \\Omega}\\), tenemos\n\n\n\\[\\begin{equation}\n\\mathbb{P}(Y_n =a_r \\mid \\boldsymbol{\\mathbf{\\xi}}_0)=\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\prod_{t=1}^{n}\\boldsymbol{M}_t\\Big)\\boldsymbol{e_r'}\n\\end{equation}\\]\n\nAdemás, de las Definiciones 2.6(b) y (c) se deduce que, para cada \\(\\small{x =0,1\\ldots,l_n}\\),\n\n\n\\[\\begin{equation}\n\\begin{split}\n\\mathbb{P}\\{ X_n(\\Lambda)=x\\} & =  \\mathbb{P}(Y_n \\in C_x \\mid \\boldsymbol{\\mathbf{\\xi}}_0) \\\\\n& = \\sum_{a_r\\in C_x}\\mathbb{P}\\{Y_n=a_r\\mid \\boldsymbol{\\mathbf{\\xi}_0}\\}\\\\\n& = \\sum_{a_r\\in C_x} \\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\prod_{t=1}^{n}\\boldsymbol{M}_t\\Big)\\boldsymbol{e_r'}\\\\\n& = \\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\prod_{t=1}^{n}\\boldsymbol{M}_t\\Big)\\boldsymbol{\\mathbf{U}'}( {C_x})\\quad \\quad \\quad \\quad \\quad \\Box\n\\end{split}\n\\end{equation} \\Box\\]\n\nEl \\(\\small{k-}ésimo\\) momento \\(\\small{\\mathbb{E}\\{X_n^k(\\Lambda)\\},\\,\\,k=1,2,\\ldots,}\\) puede expresarse como:\n\n\n\\[\\begin{equation}\n\\mathbb{E}\\{X_n^k(\\Lambda)\\}=\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\prod_{t=1}^{n}\\boldsymbol{M}_t\\Big)\\boldsymbol{{V}_k'}\n\\end{equation}\\]\n\nen donde\n\n\n\\[\\begin{equation}\n\\boldsymbol{{V}_k'}=\\sum_{x=0}^{l_n}x^{k}\\boldsymbol{U}(\\mathbf{C_x})\n\\end{equation}\\]\n\nDe manera ánaloga la función generadora de probabilidad de la variable aleatoria \\(\\small{X_n(\\Lambda)}\\) puede escribirse como:\n\n\n\\[\\begin{equation}\n\\psi(s)= \\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\prod_{t=1}^{n}\\boldsymbol{M}_t\\Big)\\boldsymbol{W'}(s)\n\\end{equation}\\]\n\nen donde \n\n\\[\\begin{equation}\n\\boldsymbol{W}(s)=\\sum_{x=0}^{l_n}s^{x}\\boldsymbol{U}(\\mathbf{C_x})\n\\end{equation}\\]\n\nLos funciones generadoras de probabilidad y de momentos se discutirán dentro del contexto de aplicaciones específicas en secciones posteriores.\nEjemplo 2.4 (Número de parejas de resultados sucesivos idénticos). Sea \\(\\small{\\{X_t:t = 0,1,\\ldots, n\\}}\\) una sucesión de \\(\\small{n}\\) ensayos Markov-dependientes homogéneos con \\(\\small{m}\\) estados y matriz de probabilidad de transición \\(\\small{\\boldsymbol{A}_{m\\times m} = \\big(P_{ij}\\big)}\\) y una distribución de probabilidad inicial \\(\\small{\\boldsymbol{\\xi}_0=\\big(\\mathbb{P}\\{X_0=1\\},\\mathbb{P}\\{X_0=2\\},\\ldots,\\mathbb{P}\\{X_0=m\\}\\big)=(1/m,1/m,\\ldots,1/m)}\\). Definiendo una sucesión de funciones indicadoras\n\n\n\\[\\begin{equation}\nI_i=\\begin{cases}\n1 \\quad \\text{si }X_t=X_{t-1}\\\\\n0 \\quad \\text{en otro caso}\n\\end{cases}\n\\end{equation}\\]\n\npara todo \\(\\small{t=1,\\ldots,n}\\)\nEn este ejemplo, nos interesa el número de veces que un resultado particular (uno de \\(\\small{m}\\) resultados posibles) en un ensayo determinado se repite en el ensayo inmediatamente siguiente. En términos matemáticos, definimos el patrón \\(\\small{\\Lambda}\\) para denotar dicho resultado repetido, un patrón que está presente en el índice de tiempo \\(\\small{1 \\leq t \\leq n}\\) si \\(\\small{X_{t-1} = X_t}\\) o, de manera equivalente en términos de la función indicadora anterior, si \\(\\small{I_t = 1}\\). La estadística de rachas:\n\n\n\\[\\begin{equation}\nX_n(\\Lambda)= \\sum_{t=1}^{n}I_t\n\\end{equation}\\]\n\ncorresponde al número de veces que ocurrió el patrón \\(\\small{\\Lambda}\\) en la sucesión \\(\\small{\\{X\\}_{t=0}^{n}}\\) de \\(\\small{n}\\) ensayos Markov-dependientes con \\(\\small{m}\\) estados. En el sector sanitario, por ejemplo, la estadística \\(\\small{X_n(\\Lambda)/n}\\) se conoce como \\(SECON\\) y forma la medida principal de continuidad secuencial en una serie de \\(\\small{n}\\) visitas de pacientes a \\(\\small{m}\\) posibles proveedores de atención sanitaria ( Steinwachs 1979).\nUna dificultad aquí es que las variables aleatorias \\(\\small{\\{I_t\\}}\\) no son independientes y no conforman una cadena de Markov, incluso si la sucesión \\(\\small{\\{X\\}_{t=0}^{n}}\\) se extrajera de ensayos i.i.d. de \\(\\small{m}\\) estados. De hecho, se puede demostrar que las variables aleatorias \\(\\small{\\{I_t\\}}\\) son dependientes y están correlacionadas positivamente probando que \\(\\small{Cov(I_i, I_j) &gt; 0}\\) para todo \\(\\small{i}\\) y \\(\\small{j}\\), con \\(\\small{Cov(I_i, I_j) \\rightarrow 0}\\) cuando \\(\\small{\\mid i-j \\mid\\rightarrow 0}\\). Sin embargo, como se indica a continuación, la distribución exacta aún se puede obtener fácilmente utilizando la técnica de incrustación de cadenas de Markov finitas.\nPrimero, descomponemos la matriz de probabilidad de transición \\(\\small{\\boldsymbol{A}}\\) en dos matrices \\(\\small{\\boldsymbol{G}}\\) y \\(\\small{\\boldsymbol{D}}\\), donde la matriz \\(\\small{\\boldsymbol{D}}\\) contiene sólo los elementos diagonales de \\(\\small{\\boldsymbol{A}}\\); es decir:\n\n\n\\[\\begin{equation}\n\\boldsymbol{A}_{m\\times m}=\\boldsymbol{G}_{m\\times m}+\\boldsymbol{D}_{m\\times m}\n\\end{equation}\\]\n\nen donde: \n\n\\[\\begin{equation}\n\\boldsymbol{G}_{m\\times m}=\n\\begin{pmatrix}\n0 & p_{ij} & \\cdots \\\\\n  & \\ddots &        \\\\\n\\cdots & p_{ij} & 0\n\\end{pmatrix}\n\\quad \\text{y} \\quad\n\n\\boldsymbol{D}_{m\\times m}=\n\\begin{pmatrix}\np_{11} &  & \\boldsymbol{0} \\\\\n  & \\ddots &        \\\\\n\\boldsymbol{0} &   & p_{mm}\n\\end{pmatrix}\n\\end{equation}\\]\n\nSea \\(\\small{\\Omega=\\{(u,v): u = 0,\\ldots,n, \\text{ y }v = 1,2,\\ldots, m\\}}\\) el espacio de estados que contiene un total de \\(\\small{(n+1)m}\\) estados. Dado \\(\\small{n}\\), se define una cadena de Markov homogénea y finita \\(\\small{\\{Y_t: t\\in \\Gamma\\}}\\) en el espacio de estados \\(\\small{\\Omega}\\) como\n\n\n\\[\\begin{equation}\nY_t=\\begin{cases}\n\\Big(\\displaystyle\\sum_{i=1}^{t}I_i, X_t \\Big) \\quad \\text{si } 1 \\leq t \\leq n\\\\\n\\big(0,X_0\\big) \\quad t=0\n\\end{cases}\n\\end{equation}\\]\n\ncon matriz de probabilidades de transición:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\\begin{pmatrix}\n\\boldsymbol{G} & \\boldsymbol{D} & \\boldsymbol{O} & \\cdots & \\boldsymbol{O}\\\\\n\\boldsymbol{O} & \\boldsymbol{G} & \\boldsymbol{D} & \\cdots & \\boldsymbol{O} \\\\\n\\vdots & \\ddots & \\ddots & \\ddots & \\vdots \\\\\n\\boldsymbol{O} & \\cdots & \\cdots & \\boldsymbol{G}& \\boldsymbol{D}\\\\\n\\boldsymbol{O} & \\boldsymbol{O} & \\cdots & \\boldsymbol{O}& \\boldsymbol{I}\\\\\n\\end{pmatrix}\n\\end{equation}\\]\n\ndonde \\(\\small{\\boldsymbol{M}}\\) es una matriz \\(\\small{(n + 1)m \\times (n + 1)m}\\), \\(\\small{\\boldsymbol{O}}\\) representa la matriz cero \\(\\small{m\\times m}\\) e \\(\\small{\\boldsymbol{I}}\\) es la matriz identidad \\(\\small{m\\times m}\\). Los estados en \\(\\small{\\boldsymbol{M}}\\) están ordenados en orden lexicográfico (diccionario). Por último, defininiendo la partición \\(\\small{\\{C_x: x=0,1,2,\\ldots,n\\}}\\) en el espacio de estados \\(\\small{\\boldsymbol{\\Omega}}\\) como\n\n\n\\[\\begin{equation}\nC_x=\\{(x,v): v=1,2,\\ldots,m\\}\n\\end{equation}\\]\n\nDadas las definiciones anteriores para la cadena de Markov \\(\\small\\{Y_t\\}\\), la variable aleatoria \\(\\small{X_n(\\Lambda)}\\) es, según la Definición 2.6, una cadena de Markov finita incrustable y su distribución exacta se desprende del Teorema 2.1: para \\(\\small{0 \\leq x \\leq n}\\),\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\{X_n(\\Lambda)=x\\}=\\boldsymbol{\\xi_0}\\begin{pmatrix}\n\\boldsymbol{G} & \\boldsymbol{D} & \\boldsymbol{O} & \\cdots & \\boldsymbol{O}\\\\\n\\boldsymbol{O} & \\boldsymbol{G} & \\boldsymbol{D} & \\cdots & \\boldsymbol{O} \\\\\n\\vdots & \\ddots & \\ddots & \\ddots & \\vdots \\\\\n\\boldsymbol{O} & \\cdots & \\cdots & \\boldsymbol{G}& \\boldsymbol{D}\\\\\n\\boldsymbol{O} & \\boldsymbol{O} & \\cdots & \\boldsymbol{O}& \\boldsymbol{I}\\\\\n\\end{pmatrix}^{n}\\boldsymbol{U'}(C_x)\n\\end{equation}\\]\n\ndonde \\(\\small{\\boldsymbol{\\xi_0}(\\pi_0,0,\\ldots,0)_{(n+1)\\times m}}\\) es la distribución inicial del vector de estado \\(\\small{Y_0}\\), y \\(\\small{\\boldsymbol{U'}(C_x): (0,\\ldots, 0, \\underbrace{1, 1, ..., 1}_{C_x}, 0,\\ldots,0)}\\) es un vector de fila \\(\\small{1 \\times(n+1)m}\\) con \\(\\small{1}\\) en las coordenadas asociadas con los estados en \\(\\small{C_x}\\) y cero en otros posiciones. En el Capítulo 7 se darán más detalles y un ejemplo numérico de este problema.\nKoutras y Alexandrou (1995) introdujeron la noción de variables incrustables en cadenas finitas de Markov de tipo binomial (MVBS), y muchas estadísticas comunes para rachas y patrones caen en esta categoría especial. Sea la partición \\(\\small{ \\{C_x\\}=\\{[(x, v): v=1,...,r], \\text{ para } x = 0, 1,\\ldots, l_n\\}}\\), la partición del espacio de estados \\(\\small{\\Omega}\\).\nDefinición 2.7 Una variable aleatoria \\(\\small{X_n(\\Lambda)}\\) es una cadena de Markov finita incrustable de tipo binomial si:\n(i) \\(\\small{X_n(\\Lambda)}\\) es una cadena de Markov finita incrustable como en la Definición 2.6.\n(ii) \\(\\small{\\mathbb{P}\\{Y_t=(y,j) \\mid Y_{t-1} =(x,i)\\} \\equiv 0}\\) para todo \\(\\small{y\\neq x}\\) o \\(\\small{x + 1}\\).\nPara cualquier \\(\\small{MVB}\\), introduzca dos matrices de probabilidad de transición \\(\\small{r\\times r}\\):\n\n\n\\[\\begin{equation}\n\\boldsymbol{A_t}(x) = \\big(a_{ij}(t)\\big) = \\Big(\\mathbb{P}\\{Y_t = (x,j)\\mid Y_{t−1} = (x, i)\\}\\Big)\n\\end{equation}\\]\n\ny \n\n\\[\\begin{equation}\n\\boldsymbol{B_t}(x) = \\big(b_{ij}(t)\\big) = \\Big(\\mathbb{P}\\{Y_t = (x+1,j)\\mid Y_{t−1} = (x, i)\\}\\Big)\n\\end{equation}\\]\n\nPor tanto las matrices de probabilidad de transición \\(\\small{\\boldsymbol{M_t}}\\) de la cadena de Markov incrustada tienen la siguiente forma: \n\n\\[\\begin{equation}\n\\boldsymbol{M}=\\begin{pmatrix}\n\n\\boldsymbol{A}_t(0) & \\boldsymbol{B}_t(0) & \\boldsymbol{O} & \\cdots &\\cdots  & \\boldsymbol{O} \\\\\n\n\\boldsymbol{O} &\\boldsymbol{A}_t(1) & \\boldsymbol{B}_t(1)  & \\boldsymbol{O} & \\cdots  & \\boldsymbol{O}\\\\\n\n\\vdots & \\boldsymbol{O} & \\ddots & \\ddots & \\ddots & \\vdots \\\\\n\\vdots & \\ddots & \\boldsymbol{O}& \\ddots & \\ddots & \\boldsymbol{O} \\\\\n\\vdots & \\cdots & \\cdots & \\boldsymbol{O}& \\boldsymbol{A}_t(l_n-1) & \\boldsymbol{B}_t(l_n-1) \\\\\n\\boldsymbol{O} & \\boldsymbol{O} & \\cdots &  \\boldsymbol{O}& \\boldsymbol{O} &  \\boldsymbol{A}_t(l_n) \\\\\n\\end{pmatrix}\n\\end{equation}\\]\n\npara \\(\\small{t = 1,\\ldots,n}\\), en donde los estados están ordenados en orden lexicográfico (diccionario). Hay muchas estadísticas para rachas y patrones con matrices de transición que tienen esta forma, como, por ejemplo, las estadísticas de rachas \\(\\small{N_{n,k},\\, M_{n,k}\\, \\text{y}\\, G_{n,k}}\\) introducidas en la Sección 2.4 (y estudiadas más a fondo en el Capítulo 3).\nPara \\(\\small{MVB´s}\\), se puede derivar una ecuación recursiva eficiente para la distribución de \\(\\small{X_n(\\Lambda)}\\), que aprovecha parcialmente la estructura de bandas de las matrices de probabilidad de transición \\(\\small{\\boldsymbol{M}_t}\\). Sea el vector fila \\(\\small{\\boldsymbol{\\alpha}_t(x)=\\big(\\mathbb{P}\\{Y_t=(x,1)\\},\\ldots, \\mathbb{P}\\{Y_t=(x,1)\\}\\big)}\\) , para \\(\\small{t= 1,\\ldots, n}\\), de modo que la probabilidad de \\(\\small{X_n(\\Lambda)=x}\\) se puede representar como\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\{X_n(\\Lambda)=x \\mid \\boldsymbol{\\xi}_0\\}=\n\\boldsymbol{\\alpha}_n(x)\\boldsymbol{1}', \\, \\text{para toda}\\,\\,\nx=0,1,\\dots,l_n\n\\end{equation}\\]\n\ndonde \\(\\small{\\boldsymbol{1}'=(1,\\ldots,1)'}\\). Descomponga \\(\\small{\\boldsymbol{M}_t}\\) como \\(\\small{\\boldsymbol{M}_t=\\boldsymbol{K}_t+\\boldsymbol{H}_t}\\), donde \\(\\small{\\boldsymbol{K}_t}\\) es una matriz diagonal con componentes \\(\\small{\\boldsymbol{A}_t(x)}\\), para \\(\\small{x = 0,1,\\ldots,l_n}\\), y \\(\\small{\\boldsymbol{H}_t}\\) es una matriz diagonal superior con componentes \\(\\small{\\boldsymbol{B}_t(x)}\\), para \\(\\small{x = 0,1,\\ldots,l_{n-1}}\\). A partir de la multiplicación hacia atrás, \\(\\small{\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\displaystyle\\prod_{j=1}^{t}\\boldsymbol{M}_j\\Big)=\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\displaystyle\\prod_{j=1}^{t-1}\\boldsymbol{M}_j\\Big)\\boldsymbol{M}_t=\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\displaystyle\\prod_{j=1}^{t-1}\\boldsymbol{M}_j\\Big)\\big(\\boldsymbol{K}_t+\\boldsymbol{H}_t\\big)}\\), puede demostrarse que se cumplen las siguientes ecuaciones recursivas:\n\n\n\\[\\begin{align*}\n\\boldsymbol{\\alpha_t}(0)&=\\boldsymbol{\\alpha_{t-1}}(0)\\boldsymbol{A_t}(0) \\\\\n\\boldsymbol{\\alpha_t}(X)&=\n\\boldsymbol{\\alpha_{t-1}}(x-1)\\boldsymbol{B_{t-1}}(t-1)+\\boldsymbol{\\alpha_{t-1}}(x)\\boldsymbol{A_t}(x),\\, x=1,\\ldots,l_n.\n\\end{align*}\\]\n\nLa ecuación (2.17) proporciona un algoritmo eficiente para calcular las probabilidades \\(\\small{ \\mathbb{P}\\{X_n(\\Lambda)=x \\mid\\boldsymbol{\\xi}_0\\}=\\boldsymbol{\\alpha}_n(x)\\boldsymbol{1}', \\, \\text{para toda }\\, x=0,1,\\dots,l_n}\\), y esto es especialmente importante cuando la dimensión de las matrices de transición \\(\\small{\\boldsymbol{M_t}}\\) es grande y el esfuerzo computacional para calcular ingenuamente \\(\\small{\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\displaystyle\\prod_{t=1}^{n}\\boldsymbol{M}_t\\Big)\\boldsymbol{U'}(C_x)}\\) se vuelve prohibitivo. A partir de la multiplicación hacia atrás, la técnica de incrustación de cadenas finitas de Markov a menudo proporciona una ecuación recursiva en una forma similar a la ecuación (2.17), una forma que, en general, no puede obtenerse tan fácilmente mediante los métodos combinatorios o de renovación tradicionales.\n\n\n\nEn esta sección se derivan algunas expresiones útiles para la probabilidad de entrar en un estado absorbente. Para mayor claridad de la exposición, nos centraremos en las cadenas de Markov homogéneas, pero las ideas pueden generalizarse fácilmente a casos no homogéneos.\nUn estado \\(\\small{\\alpha \\in \\Omega}\\) se llama estado absorbente si, una vez que el sistema entra en el estado \\(\\small{\\alpha}\\), nunca sale; es decir, \\(\\small{p_{\\alpha\\alpha}\\equiv 1}\\) (y \\(\\small{p_{\\alpha\\beta}\\equiv 0}\\) para cualquier \\(\\small{\\alpha\\neq\\beta}\\)). Sea \\(\\small{A=\\{\\alpha_1,\\ldots,\\alpha_k\\}}\\) el conjunto de todos los estados absorbentes de una cadena de Markov homogénea \\(\\small{\\{Y_t\\}}\\) con una matriz de probabilidad de transición \\(\\small{\\boldsymbol{M}}\\). Bajo una disposición apropiada del espacio de estados, la matriz de probabilidad de transición \\(\\small{\\boldsymbol{M}}\\) siempre se puede escribir de la siguiente forma:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\\left(\\begin{array}{c|c}\n\\boldsymbol{N}_{(m-k)\\times (m-k)} & \\boldsymbol{C}_{(m-k)\\times (m-k)}\\\\\n\\hline  \n\\boldsymbol{O}_{k\\times (m-k)} & \\boldsymbol{1}_{k \\times k}\n\\end{array}\\right)\n\\end{equation}\\]\n\ndonde \\(\\small{m}\\) y \\(\\small{k}\\) \\(\\small{(m&gt;k)}\\) son los números de estados en \\(\\small{\\Omega}\\) y \\(\\small{A}\\), respectivamente. La matriz \\(\\small{\\boldsymbol{N}}\\) definida por la ecuación. (2.18) se conoce como la submatriz de probabilidad de transición esencial de la cadena de Markov. Desempeña un papel importante en el estudio de las distribuciones exactas de variables aleatorias incrustables en cadenas de Markov, especialmente para las distribuciones asociadas de tiempos de espera.\nSea \\(\\small{\\boldsymbol{\\xi_{0}}=\\big(\\boldsymbol{\\xi}:\\boldsymbol{0}\\big)_{1\\times m}}\\) la distribución inicial, donde \\(\\small{\\boldsymbol{\\xi}=(\\xi_1,\\ldots,\\xi_{m-k}), \\, \\boldsymbol{0}=(0,\\ldots,0)_{1\\times k}}\\) y \\(\\small{\\displaystyle{\\sum_{i=1}^{m-k}\\xi_i=1}}\\) y sea \\(\\small{\\big(\\boldsymbol{1:0}\\big)_{1\\times m}}\\) un vector fila, en donde \\(\\small{\\boldsymbol{1}=(1,\\ldots,1)_{1\\times (m-k)}}\\) La razón por la que suponemos que la distribución inicial tiene la forma \\(\\small{\\big(\\boldsymbol{\\xi_0}:\\boldsymbol{0}\\big)}\\) es estrictamente por razones prácticas, ya que la mayoría de los sistemas siempre comienzan en un estado no absorbente.\nTeorema 2.2 Dada una matriz de probabilidad de transición \\(\\small{\\boldsymbol{M}}\\) de una cadena de Markov homogénea \\(\\small{\\{Y_t\\}}\\) en la forma de la ecuación (2.18), la probabilidad para el índice de tiempo \\(\\small{n}\\) cuando el sistema ingresa por primera vez al conjunto de estados absorbentes puede ser obtenida como:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(Y_n\\in A,Y_{n-1}\\notin A,\\ldots,  Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)=\\boldsymbol{\\xi N}^{n-1}\\boldsymbol{(I-N)1'}\n\\end{equation}\\]\n\nDemostración: Dado que \\(\\small{\\boldsymbol{M}}\\) tiene la forma de la Equación 2.18, se sigue que:\n\n\n\\[\\begin{equation}\n\\mathbf{M}^{n-1}=\\left(\\begin{array}{c|c}\n\\boldsymbol{N}^{n-1} & \\boldsymbol{K}_{n-1}\\\\\n\\hline  \n\\boldsymbol{O} & \\boldsymbol{I}\n\\end{array}\\right)\n\\end{equation}\\]\n\nen donde \\(\\small{\\boldsymbol{K}_{n-1}=\\big( \\boldsymbol{I}+\\boldsymbol{N}+\\cdots+\\boldsymbol{N}^{n-2}\\big)\\boldsymbol{C}}\\). Además, como todos los estados en \\(\\small{\\boldsymbol{A}}\\) son estados absorbentes, de la ecuación de Chapman-Kolmogorov se deduce que:\n\n\n\\[\\begin{align*}\n\\mathbb{P}\\big(Y_{n-1}\\notin A,\\cdots,  Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big) & =\\mathbb{P}\\big(Y_{n-1}\\in \\Omega-A\\mid \\boldsymbol{\\xi_0}\\big)\\\\\n& =\\big(\\boldsymbol{\\xi_0}:\\boldsymbol{0}\\big) \\boldsymbol{ M}^{n-1}\\big(\\boldsymbol{1}:\\boldsymbol{0}\\big)'.\n\\end{align*}\\]\n\nLuego la ecuación (2.19) puede entonces deducirse utilizando las ecuaciones (2.20) y (2.21) a traves de:\n\n\n\\[\\begin{align*}\n& \\quad \\, \\, \\mathbb{P}\\big(Y_n\\in A,Y_{n-1}\\notin A,\\ldots,  Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)\\\\\n& =\\mathbb{P}\\big(Y_{n-1}\\notin A,\\ldots,  Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)-\\mathbb{P}\\big(Y_n\\notin A,Y_{n-1}\\notin A,\\ldots,  Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)\\\\\n& = \\big(\\boldsymbol{\\xi_0}:\\boldsymbol{0}\\big) \\boldsymbol{ M}^{n-1}\\big(\\boldsymbol{I-M}\\big)\\big(\\boldsymbol{1}:\\boldsymbol{0}\\big)' \\\\\n& =\\boldsymbol{\\xi N}^{n-1}\\boldsymbol{(I-N)1'}.\\hspace{8cm} \\Box\n\\end{align*}\\]\n\nEn vista de las Ecs. (2.20) y (2.21), los siguientes teoremas son inmediatos.\nTeorema 2.3 Para todo estado \\(\\small{i\\in \\Omega-A}\\)\n\n\n\\[\\begin{align*}\n\\mathbb{P}\\big(Y_{n-1}=i,Y_{n-2}\\notin A,\\ldots,  Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)= \\boldsymbol{\\xi N}^{n-1}\\boldsymbol{e_i'}.\n\\end{align*}\\]\n\nPrueba. Utilizando los mismos argumentos que en la demostración del Teorema 2.2 y reemplazando \\(\\small{\\boldsymbol{1'}}\\) por \\(\\small{\\boldsymbol{e_i'}}\\), la Ec. (2.22) se sigue directamente de las ecuaciones (2.20) y (2.21). \\(\\hspace{1cm} \\Box\\)\nTeorema 2.4 Para cualquier estado absorbente \\(\\small{j \\in A}\\), la probabilidad del sistema para llegar por primera vez al estado absorbente \\(\\small{j}\\) en el \\(\\small{n}-\\)ésimo ensayo es:\n\n\n\\[\\begin{align*}\n\\mathbb{P}\\big(Y_{n}=j,Y_{n-1}\\notin A,\\ldots,  Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)= \\boldsymbol{\\xi N}^{n-1}{C_j'}.\n\\end{align*}\\]\n\nen donde, \\(\\small{C_j'}\\) es la \\(\\small{j}-\\)ésima columna de la matriz \\(\\small{\\boldsymbol{C}}\\).\nPrueba: Para cualquier \\(\\small{j \\in A}\\), de la definición de la cadena de Markov y del Teorema 2.3 se deduce que:\n\n\n\\[\\begin{align*}\n& \\quad \\, \\mathbb{P}\\big(Y_{n-1}=j,Y_{n-1}\\notin A,\\ldots,  Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)\\\\\n& = \\sum_{i\\in \\Omega-A}\\mathbb{P}\\big(Y_{n-1}=i,Y_{n-2}\\notin A,\\ldots,  Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)\\times \\mathbb{P}\\big( Y_n=j\\mid Y_{n-1}=i \\big)\\\\\n&= \\sum_{i\\in \\Omega-A}\\boldsymbol{\\xi N}^{n-1}{e_i'}p_{ij}\\\\\n&= \\boldsymbol{\\xi N}^{n-1}\\sum_{i\\in \\Omega-A}{e_i'}p_{ij}\\\\\n&= \\boldsymbol{\\xi N}^{n-1}{C_j'}\\hspace{8cm}\n\\end{align*}\\]\n\nPara ilustrar los teoremas 2.2 a 2.4 y sus relaciones, proporcionamos el siguiente ejemplo sencillo.\nEjemplo 2.5 Sea \\(\\small{\\{Y_t\\}}\\) una cadena de Markov homogénea definida en el espacio de estados \\(\\small{\\{1, 2, 3, 4\\}}\\) con distribución inicial \\(\\small{\\boldsymbol{\\xi_0}=\\big(\\xi : 0 \\big)=(1,0:0,0)}\\) y matriz de probabilidad de transición\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\\begin{array}{cccc}&\n\\begin{array}{cccc}\n\\end{array}\n\\\\\n\\begin{array}{ccc}\n1 \\\\\n2 \\\\\n3\\\\\n4\\\\\n\\end{array}\n&\n\\left(\n\\begin{array}{cc|cc}\n1/2 & 1/4 & 1/4  &  0 \\\\\n1/3 & 1/3 & 0 &  1/3 \\\\\n\\hline\n0& 0  &  1 & 0 \\\\\n0&  0 & 0 &  1\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nen donde \\(\\small{A=\\{3,4\\}}\\) es el conjunto de estados absorbentes. Para \\(\\small{n = 3}\\) (tercer ensayo), las probabilidades de entrada del sistema en los estados absorbentes \\(\\small{3}\\) y \\(\\small{4}\\) son, respectivamente:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(Y_{3}=3,Y_{2}\\notin A,Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)=(0,1)\n\\left(\\begin{array}{cc}\n1/2 & 1/4\\\\\n1/3 & 1/3\\\\\n\\end{array} \\right)^{2}\n\\left(\\begin{array}{c}\n1/4\\\\\n0\\\\\n\\end{array} \\right)=\\frac{1}{12}\n\\end{equation}\\]\n\ny \n\n\\[\\begin{equation}\n\\mathbb{P}\\big(Y_{3}=4,Y_{2}\\notin A,Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)=(0,1)\n\\left(\\begin{array}{cc}\n1/2 & 1/4\\\\\n1/3 & 1/3\\\\\n\\end{array} \\right)^{2}\n\\left(\\begin{array}{c}\n0\\\\\n1/3\\\\\n\\end{array} \\right)=\\frac{5}{72}.\n\\end{equation}\\]\n\nAdemás, por el Teorema 2.2, la probabilidad de que el sistema entre por primera vez en el subconjunto \\(\\small{A=\\{3,4\\}}\\) en el tercer ensayo es\n\n\n\\[\\begin{align*}\n& \\quad \\,\\, \\mathbb{P}\\{Y_3\\in A,Y_{2}\\notin A,Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\}\\\\\n&=\\boldsymbol{\\xi N}^{3-1}\\boldsymbol{(I-N)1'}\\\\\n&=(0,1)\n\\left(\\begin{array}{cc}\n1/2 & 1/4\\\\\n1/3 & 1/3\\\\\n\\end{array} \\right)^{2}\n\\left[\n\\left(\\begin{array}{cc}\n1 & 0\\\\\n0 & 1\\\\\n\\end{array} \\right)-\n\\left(\\begin{array}{cc}\n1/2 & 1/4\\\\\n1/3 & 1/3\\\\\n\\end{array} \\right)\n\\right]\n\\left(\\begin{array}{c}\n1\\\\\n1\\\\\n\\end{array} \\right)\\\\\n& =\\frac{11}{72}\n\\end{align*}\\]\n\nComo verificación de los resultados anteriores, observemos que:\n\n\n\\[\\begin{align*}\n\\mathbb{P}\\big(Y_3\\in A,Y_{2}\\notin A,Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)& =\n\\mathbb{P}\\big(Y_3= 3,Y_{2}\\notin A,Y_1\\notin A \\mid \\boldsymbol{\\xi_0} \\big)\\\\\n&+ \\mathbb{P}\\big(Y_3= 4,Y_{2}\\notin A,Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\\\\n&= \\frac{11}{72} \\hspace{5cm}\\Diamond\n\\end{align*}\\]\n\nDe forma más general, puesto que para cada \\(\\small{i\\in \\Omega-A}\\)\n\n\\[\\begin{align*}\n\\sum_{j\\in A}p_{ij}= 1- \\sum_{j \\in \\Omega- A}p_{il}\n\\end{align*}\\]\n\nluego se deduce que \\(\\small{\\displaystyle\\sum_{j\\in A}C_j'=\\boldsymbol{(I-N)1'}}\\), y por tanto\n\n\n\\[\\begin{align*}\n\\sum_{j\\in A}\\boldsymbol{\\xi N}^{n-1}C_j'=\\boldsymbol{\\xi N}^{n-1}\\boldsymbol{(I-N)1'}\n\\end{align*}\\]\n\n\n\n\nUtilizando las ideas de la sección 2.6, podemos encontrar la probabilidad de que se produzca la primera entrada para cualquier subconjunto \\(\\small{B\\subset \\Omega}\\). Dado el subconjunto \\(\\small{B}\\), la matriz de probabilidad de transición \\(\\small{\\boldsymbol{M}}\\) de una cadena de Markov \\(\\small{\\{Y_t\\}}\\) homogénea siempre puede disponerse de la siguiente forma:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\n\\begin{array}{cc}\n{\\Omega-B} \\\\B \\end{array}\n\\left(\\begin{array}{c|c}\n\\boldsymbol{N} & \\boldsymbol{B}\\\\\n\\hline\n\\boldsymbol{J} &  \\boldsymbol{Q}\n\\end{array}\n\\right)\n\\end{equation}\\]\n\nTeorema 2.5 Sea \\(\\small{\\{Y_t\\}}\\) una cadena de Markov homogénea con matriz de probabilidad de transición \\(\\small{\\boldsymbol{M}}\\), en la forma de la ecuación (2.25), y con distribución inicial \\(\\small{\\boldsymbol{\\xi=(1:0)}}\\). Entonces, para un subconjunto \\(\\small{B}\\) de tamaño \\(\\small{k}\\) contenido en el espacio de estados \\(\\small{\\Omega}\\) de tamaño \\(\\small{m}\\), se cumplen las siguientes relaciones:\n(i) Para todo \\(\\small{j \\in B}\\)\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(Y_n =j,Y_{n-1}\\notin B,\\cdots,Y_1\\notin B \\mid \\boldsymbol{\\xi_0}\\big)=\\boldsymbol{\\xi N}^{n-1}\\boldsymbol{B_j'},\n\\end{equation}\\]\n\nen donde \\(\\small{B_j'}\\) es la \\(\\small{j}-\\)ésima columna de la matriz \\(\\small{\\boldsymbol{B}_{(m-k)\\times k}}\\) y\n(ii)\n\n\n\\[\\begin{align*}\n& \\quad \\,\\, \\mathbb{P}\\big(Y_n \\in B,Y_{n-1}\\notin B,\\cdots,Y_1\\notin B \\mid \\boldsymbol{\\xi_0}\\big)\\\\\n&=\\boldsymbol{\\xi N}^{n-1}\\boldsymbol{(I-N)1'}\\\\\n&=\\sum_{j\\in B}\\boldsymbol{\\xi N}^{n-1}{B'}_j,\n\\end{align*}\\]\n\nPrueba. Defina una nueva cadena de Markov \\(\\small{\\{Z_t\\}}\\) en el espacio de estados \\(\\small{\\Omega}\\), donde \\(\\small{\\{Z_t\\}}\\) es igual a \\(\\small{\\{Y_t\\}}\\)para todos los estados \\(\\small{i \\in \\Omega-B}\\) y donde todos los estados \\(\\small{j \\in B}\\) se toman como estados absorbentes. Entonces la matriz de probabilidad de transición \\(\\small{\\boldsymbol{M^{\\star}}}\\) para la cadena de Markov \\(\\small{\\{Z_t\\}}\\) tiene la forma\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}^{\\star}=\\big(p_{ij}^{\\ast}\\big)=\n\\left(\\begin{array}{c|c}\n\\boldsymbol{N} & \\boldsymbol{B}   \\\\\n\\hline\n\\boldsymbol{O} &  \\boldsymbol{I}\n\\end{array}\n\\right).\n\\end{equation}\\]\n\nDado que, para cada \\(\\small{n}\\) \n\n\\[\\begin{equation}\n\\mathbb{P}\\big(Y_n =j,Y_{n-1} \\notin B,\\cdots, Y_1\\notin B,Y_1\\notin B \\mid \\boldsymbol{\\xi_0}\\big)=\\mathbb{P}\\big(Z_n =j,Z_{n-1} \\notin B,\\cdots, Y_1\\notin B,Z_1\\notin B \\mid \\boldsymbol{\\xi_0}\\big),\n\\end{equation}\\]\n\nEl resultado (i) se desprende del teorema 2.4. De manera similar, el resultado (ii) se sigue inmediatamente a partir de (i) y el hecho de que \\(\\small{\\boldsymbol{(I-N)1'}=\\displaystyle\\sum_{j\\in B}{B'}_j}\\). \\(\\hspace{1cm}\\Box\\)\nLa prueba anterior está guiada por el hecho de que todos los estados en \\(\\small{B}\\) son estados absorbentes con respecto a la nueva cadena de Markov \\(\\small{\\{Z_t\\}}\\) y, por lo tanto, por ejemplo, para cada \\(\\small{i \\in \\Omega-B}\\), la probabilidad \\(\\small{\\mathbb{P}(Z_{n-1}=i)}\\) se puede dividir en dos partes de la siguiente manera:\n\n\n\\[\\begin{align*}\n\\mathbb{P}\\big(Z_{n-1} = i \\mid \\boldsymbol{\\xi_0}\\big) & =\n\\mathbb{P}\\big(Z_{n-1} =i, Z_{n-2} \\notin B,\\cdots, Z_1\\notin B \\mid \\boldsymbol{\\xi_0}\\big)\\\\\n& + \\mathbb{P}\\big(Z_{n-1} =i \\text{ y por lo menos uno de } Z_{n-2},\\cdots ,Z_1 \\text{ esta dentro de } B \\mid \\boldsymbol{\\xi_0}\\big)\n\\end{align*}\\]\n\nen donde la segunda parte es siempre cero (ya que \\(\\small{i \\in \\Omega-B}\\) y \\(\\small{p_{ij}^{\\ast}\\equiv 0}\\) para todos \\(\\small{j \\in B}\\)). Tenga en cuenta que, en el teorema 2.5, asumimos la distribución inicial \\(\\small{(\\boldsymbol{\\xi:0})}\\)), lo que equivale a decir \\(\\small{\\mathbb{P}\\big(Y_0\\in B\\big)\\equiv 1}\\). En consecuencia, la probabilidad \\(\\small{\\mathbb{P}\\big(Y_n \\in B,Y_{n-1}\\notin B,\\cdots,Y_1 \\notin B \\mid \\boldsymbol{\\xi_0}\\big)}\\) se conoce como probabilidad de primera entrada.\nEjemplo 2.6 Sea \\(\\small{\\{Y_t\\}}\\) una cadena de Markov homogénea definida en el espacio de estados \\(\\small{\\Omega=\\{1,2,3,4,5\\}}\\) con matriz de probabilidad de transición\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\n\\begin{array}{ccccc}&\n\\begin{array}{ccccc}\n\\end{array}\n\\\\\n\\begin{array}{ccccc}\n1 \\\\\n2 \\\\\n3\\\\\n4\\\\\n5\n\\end{array}\n&\n\\left(\n\\begin{array}{ccccc}\n1/2 & 1/4 & 1/4  & 0 &  0 \\\\\n1/4 & 1/2  & 0  &  1/4 & 0 \\\\\n1/4 & 1/4  &  0 & 0 & 1/2 \\\\\n0&  0 & 0 &  1 &0 \\\\\n0&  0 & 0 &  0 & 1 \\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nSupongamos que \\(\\small{B = \\{3, 4\\}}\\), entonces la matriz de probabilidad de transición de \\(\\small{B = \\{Y_t\\}}\\) se puede reorganizar como:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\n\\begin{array}{ccccc}&\n\\begin{array}{ccccc}\n\\end{array}\n\\\\\n\\begin{array}{ccccc}\n1 \\\\\n2 \\\\\n3\\\\\n4\\\\\n5\n\\end{array}\n&\n\\left(\n\\begin{array}{ccc|cc}\n1/2 & 1/4 & 0  & 1/4 &  0 \\\\\n1/4 & 1/2  & 0  &  0 & 1/4 \\\\\n0 & 0 &  1 & 0 & 0 \\\\\n\\hline\n1/4 &  1/4 & 1/2 &  0 & 0 \\\\\n0&  0 & 0 &  0 & 1 \\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nDada una distribución inicial de \\(\\small{Y_0}\\), digamos \\(\\small{\\mathbb{P}(Y_0=1)=1}\\), la probabilidad de primera entrada para \\(\\small{Y_n=3}\\), es\n\n\n\\[\\begin{align*}\n& \\quad \\,\\mathbb{P}\\big(Y_n =3,Y_{n-1} \\notin B,\\cdots,Y_1\\notin B \\mid Y_0 = 1\\big)\n\\\\\n& =(0,0,1)\n\\left(\\begin{array}{ccc}\n1/2 & 1/4 & 0\\\\\n1/4 & 1/2 & 0\\\\\n0 & 0 & 1\n\\end{array} \\right)^{n-1}\n\\left(\\begin{array}{c}\n1/4\\\\\n0\\\\\n0\n\\end{array} \\right)\\\\\n\\end{align*}\\]\n\nPara \\(\\small{n = 3}\\), obtenemos que \\(\\small{\\mathbb{P}\\big(Y_n =3,Y_{3} \\notin B,Y_1\\notin B \\mid Y_0 = 1\\big)=5/64}\\). Tenga en cuenta que dado que el estado “\\(\\small{5}\\)” es un estado absorbente, los cálculos se pueden reducir aún más a:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(Y_n =3,Y_{n-1} \\notin B,\\cdots,Y_1\\notin B \\mid Y_0 = 1\\big)=(1,0)\n\\left(\\begin{array}{ccc}\n1/2 & 1/4 \\\\\n1/4 & 1/2\n\\end{array} \\right)^{n-1}\n\\left(\\begin{array}{c}\n1/4\\\\\n0\n\\end{array} \\right) \\hspace{5cm}\\Diamond\n  \\end{equation}\\]\n\nSea \\(\\small{A}\\) el conjunto que contenga todos los estados absorbentes de \\(\\small{\\{Y_t\\}}\\) y sea \\(\\small{B^{\\ast}= A \\cup B}\\). La matriz de probabilidad de transición \\(\\small{\\boldsymbol{M^{*}}}\\) , correspondiente a la cadena de Markov asociada \\(\\small{\\{Z_t\\}}\\) en la que todos los estados en \\(\\small{B^{\\ast}}\\) se toman como estados absorbentes, puede entonces reordenarse como:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M^{\\ast}}=\n\\begin{array}{cc}\n{\\Omega-B^{\\ast}} \\\\B^{\\ast} \\end{array}\n\\left(\\begin{array}{c|c}\n\\boldsymbol{N^{\\ast}} & \\boldsymbol{B^{\\ast}}\\\\\n\\hline\n\\boldsymbol{J} &  \\boldsymbol{Q}\n\\end{array}\n\\right)\n\\end{equation}\\]\n\nen donde \\(\\small{\\boldsymbol{N^{*}}}\\) es la submatriz esencial de \\(\\small{\\boldsymbol{M^{*}}}\\), y \\(\\small{\\boldsymbol{B^{*}}}\\) es la matriz formada a partir de \\(\\small{\\boldsymbol{M^{*}}}\\) mediante la eliminación de todas las columnas asociadas con los estados en \\(\\small{\\Omega-B^{*}}\\) y de todas las filas asociadas con los estados en \\(\\small{B^{*}}\\). Entonces se cumple el siguiente corolario.\nColorario: Para todo \\(\\small{j\\in B}\\)\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(Y_n =j,Y_{n-1} \\notin B,\\cdots,Y_1\\notin B \\mid (\\boldsymbol{\\xi}:\\boldsymbol{0}) \\big)= \\boldsymbol{\\xi^{\\ast}}(\\boldsymbol{N^{\\ast}})^{n-1}B_{j}^{*'},\n\\end{equation}\\]\n\nsiendo \\(\\small{B_{j}^{*'}}\\) la \\(j-\\)ésima columna de la matriz \\(\\small{\\boldsymbol{B^{\\ast}}}\\)\nLa prueba del corolario anterior es sencilla y se deja en manos del lector. Tenga en cuenta que el tamaño de la matriz \\(\\small{\\boldsymbol{N^{\\ast}}}\\) es menor o igual que el tamaño de \\(\\small{\\boldsymbol{N}}\\).\n\n\n\n\n\n\nAunque las rachas y patrones en una sucesión de ensayos de Bernoulli son casos especiales de los ensayos multiestados, merecen un capítulo aparte debido a su larga historia, la gran cantidad de resultados asociados y su amplia aplicación a numerosos campos. El enfoque de este capítulo será derivar las distribuciones para las estadísticas de rachas más comunes y útiles en ensayos de Bernoulli mediante la técnica de incrustación de cadenas finitas de Markov, y también en extender estos resultados a secuencias de ensayos de dos estados dependientes de Markov. También se presentan técnicas para obtener ecuaciones recursivas y funciones generadoras de probabilidad de estadísticas de rachas a través del enfoque de incrustación de cadenas finitas de Markov. Estas herramientas pueden ser muy útiles para estudiar ciertas características de las distribuciones de rachas, como la media, la varianza y los momentos superiores.\nEn este capítulo se tratan las siguientes estadísticas de rachas, definidas tradicionalmente en una secuencia de \\(\\small{n}\\) ensayos de Bernoulli:\n(i) \\(\\small{N_{n,k}}\\) el número de \\(\\small{k}\\) éxitos consecutivos no superpuestos;\n(ii) \\(\\small{G_{n,k}}\\) el número de rachas exitosas de tamaño mayor o igual a \\(\\small{k}\\).\n(iii) \\(\\small{M_{n,k}}\\) el número de \\(\\small{k}\\) éxitos consecutivos solapados.\n(iv) \\(\\small{E_{n,k}}\\) el número de rachas de exctamente \\(\\small{k}\\) éxitos.\n(v) \\(\\small{L_{n,k}}\\) el tamaño de la racha de exitos más larga;\n(vi) \\(\\small{S_{n,k}}\\) el número total de éxitos en rachas exitosas de longitud mayor o igual a \\(\\small{k}\\) .\nTambién se trata la distribución del tiempo de espera de una racha de éxitos y se incluyen algunos resultados numéricos para las distribuciones de las estadísticas de las rachas anteriores.\n\n\n\nEl número de rachas de \\(\\small{k}\\) éxitos consecutivos no superpuestos, \\(\\small{N_{n,k}}\\), en una secuencia de \\(\\small{n}\\) ensayos de Bernoulli es probablemente la estadística de ejecuciones más importante, no sólo por su amplia aplicación a diversas áreas sino también por su conexión con otras estadísticas de rachas; En teoría de la distribución, la distribución de \\(\\small{N_{n,k}}\\) se conoce como distribución binomial de orden \\(\\small{k}\\). Philippou y Makri (1986) e Hirano (1986) dieron de forma independiente una fórmula para la distribución exacta de \\(\\small{N_{n,k}}\\) en una secuencia de \\(\\small{n}\\) ensayos de Bernoulli como:\n\n\n\\[\\begin{equation}\n\\mathbb{P}(N_{n,k}=x)=\\sum_{m=0}^{k-1}\\sum_{x_1+x_2+\\cdots+\\\\\nkx_k=n-m-km}\\binom{x_1+x_2+\\cdots+x_k+x}{x_1,x_2,\\cdots,x_k,x}p^n\\Big(\\frac{q}{p}\\Big)^{x_1+x_2+\\cdots+x_k},\n\\end{equation}\\]\n\nen donde, \\(\\small{x=0,1,\\ldots,[n/k]}\\,\\) (\\(\\small{[n/k]}\\) la parte entera de \\(\\small{n/k}\\)) y con probabilidades de éxito \\(\\small{p}\\) y fracaso \\(\\small{p=1-p}\\). Godbole (1990) dio una fórmula alternativa para la función de probabilidad de \\(\\small{N_{n,k}}\\) con \\(\\small{k&gt;1}\\):\n\n\n\\[\\begin{align*}\n\\mathbb{P}(N_{n,k}=x) &=\\sum_{[(n-kx)/k]\\leq y \\leq n-kx} \\binom{y+x}{x}q^yp^{n-y}\\\\\n& \\times \\sum_{0 \\leq j \\leq  [(n-kx-y)/k]}(-1)^j \\binom{y+1}{j} \\binom{n-kx-jk}{y},\n\\end{align*}\\]\n\npara \\(\\small{x=0,1,\\ldots,[n/k]}\\,\\). La fórmula (3.2) tiene la ventaja sobre la (3.1) de que es más fácil de evaluar por computadora para \\(\\small{n}\\,\\) grande. Hirano y Aki (1987, 1993) estudiaron algunas propiedades de esta distribución y ampliaron los resultados al caso de ensayos de Markov dependientes de dos estados.\nPara comenzar nuestro estudio de \\(\\small{N_{n,k}}\\) utilizando el método de incrustación de cadenas finitas de Markov, consideremos el espacio de estados\n\n\n\\[\\begin{equation}\n\\Omega =\\{(x,i):x=0,1,\\cdots,l_n\\, \\text{y}\\, 0,1,\\cdots,k-1\\},\n\\end{equation}\\]\n\nen donde, \\(\\small{l_n=[n/k]}\\,\\) es el número máximo de rachas exitosas no superpuestas de longitud \\(\\small{k}\\) que pueden ocurrir en \\(\\small{n}\\) ensayos. Ahora definamos la Cadena de Markov finita homogenea \\(\\small{\\{Y_t:t=0,1,\\ldots,n\\}}\\,\\) sobre \\(\\small{\\Omega}\\,\\) como sigue:\n\n\n\\[\\begin{equation}\nY_t=(N_{t,k},E_{t}),\\quad \\text{para }1\\leq t \\leq n,\n\\end{equation}\\]\n\ndonde \\(\\small{N_{n,k}}\\) es el número de \\(\\small{k}\\) éxitos consecutivos no superpuestos que ocurrieron durante los primeros \\(\\small{t}\\) ensayos \\(\\small{X_1,X_2,\\ldots,X_n}\\). El “bloque final” \\(\\small{E_t}\\) es igual a \\(\\small{m}\\) módulo \\(\\small{k}\\), donde \\(\\small{m}\\) representa el número de éxitos finales (posiblemente cero) que existen en la sucesión después de las primeros \\(\\small{t}\\) ensayos:\n\n\n\\[\\begin{equation}\nFFSSF\\underbrace{SS\\cdots S}_{m}.\n\\end{equation}\\]\n\nObservemos que \\(\\small{E_t=0}\\) si \\(\\small{m}\\) es un múltiplo positivo de \\(\\small{k}\\) o si el \\(\\small{t-}\\)ésimo resultado es \\(\\small{F}\\). Esta variable de bloque final realiza un seguimiento del número de éxitos en una posible racha parcial asociada con en el \\(\\small{t-}\\)ésimo ensayo. Por ejemplo, dados \\(\\small{n=10}\\) ensayos de Bernoulli con resultados \\(\\small{\\{FSFFSSSFSS\\}}\\) y una duración de ejecución exitosa elegida de \\(\\small{k=2}\\), la realización de la cadena de Markov incorporada \\(\\small{\\{Y_t: t = 1,2,\\ldots, 10\\}}\\) con respecto a estos diez resultados es: \\(\\small{\\{Y_1=(0,0), Y_2 = (0, 1), Y_3=(0,0), Y_4=(0,0),Y_5= (0,1),Y_6 = (1,0), Y_7=(1, 1), Y_8=(1,0),Y_9=(1,1), Y_{10}=(2,0)\\}}\\). Tenga en cuenta que para una secuencia dada de resultados \\(\\small{\\{FS\\cdots SF\\}}\\), la realización de \\(\\small{\\{Y_t\\}}\\) es siempre única.\nDefinir los subconjuntos\n\n\n\\[\\begin{equation}\nC_x =\\{(x,i): i=0,1,\\cdots,k-1\\},\\quad 0\\leq x \\leq l_n\n\\end{equation}\\]\n\nLa colección de subconjuntos \\(\\small{\\{C_x:x = 0,1,\\ldots,l_n\\}}\\) forma una partición del espacio de estados \\(\\small{\\Omega}\\). Dado que \\(\\small{\\{X_t\\}}\\) es, por el momento, una sucesión de ensayos Bernoulli, de las definiciones anteriores se deduce que \\(\\small{Y_t}\\) tiene una matriz de probabilidad de transición \\(\\small{\\boldsymbol{M_t} = (p_{(x,i)(y,j)})}\\) para todo \\(\\small{t=1,2,\\ldots,n}\\), con las probabilidades de transición \\(\\small{(p_{(x,i)(y,j)})}\\) dadas por la siguiente ecuación: para \\(\\small{1 \\leq t \\leq n}\\) y \\(\\small{0 \\leq x \\leq l_n}\\) \n\n\\[\\begin{align*}\np_{(x,i)(y,j)} & = \\mathbb{P}\\big(Y_t=(y,j)\\mid Y_{t-1}=(x,i)\\big)\\\\\n& =\\begin{cases}\nq \\quad \\text{si }y=x\\,\\text{y }j=0,\\,\\text{para }i=0,1,\\ldots, k-1\n\\\\\np \\quad \\text{si }y=x\\,\\text{y }j=i+1,\\,\\text{para }i=0,1,\\ldots, k-2\n\\\\\np \\quad \\text{si }y=x+1\\,\\text{y }j=0,\\,\\text{para }i=k-1\\,\\text{y },x=0,1,\\ldots, l_{n}-1\n\\\\\n1 \\quad \\text{si }y=x=l_{n}\\,\\text{y }j=i=k-1\n\\\\\n0 \\quad \\text{en otro caso}\n\\end{cases}\n\\end{align*}\\]\n\nA modo de ilustración, la matriz de probabilidad de transición \\(\\small{\\boldsymbol{M_t}}\\) de la cadena de Markov incrustada \\(\\small{{Y_t}}\\) asociada con la variable aleatoria \\(\\small{N_{5,2}}\\) viene dada por\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\n\\begin{array}{cccccc}&\n\\begin{array}{cccccc}\n\\end{array}\n\\\\\n\\begin{array}{cccccc}\n(0,0)\\\\\n(0,1)\\\\\n(1,0)\\\\\n(1,1)\\\\\n(2,0)\\\\\n(2,1)\n\\end{array}\n&\n\\left(\n\\begin{array}{cc|cc|cc}\nq&p&0&0&0&0\\\\\nq&0&p&0&0&0\\\\\n\\hline\n0&0&q&p&0&0\\\\\n0&0&q&0&p&0\\\\\n\\hline\n0&0&0&0&q&p\\\\\n0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}_{6\\times6}\n\\end{equation}\\]\n\npara \\(\\small{1\\leq t \\leq 5.}\\)\nPara el caso donde \\(\\small{\\{X_t\\}}\\) es una sucesión de ensayos de dos estados independientes pero no idénticamente distribuidos con probabilidades \\(\\small{\\mathbb{P}(X_t=S)=p_t}\\) y \\(\\small{\\mathbb{P}(X_t=F)=q_t}\\) , para \\(\\small{t=1,2,\\ldots,n}\\), las matrices de transición \\(\\small{\\boldsymbol{M_t}}\\) para la cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) permanece sin cambios excepto que la probabilidad \\(\\small{p}\\) se reemplaza por \\(\\small{p_t}\\) y \\(\\small{q}\\) se reemplaza por \\(\\small{q_t}\\). En general, para ensayos de dos estados independientes pero no idénticamente distribuidos, las matrices de probabilidad de transición se pueden escribir como\n\n\n\\[\\begin{equation}\n\\boldsymbol{M_t}(N_{n,k})=\n\\left(\\begin{array}{cccc}\n\\boldsymbol{A_t}&\\boldsymbol{B_t}&&&\\boldsymbol{0}\\\\\n&&\\ddots&\\ddots&\\\\\n\\boldsymbol{0}&&&\\boldsymbol{A_t}&\\boldsymbol{B_t}\\\\\n&&&&\\boldsymbol{A_{t}^{\\ast}}\\\\\n\\end{array}\\right)_{d\\times d},\n\\end{equation}\\]\n\npara \\(\\small{t=1,2,\\dots,n}\\), en donde:\n\n\n\\[\\begin{equation}\n\\boldsymbol{A_t}=\n\\left(\\begin{array}{ccccc}\nq_t&p_t&0&\\cdots&0\\\\\nq_t&0&p_t&\\cdots&0\\\\\n\\vdots& &\\ddots&\\ddots&\\\\\n\\vdots& & &\\ddots&p_t\\\\\nq_t&0&0&\\cdots&0\\\\\n\\end{array}\\right)_{k\\times k},\n\\end{equation}\\]\n\n\\(\\small{\\boldsymbol{B_t}}\\) es una matriz \\(\\small{k\\times k}\\) que tiene \\(\\small{p_t}\\) en la entrada \\(\\small{(k,1)}\\) y cero en el resto, \\(\\small{\\boldsymbol{A_t}^{\\ast}}\\) es igual que \\(\\small{\\boldsymbol{A_t}}\\) excepto que su última fila se reemplaza con \\(\\small{(0,0,...,0,1)}\\), y la dimensión de \\(\\small{\\boldsymbol{M_t}(N_{n,k})}\\) viene dado por \\(\\small{d = k(l_n+1)}\\). Por tanto, en virtud del teorema 2.1, podemos afirmar que\n\n\n\\[\\begin{equation}\n\\small{\\mathbb{P}\\big( N_{n,k}=x\\big)=\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\prod_{t=1}^{n}\\boldsymbol{M}_t(N_{n,k})\\Big)\\boldsymbol{\\mathbf{U}'}(\\mathbf{C_x})},\\,\\,  x=1,2,\\ldots,l_n,\n\\end{equation}\\]\n\nen donde, \\(\\small{\\boldsymbol{\\mathbf{\\xi}}_0=(1,0,\\ldots,0)_{1\\times d}}\\) y \\(\\small{\\boldsymbol{\\mathbf{U}'}({C_x})}\\) es la transpuesta del vector \\(\\small{\\boldsymbol{\\mathbf{U}'}({C_x})=(0,\\ldots,0, 1,\\ldots, 1, 0,\\ldots,0)}\\) con unos en las ubicaciones asociadas con los estados en \\(\\small{C_x}\\). La ecuación (3.8) representa la distribución exacta de \\(\\small{N_{n,k}}\\) para ensayos independientes de dos estados distribuidos tanto de forma idéntica como no idéntica. En vista de la matriz de probabilidad de transición en la ecuación (3.7), \\(\\small{N_{n,k}}\\) es una cadena finita de Markov incrustable de tipo binomial en el sentido de la Definición 2.7 (Koutras y Alexandrou 1995).\nSi \\(\\small{\\{X_t\\}}\\) es una Cadena de Markov no homogenea com matriz de probabilidades de transición:\n\n\n\\[\\begin{equation}\n\\left(\\begin{array}{cc}\np_{FF}(t)&p_{SS}(t)\\\\\np_{FF}(t)&p_{SS}(t)\n\\end{array}\\right),\n\\end{equation}\\]\n\nentonces, es necesaria una modificación menor en el procedimiento de incrustación para obtener la distribución de \\(\\small{N_{n,k}}\\). Dado que el resultado de \\(\\small{X_{t+1}}\\), y por tanto también de \\(\\small{Y_{t+1}}\\), ahora depende de \\(\\small{X_t}\\), cada estado de la cadena de Markov \\(\\small{Y_t}\\) debe implicar un cierto resultado de \\(\\small{X_t}\\). Este ya es el caso en nuestra definición anterior de \\(\\small{Y_t}\\), salvo para los estados con un bloque final de \\(\\small{E_t=0}\\), que puede surgir para cualquier resultado de \\(\\small{X_t}\\). Para resolver esta ambigüedad, definimos un estado de bloque final adicional, \\(\\small{E_t=\\gamma}\\), para corresponder al caso donde la serie de éxitos finales es un múltiplo distinto de cero de \\(\\small{k}\\) éxitos, y reservamos el estado \\(\\small{E_t=0}\\) para el caso donde el resultado \\(\\small{t-}\\)ésimo es un fracaso. La cadena de Markov incrustada se define entonces de la siguiente manera:\n\n\n\\[\\begin{equation}\nY_t =\n\\begin{cases}\n(x,\\gamma) & \\begin{array}{l} \\text{Si existen } x \\text{ rachas de } k \\text{ aciertos} \\\\\n\\text{consecutivos en los primeros } t \\\\\n\\text{ensayos con } m &gt; 0 \\text{ aciertos finales}\\\\\n\\text{tales que } m \\equiv k \\pmod{k} \\end{array} \\\\\n\\\\\n(x,0) & \\begin{array}{l}\\text{Si existen } x \\text{ rachas de } k \\text{ aciertos}\\\\\n\\text{consecutivos en los primeros } t\\text{ ensayos} \\\\ \\text{con } m = 0 \\text{ aciertos finales} \\text{ (}X_t=F\\text{)} \\end{array}\n\\end{cases}\n\\end{equation}\\]\n\ny \\(\\small{Y_t=(x,i)}\\), para \\(\\small{i=1,2,\\ldots,k-1}\\) se define como se indica en la ecuación (3.3). La diferencia entre los estados \\(\\small{(x,\\gamma)}\\) y \\(\\small{ (x,0)}\\) se puede ver en el siguiente ejemplo: para una racha exitosa de longitud \\(\\small{k=2}\\), \\(\\small{Y_8=(SFFFSSSS) = (2,\\gamma)}\\) y \\(\\small{Y_8=(SFSSFSSF)= (2,0)}\\). Tenga en cuenta que el bloque final \\(\\small{E_t}\\) ahora contiene no solo la información requerida sobre los subpatrones sino que también implica el resultado de \\(\\small{X_t}\\), lo que permite la asignación de probabilidades de transición para la Cadena de Markov incustada.\nLas matrices de probabilidad de transición correspondientes a estas definiciones pueden deducirse fácilmente. La cadena de Markov incrustada asociada con la variable aleatoria \\(\\small{N_{5,2}}\\) como se considera en la Ecuación (3.6) para ensayos de Bernoulli, tiene las siguientes matrices de transición \\(\\small{\\boldsymbol{M_t^{\\ast}}}\\) bajo ensayos dependientes de Markov no homogéneos: para \\(\\small{t=1,2,\\ldots,n}\\)\n\n\n\\[\\begin{equation}\n\\boldsymbol{M_t^*}(N_{5,2})=\n\\begin{array}{cc}\n\\begin{array}{c}\n(0,0)\\\\\n(0,1)\\\\\n(1,c)\\\\\n(1,0)\\\\\n(1,1)\\\\\n(2,c)\\\\\n(2,1)\\\\\n(2,1)\n\\end{array}&\n\\left(\n\\begin{array}{cc|ccc|ccc}\np_{FF}(t)&p_{FS}(t)&0&0&0&0&0&0\\\\\np_{FS}(t)&0&p_{SS}(t)&0&0&0&0&0\\\\\n\\hline\n0&0&0&p_{SF}(t)&p_{SS}(t)&0&0&0\\\\\n0&0&0&p_{FF}(t)&p_{FS}(t)&0&0&0\\\\\n0&0&0&p_{SF}(t)&0&p_{SS}(t)&0&0\\\\\n\\hline\n0&0&0&0&0&&p_{SF}(t)&p_{SS}(t)\\\\\n0&0&0&0&0&0&p_{FF}(t)&p_{FS}(t)\\\\\n0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nNote que la estructura de “franja/banda” de \\(\\small{\\boldsymbol{M_t^{\\ast}}(N_{5,2})}\\) es similar con \\(\\small{\\boldsymbol{M_t}(N_{5,2})}\\) de la ecuación (3.6) para ensayos de Bernoulli. Como es sencillo derivar la forma general de \\(\\small{\\boldsymbol{M_t^{\\ast}}(N_{n,k})}\\) análoga a la ecuación (3.7), esto lo dejamos al lector interesado.\nCuando la secuencia \\(\\small{\\{X_t\\}}\\) es i.i.d., la distribución inicial \\(\\small{\\boldsymbol{\\xi}_0}\\) puede definirse como \\(\\small{\\mathbb{P}\\big(Y_0=(0,0)\\big)=1}\\), y luego para \\(\\small{k&gt;1}\\), las probabilidades de transición \\(\\small{\\mathbb{P}\\big(Y_1=(0,1)\\mid Y_0=(0,0)\\big)=p}\\) y \\(\\small{\\mathbb{P}\\big(Y_1=(0,0)\\mid Y_0=(0,0)\\big)=q=(1-p)}\\). Sin embargo, cuando \\(\\small{\\{X_t\\}}\\) es una sucesión de variables aleatorias Markov-Dependientes , se debe tener cuidado al asumir \\(\\small{\\mathbb{P}\\big(Y_0=(0,0)\\big)=1}\\), lo que implicaría que las probabilidades de transición entre \\(\\small{Y_0}\\) e \\(\\small{Y_1}\\) están dadas por \\(\\small{\\mathbb{P}\\big(Y_1=(0,1)\\mid Y_0=(0,0)\\big)=p_{FS}(1)}\\) y \\(\\small{\\mathbb{P}\\big(Y_1=(0,0)\\mid Y_0=(0,0)\\big)=p_{FF}=1}\\), independiente de \\(\\small{p_{SF}}\\) y \\(\\small{p_{FF}}\\). Para evitar este tipo de sesgo, es útil crear un estado ficticio \\(\\small{\\emptyset}\\) como estado inicial para \\(\\small{Y_0}\\). Luego definimos \\(\\small{\\mathbb{P}\\big(Y_0=\\emptyset\\big)=1}\\), y las probabilidades de transición \\(\\small{\\mathbb{P}\\big(Y_1=(0,1)\\mid Y_0=\\emptyset\\big)=p_{s}}\\), y \\(\\small{\\mathbb{P}\\big(Y_1=(0,0)\\mid Y_0=\\emptyset\\big)=p_{f}}\\). Por tanto, para \\(\\small{N_{5,2}}\\) la correspondiente cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) se define en el espacio de estados expandido \\(\\small{\\Omega=\\{\\emptyset,(0,0),(0,1),(1,0),\\ldots\\}}\\) con matrices de probabilidad de transición:\n\n\n\\[\\begin{equation}\n\\begin{array}{cc} &\n\\begin{array}{cccccc}(0,0)&(0,1)&(1,c)&(1,0)&(1,1)&\\cdots\n\\end{array}\\\\\n\\begin{array}{cccccccc}\n\\end{array}\n&\n\\left(\n\\begin{array}{c|ccccc}\n0 &  p_{f}  & p_{s} &  0  &   0 & \\cdots \\\\\n\\hline\n\\, 0&&&&&\\\\\n0&&&\\boldsymbol{M_t}^{\\ast}(N_{5,2})&&\\\\\n0&&&&&\\\\\n\\end{array}\n\\right)\\end{array}\n\\end{equation}\\]\n\nTenga en cuenta que el procedimiento de incrustación de cadenas finitas de Markov utilizado para obtener la distribución exacta de \\(\\small{N_{n,k}}\\) sigue siendo el mismo, excepto por diferencias menores en las matrices de probabilidad de transición, independientemente de si la secuencia de ensayos \\(\\small{\\{X_t\\}}\\) es i.i.d., independiente pero no idéntica distribuida o si es Markov-Dependiente.\n\n\n\nPara una sucesión de ensayos de dos estados, la variable aleatoria \\(\\small{G_{n,k}}\\) se define como el número de rachas exitosas de longitud mayor o igual a \\(\\small{G_{n,k}}\\). Consideremos una cadena de Markov finita \\(\\small{\\{Y_t:t=0,1,2,\\ldots,n\\}}\\) definida en el espacio de estados:\n\n\n\\[\\begin{equation}\n\\Omega =\\{(x,i):x=0,1,\\cdots,l_n\\,\\, \\text{y}\\,\\, i= \\gamma,0,1,\\cdots,k-1\\}-{\\{(0,\\gamma)\\}},\n\\end{equation}\\]\n\nen donde, \\(\\small{l_n=[(n+1)/(k+1)]}\\). Para una sucesión de resultados de los primeros \\(\\small{t}\\) ensayos con \\(\\small{m}\\) éxitos finales, digamos \\(\\small{FS \\cdots F \\underbrace{SS \\cdots}_{m}S}\\), definimos la cadena de Markov:\n\n\n\\[\\begin{equation}\nY_t=(G_{n,k},E_t) \\quad 1\\leq t\\leq n,\n\\end{equation}\\]\n\ndonde \\(\\small{G_{n,k}}\\), es el número de rachas exitosas de longitud mayor o igual a \\(\\small{k}\\) en la sucesión \\(\\small{\\{X_t\\}}\\), y \\(\\small{E_t}\\) es la variable del bloque final con \\(\\small{E_t=m}\\) si \\(\\small{m=0,1,2,\\ldots,k-1}\\), y \\(\\small{E_t=\\gamma}\\) si \\(\\small{m\\geq k}\\). Para ilustrar esta definición, considere una longitud de racha mínima de \\(\\small{k=2}\\) y los siguientes doce resultados, de un ensayo de dos estados: \\(\\small{FSFFSSFSSSFS}\\), para los cuales \\(\\small{G_{12,2}=2}\\). Se deduce de la Ec.(3.9) que la realización de la Cadena de Markov \\(\\small{\\{Y_t:t=0,1,2,\\ldots,14\\}}\\) es : \\(\\small{\\{Y_1=(0,0),Y_2=(0,1),Y_3=(0,0),Y_4=(0,0),Y_5=(0,1),Y_6=(1,\\gamma),Y_7=(1,0),Y_8=(1,1),Y_9=(2,\\gamma),Y_{10}=(2,\\gamma),Y_{11}=(2,0),Y_{12}=(2,0)\\}}\\). Note que el bloque final \\(\\small{E_t=\\gamma}\\) puede ocurrir sólo cuando hay al menos \\(\\small{k}\\) éxitos finales, en cuyo caso \\(\\small{G_{n,k}\\geq k}\\) por esta razón, el estado \\(\\small{(0,\\gamma)}\\) fue excluido en la definición anterior del espacio de estados \\(\\small{\\Omega}\\).\nDe la definición de la cadena de Markov incrustada dada por la Ecu. (3.9), las probabilidades de transición de un paso en \\(\\small{\\boldsymbol{M_t}(G_{n,k})}\\) para ensayos independientes pero no identicamente distribuidos se especifican mediante la siguiente ecuación: para \\(\\small{t=1,2,\\ldots,n}\\)\n\n\n\\[\\begin{equation}\np_{(x,i)(y,i)}(t) =\n\\begin{cases}\nq_t & \\begin{array}{l} \\text{Si}\\,\\, y=x \\,\\, \\text{y}\\,\\, j=0 \\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n \\,\\text{y}\\, i=\\gamma,0,1,\\ldots,k-1  \\end{array} \\\\\np_t & \\begin{array}{l} \\text{Si}\\,\\, y=x \\,\\, \\text{y}\\,\\, j=i=\\gamma\\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n  \\end{array}\n\\\\\np_t & \\begin{array}{l} \\text{Si}\\,\\, y=x \\,\\, \\text{y}\\,\\, j=i+1\\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n \\,\\text{y}\\, i=\\gamma,0,1,\\ldots,k-2  \\end{array}\n\\\\\np_t & \\begin{array}{l} \\text{Si}\\,\\, y=x+1,\\,i=k-1 \\,\\, \\text{y}\\, j=\\gamma \\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n-1  \\end{array}\n\\\\\n1 & \\begin{array}{l} \\text{Si}\\,\\, y=x=l_n,\\,j=x=k-1\\end{array} \\\\\n0 & \\begin{array}{l} \\text{Otro caso} \\end{array}\n\\end{cases}\\\\\n\\end{equation}\\]\n\nEn el caso especial de \\(\\small{n=5}\\) y \\(\\small{k=2}\\) la matriz de probabilidades de transición \\(\\small{\\boldsymbol{M_t}(G_{n,k})}\\) esta dada por:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M_t}(G_{5,2})=\n\\begin{array}{cc}&\n\\begin{array}{cccccc}\n\\end{array}\n\\\\\n\\begin{array}{cccccc}\n(0,0)\\\\\n(0,1)\\\\\n(1,\\gamma)\\\\\n(1,0)\\\\\n(1,1)\\\\\n(2,\\gamma)\\\\\n(2,0)\\\\\n(2,1)\n\\end{array}\n&\n\\left(\n\\begin{array}{cc|c|cc|c|cc}\nq_t&p_t&0&0&0&0&0&0\\\\\nq_t&0&p_t&0&0&0&0&0\\\\\n\\hline\n0&0&p_t&q_t&0&0&0\\\\\n\\hline\n0&0&0&q_t&p_t&0&0&0\\\\\n0&0&0&q_t&0&p_t&0&0\\\\\n\\hline\n0&0&0&0&0&p_t&q_t&0\\\\\n\\hline\n0&0&0&0&0&0&q_t&p_t\\\\\n0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\npara \\(\\small{t=1,2,\\ldots,5}\\). En general \\(\\small{\\boldsymbol{M_t}(G_{n,k})}\\) es una matriz bidiagonal de bloques de la forma: \n\n\\[\\begin{equation}\n\\left(\n\\begin{array}{ccccccc}\n\\boldsymbol{A_t}&p_t\\boldsymbol{e_k'}&&&&&\\boldsymbol{O}\\\\\n&p_t&q_t\\boldsymbol{e_1}&&\\boldsymbol{O}&&\\\\\n&&\\boldsymbol{A_t}&p_t\\boldsymbol{e_k'}&&&\\\\\n&&&\\ddots&\\ddots&&\\\\\n&&&&\\ddots&\\ddots&\\\\\n&&\\boldsymbol{O}&&&p_t&q_t\\boldsymbol{e_1}\\\\\n\\boldsymbol{O}&&&&&&\\boldsymbol{A_t^{\\ast}}\\\\\n\\end{array}\n\\right)\n\\end{equation}\\]\n\nen donde \\(\\small{\\boldsymbol{e_1}=(1,0,\\ldots,0)}\\) y \\(\\small{\\boldsymbol{e_1}=(0,\\ldots,0,1)}\\) son vectores fila unitarios \\(\\small{1\\times k}\\), y \\(\\small{\\boldsymbol{A_t}}\\) es dada por:\n\n\n\\[\\begin{equation}\n\\boldsymbol{A_t} =\\left(\n\\begin{array}{ccccc}\nq_t & p_t & 0  & \\ldots &  0 \\\\\n\\vdots & \\ddots & \\ddots  &    &   \\\\\n\\vdots &  &  \\ddots& \\ddots &   \\\\\n\\vdots&  &   &  \\ddots &p_t \\\\\nq_t&  0 & 0 &  \\cdots & 1 \\\\\n\\end{array}\n\\right)\n\\end{equation}\\]\n\nLa matriz de probabilidad de transición \\(\\small{\\boldsymbol{A_t}}\\), en el contexto de la demografía, a menudo se denomina matriz de Leslie o, más generalmente, matriz de tipo renovación (véase Seneta, 1981). La dimensión de \\(\\small{\\boldsymbol{A_t}(G_{n,k})}\\) es igual a \\(\\small{(l_n+1)(k+1)-1}\\). La matriz \\(\\small{\\boldsymbol{A_t^{\\ast}}}\\) en la Ec. (3.11) es igual que \\(\\small{\\boldsymbol{A_t}}\\) excepto por la última fila, que se reemplaza por \\(\\small{(0,\\ldots,0,1)}\\)\nSi definimos la partición \\(\\small{\\{C_x:i=0,1,2,\\ldots,l_n\\}}\\) sobre \\(\\small{\\Omega}\\)\n\n\n\\[\\begin{align*}\nC_0&=\\{(0,i):i=0,1,\\ldots,k-1\\} \\\\\nC_x&=\\{(0,i):i=\\gamma,0,1,\\ldots,k-1\\},\\,\\text{para}\\, x=1,2,\\ldots,l_n\n\\end{align*}\\]\n\ny en consecuencia \\(\\small{\\mathbb{P}\\big(G_{n,k}=x\\big)=\\mathbb{P}\\big(Y_n \\in C_x \\big)}\\) para todo \\(\\small{x=0,1,2,\\ldots,l_n}\\). La función de distribución, los momentos y la función generadora de probabilidad ahora se pueden calcular fácilmente mediante las ecuaciones (2.11), (2.12) y (2.13), respectivamente.\nPara el caso de ensayos i.i.d., todas las probabilidades de transición serían constantes y se podría llevar a cabo una extensión a los ensayos de Markov-Dependientes como se describe para el estadístico \\(\\small{N_{n,k}}\\) en la sección anterior; En el resto de este capítulo sobre ensayos en dos Estados, nos centraremos principalmente en el caso de ensayos independientes pero no idénticamente distribuidos.\n\n\n\nLa variable aleatoria \\(\\small{M_{n,k}}\\) se define como el número \\(\\small{k}\\) de éxitos consecutivos superpuestos en una sucesión de \\(\\small{n}\\) ensayos independientes de dos estados. La cadena de Markov incrustada \\(\\small{\\{Y_t:t=0,1,2,\\ldots,n\\}}\\) asociada a \\(\\small{M_{n,k}}\\) puede definirse como\n\n\n\\[\\begin{align*}\nY_t=(M_{t,k},E_t),\\quad t=1,2,\\ldots,n\n\\end{align*}\\]\n\nsobre el espacio de estados\n\n\n\\[\\begin{align*}\n\\Omega &=\\{(x,i):x=0,1,\\cdots,l_n-1\\,\\, \\text{e}\\,\\, i=\\gamma, 0,1,\\cdots,k-1\\} \\\\\n& \\cup \\{(l_n,\\gamma)\\}-\\{(0,\\gamma)\\},\n\\end{align*}\\]\n\ndonde \\(\\small{l_n=n-k+1,\\, M_{n,k}}\\) es el número de \\(\\small{k}\\) éxitos consecutivos superpuestos en las primeros \\(\\small{t}\\) ensayos, y \\(\\small{E_t}\\) es la variable del bloque final que lleva la cuenta del número \\(\\small{m}\\) de éxitos finales:\n\n\n\\[\\begin{equation}\nE_t=\\begin{cases}\n\\gamma & \\text{si}\\, m\\geq k\\\\\nm & \\text{si}\\, m=0,1,\\ldots,k-1.\n\\end{cases}\n\\end{equation}\\]\n\nCon conteo superpuesto, es fácil verificar que las probabilidades para las matrices de probabilidad de transición \\(\\small{\\boldsymbol{M_t}=p_{(x,i)(y,j)}(t)}\\) se pueden obtener a partir de la siguiente ecuación:\n\n\n\\[\\begin{equation}\np_{(x,i)(y,j)}(t) =\n\\begin{cases}\nq_t & \\begin{array}{l} \\text{Si}\\,\\, y=x \\,\\, \\text{y}\\,\\, j=0 \\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n \\,\\,\\text{e}\\, i=\\gamma,0,1,\\ldots,k-1 \\end{array} \\\\\np_t & \\begin{array}{l} \\text{Si}\\,\\, y=x \\,\\, \\text{y}\\,\\, j=i+1\\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n \\,\\, \\text{e}\\,\\,i=0,1,\\ldots,k-2 \\end{array}\n\\\\\np_t & \\begin{array}{l} \\text{Si}\\,\\, y=x+1 \\,\\, \\text{y}\\,\\, j=\\gamma\\,\\,\\text{e}\\,\\,i=k-1,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n-1 \\end{array}\n\\\\\np_t & \\begin{array}{l} \\text{Si}\\, y=x+1,\\,j=i=\\gamma\\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n-1  \\end{array}\n\\\\\n1 & \\begin{array}{l} \\text{Si} \\,\\, y=x=l_n,\\,\\text{y}\\ j=i=\\gamma\\end{array} \\\\\n0 & \\begin{array}{l} \\text{Otro caso} \\end{array}\n\\end{cases}\\\\\n\\end{equation}\\]\n\nLa partición correspondiente del espacio de estados \\(\\small{\\Omega}\\) se puede especificar de la siguiente manera:\n\n\n\\[\\begin{align*}\nC_0 &=\\{(x,i):i=0,1,\\cdots,k-1\\}\\\\\nC_x &=\\{(x,i):i=\\gamma,0,1,\\cdots,k-1\\},\\, x=1,\\cdots,l_n,\\\\\nC_{l_n} &= \\{(l_n,\\gamma)\\}\n\\end{align*}\\]\n\nComo ejemplo considerese, \\(\\small{n=4}\\) y \\(\\small{k=2}\\), luego las matrices de probabilidades de transición \\(\\small{\\boldsymbol{M_t}(M_{4,2})}\\) para \\(\\small{t=1,2,3,4}\\) son:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M_t}(M_{4,2})=\n\\begin{array}{cc}&\n\\begin{array}{cccccc}\n\\end{array}\n\\\\\n\\begin{array}{cccccc}\n(0,0)\\\\\n(0,1)\\\\\n(1,\\gamma)\\\\\n(1,0)\\\\\n(1,1)\\\\\n(2,\\gamma)\\\\\n(2,0)\\\\\n(2,1)\\\\\n(3,\\gamma)\n\\end{array}\n&\n\\left(\n\\begin{array}{cc|c|cc|c|cc|c}\nq_t&p_t&0&0&0&0&0&0&0\\\\\nq_t&0&p_t&0&0&0&0&0&0\\\\\n\\hline\n0&0&0&q_t&0&p_t&0&0&0\\\\\n\\hline\n0&0&0&q_t&p_t&0&0&0&0\\\\\n0&0&0&q_t&0&p_t&0&0&0\\\\\n\\hline\n0&0&0&0&0&0&q_t&0&p_t\\\\\n\\hline\n0&0&0&0&0&0&q_t&p_t&0\\\\\n0&0&0&0&0&0&q_t&0&p_t\\\\\n\\hline\n0&0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nEn general para \\(\\small{n}\\) y \\(\\small{k}\\) arbitrareos, las matrices de probabilidad de transición continúan teniendo una forma de bandas similar a \\(\\small{\\boldsymbol{M_t}(M_{4,2})}\\) en la ecuación (3.15), y son de dimensión \\(\\small{l_n(k+1)}\\). La distribución y los momentos de la variable aleatoria \\(\\small{M_{n,k}}\\) se pueden calcular nuevamente mediante las ecuaciones (2.11) y (2.12), respectivamente.\n\n\n\nLa Cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) asociada con la variable aleatoria, \\(\\small{E_{n,k}}\\), del número de rachas exitosas de tamaño exactamente \\(\\small{k}\\) en \\(\\small{n}\\) ensayos independientes de dos estados, se define por:\n\n\n\\[\\begin{equation}\nY_t=(E_{t,k},E_t)\n\\end{equation}\\]\n\nsobre el espacio de estados:\n\n\n\\[\\begin{equation}\n\\Omega =\\{(x,i):x=0,1,\\cdots,l_n\\,\\, \\text{e}\\,\\, i=\\beta,\\gamma,0,1,\\cdots,k-1\\}-\\{(0,\\gamma)\\},\n\\end{equation}\\]\n\nen donde, \\(\\small{l_n=[(n+1)/(k+1)]}\\), \\(\\small{E_{t,k}}\\) es el número de rachas éxitosas de longitud igual a \\(\\small{k}\\) en los primeros \\(\\small{t}\\) ensayos, y el bloque final \\(\\small{E_{t}}\\) se define en función del número de éxitos finales \\(\\small{m}\\), en los primeros \\(\\small{t}\\) ensayos de la siguiente manera:\n\n\n\\[\\begin{equation}\nE_t=\\begin{cases}\nm & \\text{Si}\\,\\, m=0,1,\\ldots,k-1\\\\\n\\gamma & \\text{Si}\\,\\, m = k\\\\\n\\beta & \\text{Si}\\,\\, m&gt;k\n\\end{cases}\n\\end{equation}\\]\n\nLos dos estados del bloque final \\(\\small{\\beta}\\) e \\(\\small{\\gamma}\\) tienes la siguiente interpretación:\n(i) Estado de espera \\(\\small{(x,\\gamma),\\,\\,x=1,2,\\dots,l_n}\\):\n\\(\\small{ Y_t=(x,\\gamma)}\\) significa que \\(\\small{m=k}\\) y que \\(\\small{x-}\\)ésima racha exitosa de tamaño \\(\\small{k}\\) ha ocurrido en el \\(\\small{t-}\\)ésimo ensayo, y\n(ii) Estado de desbordamiento \\(\\small{(x,\\beta),\\,\\,x=1,2,\\dots,l_n}\\):\n\\(\\small{ Y_t=(x,\\beta)}\\) significa que \\(\\small{m&gt;k}\\) y que exactamente \\(\\small{x}\\) rachas exitosas de tamaño \\(\\small{k}\\) han aparecido antes de los últimos \\(\\small{m+1}\\) resultados \\(\\small{(F\\underbrace{S\\cdots S}_{m})}\\).\nCon estos bloques finales en mente, podemos construir fácilmente la partición para el espacio de estados \\(\\small{\\Omega:\\, C_0=\\{(0,i):i=\\beta,0,1,\\ldots, k-1\\} }\\) y \\(\\small{C_x=\\{(x,i):i=\\gamma,\\beta,0,1,\\ldots, k-1\\} }\\), para \\(\\small{x=1,\\ldots,l_n}\\).\nLas probabilidades para las matrices de transición \\(\\small{\\boldsymbol{M_t}(E_{t,k})}\\) de la cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\), se especifican mediante la siguiente ecuación:\n\n\n\\[\\begin{equation}\np_{(x,i)(y,j)}(t) =\n\\begin{cases}\nq_t & \\begin{array}{l} \\text{Si}\\,\\, y=x \\,\\, \\text{y}\\,\\, j=0 \\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n \\,\\,\\text{e}\\,\\, i=\\gamma,\\beta,0,1,\\ldots,k-1 \\end{array} \\\\\np_t & \\begin{array}{l} \\text{Si}\\,\\, y=x \\,\\, \\text{y}\\,\\, j=i+1\\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n \\,\\, \\text{e}\\,\\,i=0,1,\\ldots,k-2 \\end{array}\n\\\\\np_t & \\begin{array}{l} \\text{Si}\\,\\, y=x+1 \\,\\, \\text{y}\\,\\, j=\\gamma\\,\\,\\text{e}\\,\\,i=k-1,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n-1 \\end{array}\n\\\\\np_t & \\begin{array}{l} \\text{Si}\\,\\, y=x-1,\\,\\,j=\\beta\\,\\, \\,\\,\\text{e}\\,\\, i=\\gamma\\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n  \\end{array}\n\\\\\np_t & \\begin{array}{l} \\text{Si}\\,\\, y=x,\\,\\,\\text{e}\\,\\, j=i=\\beta\\,, \\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n  \\end{array}\n\\\\\n1 & \\begin{array}{l} \\text{Si} \\,\\, y=x=l_n\\,\\,\\text{y}\\,\\, j=i=k-1\\end{array} \\\\\n0 & \\begin{array}{l} \\text{Otro caso}. \\end{array}\n\\end{cases}\\\\\n\\end{equation}\\]\n\nA modo de ilustración, consideremos el caso \\(\\small{n=5}\\) y \\(\\small{k=2}\\), para lo cual tenemos las matrices de probabilidad de transición:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M_t}(E_{5,2})=\n\\begin{array}{cc}&\n\\begin{array}{c}\n(0,\\beta)\\\\\n(0,0)\\\\\n(0,1)\\\\\n(1,\\gamma)\\\\\n(1,\\beta)\\\\\n(1,0)\\\\\n(1,1)\\\\\n(2,\\gamma)\\\\\n(2,\\beta)\\\\\n(2,0)\\\\\n(2,1)\n\\end{array}\n&\n\\left(\n\\begin{array}{c|cc|cc|cc|cc|cc}\nq_t&p_t&0&0&0&0&0&0&0&0&0\\\\\n\\hline\n0&q_t&p_t&0&0&0&0&0&0&0&0\\\\\n0&q_t&0&p_t&0&0&0&0&0&0&0\\\\\n\\hline\np_t&0&0&0&0&q_t&0&0&0&0&0\\\\\n0&0&0&0&p_t&q_t&0&0&0&0&0\\\\\n\\hline\n0&0&0&0&0&q_t&p_t&0&0&0&0\\\\\n0&0&0&0&0&q_t&0&p_t&0&0&0\\\\\n\\hline\n0&0&0&0&p_t&0&0&0&0&q_t&0\\\\\n0&0&0&0&0&0&0&0&p_t&q_t&0\\\\\n\\hline\n0&0&0&0&0&0&0&0&0&q_t&p_t\\\\\n0&0&0&0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nEn general, las matrices de probabilidad de transición de la cadena de Markov \\(\\small{\\{Y_t\\}}\\) asociadas con \\(\\small{E_{n,k}}\\) tienen la forma dada por la ecuación (3.19) con dimensión \\(\\small{(l_n + 1)(k+1)+l_n}\\).\n\n\n\nSea \\(\\small{L_n(S)}\\), la duración de la racha exitosa más larga en una sucesión de ensayos de dos estados. Para el caso de \\(\\small{n}\\) lanzamientos independientes de una moneda justa, sea \\(\\small{A_n(k)}\\) el número de secuencias de longitud \\(\\small{n}\\) en las que la racha más larga de éxitos (cara) es menor o igual a \\(\\small{k}\\). Dado que todas las sucesiones son igualmente probables con probabilidad \\(\\small{(1/2)^n}\\), la distribución del racha más largo es:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(L_n(S)\\leq k\\big)=2^{-n}A_n(k)\n\\end{equation}\\]\n\ndonde \\(\\small{A_n(k)}\\) satisface la ecuación recursiva (Schilling 1990)\n\n\n\\[\\begin{equation}\nA_n(k)=\\begin{cases}\n\\displaystyle\\sum_{j=0}^{k}A_{n-1-j}(k) & \\text{si}\\, n &gt; k\\\\\n2^{n} & \\text{si}\\,\\, n \\leq k\\\\\n1 & \\text{si}\\,\\, k = 0\\\\\n\\end{cases}\n\\end{equation}\\]\n\nPara monedas sesgadas \\(\\small{(p\\neq1/2)}\\), el análisis combinatorio es:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(L_n(S)\\leq k\\big)=\\displaystyle\\sum_{x=0}^{k}C_{n}^{(x)}(k)p^{x}q^{n-x},\n\\end{equation}\\]\n\npara \\(\\small{1 \\leq k \\leq n}\\), y \\(\\small{\\mathbb{P}\\big(L_n(S)=0 \\big)=q^{-n}}\\), donde \\(\\small{C_n^{(x)}(k)}\\) es el número de secuencias de longitud \\(\\small{n}\\) en las que ocurren exactamente \\(\\small{x}\\) éxitos, pero en las que no más de \\(\\small{k}\\) de estos éxitos ocurren consecutivamente. \\(\\small{C_n^{(x)}(k)}\\) se puede obtener a través de la ecuación recursiva:\n\n\n\\[\\begin{equation}\nC_n^{(x)}(k)=\\begin{cases}\n\\displaystyle\\sum_{j=0}^{k}C_{n-1-j}^{x-j}(k) & \\text{si}\\,\\,  k&lt;x&lt;n\\\\\n\\binom{n}{x} & \\text{si}\\,\\,  x \\leq k \\leq n\\\\\n\\, 0 & \\text{si}\\,\\,k&lt;x= n\\\\\n\\end{cases}\n\\end{equation}\\]\n\nDe manera más general, supongamos que las probabilidades de éxito y fracaso podrían ser diferentes en cada ensayo, iguales a \\(\\small{p_t}\\) y \\(\\small{q_t}\\), respectivamente, para \\(\\small{t=1,2,\\ldots,n}\\). El siguiente teorema deriva la distribución de \\(\\small{L_n(S)}\\):\nTeorema 3.1 Para \\(\\small{0\\leq k\\leq n}\\),\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(L_n(S)\\leq k\\big)=\\boldsymbol{\\mathbf{\\xi}} \\Big(\\prod_{t=1}^{n}\\boldsymbol{N}_t\\Big)\\boldsymbol{\\mathbf{1}'}_{1 \\times(k+1)}\n\\end{equation}\\]\n\nen donde \\(\\small{\\boldsymbol{\\mathbf{\\xi}}=(1,0,\\ldots,0)}\\) es un vector fila unitario de tamaño \\(\\small{1\\times (k+1)}\\) y \\(\\small{\\boldsymbol{N_t}}\\) es como se indica a continuación, la submatriz esencial \\(\\small{(k+1)\\times (k+1)}\\) de la matriz de probabilidades de transición:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M_t}=\n\\begin{array}{cc}&\n\\begin{array}{c}\n0\\\\\n1\\\\\n\\vdots\\\\\n\\vdots\\\\\nk\\\\\n\\alpha\n\\end{array}\n&\\left(\n\\begin{array}{ccccc|c}\nq_t&p_t&0&\\cdots&0&0\\\\\nq_t&0&p_t&\\cdots&0&0\\\\\n\\vdots&&\\ddots&\\ddots&&\\vdots\\\\\n\\vdots&&\\ddots&\\ddots&\\ddots&\\vdots\\\\\nq_t&0&\\cdots&\\cdots&0&p_t\\\\\n\\hline\n0&0&\\cdots&\\cdots&0&1\\\\\n\\end{array}\n\\right)_{(k+2) \\times (k+2)}\n\\end{array}=\\left(\\begin{array}{c|c}\n\\boldsymbol{N_t} &  {C_t}\\\\\n\\hline\n\\boldsymbol{0}&  {1}\\\\\n\\end{array}\n\\right)\n\\end{equation}\\]\n\nDemostración: La racha exitosa más larga en una sucesión de ensayos de dos estados está relacionada con las estadísticas de ejecución \\(\\small{N_{n,k}}\\), \\(\\small{G_{n,k}}\\) y \\(\\small{M_{n,k}}\\) de la siguiente manera sencilla:\n\n\n\\[\\begin{equation}\nL_n(S)\\leq k \\,\\, \\text{si y solo si}\\,\\, N_{n,k+1} = G_{n,k+1}=M_{n,k+1}=0\n\\end{equation}\\]\n\nPor tanto, \\(\\small{\\mathbb{P}\\big(L_n(S)\\leq k\\big)=\\mathbb{P}\\big(N_{n,k+1}=0\\big)}\\), y podemos completar la demostración considerando la Ecuación (3.8) para \\(\\small{\\mathbb{P}\\big(N_{n,k+1}=x\\big)}\\) con \\(\\small{x=0}\\). Cambiando los estados \\(\\small{(0,0),(0,1),\\ldots,(0,k)}\\) en esta aplicación de la Ecuación (3.8) a los estados \\(\\small{0,1,2,\\ldots,k}\\) respectivamente, y combinando todos los demás estados en el estado absorbente \\(\\small{\\alpha}\\), obtenemos:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(L_n(S)\\leq k\\big)=\\mathbb{P}\\big(N_{n,k+1}=0\\big)=\\boldsymbol{\\mathbf{\\xi}_0} \\Big(\\prod_{t=1}^{n}\\boldsymbol{M}_t\\Big)(1,\\ldots,1,0)'\n\\end{equation}\\]\n\nen donde \\(\\small{\\boldsymbol{\\xi_0}=(1,0\\ldots,0)_{1\\times(k+2)}=(\\boldsymbol{\\xi}:0)}\\). Con la notación \\(\\small{(1,\\ldots,1,0)_{1\\times(k+2)}=(\\boldsymbol{1}:0)}\\) y haciendo uso del hecho que las matrices de transición de probabilidad tienen la forma:\n\n\n\\[\\begin{equation}\n\\prod_{t=1}^{n}\\boldsymbol{M_t}=\n\\left(\n\\begin{array}{c|c}\n\\displaystyle\\prod_{t=1}^{n}\\boldsymbol{N_t}& C_t(n)\\\\\n\\hline\n\\boldsymbol{0}&1\n\\end{array}\n\\right)\n\\end{equation}\\]\n\nluego, el teorema se sigue inmediatamente. \\(\\hspace{3cm}\\Box\\)\nColorario Dados \\(\\small{1 \\leq k \\leq n}\\) se satisface la siguiente ecuación recursiva:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(L_n(S)\\leq k\\big)=q_n\\cdot\\mathbb{P}\\big(L_{n-1}(S)\\leq k\\big)+\\displaystyle\\sum_{i=1}^{k}q_{n-i} \\prod_{j=n-i+1}^{n}p_{j}\\cdot\\mathbb{P}\\big(L_{n-i-1}(S)\\leq k\\big)\n\\end{equation}\\]\n\ncon \\(\\small{\\mathbb{P}\\big(L_n(S)=0\\big)=\\displaystyle\\prod_{j=1}^{n}q_j}\\) y \\(\\small{\\mathbb{P}\\big(L_n(S)\\leq n\\big)\\equiv1}\\) para \\(\\small{k=m}.\\)\nDemostración De la estructuradada dada por la Ec.(3.25) para las matrices de probabilidades de transición \\(\\small{\\boldsymbol{M_t}}\\), se sigue que:\n\n\n\\[\\begin{align*}\n\\text{(i)}\\,\\, \\boldsymbol{M_te_0'} &=q_t(1,\\ldots,1,0)'_{1\\times(k+2)}\\,\\, \\text{y} \\\\\n\\text{(ii)}\\,\\,\\boldsymbol{M_te_i'} &=p_t\\boldsymbol{e_{i-1}'},\\,\\,\\text{para}\\,\\, i=1,2,\\ldots,k,\n\\end{align*}\\]\n\nen donde \\(\\small{\\boldsymbol{e_i}=(0,\\ldots,0,1,0,\\ldots,0)}\\) es un vector fila unitario con un uno en la coordenada asociada al estado \\(\\small{i}\\), para \\(\\small{i=0,1,2,\\ldots,k}\\).\nDado que \\(\\small{\\displaystyle\\sum_{i=0}^{k}\\boldsymbol{e_i'}}\\), nuestro resultado es una consecuencia directa de (i),(ii) y multiplicaciones hacia atrás de la ecuación (3.24).\nTomando \\(\\small{p_t=q_t=1/2}\\) para todo \\(\\small{t=1,2,\\ldots,n}\\) y multiplicando \\(\\small{\\mathbb{P}\\big(L_n(S)\\leq k\\big)=1}\\) por \\(\\small{2^n}\\), la ecuación (3.26) produce la ecuación recursiva (3.21) para \\(\\small{A_n(k)}\\). El teorema 3.1 también se puede extender para la rachas de falla más larga \\(\\small{L_n(F)}\\) y a la estadística de racha más larga \\(\\small{L_n = \\max\\{L_n(S), L_n(F)\\}}\\). Para el caso i.i.d. y para \\(\\small{n}\\) grande, hay varios resultados sobresalientes sobre la duración de la racha exitosa más larga. Rényi (1970), Csörgö (1979), Erdös y Rényi (1970) y Erdös y Révész (1975) muestran que, cuando \\(\\small{n \\rightarrow \\infty}\\)\n\n\n\\[\\begin{equation}\n\\frac{L_n(S)}{\\log_{1/p}(n)} \\xrightarrow{a.s} 1\n\\end{equation}\\]\n\nA este resultado se le suele denominar la nueva ley de los grandes números.\nEn el Capítulo 5, desarrollaremos una aproximación de grande desviación para la probabilidad de \\(\\small{L_n(S)}\\) bajo ensayos i.i.d. (y Markov-Dependientes homogéneos):\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(L_n(S)\\leq  k\\big)\\sim \\exp\\{-n\\beta\\}\n\\end{equation}\\]\n\nen donde \\(\\small{\\beta=-\\log(\\lambda_{[1]})}\\) y \\(\\small{\\lambda_{[1]}}\\) es el valor propio más grande de la submatriz de probabilidad de transición esencial \\(\\small{\\boldsymbol{N_t}}\\) (con \\(\\small{p_t}\\) y \\(\\small{q_t}\\) constantes) dada por la ecuación (3.25).\n\n\n\nSea \\(\\small{\\Lambda=S\\cdots S}\\) el patrón simple de \\(\\small{k}\\) éxitos consecutivos y defina la variable aleatoria \\(\\small{W(\\Lambda)}\\) como el tiempo de espera para que ocurra el patrón \\(\\small{\\Lambda}\\), es decir \n\n\\[\\begin{equation}\nW(\\Lambda)=\\inf\\{n:X_{n-k+1}=X_{n-k+2}=\\cdots=X_{n}=S\\}.\n\\end{equation}\\]\n\nPor ejemplo, dado \\(\\small{k=3}\\), \\(\\small{W(\\Lambda)=6}\\) significa que el patrón \\(\\small{SSS}\\) ocurre por primera vez después de seis intentos, como en \\(\\small{SFFSSS}\\). La distribución de \\(\\small{W(\\Lambda)}\\) para los ensayos de Bernoulli a menudo se denomina distribución geométrica de orden \\(\\small{k}\\) (ver Aki 1985 e Hirano 1986).\nTeorema 3.2 Dado un patrón de longitud \\(\\small{k\\geq 1}\\) y una sucesión de ensayos Bernoulli \\(\\small{\\{X_t\\}}\\), la distribución de \\(\\small{W(\\Lambda)}\\) esta dada por:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(W(\\Lambda)=n\\big)=\\boldsymbol{\\xi} \\boldsymbol{N_t}^{n-1}(\\Lambda)\\big(\\boldsymbol{I-N}(\\Lambda)\\big)\\boldsymbol{1'}\n\\end{equation}\\]\n\nen donde \\(\\small{\\boldsymbol{\\xi}=(1,0,\\ldots,0)}\\) es un vector fila \\(\\small{1\\times k}\\) y \\(\\small{\\boldsymbol{N}(\\Lambda)}\\) es la submatriz de probabilidades de transición esencial:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}(\\Lambda)=\n\\begin{array}{cc}&\n\\begin{array}{c}\n0\\\\\n1\\\\\n\\vdots\\\\\n\\vdots\\\\\nk-1\\\\\n\\alpha\n\\end{array}\n&\\left(\n\\begin{array}{ccccc|c}\np&q&0&\\cdots&0&0\\\\\nq&0&p&\\cdots&0&0\\\\\n\\vdots& &\\ddots&\\ddots&&\\vdots\\\\\n\\vdots&&\\ddots&\\ddots&\\ddots&\\vdots\\\\\nq&0&\\cdots&\\cdots&0&p\\\\\n\\hline\n0&0&\\cdots&\\cdots&0&1\\\\\n\\end{array}\n\\right)_{(k+1)\\times(k+1)}\n\\end{array}=\n\\left(\n\\begin{array}{c|c}\n\\boldsymbol{N}(\\Lambda)&C\\\\\n\\hline\n\\boldsymbol{0} & 1\n\\end{array}\\right)\n\\end{equation}\\]\n\nSe deduce además que la función generadora de probabilidad de \\(\\small{W(\\Lambda)}\\) está dada por:\n\n\n\\[\\begin{equation}\n\\varphi_{W}(s)=\\frac{p^ks^k(1-ps)}{1-s+qp^ks^{k+1}}\n\\end{equation}\\]\n\nPrueba. Dados \\(\\small{\\Lambda}\\),\\(\\small{}\\) y \\(\\small{k \\leq n}\\), de la definición de \\(\\small{W(\\Lambda)}\\) y \\(\\small{N_{n,k}}\\), se deduce que estas dos variables aleatorias tienen la siguiente relación:\n\n\n\\[\\begin{equation}\nW(\\Lambda) \\leq n \\quad \\text{si y solo si}\\quad N_{n,k}\\geq 1 \\,\\,\\text{para todo }\\, n \\geq k.\n\\end{equation}\\]\n\nPor tanto \\(\\small{\\mathbb{P}\\big(W(\\Lambda)\\leq n\\big)=\\mathbb{P}\\big(N_{n,k}\\geq 1\\big)}\\) y\n\n\n\\[\\begin{align*}\n\\mathbb{P}\\big(W(\\Lambda)\\leq n\\big) &= \\mathbb{P}\\big(N_{n,k}\\geq 1\\big)-\\mathbb{P}\\big(N_{n-1,k}\\geq 1\\big), \\\\\n&=  \\mathbb{P}\\big(N_{n-1,k}= 0\\big)-\\mathbb{P}\\big(N_{n,k}= 0\\big).\n\\end{align*}\\]\n\nPuesto que sólo necesitamos el resultado general de \\(\\small{\\mathbb{P}\\big(N_{n,k}= 0\\big)}\\) para completar la prueba, podemos, como en la sección anterior sobre la racha exitosa más larga, reemplazar los estados \\(\\small{(0,0),\\cdots,(0,k-1)}\\) definidos en la Sección 3.2 por los estados \\(\\small{0,1,2,\\ldots,k-1}\\) y combinar todos los demás estados en un estado absorbente \\(\\small{\\alpha}\\). Bajo este espacio de estados reducido, la matriz de probabilidad de transición \\(\\small{\\boldsymbol{M_t}(N_{n,k})}\\) se simplifica a \\(\\small{\\boldsymbol{M}(\\Lambda)}\\). La ecuación (3.27) del teorema 3.2 es entonces una consecuencia inmediata de las ecuaciones (3.8), (3.30) y Teorema 3.1.\nNote que, para \\(\\small{0\\leq i\\leq k-1,}\\)\n\n\n\\[\\begin{equation}\n\\boldsymbol{e_iN}(\\Lambda)=q\\boldsymbol{e_0}+p\\boldsymbol{e_{i+1}}.\n\\end{equation}\\]\n\nDado \\(\\small{\\boldsymbol{\\xi=e}_0}\\), y usando del resultado de multiplicación hacia adelante obtenemos la siguiente ecuación recursiva:\n\n\n\\[\\begin{align*}\n\\mathbb{P}\\big(W(\\Lambda)= n\\big) &= \\boldsymbol{\\xi N}^{n-1}(\\Lambda)\\big(\\boldsymbol{I-N}(\\Lambda)\\big)\\boldsymbol{1'} \\\\\n&= \\sum_{i=1}^{k}qp^{i-1}\\mathbb{P}\\big(W(\\Lambda)=n-i\\big).\n\\end{align*}\\]\n\nLa anterior ecuación recursivay la condición de frontera \\(\\small{\\mathbb{P}\\big(W(\\Lambda)=k\\big)=p^{k}}\\) conducen a la siguiente ecuación recursiva para la función generadora de probabilidad \\(\\small{\\varphi_{W}(s)}\\):\n\n\n\\[\\begin{equation}\n\\varphi_{W}(s)= s^kp^k+\\sum_{i=1}^{k}qp^{i-1}s^{i}\\varphi_{W}(s)\n\\end{equation}\\]\n\nSumando las series de potencias finitas se obtiene el resultado explícito para \\(\\small{\\varphi_{W}(s)}\\) dado en la Ec. (3.29), resultado que fue derivado por primera vez por Feller (1968) utilizando la teoría de la renovaciones.\\(\\hspace{3cm}\\Box\\)\nSi definimos las matrices:\n\n\n\\[\\begin{equation}\n\\boldsymbol{A}=\\left(\n\\begin{array}{ccccc}\nq&p&0&\\cdots&0\\\\\nq&0&p& &0\\\\\n\\vdots& &\\ddots&\\ddots& \\\\\nq& & &0&p\\\\\nq&0&\\cdots&&0\\\\\n\\end{array}\n\\right)_{k\\times k},\\,\n\\boldsymbol{B}=\\left(\n\\begin{array}{ccccc}\n0&0&0&\\cdots&0\\\\\n0&0&0& &\\\\\n\\vdots& &\\ddots&\\ddots& \\\\\n0& & &0&0\\\\\np&0&\\cdots&&0\\\\\n\\end{array}\n\\right)_{k\\times k}\n\\end{equation}\\]\n\n\n\n\\[\\begin{equation}\n\\boldsymbol{A}^{\\ast}=(1)_{1\\times 1}\\,\\, \\text{y}\\,\\, \\boldsymbol{B}^{\\ast}=(0\\,\\,0\\,\\,\\cdots \\, 0\\,\\,p)'_{k\\times 1}\n\\end{equation}\\]\n\ny sea \\(\\small{W(m,\\Lambda)}\\) el tiempo de espera para la \\(\\small{m-}\\)ésima racha de \\(\\small{k}\\) éxitos consecutivos (sin solapamiento). De forma similar al desarrollo anterior para \\(\\small{W(\\Lambda)}\\), la distribución de la variable aleatoria \\(\\small{W(m,\\Lambda)}\\) puede ser obtenida usando la Ecuación (3.27) al remplazar la matriz de probabilidades de transición \\(\\small{W(\\Lambda)}\\), por:\n\n\n\\[\\begin{equation}\n\\boldsymbol{W}(m,\\Lambda)=\\left(\n\\begin{array}{ccccc}\n\\boldsymbol{A}&\\boldsymbol{A}& &\\boldsymbol{O}&\\\\\n&\\ddots & \\ddots& &\\\\\n& &\\boldsymbol{A}&\\boldsymbol{B}& \\\\\n&\\boldsymbol{O} &&\\boldsymbol{A}&\\boldsymbol{B^{\\ast}}\\\\\n& & &&\\boldsymbol{A^{\\ast}}\\\\\n\\end{array}\n\\right)_{(mk+1)\\times (mk+1)}\n\\end{equation}\\]\n\nObsérvese que la matriz de probabilidad de transición \\(\\small{\\boldsymbol{M}(\\Lambda)}\\) de la Ec. (3.28) es el caso especial de \\(\\small{\\boldsymbol{M}(m,\\Lambda)}\\) con \\(\\small{m=1}\\). Puesto que \\(\\small{W(m,\\Lambda)=\\displaystyle\\sum_{i=1}^{m}W_i(\\Lambda)}\\), donde \\(\\small{W_i(\\Lambda)}\\) representa el tiempo de espera desde la \\(\\small{(i-1)-}\\)ésima ocurrencia hasta la \\(\\small{(i)-}\\)ésima ocurrencia del patrón \\(\\small{\\Lambda}\\), y puesto que las variables aleatorias \\(\\small{W(\\Lambda)}\\) son i.i.d., se deduce de la Ec. (3.29) que la función generadora de probabilidad de \\(\\small{W(m,\\Lambda)}\\) es:\n\n\n\\[\\begin{equation}\n\\varphi_{W(m,\\Lambda)}^{m}(s)=\\varphi_{W}^{m}(s)=\\Bigg(\\frac{p^ks^k(1-ps)}{1-s+qp^ks^{k+1}}\\Bigg)^{m}.\n\\end{equation}\\]\n\nLa función generadora de probabilidad \\(\\small{\\varphi_{W}(s)}\\) siempre existe para todo \\(\\small{|s| \\leq 1}\\)\nEsto se desprende de su definición y del hecho de que:\n\n\n\\[\\begin{equation}\n|\\varphi_{W}(s)|\\leq\\sum_{n=1}^{\\infty}|s^{n}|\\cdot\\mathbb{P}(W=n)\\leq\\sum_{n=1}^{\\infty}\\mathbb{P}(W=n)=1.\n\\end{equation}\\]\n\nSin embargo, la función generadora de probabilidad \\(\\small{\\varphi_{W}(s)}\\) puede existir más allá de la región \\(\\small{|s| \\leq 1}\\). La región exacta varía de un problema a otro. Volveremos a discutir la mayor región de existencia de \\(\\small{\\varphi_{W}(s)}\\) en la sección 5.7.\nLa distribución de \\(\\small{W(m,\\Lambda)}\\) también puede obtenerse mediante la ecuación\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(W(m,\\Lambda)=n\\big)=\\frac{1}{n!}\\frac{d^{n}}{ds^{n}}\\varphi_{W(m,\\Lambda)}(s)\\Bigr|_{s=0}.\n\\end{equation}\\]\n\nenfoque que puede obtenerse más fácilmente utilizando software de manipulación simbólica (por ejemplo, MAPLE o MATLAB). En el capítulo 5 se ofrece un tratamiento más detallado de las distribuciones de tiempo de espera para patrones simples y compuestos en ensayos i.i.d. y Markov-Dependientes multiestado.\n\n\n\nAntes de estudiar estadísticas de rachas más complejas, en esta sección proporcionamos algunos resultados numéricos para las estadísticas de rachas y los tiempos de espera descritos en las secciones anteriores con el fin de ilustrar los resultados teóricos. Dada la matriz (o matrices) de probabilidad de transición de la cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) , en general sólo necesitamos dos tipos de fórmulas, en las formas de las Ecs. (3.8) y (3.27), para evaluar las distribuciones de \\(\\small{X_n(\\Lambda)}\\) y \\(\\small{W(\\Lambda)}\\), respectivamente. Las fórmulas son sencillas y eficientes desde el punto de vista computacional, adecuadas incluso para \\(\\small{n}\\) muy grandes. Los resultados numéricos que aquí se presentan también pueden servir para comprobar los propios cálculos de programación. En todos los ejemplos considerados, el tiempo de cálculo para obtener cada distribución es mínimo, una fracción de segundo en un PC actual.\nEn la Tabla 3.1 se presentan las distribuciones exactas y las medias de las variables aleatorias \\(\\small{E_{15,2},\\, G_{15,2},\\,N_{15,2},\\, M_{15,2}}\\) y \\(\\small{L_{15}(S)}\\) bajo el supuesto de que \\(\\small{\\{X_t\\}}\\)es una secuencia de ensayos independientes de dos estados con probabilidades \\(\\small{p_t=1/(t+1)}\\) para \\(\\small{t=1,2,\\ldots,15}\\).\nLa Tabla 3.2 muestra las distribuciones del tiempo de espera de la primera racha con éxito de longitud \\(\\small{k}\\), para varios valores de \\(\\small{k}\\) y probabilidades de estado \\(\\small{p_t}\\). En los capítulos 5 y 7 se ofrecen más resultados numéricos sobre las distribuciones del tiempo de espera.\n\n\n\nSea \\(\\small{S_{n,k}}\\) el número total de éxitos en rachas de éxitos de longitud mayor o igual que \\(\\small{}\\), para \\(\\small{k=1,2,\\ldots,n}\\). Puede escribirse como\n\n\n\\[\\begin{equation}\nS_{n,k}=\\sum_{i=k}^{n}iR_n(i),\n\\end{equation}\\]\n\nen donde \\(\\small{R_n(i)}\\), para \\(\\small{i=k,\\ldots,n}\\) es el número de rachas éxitosas de longitud exactamente igual a \\(\\small{i}\\) en una sucesión \\(\\small{\\{X_t\\}}\\). Para \\(\\small{k=1}\\), la Ec. (3.33) es equivalente al número total de éxitos en la sucesión \\(\\small{\\{X_t\\}}\\), es decir:\n\n\n\\[\\begin{equation}\nS_{n,1}=\\sum_{i=k}^{n}I_{X_i},\n\\end{equation}\\]\n\nen donde \\(\\small{I_{X_i}=1}\\) cuando el \\(\\small{i-}\\)ésimo ensayo es éxito y cero en otro caso. Si \\(\\small{\\{X_t\\}}\\) es una sucesión de ensayos Bernoulli, entonces \\(\\small{S_{n,1}}\\) tiene distribuciones binomial exacta y normal en el límite, respectivamente. De manera más general, para el caso \\(\\small{\\{X_t\\}}\\) es una sucesión de variables aleatorias Markov-Dependientes, la estadística \\(\\small{S_{n,k}}\\) también tiene una distrubución límite normal, como determino Nagaev (1957) para \\(\\small{k=1}\\) y Fu, Lou, Bai y Li (2002) para \\(\\small{k \\geq 2}\\). En esta sección, sólo estudiamos la distribución exacta de \\(\\small{S_{n,k}}\\) con \\(\\small{k \\geq 2}\\).\nSea \\(\\small{L_j}\\), para \\(\\small{j \\geq 2}\\), la longitud de la racha de éxitos situada entre el \\(\\small{(j-1)-}\\)ésimo y el \\(\\small{j-}\\) ésimo fallo en la sucesión \\(\\small{\\{X_t\\}}\\), con \\(\\small{L_1=0}\\) si el primer ensayo es un fallo y \\(\\small{L_1=l}\\) si los primeros \\(\\small{l}\\) ensayos son éxitos y el \\(\\small{(j+1)-}\\)ésimo ensayo es un fallo. Para un índice de tiempo \\(\\small{t}\\) dado, sea \\(\\small{m_t}\\) el número de fracasos en la subsecuencia \\(\\small{X_1, X_2,\\ldots, X_t}\\) y sea \\(\\small{L_t^{\\star}}\\) el número de éxitos que se producen después del \\(\\small{m_t-}\\)ésimo fracaso en esta subsecuencia. Nótese que \\(\\small{0 \\leq L_{t}^{\\star} \\leq t}\\) y \\(\\small{0\\leq L_t^{\\star} \\leq L_{m_t+1}}\\). Por otra parte, \\(\\small{S_{t,k}}\\), tal como se define en la Ec. (3.33), también se puede escribir como:\n\n\n\\[\\begin{equation}\nS_{t,k}=\\sum_{j=1}^{m_t}L_{j}(k)+L_t^{\\star}(t),\n\\end{equation}\\]\n\ncon \n\n\\[\\begin{equation}\nL_{j}(k)=L_j\\cdot I_{\\{L_j\\geq k\\}}\\quad \\text{y}\\quad L_{j}^{\\star}(k)=L_j^{\\star}\\cdot I_{\\{L_j^{\\star} \\geq k\\}}.\n\\end{equation}\\]\n\nAcá \\(\\small{I_{\\{L_j \\geq k\\}}}\\), es la función indicadora del evento \\(\\small{\\{L_j \\geq k\\}}\\), es decir, es igual a uno cuando (\\(\\small{I_{\\{L_j^{\\star} \\geq k\\}}}\\), se define de manera análoga) Para capturar la información relevante en la subsucesión \\(\\small{\\{X_1,X_2,\\cdots, X_t\\}}\\) definimos una nueva sucesión de variables aleatorias en la forma del vector de dos componentes\n\n\n\\[\\begin{equation}\nY_t=\\big( S_{t,k},E_{t}(t)\\big),\\,\\, t=1,2,\\ldots,n,\n\\end{equation}\\]\n\nen donde \\(\\small{S_{t,k}}\\) indica el número total de éxitos en rachas exitosas de longitud mayor o igual a \\(\\small{k}\\) en los primeros \\(\\small{t}\\) ensayos, y \\(\\small{E_{t}(k)}\\) es la variable aleatoria de bloque final dada por:\n\n\n\\[\\begin{equation}\nE_{t}(k)= L_{t}^{\\star}\\big(1-I_{\\{L_j^{\\star}\\geq k\\}}\\big)+k^{+}\\cdot I_{\\{L_j^{\\star} \\geq k\\}}.\n\\end{equation}\\]\n\nEn esta expresión, el símbolo \\(\\small{k^{+}}\\) representa el estado donde \\(\\small{L_t}\\) es mayor o igual que \\(\\small{k}\\).\nEl bloque final \\(\\small{E_t(k)}\\) representa la longitud de la racha de éxitos contando hacia atrás desde el \\(\\small{t-}\\)ésimo ensayo, con \\(\\small{E_t(k)=0}\\) si el \\(\\small{t-}\\)ésimo ensayo es un fracaso y \\(\\small{E_t(k)=k^{+}}\\) si la longitud es mayor o igual a \\(\\small{k}\\). Más específicamente, considere que desde el 1 \\(\\small{ m_t-}\\)ésimo (o más reciente) fracaso \\(\\small{F}\\) hasta el final de la subsucesión \\(\\small{\\{X_1,X_2,\\cdots, X_t\\}}\\) sólo podemos tener los siguientes resultados posibles: \\(\\small{\\{F,FS,\\cdots,FS\\cdots S,\\,\\text{or}\\, S\\cdots S\\, \\text{si } m_t = 0\\}}\\); la variable aleatoria \\(\\small{E_t(k)}\\) es igual al número de éxitos en estos resultados si el número es menor que \\(\\small{k}\\), y \\(\\small{E_t(k)=k^{+}}\\) si es igual o mayor que \\(\\small{k}\\). Este bloque final de los primeros \\(\\small{t}\\) ensayos proporciona información esencial sobre las probabilidades de transición de \\(\\small{Y_t}\\) a \\(\\small{Y_{t+1}}\\).\nDefinimos el espacio de estados\n\n\n\\[\\begin{equation}\n\\Omega =\\{(u,v):u=0,k,\\cdots,n-1,n\\,\\, \\text{y}\\,\\, v=0,1,\\cdots,k-1,k^{+}\\},\n\\end{equation}\\]\n\ncon tamaño \\(\\small{d=\\text{card}(\\Omega)=(n-k+2)(k+1)}\\), y consideraremos aquí el caso en que la sucesión \\(\\small{\\{X_t\\}}\\) es una cadena de Markov homogénea con probabilidades de transición \\(\\small{p_{FF},p_{Fs},p_{SF}}\\) y \\(\\small{p_{SS}}\\). En nuestro procedimiento de recuento, la sucesión de vectores aleatorios \\(\\small{Y_t=\\big( S_{t,k},E_{t}(t)\\big),\\,\\, t=1,2,\\ldots,n,}\\) definida en \\(\\small{\\Omega}\\) obedece las siguientes reglas:\n(i) Dado \\(\\small{Y_{t-1}=(x,0)}\\), entonces \\(\\small{Y_{t}=(x,0)}\\) con probabilidad \\(\\small{p_{FF}}\\) si el resultado del \\(\\small{t-}\\)ésimo ensayo es \\(\\small{F}\\), e \\(\\small{Y_{t}=(x,1)}\\) con probabilidad \\(\\small{p_{FS}}\\) si el resultado del \\(\\small{t-}\\)ésimo ensayo es \\(\\small{S}\\).\n(ii) Dado \\(\\small{Y_{t-1}=(x,y)}\\) para \\(\\small{1\\leq y \\leq k-2}\\) entonces \\(\\small{Y_{t}=(x,0)}\\) con probabilidad \\(\\small{p_{SF}}\\) si el resultado del \\(\\small{t-}\\)ésimo ensayo es \\(\\small{F}\\), e \\(\\small{Y_{t}=(x,y+1)}\\) con probabilidad \\(\\small{p_{SS}}\\) si el resultado del \\(\\small{t-}\\)ésimo ensayo es \\(\\small{S}\\).\n(iii) Dado \\(\\small{Y_{t-1}=(x,k-1)}\\), entonces \\(\\small{Y_{t}=(x,0)}\\), con probabilidad \\(\\small{p_{SF}}\\) si el resultado del \\(\\small{t-}\\)ésimo ensayo es \\(\\small{F}\\), e \\(\\small{Y_{t-1}=(x+k,k^{+})}\\), con probabilidad \\(\\small{p_{SS}}\\) si el resultado del \\(\\small{t-}\\)ésimo ensayo es \\(\\small{S}\\).\n(iv) Dado \\(\\small{Y_{t-1}=(x,k^{+})}\\), entonces \\(\\small{Y_{t}=(x,0)}\\) con probabilidad \\(\\small{p_{SF}}\\) si el resultado del \\(\\small{t-}\\)ésimo ensayo es \\(\\small{F}\\), e \\(\\small{Y_{t}=(x+1,k^{+})}\\) con probabilidad \\(\\small{p_{SS}}\\) si el resultado del \\(\\small{t-}\\)ésimo prueba es \\(\\small{S}\\).\nA la vista de nuestra construcción, la sucesión \\(\\small{\\{Y_t = \\big( S_{t,k}, E_t(k) \\big) : t = 1, 2,..., n\\}}\\) forma una cadena de Markov homogénea con matriz de probabilidad de transición:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\\big( p_{(x,y)\\times(u,v)}\\big)_{d\\times d}\n\\end{equation}\\]\n\ndonde las probabilidades de transición \\(\\small{p_{(x,y)\\times(u,v)}}\\), bajo orden lexicográfico de los estados \\(\\small{(\\cdot,\\cdot)}\\), se pueden especificar explícitamente de la siguiente manera. Dado \\(\\small{(x,y)\\in \\Omega}\\),\n\n\n\\[\\begin{equation}\np_{(x,y)(u,v)}(t) =\n\\begin{cases}\np_{FF} & \\begin{array}{l} \\text{Si}\\,\\, y=v=0 \\,\\, \\text{y}\\,\\, u=x, \\end{array} \\\\\np_{FS} & \\begin{array}{l} \\text{Si}\\,\\, y=0,\\,v=1 \\,\\, \\text{y}\\,\\, u=x, \\end{array}\n\\\\\np_{SF} & \\begin{array}{l} \\text{Si}\\,\\, y\\neq 0,\\,v=0\\,\\, \\text{y}\\,\\, u=x, \\end{array}\n\\\\\np_{SS} & \\begin{array}{l} \\text{Si}\\,\\, 1 \\leq y \\leq k-2,\\,\\,v=y+1\\,\\, \\,\\,\\text{e}\\,\\, u=x,\\\\\n\\text{o si}\\,\\, y=k-1,\\,\\, v=k^{+}\\,\\,\\text{e}\\,\\, u=x+k,\\\\\n\\text{o si}\\,\\, y=k^{+},\\,\\, v=k^{+}\\,\\,\\text{e}\\,\\, u=x+1\\\\\n\\end{array}\n\\\\\n1 & \\begin{array}{l} \\text{Si} \\,\\, y=v\\,\\,\\text{y}\\,\\, u=x=n\\end{array} \\\\\n0 & \\begin{array}{l} \\text{Otro caso}. \\end{array}\n\\end{cases}\n\\end{equation}\\]\n\nPor lo tanto, la variable aleatoria \\(\\small{S_{n,k}}\\) es una Cadena de Markov incrustable y las probabilidades exactas se pueden obtener de:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(S_{n,k}= x\\big) = \\boldsymbol{\\xi_0 M}^{n-1}\\boldsymbol{U}(C_x),\\,\\, x=0,k,\\ldots,n\n\\end{equation}\\]\n\ndonde el vector fila \\(\\small{\\boldsymbol{\\xi_0}=(q_0,p_0,0,\\ldots,0)_{1 \\times d}}\\) es la distribución inicial de \\(\\small{Y_1}\\), la partición \\(\\small{\\{C_x\\}}\\) se define como:\n\n\n\\[\\begin{equation}\nC_x =\\{(x,y):y=0,1,\\cdots,k-1,k^{+}\\},\\,\\,x=0,k,\\cdots,n,\n\\end{equation}\\]\n\ny \\(\\small{\\boldsymbol{U}'(C_x)}\\) es la transposición del vector fila \\(\\small{\\boldsymbol{U}(C_x)=(0,\\ldots,0,1,\\ldots,1,0,\\ldots,0)}\\) con unos en las coordenadas correspondientes a los estados de \\(\\small{C_x}\\).\nPara comprender mejor los efectos de los distintos parámetros, en la Figura 3.1 se muestran gráficamente las distribuciones de \\(\\small{S_{n,k}}\\) para algunos casos representativos con \\(\\small{n=15,30,60}\\), en los que se supone la distribución inicial \\(\\small{\\boldsymbol{\\xi_0}=(1,0,\\ldots,0)}\\). Cuando \\(\\small{p_{SS}}\\) es pequeño (por ejemplo, \\(\\small{p_{SS}=0.2}\\)), los efectos de los parámetros sobre la distribución son menos pronunciados, por lo que en la Figura 3.1 sólo se presentan casos con valores grandes de \\(\\small{p_{SS}\\,(=0.8)}\\). A efectos de comparación, también se incluyen las esperanzas.\nPara \\(\\small{n}\\) fijo, el efecto de \\(\\small{k}\\) y \\(\\small{p_{FS}}\\) puede resumirse como sigue. Para \\(\\small{k}\\) pequeño \\(\\small{(k=2)}\\) , la distribución de \\(\\small{S_{n,k}}\\) se suaviza y adquiere forma de campana a medida que aumenta \\(\\small{n}\\) (de la Figura 3.1(a) a (d) a (g)), y esta tendencia se amplifica con valores mayores de \\(\\small{p_{FS}}\\). A medida que \\(\\small{k}\\) aumenta, las distribuciones se alejan de la forma normal y se vuelven muy sesgadas hacia la derecha (por ejemplo, de la Figura 3.1(d) a (e) a (f)). La distribución de \\(\\small{S_{n,k}}\\) sólo puede aproximarse a una distribución normal cuando \\(\\small{k}\\) es mucho menor que \\(\\small{n}\\), y las aproximaciones normales deben utilizarse con precaución. En Fu, Lou, Bai y Li (2002) se ofrecen más detalles sobre la distribución límite de \\(\\small{S_{n,k}}\\).\n\n\n\n\n\n\nEn el capítulo 3, analizamos las ideas clave de la técnica de Incrustación de Cadenas de Markov Finitas (ICMF) para obtener las distribuciones exactas del número de rachas y patrones con éxitos en una sucesión de ensayos de dos estados. El objetivo principal de este capítulo es ampliar la técnica de ICMF para estudiar el número de rachas y patrones en una secuencia de ensayos multiestado. Podría parecer que, en principio, la ampliación debería ser sencilla y requerir sólo pequeñas modificaciones. Sin embargo, no es así, especialmente cuando el patrón es complejo y la sucesión \\(\\small{\\{X_t\\}}\\) está formada por ensayos multiestado Markov-Dependientes. Las principales dificultades se deben a la complejidad de construir una cadena de Markov finita adecuada asociada a la variable aleatoria \\(\\small{X_n(\\Lambda)}\\), especialmente en el proceso de obtención de las probabilidades de transición. Para superar estas dificultades, introducimos el principio de avance y retroceso. En este capítulo nos centraremos en la utilización del principio de avance y retroceso para obtener las distribuciones de patrones simples y compuestos. De hecho, el principio de avance y retroceso desempeña un papel indispensable en la construcción de la Cadena de Markov Incrustada para casi todas las aplicaciones cubiertas por este libro.\n\n\n\nComencemos con el caso simple de que \\(\\small{\\{X_t\\}_{t=1}^{n}}\\) es una secuencia de i.i.d. ensayos miltiestados. Cada ensayo tiene \\(\\small{m\\,\\, (m\\geq 2)}\\) resultados posibles (estados o símbolos), etiquetados como \\(\\small{\\mathscr{S} =\\{b_1,\\ldots, b_m\\}}\\) y que ocurren con probabilidades \\(\\small{p_1,p_2,\\ldots,p_m,}\\) respectivamente. Denotamos \\(\\small{X_n(\\Lambda)}\\) al número de patrones simples \\(\\small{\\Lambda}\\) no-superpuestos en la sucesión \\(\\small{\\{X_t\\}}\\). Primero, nos gustaría presentar el principio de avance y retroceso para la técnica de incrustación de cadenas de Markov finitas, un principio que guiará la construcción de una cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) y la determinación de sus matrices de probabilidad de transición. Para facilitar la discusión, el principio de avance y retroceso se introduce mediante el siguiente ejemplo.\nEjemplo 4.1 Consideremos el patrón simple \\(\\small{\\Lambda=\\{b_{1}b_{1}b_{2}\\}}\\) en una sucesión de ensayos de tres estados (\\(\\small{\\mathscr{S} =\\{b_1,b_{2}, b_{3}\\}}\\)).\n(i) Descompongamos el patrón \\(\\small{\\Lambda=b_{1}b_{1}b_{2}}\\) en un conjunto de subpatrones secuenciales \\(\\small{\\mathscr{S}(\\Lambda) =\\{b_1,b_{1}b_{1}, b_{1}b_{1}b_{2}\\}}\\). Definiendo\n\n\n\\[\\begin{equation}\n\\mathscr{E}=\\mathscr{S}\\, \\cup \\,\\mathscr{S}(\\Lambda)=\\{b_{1},b_{2},b_{3},b_{1}b_{1}, b_{1}b_{1}b_{2}\\}\n\\end{equation}\\]\n\ncomo un conjunto de bloques finales inducidos por el patrón \\(\\small{ b_{1}b_{1}b_{2}}\\) con respecto a sucesión de ensayos \\(\\small{\\{X_t\\}}\\)\n(ii) Sea \\(\\small{{\\omega} =(x_{1},\\ldots, x_n)}\\) una realización de una sucesión de \\(\\small{n}\\) ensayos de tres estados. Definiendo el espacio de estados:\n\n\n\\[\\begin{equation}\n\\Omega =\\{(u,v):u=0,1,\\cdots,[n\n/3],\\,\\, v\\in \\mathscr{E}\\}\\,\\cup \\,\\{\\emptyset\\}\\, -\\,\\{(0,b_{1}b_{1}b_{2})\\}\n\\end{equation}\\]\n\ny una cadena de Markov\n\n\n\\[\\begin{equation}\n\\big\\{Y_t=\\big(X_n(\\Lambda), E_t\\big),\\,t=0,1,2,\\ldots,n\\big\\}\n\\end{equation}\\]\n\noperando sobre \\(\\small{\\omega}\\) como\n\n\n\\[\\begin{equation}\nY_t(\\omega)=(u,v),\\,\\, \\text{para}\\,\\, t=1,\\ldots,n\n\\end{equation}\\]\n\nen donde: \n\n\\[\\begin{align*}\nu &=\\begin{cases}\n\\begin{array}{l}\nX_n(\\Lambda)(\\omega)=\\,\\text{el número total de patrones no-solapados}\\,\\Lambda\\,\\\\\n\\text{en los primeros}\\,\\, t\\,\\, \\text{ensayos contando hacia delante desde} \\\\\n\\text{el primer ensayo hasta el}\\,\\, t-ésimo\\,\\, \\text{ensayo, y}\n\\end{array}\n\\end{cases}\\\\\n\\\\\nv &=\\begin{cases}\n\\begin{array}{l}\nE_t(w) =\\,\\text{el bloque final más largo en}\\ \\mathscr{S},\\\\\n\\text{contando hacia atrás desde}\\, X_t.\n\\end{array}\n\\end{cases}\n\\end{align*}\\]\n\nLas definiciones de \\(\\small{u}\\) y \\(\\small{v}\\) para la sucesión de los primeros \\(\\small{t}\\) ensayos se ilustran gráficamente en la figura 4.1. Para que la cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) y el concepto de bloque final más largo sean más transparentes, consideremos la siguiente realización, \\(\\small{\\omega=(b_{3}b_{1}b_{2}b_{1}b_{1}b_{2}b_{1})}\\), de una sucesión de siete ensayos de tres estados. Aplicando el principio de avance y retroceso, la correspondiente del la cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) sobre \\(\\small{\\omega}\\) viene dada por \\(\\small{\\{Y_{1}(\\omega)=(0,b_{3}), Y_{2}(\\omega)=(0, b_{1}), Y_{3}(\\omega) = (0, b_{2}), Y_{4}(\\omega)= (0, b_{1}), Y_{5}(\\omega)=(0, b_{1}b_{1}), Y_{6}(\\omega) = (1, b_{1}b_{1}b_{2})\\,\\text{y}\\, Y_{7}(\\omega)=(1, b_{1})\\}}\\). Tenga en cuenta que para cada \\(\\small{\\omega}\\) dada, la realización de la cadena de Markov incrustada \\(\\small{Y_t(\\omega) = (u, v)}\\) está determinada únicamente por lo anterior procedimientos (i) y (ii) bajo conteo sin superposición. En palabras sencillas, el el bloque final \\(\\small{v}\\) representa el estado de formación del siguiente patrón \\(\\small{\\Lambda}\\) para el subsecuencia \\(\\small{\\{{x_1,., ,x_t} \\}}\\) que contiene \\(\\small{u}\\) patrones completos.\n(iii) La cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) es homogénea y su matriz de probabilidad de transición \\(\\small{\\boldsymbol{M_t}= \\big(p_{(x,z),(u,v)}\\big)}\\) puede determinarse del siguiente modo. Por ejemplo, dado \\(\\small{Y_5(\\omega)=(0,b_{1}b_{1})}\\), como \\(\\small{X_{6}}\\) sólo puede ser uno de los tres resultados posibles \\(\\small{b_{1}, b_{2}}\\) y \\(\\small{b_{3}}\\), el procedimiento de recuento hacia delante y hacia atrás da como resultado\n\n\n\\[\\begin{align*}\nY_{5}(\\omega) & \\rightarrow \\quad \\quad Y_{6}(\\omega)\n\\\\\n(0,b_{1}b_{1}) &\\rightarrow  \\begin{cases}\n\\begin{array}{cl}\n(0,b_{1}b_{1}) & \\text{si}\\,\\, X_6= b_{1}\\,\\,(\\text{con probabilidad}\\, p_{1})\\\\\n(1,b_{1}b_{1}b_{2}) & \\text{si}\\,\\, X_6= b_{2}\\,\\,(\\text{con probabilidad}\\, p_{2})\\\\\n(0,b_{3}) & \\text{si}\\,\\, X_6= b_{3}\\,\\,(\\text{con probabilidad}\\, p_{3}),\n\\end{array}\n\\end{cases}\n\\end{align*}\\]\n\ne \\(\\small{Y_5(\\omega)}\\) pasa a cualquier otro estado con probabilidad cero. De esta forma se obtienen todas las probabilidades de transición \\(\\small{\\mathbb{P}\\big(Y_t=(u,v)\\mid Y_{t-1}=(x,z)\\big)}\\). El estado ficticio \\(\\small{\\emptyset}\\) se añadirá como estado inicial con \\(\\small{\\mathbb{P}\\big(Y_{0}=\\emptyset\\big)=1}\\) y con probabilidades de transición \\(\\small{\\mathbb{P}\\big(Y_{1}=b_{i}\\mid Y_0=\\emptyset\\big)=p_{i}}\\) para \\(\\small{i=1,2,3}\\). Obsérvese que el estado \\(\\small{(0,\\Lambda=b_{1}b_{1}b_{2})}\\) se eliminó del espacio de estados, ya que siempre que el bloque final \\(\\small{v}\\) sea igual a \\(\\small{\\Lambda}\\) debe haber al menos una ocurrencia de el patrón en la secuencia (es decir, \\(\\small{u\\geq1}\\) si \\(\\small{v=\\Lambda}\\)).\n(iv) Dado \\(\\small{n}\\), tenemos la siguiente partición en el espacio de estados \\(\\small{\\Omega}\\):\n\n\n\\[\\begin{align*}\n\\big\\{C_{\\emptyset} &=[\\emptyset], C_{0}=[(0,b_{1}),(0,b_{2}),(0,b_{3}),(0,b_{1}b_{1})], \\\\\n& \\,\\,\\text{y}\\,\\,C_{x}=[(x,v),v\\in \\mathscr{E}],\\, x=1,\\ldots,[n/3] \\big\\}.\n\\end{align*}\\]\n\nPara \\(\\small{n=5}\\) y la probabilidad inicial \\(\\small{\\mathbb{P}\\big(Y_0=\\emptyset \\big)\\equiv 1}\\), se deduce de los procedimientos (i) a (iv) anteriores que la cadena de Markov incrustada \\(\\small{\\{Y_t\\}_{t=0}^{5}}\\) está definida en el espacio de estados \\(\\small{\\Omega=\\{\\emptyset, (0, b_{1}), (0, b_{2}), (0, b_{3}), (0, b_{1}b_{1}), (1, b_{1}b_{1}b_{2}), (1, b_{1}), (1, b_{2}), (1, b_{3}), (1, b_{1}b_{1})\\}}\\) con matriz de probabilidad de transición\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\n\\begin{array}{cc}&\n\\begin{array}{c}\n\\emptyset\\\\\n(0,b_{1})\\\\\n(0,b_{2})\\\\\n(0,b_{3})\\\\\n(0,b_{1}b_{1})\\\\\n(1,b_{1}b_{1}b_{2})\\\\\n(1,b_{1})\\\\\n(1,b_{2})\\\\\n(1,b_{3})\\\\\n(1,b_{1}b_{1})\n\\end{array}\n&\n\\left(\n\\begin{array}{c|cccc|ccccc}\n0&p_{1}&p_{2}&p_{3}&0&0&0&0&0&0\\\\\n\\hline\n0&0&p_{2}&p_{3}&0&0&0&0&0&0\\\\\n0&p_{1}&p_{2}&p_{3}&0&0&0&0&0&0\\\\\n0&p_{1}&p_{2}&p_{3}&0&0&0&0&0&0\\\\\n0&0&0&p_{3}&p_{1}&p_{2}&0&0&0\\\\\n\\hline\n0&0&0&0&0&0&p_{1}&p_{2}&p_{3}&0\\\\\n0&0&0&0&0&0&0&p_{2}&p_{3}&p_{1}\\\\\n0&0&0&0&0&0&p_{1}&p_{2}&p_{3}&0\\\\\n0&0&0&0&0&0&p_{1}&p_{2}&p_{3}&0\\\\\n0&0&0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nLas probabilidades \\(\\small{\\mathbb{P}\\big(X_n(\\Lambda)=5\\big)=\\boldsymbol{\\xi_0M}^5\\boldsymbol{U'}(C_x),\\, x=0,1,}\\), pueden computarse facilmente.\nPara demostrar la aplicabilidad del principio de avance y retroceso a los patrones compuestos, consideremos el siguiente ejemplo.\nEjemplo 4.2 Dado \\(\\small{n=4}\\) y un patrón compuesto \\(\\small{\\Lambda= \\Lambda_{1} \\cup \\Lambda_{2}}\\), que consiste en la unión de dos patrones simples distintos \\(\\small{ \\Lambda_{1}=b_{1}b_{2}}\\) y \\(\\small{ \\Lambda_{1}=b_{3}b_{1}}\\), estamos interesados en encontrar la distribución de la variable aleatoria \\(\\small{X_4(\\Lambda)}\\), el número de ocurrencias de \\(\\small{\\Lambda_{1}}\\) o \\(\\small{\\Lambda_{2}}\\) en una secuencia de cuatro ensayos i.i.d. de tres estados. Procediendo como en el ejemplo anterior, se obtiene la cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) definida en el espacio de estados\n\n\n\\[\\begin{align*}\n\\Omega &=\\big\\{\\emptyset,(0,b_{1}),(0,b_{2}),(0,b_{3}),(1,b_{1}b_{2}), (1,b_{3}b_{1}), \\\\\n& \\quad \\quad (1,b_{1}),(1,b_{2}),(1,b_{3}),(2,b_{1}b_{2}),(2,b_{3}b_{1})\\big\\}.\n\\end{align*}\\]\n\ncon matriz de probabilidades de transición:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\n\\begin{array}{cc}&\n\\begin{array}{c}\n\\emptyset\\\\\n(0,b_{1})\\\\\n(0,b_{2})\\\\\n(0,b_{3})\\\\\n(1,b_{1}b_{2})\\\\\n(1,b_{3}b_{1})\\\\\n(1,b_{1})\\\\\n(1,b_{2})\\\\\n(1,b_{3})\\\\\n(2,b_{1}b_{2})\\\\\n(2,b_{3}b_{1})\n\\end{array}\n&\n\\left(\n\\begin{array}{c|ccc|ccccc|cc}\n0&p_{1}&p_{2}&p_{3}&0&0&0&0&0&0&0\\\\\n\\hline\n0&p_{1}&0&p_{3}&p_{2}&0&0&0&0&0&0\\\\\n0&p_{1}&p_{2}&p_{3}&0&0&0&0&0&0&0\\\\\n0&0&p_{2}&p_{3}&0&p_{1}&0&0&0&0&0\\\\\n\\hline\n0&0&0&0&p_{1}&0&0&p_{2}&p_{3}&0&0\\\\\n0&0&0&0&0&0&p_{1}&p_{2}&p_{3}&0&0\\\\\n0&0&0&0&0&0&p_{1}&0&p_{3}&p_{2}&0\\\\\n0&0&0&0&0&0&p_{1}&p_{2}&p_{3}&0&0\\\\\n0&0&0&0&0&0&0&p_{2}&p_{3}&0&p_{1}\\\\\n\\hline\n0&0&0&0&0&0&0&0&0&1&0\\\\\n0&0&0&0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nLas probabilidades \\(\\small{\\mathbb{P}\\big(X_n(\\Lambda)=4\\big)=\\boldsymbol{\\xi_0M}^4\\boldsymbol{U'}(C_x),\\, x=0,1,2}\\), pueden computarse facilmente.\nEl método también puede extenderse, con modificaciones simples, a la caso donde \\(\\small{\\{X_t\\}}\\) es una sucesión de ensayos multiestado Markov-Dependientes.\nEjemplo 4.3 Volvamos al Ejemplo 4.1, pero consideremos aquí que \\(\\small{\\{X_t\\}}\\) es una secuencia de ensayos de tres estados Markov-Dependientes con matriz de probabilidad de transición:\n\n\n\\[\\begin{equation}\n\\boldsymbol{A}=\\left(\n\\begin{array}{ccc}\np_{11}&p_{12}&p_{13}\\\\\np_{21}&p_{22}&p_{23}\\\\\np_{31}&p_{32}&p_{33}\\\\\n\\end{array}\n\\right)\n\\end{equation}\\]\n\nNuestro objetivo es determinar la distribución del patrón \\(\\small{\\Lambda=b_{1}b_{1}b_{2}}\\) en una secuencia de cinco ensayos. De forma análoga al Ejemplo 4.1, las probabilidades de transición de la cadena de Markov incrustada pueden obtenerse para cada estado mediante el siguiente argumento. Dado \\(\\small{Y_3 = (0, b_{1}b_{1})}\\), por ejemplo, tenemos:\n\n\n\\[\\begin{align*}\nY_3 & \\rightarrow \\quad \\quad \\, Y_{4}\\\\\n(0,b_{1}b_{1}) &\\rightarrow  \\begin{cases}\n\\begin{array}{cl}\n(0,b_{1}b_{1}) & \\text{si}\\,\\, X_{4}= b_{1}\\,\\,(\\text{con probabilidad}\\, p_{11})\\\\\n(1,b_{1}b_{1}b_{2}) & \\text{si}\\,\\, X_{4}= b_{2}\\,\\,(\\text{con probabilidad}\\, p_{12})\\\\\n(0,b_{3}) & \\text{si}\\,\\, X_{4}= b_{3}\\,\\,(\\text{con probabilidad}\\, p_{13}).\n\\end{array}\n\\end{cases}\n\\end{align*}\\]\n\nLas ecuaciones (4.4) y (4.9) son equivalentes, salvo que las probabilidades \\(\\small{p_{1}}\\),\\(\\small{p_{2}}\\) y \\(\\small{p_{3}}\\) se sustituyen por \\(\\small{p_{11}}\\),\\(\\small{p_{12}}\\) y \\(\\small{p_{13}}\\) respectivamente. Por lo tanto, la cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) se define aquí en el mismo espacio de estados \\(\\small{\\Omega}\\) y con matriz de probabilidad de transición:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\n\\begin{array}{cc}&\n\\begin{array}{c}\n\\emptyset\\\\\n(0,b_{1})\\\\\n(0,b_{2})\\\\\n(0,b_{3})\\\\\n(0,b_{1}b_{1})\\\\\n(1,b_{1}b_{1}b_{2})\\\\\n(1,b_{1})\\\\\n(1,b_{2})\\\\\n(1,b_{3})\\\\\n(1,b_{1}b_{1})\n\\end{array}\n&\n\\left(\n\\begin{array}{c|cccc|ccccc}\n0&p_{1}&p_{2}&p_{3}&0&0&0&0&0&0\\\\\n\\hline\n0&0&p_{12}&p_{13}&p_{11}&0&0&0&0&0\\\\\n0&p_{21}&p_{22}&p_{23}&0&0&0&0&0&0\\\\\n0&p_{31}&p_{32}&p_{33}&0&0&0&0&0&0\\\\\n0&0&0&p_{13}&p_{11}&p_{12}&0&0&0\\\\\n\\hline\n0&0&0&0&0&0&p_{21}&p_{22}&p_{23}&0\\\\\n0&0&0&0&0&0&0&p_{12}&p_{13}&p_{11}\\\\\n0&0&0&0&0&0&p_{21}&p_{22}&p_{23}&0\\\\\n0&0&0&0&0&0&p_{31}&p_{32}&p_{33}&0\\\\\n0&0&0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\ndonde las probabilidades de transición \\(\\small{\\mathbb{P}\\big(Y_{t}(u,v)=Y_{t-1}(x,z)\\big)}\\) se obtienen como se ilustra en la Ec. (4.9). Obsérvese que la matriz de probabilidades de transición de la Ec. (4.10) tiene exactamente la misma forma que la matriz de la Ec. (4.6) para el caso i.i.d..\nEn vista de las transiciones de estado esbozadas por las Ecs. (4.4) y (4.9), que conducen a las matrices de probabilidad de transición de los Ejemplos 4.1 a 4.3, dadas en las Ecs. (4.6), (4.8) y (4.10) respectivamente, definimos la siguiente notación: dado \\(\\small{Y_{t-1} = (x, z) \\in \\Omega}\\) y \\(\\small{X_t = j\\in \\mathscr{S}}\\), \n\n\\[\\begin{equation}\n(u,v)\\equiv &lt;(x,z),j&gt;_{\\Omega}\n\\end{equation}\\]\n\ndonde el estado \\(\\small{(u,v)\\in \\Omega}\\) es el resultado del recuento hacia delante y hacia atrás (no solapado) cuando se incluye un resultado adicional \\(\\small{X_t=j}\\). Para cada \\(\\small{(x, z)\\in \\Omega}\\), definimos también \\(\\small{L(z)\\in \\mathscr{S}}\\) como el último elemento del bloque final \\(\\small{z}\\). Entonces, para el caso general, las probabilidades de transición de la cadena de Markov incrustada \\(\\small{Y_t}\\) se especifican mediante la siguiente ecuación:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(Y_t=(u,v)\\mid Y_{t-1}=(x,z)\\big) =\\begin{cases}\np_{ij} & \\quad\n\\begin{array}{l}\n\\text{si}\\,\\, X_{t}=j\\in\\mathscr{S},\\, L(z)=i\\\\\n\\text{y}\\,\\,(u,v)= &lt;(x,z),j&gt;_{\\Omega}\n\\end{array}\\\\\nm & \\quad \\text{en otro caso}\n\\end{cases}\n\\end{equation}\\]\n\ndonde \\(\\small{p_{ij}}\\) son las probabilidades de transición de la cadena de Markov \\(\\small{\\{X_t\\}}\\). Si \\(\\small{\\{X_t\\}}\\) es una secuencia de ensayos multiestado i.i.d., la Ec.(4.12) se convierte en\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(Y_t=(u,v)\\mid Y_{t-1}=(x,z)\\big) =\\begin{cases}\np_{j} & \\quad\n\\begin{array}{l}\n\\text{si}\\,\\, X_{t}=j\\in\\mathscr{S},\\\\\n\\text{y}\\,\\,(u,v)= &lt;(x,z),j&gt;_{\\Omega}\n\\end{array}\\\\\n0 & \\quad \\text{en otro caso}\n\\end{cases}\n\\end{equation}\\]\n\nTeorema 4.1 Suponiendo que \\(\\small{\\{X_t\\}}\\) es una cadena de Markov homogénea con matriz de probabilidad de transición \\(\\small{\\boldsymbol{A} = \\big(p_{ij}\\big)_{m\\times m}}\\), y \\(\\small{\\Lambda=\\displaystyle{\\bigcup_{i=1}^{l}\\Lambda_{i}}}\\) es un patrón compuesto generado por \\(\\small{l}\\) patrones simples distintos \\(\\small{\\Lambda_{i}}\\) que tienen la misma longitud \\(\\small{k}\\), entonces la cadena de Markov incrustada \\(\\small{\\big\\{Y_t=\\big(X_{t}(\\Lambda),E_{t} \\big),\\,t=1,2,\\,\\ldots,n\\big\\}}\\) correspondiente a la variable aleatoria \\(\\small{X_{n}(\\Lambda)}\\)\n(i) se define sobre el espacio de estados:\n\n\n\\[\\begin{align*}\\Omega &=\\{\\emptyset\\}\\, \\cup\\,\\{(x,z):x=0,1,\\cdots,[n\n/k],\\,\\, z\\in \\mathscr{E}\\}\\\\\n&\\quad- \\{(0,\\Lambda_{i}):i=1,\\cdots,l\\}\n-\\,\\{([n/k],z):k[n/k]+z(k)&gt;n\\},\\end{align*}\\]\n\nen donde \\(\\small{\\mathscr{E} =\\mathscr{S}\\,\\cup\\Bigg(\\displaystyle\\bigcup_{i=1}{\\mathscr{S}(\\Lambda_{i})\\Bigg)}}\\) y \\(\\small{z(k)\\equiv [\\text{longitud de}\\,z] \\pmod k}\\)\n(ii) tiene la matriz de probabilidades de transición: \n\n\\[\\begin{equation}\n\\boldsymbol{M}=\\big(p_{(x,z)(u,v)}\\big)_{d\\times d}\n\\end{equation}\\]\n\nen donde las probabilidades de transición estan dadas por: \n\n\\[\\begin{equation}\np_{(x,z)(u,v)}=\\begin{cases}\np_{j} & \\,\\text{si}\\, (x,z)=\\emptyset,\\,u=0,\\,v=j,\\, \\text{para todo}\\, j \\in \\mathscr{S}\\\\ \\\\\np_{ij} &\n\\begin{array}{l}\n\\text{si}\\,(u,v)=&lt;(x,z),j&gt;_{\\Omega},\\, x\\leq [n/k],\\, j\\in \\mathscr{S},\\\\\nL(z)=i,\\,\\text{y}\\,\\, kx+z(k)&lt;n\n\\end{array} \\\\ \\\\\n1 &\n\\begin{array}{l}\n\\text{si}\\,(u,v)= (x,z) ,\\, x= [n/k]\\\\\n\\,\\text{y}\\,\\, k[n/k]+z(k)=n\n\\end{array} \\\\\\\\\nm & \\text{en otro caso.}\n\\end{cases}\n\\end{equation}\\]\n\ncon \\(\\small{d=\\text{card}(\\Omega)}\\), el tamaño del espacio de estados \\(\\small{\\Omega}\\), igual a:\n\n\n\\[\\begin{align*}d =1 & +([n/k]+1)\\times \\text{card}\\big(\\mathscr{E}\\big)-l\\\\\n& -\\text{card}\\Big(\\big\\{([n/k],z):\\,z \\in \\mathscr{E}, \\,k[n/k]+z(k)&gt;n\\big\\}\\big),\\end{align*}\\]\n\ny (iii) se obtiene la distribución:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big( X_n(\\Lambda)=x\\big)=\\boldsymbol{\\mathbf{\\xi}}_0\\boldsymbol{M}^{n}\\boldsymbol{\\mathbf{U}'}( {C_x}),\\,\\,  x=1,2,\\ldots,[n/k],\n\\end{equation}\\]\n\nen donde \\(\\small{\\boldsymbol{\\xi}_0}\\) es la distribución inicial especificada por \\(\\small{\\mathbb{P}\\big(Y_{0}=\\emptyset\\big)\\equiv 1}\\) y \n\n\\[\\begin{align*}\nC_{\\emptyset} &=[\\emptyset],\\, C_{0}=[(0,z):z\\in\\mathscr{S}]-[(0,\\Lambda_{i}):i=1,2,\\ldots,l], \\\\\nC_{x} &=  [(x,z):z\\in \\mathscr{E}],\\, 1\\leq x \\leq [n/k], \\, \\text{y}\\\\\nC_{[n/x]}&=[([n/k],z):z\\in \\mathscr{E},\\,k[n/k]+z(k)\\leq n]\n\\end{align*}\\]\n\nson las particiones del espacio de estados \\(\\small{\\Omega}\\).\nNótese que el espacio de estados \\(\\small{\\Omega}\\) y su tamaño \\(\\small{d}\\) son funciones de \\(\\small{n}\\), la estructura de los patrones \\(\\small{\\Lambda_{i},\\,i=1,\\ldots,l}\\) y la longitud del patrón común \\(\\small{k}\\). El lector puede comprobar que los resultados de los Ejemplos 4.1 a 4.3 se deducen directamente del Teorema 4.1.\nDemostración. Dado \\(\\small{n}\\), como la longitud de cada patrón es \\(\\small{k}\\), el número máximo de patrones es \\(\\small{[n/k]}\\) (bajo conteo no solapado). El conjunto \\(\\small{\\mathscr{E} =\\mathscr{S}\\,\\cup\\Bigg(\\displaystyle\\bigcup_{i=1}{\\mathscr{S}(\\Lambda_{i})\\Bigg)}}\\) contiene todos los posibles bloques finales generados por \\(\\small{\\mathscr{S}}\\) y todos los patrones, y se deduce que para recuento hacia delante y hacia atrás sin solapamiento, el espacio de estados tiene la forma \\(\\small{\\big\\{(x,z): x=0,\\ldots,[n/k]},\\,z\\in\\mathscr{E}\\big\\}\\). Los estados \\(\\small{\\big\\{(0,\\Lambda_{i}): i=1,\\ldots,l}\\big\\}\\) se eliminan porque si el bloque final es \\(\\small{\\Lambda_{i}}\\), entonces debe haber al menos un patrón \\(\\small{\\Lambda_{i}}\\), en la secuencia \\(\\small{(x\\geq 1)}\\), por lo que los estados \\(\\small{\\big\\{(0,\\Lambda_{i})\\big\\}}\\) son inalcanzables; por la misma razón, los estados \\(\\small{\\big\\{([n/k],z):k[k/z]+z(k)&gt;n\\big\\}}\\) tampoco pueden darse y pueden eliminarse. Así, el espacio de estados \\(\\small{\\Omega}\\) de la cadena de Markov incrustada tiene la forma dada por la Ec. (4.14), y su tamaño \\(\\small{d}\\) viene determinado por la Ec.(4.17).\nDados \\(\\small{(x,z)\\in \\Omega,\\,0\\leq x \\leq [n/n]}\\), y \\(\\small{kx + z(k) &lt; n}\\), si \\(\\small{X_{t}=j\\in \\mathscr{S}}\\) y \\(\\small{(u, v) = &lt; (x, z), j &gt;_{\\Omega}}\\) , entonces, como se describe en las Ecs. (4.9) y (4.12), se deduce que\n\n\n\\[\\begin{align*}\np_{(x,z)(u,v)}=\\mathbb{P}\\big(Y_t=(u,v)\\mid Y_{t-1}=(x,z)\\big)=p_{ij},\n\\end{align*}\\]\n\ndonde \\(\\small{i=L(z)}\\). Si \\(\\small{Y_{t-1}=([n/k], z) }\\), y \\(\\small{[kn/k] + z(k) = n}\\) entonces \\(\\small{t-1\\equiv n}\\); por conveniencia, asignamos las probabilidades de transición para estos estados como \\(\\small{\\mathbb{P}\\big(Y_t=([n/k],z)\\mid Y_{t-1}=([n/k],z)\\big)\\equiv1}\\) . Esto completa la construcción de la Ec. (4.16) y la matriz de probabilidad de transición \\(\\small{\\boldsymbol{M}}\\) . Las particiones en el espacio de estados \\(\\small{\\Omega}\\) , dadas por la Ec. (4.19), son una consecuencia directa de la definición de la cadena de Markov incrustada introducida en la Ec. (4.3). Por lo tanto, la distribución para el patrón compuesto \\(\\small{\\Lambda}\\) en la Ec. (4.18) es una consecuencia inmediata del Teorema 2.1. Esto completa la demostración. \\(\\hspace{1cm}\\Box\\)\nEl teorema 4.1 anterior también es válido para patrones simples, el caso especial cuando \\(\\small{l=1}\\) . Cuando las longitudes de los patrones \\(\\small{k_{i},\\, i=1,\\ldots,l}\\) no son todas iguales, el principio de avance y retroceso puede seguir utilizándose para hallar la distribución del patrón compuesto \\(\\small{\\Lambda}\\) . En principio, el procedimiento de recuento de avance y retroceso es aplicable a cualquier número de patrones \\(\\small{l}\\) de tamaños \\(\\small{k_{i}}\\) variables, pero no es sencillo escribir la forma general del espacio de estados y la matriz de probabilidad de transición de la cadena de Markov incrusrada. Trataremos este problema en el capítulo 5 utilizando la relación de dualidad entre \\(\\small{X_{n}(\\Lambda)}\\) y el tiempo de espera \\(\\small{W(\\Lambda)}\\).\n\n\n\nConsideremos que la secuencia \\(\\small{\\{X_t\\}}\\) es una cadena de Markov homogénea definida sobre el espacio de estados \\(\\small{\\mathscr{S}=\\{a, b, c\\}}\\) con matriz de probabilidades de transición\n\n\n\\[\\begin{equation}\n\\boldsymbol{A}=\\big(p_{ij}\\big),\\, i,j=a,b,c\n\\end{equation}\\]\n\nSea \\(\\small{\\Lambda}\\) un patrón simple de longitud \\(\\small{k}\\). La diferencia básica entre el recuento por solapamiento y el recuento sin solapamiento es que cuando se forma el patrón \\(\\small{\\Lambda}\\), una parte de A se contará para formar el siguiente patrón \\(\\small{\\Lambda}\\) bajo el recuento por solapamiento, hasta los últimos \\(\\small{(k-1)}\\) ensayos.\nDefinición 4.1 Un bloque final \\(\\small{E^°}\\) generado por el patrón \\(\\small{\\Lambda}\\) es el bloque final más largo \\(\\small{(E^{°} \\neq \\Lambda)}\\) que, después de cada aparición de \\(\\small{\\Lambda}\\) bajo conteo superpuesto, se puede asignar como bloque final inicial para la siguiente aparición de \\(\\small{\\Lambda}\\). Escribimos \\(\\small{(E^{°} \\cong \\Lambda}\\) , con respecto al conteo de superposición.\nPor ejemplo, bajo el conteo superpuesto:\n\nSi \\(\\small{\\Lambda=aca}\\), entonces \\(\\small{E^{°}=a}\\),\nSi \\(\\small{\\Lambda=abcab}\\), entonces \\(\\small{E^{°}=ab}\\), y\nSi \\(\\small{\\Lambda=\\underbrace{a\\cdots a}_{k}}\\), entonces \\(\\small{E^{°}=\\underbrace{a\\ldots a}_{k-1}}\\).\n\nPara un patrón como \\(\\small{\\Lambda=abc}\\), no existe un \\(\\small{E^{°}}\\), en cuyo caso el conteo superpuesto y no superpuesto es el mismo. Tenga en cuenta que bajo el conteo superpuesto, dado que el primer patrón requiere \\(\\small{k}\\) elementos y cada patrón adicional requiere solo \\(\\small{k-\\text{Card}(E^{°})}\\) elementos, el mayor número posible de patrones \\(\\small{\\Lambda}\\) que pueden ocurrir en \\(\\small{n (n \\geq k)}\\) ensayos es\n\n\n\\[\\begin{equation*}\nl_{n}^{o}=1+\\bigg[\\frac{n-k}{k-\\text{Card}(E^{°})}\\bigg].\n\\end{equation*} \\]\n\nPara ilustrar las diferencias menores que surgen de los dos tipos de conteo, se proporciona el siguiente ejemplo.\nEjemplo 4.4 Consideremos el número de patrones \\(\\small{\\Lambda=aca}\\) que ocurren en \\(\\small{n=5}\\) ensayos i.i.d. de tres estados. Bajo el conteo no superpuesto, la matriz de transición de probabilidades \\(\\small{\\boldsymbol{M}}\\) asociada con la cadena de Markov incrustada\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\n\\begin{array}{cc}&\n\\begin{array}{c}\n(0,a)\\\\\n(0,b)\\\\\n(0,c)\\\\\n(0,ab)\\\\\n(1,\\Lambda)\\\\\n(1,a)\\\\\n(1,b)\\\\\n(1,c)\\\\\n(1,ac)\\\\\n\\end{array}\n&\n\\left(\n\\begin{array}{ccccccccc}\np_{a}&p_{b}&0&p_{c}&0&0&0&0&0\\\\\np_{a}&p_{b}&p_{c}&0&0&0&0&0&0\\\\\np_{a}&p_{b}&p_{c}&0&0&0&0&0&0\\\\\n0&p_{b}&p_{c}&0&p_{a}&0&0&0&0\\\\\n0&0&0&0&0&p_{a}&p_{b}&p_{c}&0\\\\\n0&0&0&0&0&p_{a}&p_{b}&0&p_{c}\\\\\n0&0&0&0&0&p_{a}&p_{b}&p_{c}&0\\\\\n0&0&0&0&0&p_{a}&p_{b}&p_{c}&0\\\\\n0&0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\ndonde \\(\\small{(1,\\Lambda)\\equiv (1,aca)}\\) . Bajo conteo de superpuesto, la matriz de probabilidad de transición \\(\\small{\\boldsymbol{M^{°}}}\\) asociada con la cadena de Markov incrustada es\n\n\n\\[\\begin{equation}\n\\boldsymbol{M^{°}}=\n\\begin{array}{cc}&\n\\begin{array}{c}\n(0,a)\\\\\n(0,b)\\\\\n(0,c)\\\\\n(0,ab)\\\\\n(1,\\Lambda)\\\\\n(1,a)\\\\\n(1,b)\\\\\n(1,c)\\\\\n(1,ac)\\\\\n(2,\\Lambda)\n\\end{array}\n&\n\\left(\n\\begin{array}{ccccc|cccc}\np_{a}&p_{b}&0&p_{c}&0&0&0&0&0&0\\\\\np_{a}&p_{b}&p_{c}&0&0&0&0&0&0&0\\\\\np_{a}&p_{b}&p_{c}&0&0&0&0&0&0&0\\\\\n0&p_{b}&p_{c}&0&p_{a}&0&0&0&0&0\\\\\n\\hline\n0&0&0&0&0&p_{a}&p_{b}&0&p_{c}&0\\\\\n\\hline\n0&0&0&0&0&p_{a}&p_{b}&0&p_{c}&0\\\\\n0&0&0&0&0&p_{a}&p_{b}&p_{c}&0&0\\\\\n0&0&0&0&0&p_{a}&p_{b}&p_{c}&0&0\\\\\n0&0&0&0&0&0&p_{b}&p_{c}&0&p_{a}\\\\\n0&0&0&0&0&0&0&0&1&0\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nLa principal diferencia entre las dos matrices surge después de que ha ocurrido el primer patrón. Con probabilidad \\(\\small{p_{c}}\\) , el estado \\(\\small{(1,\\Lambda)}\\) pasa al estado \\(\\small{(1,c)}\\) bajo conteo no superpuesto, mientras que \\(\\small{(1,\\Lambda)}\\) pasa a \\(\\small{(1,ac)}\\) bajo conteo superpuesto, lo que también implica el estado adicional \\(\\small{l_{n}^{°}=(2,\\Lambda)}\\). \\(\\hspace{1cm}\\Diamond\\)\nSi \\(\\small{\\{X_t\\}}\\) es una cadena de Markov homogénea con probabilidades de transición dadas por la Ecuación. (4.20), la matriz de probabilidad de transición \\(\\small{\\boldsymbol{M^{°}}}\\) del anterior ejemplo (bajo conteo superpuesto) se convierte en:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M^{°}}=\n\\begin{array}{cc}&\n\\begin{array}{c}\n\\emptyset\\\\\n(0,a)\\\\\n(0,b)\\\\\n(0,c)\\\\\n(0,ab)\\\\\n(1,\\Lambda)\\\\\n(1,a)\\\\\n(1,b)\\\\\n(1,c)\\\\\n(1,ac)\\\\\n(2,\\Lambda)\n\\end{array}\n&\n\\left(\n\\begin{array}{cccccc|ccccc}\n0&p_{a}&p_{b}&p_{c}&0&0&0&0&0&0&0\\\\\n0&p_{aa}&p_{ab}&0&p_{ac}&0&0&0&0&0&0\\\\\n0&p_{ba}&p_{bb}&p_{bc}&0&0&0&0&0&0&0\\\\\n0&p_{ca}&p_{cb}&p_{cc}&0&0&0&0&0&0&0\\\\\n0&0&p_{bb}&p_{bc}&0&p_{ab}&0&0&0&0&0\\\\\n\\hline\n0&0&0&0&0&0&p_{aa}&p_{ab}&0&p_{ac}&0\\\\\n\\hline\n0&0&0&0&0&0&p_{aa}&p_{ab}&0&p_{ac}&0\\\\\n0&0&0&0&0&0&p_{ba}&p_{bb}&p_{bc}&0&0\\\\\n0&0&0&0&0&0&p_{ca}&p_{cb}&p_{cc}&0&0\\\\\n0&0&0&0&0&0&0&p_{cb}&p_{cc}&0&p_{ca}\\\\\n0&0&0&0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\ndonde \\(\\small{p_{a},\\, p_{b}}\\), y \\(\\small{p_{c}}\\) son las probabilidades de transición dadas del estado \\(\\small{\\emptyset}\\) a los estados \\(\\small{(0, a), (0,b)}\\) y \\(\\small{(0, c)}\\), respectivamente. Nuevamente, la extensión de i.i.d. a los emnsayos Markov-Dependientes sigue siendo sencillo. El concepto considerado en el ejemplo anterior se puede extender al caso de superposición hasta los últimos \\(\\small{d}\\) ensayos \\(\\small{(1 \\leq d \\leq k − 1)}\\), como lo introdujeron Aki e Hirano (2000). Una ventaja significativa de la técnica de incrustación de cadenas finitas de Markov es que la extensión del conteo sin superposición al conteo superpuesto es directa y simple.\n\n\n\nLa distribución del número de patrones en serie \\(\\small{\\Lambda=\\Lambda_{1}\\ast\\Lambda_{2}}\\) se puede obtener casi de la misma manera que para un patrón simple, con modificaciones menores en el estado después de que se haya producido el primer patrón \\(\\small{\\Lambda_{1}}\\).\nEjemplo 4.5 Consideremos una secuencia de \\(\\small{n=5}\\) ensayos i.i.d. de tres estados extraídos de \\(\\small{\\mathscr{S}=\\{a,b,c\\}}\\), y el patrón de serie \\(\\small{\\Lambda}=ab\\ast cc\\) generado por los dos patrones simples \\(\\small{\\Lambda_{1}=ab}\\) y \\(\\small{\\Lambda_{2}=cc}\\). Definiendo el conjunto de bloques finales \\(\\small{\\mathscr{E}=\\{a,\\bar{a},ab\\ast,ab{\\ast}c,ab{\\ast}cc\\}}\\) y el espacio de estados\n\n\n\\[\\begin{equation}\n\\Omega=\\{\\emptyset,(0,a),(0,\\bar{a}),(0,ab{\\ast}),(0,ab{\\ast}c),(1,ab{\\ast}cc),(1,a),(1,\\bar{a})\\}\n\\end{equation}\\]\n\ndonde \\(\\small{\\bar{a}}\\) representa \\(\\small{b}\\) o \\(\\small{c}\\), y \\(\\small{ab{\\ast}}\\) representa \\(\\small{ab{\\ast}a}\\) o \\(\\small{ab{\\ast}b}\\). La correspondiente cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) tiene la matriz de probabilidad de transición \\(\\small{\\boldsymbol{M}}\\) dada por:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\n\\begin{array}{cc}&\n\\begin{array}{c}\n\\emptyset\\\\\n(0,a)\\\\\n(0,\\bar{a})\\\\\n(0,ab{\\ast})\\\\\n(0,ab{\\ast}c)\\\\\n(1,ab{\\ast}cc)\\\\\n(1,a)\\\\\n(1,\\bar{a})\\\\\n\\end{array}\n&\n\\left(\n\\begin{array}{cccccccc}\n0&p_{a}&p_{b}+p_{c}&0&0&0&0&0\\\\\n0&p_{a}&p_{c}&p_{b}&0&0&0&0\\\\\n0&p_{a}&p_{b}+p_{c}&0&0&0&0&0\\\\\n0&0&0&p_{a}+p_{b}&p_{c}&0&0&0\\\\\n0&0&0&p_{a}+p_{b}&0&p_{c}&0&0\\\\\n0&0&0&0&0&0&p_{a}&p_{b}+p_{c}\\\\\n0&0&0&0&0&0&1&0\\\\\n0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nPor lo tanto:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(X_{n}(\\Lambda)=x\\big)=\\boldsymbol{\\xi}_{0}\\boldsymbol{M}^{5}\\boldsymbol{U}(C_{x}),\\,x=0,1.\n\\end{equation}\\]\n\nObsérvese que si \\(\\small{\\{Y_t\\}}\\) está en el estado \\(\\small{(0, ab{\\ast})}\\) o \\(\\small{(0,ab{\\ast}c)}\\), significa que el patrón \\(\\small{\\Lambda_{1}=ab}\\) ha ocurrido antes o en el \\(\\small{t-}\\)ésimo ensayo. Ahora bien, si la realización de \\(\\small{X_{t+1}}\\) es \\(\\small{a}\\) o \\(\\small{b}\\) , entonces \\(\\small{Y_{t+1}}\\) tiene que estar en el estado \\(\\small{(0, ab{\\ast})}\\), suceso que ocurre con probabilidad de transición \\(\\small{p_{a}+p_{b}}\\) , y si la realización de \\(\\small{X_{t+1}}\\) es \\(\\small{c}\\), entonces \\(\\small{Y_{t+1}}\\) avanza al estado \\(\\small{(0, ab{\\ast}c)}\\) o \\(\\small{(1, ab{\\ast}cc)}\\), respectivamente, sucesos que ocurren con probabilidad de transición \\(\\small{p_{c}}\\).\nEl ejemplo anterior pone de manifiesto las diferencias entre los patrones en series y los patrones simples en lo que respecta a sus matrices de probabilidad de transición de las cadenas de Markov incrustadas. Ampliando ligeramente el espacio de estados \\(\\small{\\Omega}\\), sustituyendo \\(\\small{(i,\\bar{a}),\\, i=0,1}\\), por \\(\\small{(i,b)}\\) y \\(\\small{(i, c)}\\), y sustituyendo \\(\\small{(0, ab{\\ast})}\\) por \\(\\small{(0, ab{\\ast}a)}\\) y \\(\\small{(0, ab{\\ast}b)}\\), el ejemplo anterior puede ampliarse fácilmente al caso de ensayos de tres estados Markov-Dependientes.\n\n\n\nHallar la distribución conjunta de dos números de rachas, digamos \\(\\small{X_n(\\Lambda_{1})}\\) y \\(\\small{X_n(\\Lambda_{2})}\\) , en una secuencia de ensayos de dos o varios estados \\(\\small{\\{X_t\\}}\\) utilizando la técnica de incrustación de cadenas de Markov finitas es similar a hallar la distribución exacta de \\(\\small{X_n(\\Lambda)}\\) introducida en la Sección 4.2. En general, la cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) asociada a la distribución conjunta de \\(\\small{X_n(\\Lambda_{1})}\\) y \\(\\small{X_n(\\Lambda_{2})}\\) tiene la forma\n\n\n\\[\\begin{equation}\nY_{t}=\\big(X_{t}(\\Lambda_{1}),X_{t}(\\Lambda_{2}),E_{t}\\big),\\,t=1,2,\\ldots,n.\n\\end{equation}\\]\n\nEl espacio de estados \\(\\small{\\Omega}\\) y el bloque final \\(\\small{E_{t}}\\) para \\(\\small{\\{Y_t\\}}\\) dependen en gran medida de la estructura de los patrones \\(\\small{\\Lambda_{1}}\\) y \\(\\small{\\Lambda_{2}}\\). Las matrices de probabilidad de transición \\(\\small{\\boldsymbol{M}_{t}}\\) de la cadena de Markov inscrustada pueden construirse utilizando los mismos principios descritos en secciones anteriores. A continuación, damos un ejemplo para demostrar el procedimiento para encontrar la distribución conjunta.\nEjemplo 4.6 Sea \\(\\small{X_{n}}\\) el número total de rachas de éxito \\(\\small{X_{n}(S)}\\) y de fracaso \\(\\small{X_{n}(S)}\\) en una secuencia de \\(\\small{n}\\) ensayos de dos estados. Para cada \\(\\small{X_{n} = X_{n}(S) + X_{n}(F)}\\), y los números de rachas \\(\\small{X_{n}(S)}\\) y \\(\\small{X_{n}(F)}\\) están relacionados de la siguiente manera: si hay \\(\\small{x}\\) rachas de éxito, entonces sólo puede haber \\(\\small{x+1, x}\\), o \\(\\small{x-1}\\) rachas de fracaso. De ello se deduce que sólo puede haber cuatro tipos de estados \\(\\small{Y_{t}=(X_{t}(S), X_{t}(F), E_{t})}\\), donde el bloque final \\(\\small{E_{t}}\\) es \\(\\small{S}\\) o \\(\\small{F}\\) : (i) \\(\\small{(x, x-1, S)}\\), (ii) \\(\\small{(x, x + 1, F)}\\), (iii) \\(\\small{(x, x, S)}\\) y (iv) \\(\\small{(x, x, F)}\\).\nConsideremos los resultados de diez ensayos de dos estados \\(\\small{w = (SSFFSFSSSF)}\\). La realización de la cadena de Markov imbricada \\(\\small{\\{Y_t\\}}\\) es \\(\\small{\\{Y_{1}=(1,0, S), Y_{2}=(1,0,S), Y_{3}=(1,1,F), Y_{4}=(1,1,F), Y_{5}=(2,1,S), Y_{6}= (2,2,F),Y_{7}=(3,2,S),Y_{8}=(3,2, S),Y_{9}=(3,2,S), Y_{10} = (3,3, F)\\}}\\). El espacio de estados \\(\\small{\\Omega}\\) tiene la forma \\(\\small{\\Omega=\\{(1,0,S), (0,1,F), (1,1,S), (1,1,F),\\ldots, (l_{n},l_{n}S), (l_{n}, l_{n},F)\\}}\\), donde \\(\\small{l_{n}=[(n+1)/2]}\\). Para el caso de ensayos de dos estados independientes pero no idénticamente distribuidos, la definición de \\(\\small{Y_{t}}\\) da como resultado las matrices de probabilidad de transición, para \\(\\small{t=2,3,\\ldots,n,}\\)\n\n\n\\[\\begin{equation}\n\\boldsymbol{M_{t}}=\n\\begin{array}{cc}&\n\\begin{array}{c}\n(1,0,S)\\\\\n(0,1,S)\\\\\n(1,1,S)\\\\\n(1,1,S)\\\\\n\\cdot\\\\\n\\cdot\\\\\n\\cdot\\\\\n(l_{n},l_{n}-1,S)\\\\\n(l_{n}-1,l_{n},F)\\\\\n(l_{n},l_{n},S)\\\\\n(l_{n},l_{n},F)\\\\\n\\end{array}\n&\n\\left(\n\\begin{array}{ccccccccccc}\np_{t}&0&0&q_{t}&&&&&&&\\\\\n&q_{t}&p_{t}&0&0&&&&&&\\\\\n&&p_{t}&0&0&q_{t}&&&&&\\\\\n&&&q_{t}&p_{t}&0&0&&&&\\\\\n&&&&\\ddots&\\ddots&\\ddots&\\ddots&&&\\\\\n&&&&&\\cdot&\\cdot&\\cdot&\\cdot&&\\\\\n&&&&&&\\ddots&\\ddots&\\ddots&\\ddots&\\\\\n&&&&&&&p_{t}&0&0&q_{t}\\\\\n&&&&&&&&q_{t}&p_{t}&0\\\\\n&&&&&&&&&1&0\\\\\n&&&&&&&&&&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nDado \\(\\small{\\boldsymbol{\\xi}_{1}=(p_{1},q_{1},0,\\ldots,0)}\\) , se deduce que la distribución conjunta de \\(\\small{X_n(S)}\\) y \\(\\small{X_n(F)}\\) está dada por:\n\n\n\\[\\begin{equation}\n\\small{\\mathbb{P}\\big( X_{n}(S)=x,X_{n}(F)=y\\mid \\boldsymbol{\\xi}_{1}\\big)=\\boldsymbol{\\mathbf{\\xi}}_{1} \\Big(\\prod_{t=1}^{n}\\boldsymbol{M}_{t}\\Big)\\boldsymbol{\\mathbf{U}'}(\\mathbf{C}_{(x,y)})},\n\\end{equation}\\]\n\ndonde, si \\(\\small{y= x+1}\\), entonces \\(\\small{C_{(x,x+1)}=\\{{(x, x + 1, F)}\\}}\\), si \\(\\small{y=x-1}\\), entonces \\(\\small{C_{(x, x-1)}=\\{(x, x-1, S)\\}}\\), si \\(\\small{y=x}\\) entonces \\(\\small{C_{(x,x)}=\\{(x, x, S), (x, x, F)\\}}\\), y \\(\\small{C_{(x,y)}=\\{\\emptyset\\}}\\) en cualquier otro caso.\nUna vez más, con algunas modificaciones sencillas de las matrices de probabilidades de transición, los resultados anteriores también son válidos tanto para ensayos de dos estados i.i.d., como Markov-Dependientes homogéneos y no homogéneos. Las distribuciones marginales de \\(\\small{X_{n}(S)}\\) y \\(\\small{X_{n}(F)}\\) pueden obtenerse proyectando la distribución conjunta sobre las particiones generadas por las variables aleatorias \\(\\small{X_{n}(S)}\\) y \\(\\small{X_{n}(F)}\\), respectivamente. De forma más general, la distribución conjunta de \\(\\small{l&gt;2}\\) variables aleatorias \\(\\small{X_{n}(\\Lambda_{1}),X_{n}(\\Lambda_{2}),\\ldots,X_{n}(\\Lambda_{l})}\\) puede obtenerse del mismo modo con una cadena de Markov \\(\\small{(l+1)-}\\)dimensional \\(\\small{\\{Y_{t} = \\big(X_{t}(\\Lambda_{1}),\\cdots, X_{t}(\\Lambda_{l}), E_{t}\\big)\\}}\\).\nFin 05 de Nov\n\n\n\n\n\n\n\nAbramson, M. and Moser, W. O. J. (1967). Permutations without rising or falling w-sequences. Annals of Mathematical Statistics 38, 1245-1254.\nAki, S. (1985). Discrete distributions of order k on a binary sequence. Annals of the Institute of Statistical Mathematics 37, 205-224.\nAki, S. (1997). On sooner and later problems between success and failure runs.Advances in Combinatorial Methods and Applications to Probability and Statistics (ed. N. Balakrishnan), Birkhäuser, Boston, 385-400.\nAki, S. (1999). Distributions of runs and consecutive systems on directed trees. Annals of the Institute of Statistical Mathematics 51, 1-15.\nAki, S., Balakrishnan, N. and Mohanty, S. G. (1996). Sooner and later waiting time problems for success and failure runs in higher order Markov dependent trials. Annals of the Institute of Statistical Mathematics 48, 773-787.\nAki, S. and Hirano, K. (1988). Some characteristics of the binomial distribution of order k and related distributions. Statistical Theory and Data Analysis II (ed. K. Matusita), North-Holland, Amsterdam, 211-222.\nAki, S. and Hirano K. (1999). Sooner and later waiting time problems for runs in Markov dependent bivariate trials. Annals of the Institute of Statistical Mathematics 51, 17-29.\nAki, S. and Hirano K. (2000). Numbers of success-runs of specified length until certain stopping time rules and generalized binomial distributions of order k. Annals of the Institute of Statistical Mathematics 52, 767-777.\nAki, S., Kuboki, H. and Hirano, K. (1984). On discrete distributions of order k. Annals of the Institute of Statistical Mathematics 36, 431-440.\nAntzoulakos, D. L. (1999). On waiting time problems associated with runs in Markov dependent trials. Annals of the Institute of Statistical Mathematics 51, 323-330.\nAntzoulakos, D. L. (2001). Waiting times for patterns in a sequence of multistate trials. Journal of Applied Probability 38, 508-518.\nBalakrishnan, N. and Koutras, M. V. (2002). Runs and Scans with Applications, Wiley, New York\nBalasubramanian, K., Viveros, R. and Balakrishnan, N. (1993). Sooner and later waiting time problems for Markovian Bernoulli trials. Statistics and Prob- ability Letters 18, 153–161.}\nBarnard, G. A. (1959). Control charts and stochastic processes. Journal of the Royal Statistical Society, Series B 21, 239-271.\nBarton, D. E. and David, F. N. (1958). Non-randomness in a sequence of two alternatives: II. Runs test. Biometrika 45, 253-256.\nBateman, G. (1948). On the power function of the longest run as a test for randomness in a sequence of alternatives. Biometrika 35, 97-112.\nBoutsikas, M. V. and Koutras, M. V. (2000a). Generalized reliability bounds for coherent structures. Journal of Applied Probability 37, 778-794.\nBoutsikas, M. V. and Koutras, M. V. (2000b). Reliability approximation for Markov chain imbeddable systems. Methodology and Computing in Applied Probability 2, 393-411.\nBrook, D. and Evans, D. A. (1972). An approach to the probability distribution of cusum run length. Biometrika 59, 539-549.\nCai, J. (1994). Reliability of a large consecutive-k-out-of-r-from-n:F system with unequal component-reliability. IEEE Transactions on Reliability 43, 107– 111.\nCarlitz, L. (1964). Extended Bernoulli and Eulerian numbers. Duke Mathematical Journal 31, 667-689.\nChao, M. T. (1999). Applications of Markov chains in quality-related matters. Statistical Process Monitoring and Optimization (eds. S. H. Park and G. G. Vining), Marcel Dekker, New York, 175-188.\nChao, M. T. and Fu, J. C. (1989). A limit theorem of certain repairable systems. Annals of the Institute of Statistical Mathematics 41, 809–818.\nChao, M. T. and Fu, J. C. (1991). The reliability of large series system under a Markovian structure. Advances in Applied Probability 23, 894-908.\nChao, M. T., Fu, J. C. and Koutras, M. V. (1995). Survey of reliability stud- ies of consecutive-k-out-of-n: F and related systems. IEEE Transactions on Reliability 44, 120-127.\nChao, M. T. and Lin, G. D. (1984). Economical design of large consecutive-k- out-of-n:F systems. IEEE Transactions on Reliability 33, 411-413.\nChen, J. and Glaz, J. (1997). Approximations and inequalities for the distribution of a scan statistic for 0-1 Bernoulli trials. Advances in the Theory and Practice of Statistics (eds. N. L. Johnson and N. Balakrishnan), Wiley, New York, 285-298.\nChen, J. and Glaz, J. (1999). Approximations for the distribution and the moments of discrete scan statistics. Scan Statistics and Applications (eds. J. Glaz and N. Balakrishnan), Birkhäuser, Boston, 27-66.\nCheung, L. K. W. (2002). Statistical Pattern Recognition in Genomic DNA Sequences. Ph.D. Dissertation, Department of Statistics, University of Manitoba, Canada.\nChiang, D. T. and Niu, S. C. (1981). Reliability of consecutive-k-out-of-n:F sys- tems. IEEE Transactions on Reliability 30, 87-89.\nChrysaphinou, O. and Papastavridis, S. (1988). A limit theorem on the number of overlapping appearances of a pattern in a sequence of independent trials. Probability Theory and Related Fields 79, 129-143.\nCochran, W. G. (1938). An extension of Gold’s method for examining the apparent persistence of one type of weather. Quarterly Journal of the Royal Meteorological Society 64, 631-634.\nCsörgö, S. (1979). Erdös-Rényi laws. Annals of Statistics 7, 772-787. David, F. N. (1947). A power function for tests of randomness in a sequence of alternatives. Biometrika 34, 335-339.\nDavid, F. N. and Barton, D. E. (1962). Combinatorial Chance, Hafner, New York. Derman, G., Lieberman, G. J. and Ross, S. M. (1982). On the consecutive-k-out- of-n:F system. IEEE Transactions on Reliability 31, 57-63.\nDillon, J. F. and Roselle, D. P. (1969). Simon Newcomb’s problem. SIAM Journal on Applied Mathematics 17, 1086-1093.\nDoi, M. and Yamamoto, E. (1998). On the joint distribution of runs in a sequence of multi-state trials. Statistics and Probability Letters 39, 133-141.\nDwass, M. (1973). The number of increases in a random permutation. Journal of Combinatorial Theory, Series A 15, 192-199.\nEbneshahrashoob, M. and Sobel, M. (1990). Sooner and later problems for Bernoulli trials: frequency and run quotas. Statistics and Probability Letters 9, 5-11.\nErdös, P. and Rényi, A. (1970). On a new law of large numbers. Journal d’Analyse Mathématique 23, 103-111.\nErdös, P. and Révész, P. (1975). On the length of the longest head-run. Topics in Information Theory, Colloquia Mathematica Societatis János Bolyai, 16 (eds. I. Csiszar and P. Elias; Keszthely, Hungary), North-Holland, Amster- dam, 219-228.\nEwan, W. D. and Kemp, K. W. (1960). Sampling inspection of continuous pro- cesses with no autocorrelation between successive results. Biometrika 47, 363-380.\nFeller, W. (1968). An Introduction to Probability Theory and Its Applications (Vol. I, 3rd ed.), Wiley, New York.\nFu, J. C. (1985). Reliability of consecutive-k-out-of-n:F system. IEEE Transac- tions on Reliability 34, 127-130.\nFu, J. C. (1986). Reliability of consecutive-k-out-of-n:F systems with (k-1) step Markov dependence. IEEE Transactions on Reliability 35, 602-606.\nFu, J. C. (1995). Exact and limiting distributions of the number of successions in a random permutation. Annals of the Institute of Statistical Mathematics 47, 435-446.\nFu, J. C. (1996). Distribution theory of runs and patterns associated with a sequence of multi-state trials. Statistica Sinica 6, 957-974.\nFu, J. C. (2001). Distribution of scan statistics for a sequence of bi-state trials Journal of Applied Probability 38, 1-9.\nFu, J. C. and Chang, Y. M. (2002). On probability generating functions for wait- ing time distributions of compound patterns in a sequence of multistate trials. Journal of Applied Probability 39, 70-80.\nFu, J. C. and Hu, B. (1987). On reliability of a large consecutive-k-out-of-n:F sys- tem with k-1 step Markov dependence. IEEE Transactions on Reliability 36, 75-77.\nFu, J. C. and Koutras, M. V. (1994). Distribution theory of runs: a Markov chain approach. Journal of the American Statistical Association 89, 1050-1058.\nFu, J. C. and Lou, W. Y. W. (1991). On reliabilities of certain large linearly connected engineering systems. Statistics and Probability Letters 12, 291-296.\nFu, J. C. and Lou, W. Y. W. (2000a). On the exact distribution of SECON and its application. Statistica Sinica 10, 999-1010.\nFu, J. C. and Lou, W. Y. W. (2000b). Joint distribution of rises and falls. Annals of the Institute of Statistical Mathematics 52, 415-425.\nFu, J. C., Lou, W. Y. W., Bai, Z. D. and Li, G. (2002). The exact and limiting distributions for the number of successes in success runs within a sequence of Markov-dependent two-state trials. Annals of the Institute of Statistical Mathematics 54, 719-730.\nFu, J. C., Lou, W. Y. W. and Chen, S. C. (1999). On the probability of pattern matching in nonaligned DNA sequences: a finite Markov chain imbedding approach. Scan Statistics and Applications (eds. J. Glaz and N. Balakrish- nan), Birkhäuser, Boston, 287-302.\nFu, J. C., Lou, W. Y. W. and Wang, Y. J. (1999). On the exact distributions of Eulerian and Simon Newcomb numbers associated with random permuta- tions. Statistics and Probability Letters 42, 115–125.\nFu, J. C., Shmueli, G. and Chang, Y. M. (2002). A unified Markov chain approach for computing the run length distribution for control charts with simple or compound rules. Technical Report, Department of Statistics, University of Manitoba.\nFu, J. C., Spiring, F. A. and Xie, H. (2002). On the average run lengths of quality control schemes using a Markov chain approach. Statistics and Probability Letters 56, 369-380.\nGlaz, J. (1989). Approximations and bounds for the distribution of the scan statistic. Journal of the American Statistical Association 84, 560-566.\nGlaz, J. (1992). Approximations for tail probabilities and moments of the scan statistic. Computational Statistics and Data Analysis 14, 213-227.\nGlaz, J., Naus, J. I. and Wallenstein, S. (2001). Scan Statistics, Springer-Verlag, New York.\nGodbole, A. P. (1990). Specific formulae for some success run distributions. Statistics and Probability Letters 10, 119-124.\nGodbole, A. P. (1991). Poisson approximations for runs and patterns of rare events. Advances in Applied Probability 23, 851-865.\nGoncharov, V. L. (1944). On the field of combinatory analysis. Isvestija Akad. Nauk. SSSR. Ser. Math. 8, 3-48 (in Russian); English translation: Translations of the AMS Ser. Math. 19 (1962), 1-46.\nGoodman, L. A. (1958). Simplified runs tests and likelihood ratio tests for Markoff chains. Biometrika 45, 181-197.\nHan, Q. and Aki, S. (1998). Formulae and recursions for the joint distributions of success runs of several lengths in a two-state Markov chain. Statistics and Probability Letters 40, 203-214.\nHan, Q. and Aki, S. (2000a). Sooner and later waiting time problems based on a dependent sequence. Annals of the Institute of Statistical Mathematics 52, 407-414.\nHan, Q. and Aki, S. (2000b). Waiting time problems in a two-state Markov chain. Annals of the Institute of Statistical Mathematics 52, 778-789.\nHirano, K. (1986). Some properties of the distributions of order k. Fibonacci Numbers and Their Applications (eds. A. N. Philippou, G. E. Bergum, and A. F. Horadam), Reidel, Dordrecht, 43-53.\nHirano, K. and Aki, S. (1987). Properties of the extended distributions of order k. Statistics and Probability Letters 6, 67-69.\nHirano, K. and Aki, S. (1993). One number of occurrences of success runs of specified length in a two-state Markov chain. Statistica Sinica 3, 313-320.\nHuntington, R. J. and Naus, J. I. (1975). A simpler expression for kth nearest neighbor coincidence probabilities. Annals of Probability 3, 894-896.\nHwang, F. K. (1982). Fast solutions for consecutive-k-out-of-n:F system. IEEE Transactions on Reliability 31, 447-448.\nHwang, F. K. (1986). Simplified reliabilities for consecutive-k-out-of-n systems.SIAM Journal on Algebraic and Discrete Methods 7, 258-264.\nJackson, D. M. and Reilly, J. W. (1976). Permutations with a prescribed number of p-runs. Ars Combinatoria 1, 297-305.\nJohnson, B. C. (2001). Distribution of increasing l-sequences in a random permutation. Methodology and Computing in Applied Probability 3, 35-49.\nJohnson, B. C. (2002). The distribution of increasing 2-sequences in random per- mutations of arbitrary multi-sets. Statistics and Probability Letters 59, 67-74.\nJohnson, B. C and Fu, J. C. (2000). The distribution of increasing l-sequences in random permutations: A Markov chain approach. Statistics and Probability Letters 49, 337-344.\nKaplansky, I. (1944). Symbolic solution of certain problems in permutations. Bul- letin of the American Mathematical Society 50, 906-914.\nKarlin, S. and McGregor, J. (1959). Coincident probabilities. Pacific Journal of Mathematics 9, 1141-1164.\nKontoleon, J. M. (1980). Reliability determination of a r-successive-out-of-n:F system. IEEE Transactions on Reliability 29, 437.\nKossow, A. and Preuss, W. (1989). Reliability of consecutive-k-out-of-n:F system with nonidentical component reliabilities. IEEE Transaction on Reliability 38, 229-233.\nKoutras, M. V. (1996a). On a Markov chain approach for the study of reliability structures. Journal of Applied Probability 33, 357-367.\nKoutras, M. V. (1996b). On a waiting time distribution in a sequence of Bernoulli trials. Annals of the Institute of Statistical Mathematics 48, 789-806.\nKoutras, M. V. (1997a). Waiting time distributions associated with runs of fixed length in two-state Markov chains. Annals of the Institute of Statistical Mathematics 49, 123-139.\nKoutras, M. V. (1997b). Waiting times and number of appearances of events in a sequence of discrete random variables. Advances in Combinatorial Meth- ods and Applications to Probability and Statistics (ed. N. Balakrishnan), Birkhäuser, Boston, 363-384.\nKoutras, M. V. (2003). Applications of Markov chains to the distribution the- ory of runs and patterns. Handbook of Statistics 21: Stochastic Processes, Modeling and Simulation (eds. D. N. Shanbhag and C. R. Rao), Elsevier, Amsterdam, in press.\nKoutras, M. V. and Alexandrou, V. (1995). Runs, scans and urn model distributions: a unified Markov chain approach. Annals of the Institute of Statistical Mathematics 47, 743-766.\nKoutras, M. V. and Alexandrou, V. (1997a). Non-parametric randomness tests based on success runs of fixed length. Statistics and Probability Letters 32, 393-404.\nKoutras, M. V. and Alexandrou, V. (1997b). Sooner waiting time problems in a sequence of trinary trials. Journal of Applied Probability 34, 593–609.\nKoutras, M. V. and Papastavridis, S. G. (1993). Application of the Stein-Chen method for bounds and limit theorems in the reliability of coherent struc- tures. Naval Research Logistics 40, 617-631.\nLing, K. D. (1992). A generalization of the sooner and later waiting time problems for Bernoulli trials: frequency quota. Statistics and Probability Letters 14, 401-405.\nLing, K. D and Low, T. Y. (1993). On the soonest and the latest waiting time distributions: succession quotas. Communications in Statistics Theory and Methods 22, 2207-2221.\nLou, W. Y. W. (1996). On runs and longest run tests: method of finite Markov chain imbedding. Journal of the American Statistical Association 91, 1595– 1601.\nLou, W. Y. W. (1997). An application of the method of finite Markov chain imbedding to runs tests. Statistics and Probability Letters 31, 155–161.\nLou, W. Y. W. (2000). The exact distribution of the continuity of care measure NOP. Statistics and Probability Letters 48, 361–368.\nLou, W. Y. W. (2001). The distribution of the usual provider continuity index under Markov dependence. Statistics and Probability Letters 54, 269–276.\nLou, W. Y. W. (2003). The exact distribution of the K-tuple statistic for sequence homology. Statistics and Probability Letters 1, 51-59.\nLucas, J. M. and Crosier, R. B. (1982). Fast initial response for CUSUM quality control schemes: Give your CUSUM a head start. Technometrics 24, 199-205.\nMacMahon, P. A. (1915). Combinatory Analysis, Cambridge University Press, London.\nMohanty, S. G. (1994). Success runs of length k in Markov dependent trials. Annals of the Institute of Statistical Mathematics 46, 777-796.\nMontgomery, D. C. (2001). Introduction to Statistical Quality Control (4th ed.). Wiley, New York.\nMood, A. M. (1940). The distribution theory of runs. Annals of Mathematical Statistics 11, 367–392.\nMosteller, F. (1941). Note on an application of runs to quality control charts. Annals of Mathematical Statistics 12, 228-232.\nMuselli, M. (2000). Useful inequalities for the longest run distribution. Statistics and Probability Letters 46, 239-249.\nNagaev, S. V. (1957). Some limit theorems for stationary Markov chains. Theory of Probability and its Applications 2, 378-406.\nNaus, J. I. (1965). The distribution of the size of the maximum cluster of points on a line. Journal of the American Statistical Association 60, 532-538.\nNaus, J. I. (1974). Probabilities for a generalized birthday problem. Journal of the American Statistical Association 69, 810-815\nNaus, J. I. (1982). Approximations for distributions of scan statistics. Journal of the American Statistical Association 77, 177-183.\nNishimura, K. and Sibuya, M. (1997). Extended Stirling family of discrete probability distributions. Communications in Statistics Theory and Methods 26, 1727-1744.\nPapastavridis, S. G. (1988). A Weibull limit for the reliability of a consecutive k-within-m-out-of-n system. Advances in Applied Probability 20, 690-692.\nPapastavridis, S. G. and Koutras, M. V. (1993). Bounds for reliability of consec- utive k-within-m-out-of-n:F systems. IEEE Transactions on Reliability 42, 156-160.\nPhilippou, A. N. (1986). Distributions and Fibonacci polynomials of order k, longest runs, and reliability of consecutive-k-out-of-n:F systems. Fibonacci Numbers and Their Applications (eds. A. N. Philippou, G. E. Bergum and A. F. Horadam), Reidel, Dordrecht, 203-227.\nPhilippou, A. N., Georghiou, C. and Philippou, G. N. (1983). A generalized geometric distribution and some of its properties. Statistics and Probability Letters 1, 171–175.\nPhilippou, A. N. and Makri, F. S. (1986). Success runs and longest runs. Statistics and Probability Letters 4, 211–215.\nPyke, R. (1961). Markov renewal processes: definitions and preliminary proper- ties. Annals of Mathematical Statistics 32, 1231-1242.\nReilly, J. W. and Tanny, S. M. (1979). Counting successions in permutations. Studies in Applied Mathematics 61, 73-81.\nRényi, A (1970). Probability Theory, American Elsevier Publishing Company Inc., New York.\nRiordan, J. (1958). An Introduction to Combinatorial Analysis, Wiley, New York.\nRoselle, D. P. (1968). Permutations by number of rises and successions. Proceed- ings of the American Mathematical Society 19, 8-16. Ross, S. M. (2000). Introduction to Probability Models (7th ed.), Academic Press, San Diego.\nRubin, G., McCulloch, C. E. and Shapiro, M. A. (1990). Multinomial runs tests to detect clustering in constrained free recall. Journal of the American Sta- tistical Association 85, 315-320.\nSaperstein, B. (1972). The generalized birthday problem. Journal of the American Statistical Association 67, 425-428.\nSchilling, M. F. (1990). The longest run of heads. The College Mathematics Jour- nal 21, 196-207.\nSeneta, E. (1981). Non-negative Matrices and Markov Chains (2nd ed.), Springer- Verlag, New York.\nSheng, K. N. and Naus, J. I. (1994). Pattern matching between two non-aligned random sequences. Bulletin of Mathematical Biology 56, 1143-1162.\nSteinwachs, D. M. (1979). Measuring provider continuity in ambulatory care. Medical Care 17, 551-565.\nSwed, F. S. and Eisenhart, C. (1943). Tables for testing randomness of grouping in a sequence of alternatives. Annals of Mathematical Statistics 14, 66-87.\nTanny, S. (1973). A probabilistic interpretation of Eulerian numbers. Duke Math- ematical Journal 40, 717-722.\nTanny, S. M. (1976). Permutations and successions. Journal of Combinatorial Theory, Series A 21, 196-202.\nVaggelatou, E. (2003). On the length of the longest run in a multi-state Markov chain. Statistics and Probability Letters 62, 211–221.\nUchida, M. and Aki, S. (1995). Sooner and later waiting time problems in a two- state Markov chain. Annals of the Institute of Statistical Mathematics 47, 415-433\nWald, A. and Wolfowitz, J. (1940). On a test whether two samples are from the same population. Annals of Mathematical Statistics 11, 147-162.\nWigle, D. T. (1982). Prevalence of selected chronic diseases in Canada, 1978-1979. Chronic Disease in Canada 3, 9.\nWishart, J. and Hirshfeld, H. O. (1936). A theorem concerning the distribution of joins between line segments. Journal of the London Mathematical Society 11, 227-235.\nWolfowitz, J. (1943). On the theory of runs with some applications to quality control. Annals of Mathematical Statistics 14, 280-288.\nWorpitzky, J. (1883). Studien über die Bernoullischen und Eulerschen Zahlen. Journal für die reine und angewandte Mathematik 94, 203-232.",
    "crumbs": [
      "Trabajo Grado"
    ]
  },
  {
    "objectID": "Trabajo_Grado.html#teoría-de-distribución-de-rachas-y-patrones-y-sus-aplicaciones.-un-enfoque-de-incrustación-de-cadenas-de-markov-finitas.",
    "href": "Trabajo_Grado.html#teoría-de-distribución-de-rachas-y-patrones-y-sus-aplicaciones.-un-enfoque-de-incrustación-de-cadenas-de-markov-finitas.",
    "title": "Vladimir Sanchez Tenjo",
    "section": "",
    "text": "El propósito de este libro es ofrecer una introducción rigurosa y exhaustiva a la técnica de Incrustación de Cadenas de Markov Finitas (ICMF) para estudiar las distribuciones de Rachas y Patrones desde un punto de vista unificado e intuitivo, alejado de las líneas tradicionales de la combinatoria. A lo largo de las dos últimas décadas, se han obtenido mediante este enfoque un número considerable de nuevos resultados relacionados con las distribuciones de rachas y patrones.\n\n\nEl tema central de la Incrustación de Cadenas de Markov Finitas (ICMF), como su nombre indica, es incrustar adecuadamente las variables aleatorias de interés en el marco de una cadena de Markov finita, y las representaciones resultantes de las distribuciones subyacentes son compactas y muy susceptibles de un estudio más profundo de las propiedades asociadas. En este libro, el concepto de ICMF se desarrolla sistemáticamente y se ilustra su utilidad mediante aplicaciones prácticas a diversos campos, como la fiabilidad de los sistemas de ingeniería, la comprobación de hipótesis, el control de calidad y la medición de la continuidad en el sector sanitario.\n\n\nEste libro está restringido a espacios muestrales discretos, una restricción que sirve para que este trabajo sea accesible a una audiencia más amplia al simplificar los resultados teóricos y sus aplicaciones. Las rachas y patrones considerados aquí se definen en gran medida en sucesiones de ensayos Markov-Dependientes de dos o múltiples estados, con aplicaciones prácticas en mente; los definidos sobre permutaciones aleatorias de números enteros, como los números de Eulerian y Simon Newcomb, también se tratan utilizando un procedimiento de inserción adicional. El contenido de este libro está orientado principalmente a los investigadores que utilizan la teoría de la distribución de rachas y patrones en diversos ámbitos aplicados de la estadística, la probabilidad y la combinatoria, pero también podría servir de base de un curso de temas especiales de un semestre de duración en cuarto curso de licenciatura o a nivel de primer año de posgrado.\n\n\n\nDeseamos agradecer la ayuda de Y. M. Chang y B. C. Johnson en la corrección de los primeros borradores del libro, así como el aliento de nuestros colegas de la Universidad de Manitoba y la Universidad de Toronto.\n\n\nTambién estamos en deuda con nuestras familias por su inagotable apoyo. Por último, queremos agradecer a la Sra. E. H. Chionh, de World Scientific Publishing Co. por su paciencia y apoyo administrativo.\n\n\n\n\nLa ocurrencia de rachas y patrones en una sucesión de resultados de ensayos discretos o permutaciones aleatorias es un concepto importante en diversas áreas de la ciencia, como la ingeniería de confiabilidad, el control de calidad, la psicología, la sociología, la comparación de secuencias de ADN y la comprobación de hipótesis. Resultados de las distribuciones de probabilidad de rachas y patrones elementales se obtuvieron esporádicamente en la literatura hasta aproximadamente la década de 1940, cuando se publicaron una serie de estudios pioneros sobre rachas y patrones más complejos: por ejemplo, Wishart e Hirshfeld (1936), Cochran (1938), Mood (1940), Wald y Wolfowitz (1940), Mosteller (1941) y Wolfowitz (1943). La mayoría de estos estudios se centraron en hallar la distribución condicional de las rachas de éxito dado el número total de éxitos en una sucesión de ensayos de dos estados. Un libro reciente reciente de Balakrishnan y Koutras (2002), ofrece una buena revisión exhaustiva de los avances históricos y actuales en la teoría de la distribución de rachas y las estadísticas de escaneo.\nTradicionalmente, las distribuciones de rachas y patrones se estudiaban mediante análisis combinatorio. Por ejemplo, Mood (1940) escribió: “El problema de la distribución es, por supuesto, combinatorio, y todo el desarrollo depende de algunas identidades del análisis combinatorio”. Sin embargo, encontrar las identidades combinatorias apropiadas para derivar las distribuciones de probabilidad puede ser difícil, si no imposible, para rachas y patrones complejos, y quizá sea ésta la razón por la que las distribuciones exactas de muchos estadísticos comunes definidos en rachas y patrones siguen siendo desconocidas. Además las identidades requeridas a menudo difieren incluso para rachas y patrones similares, y por lo tanto, incluso en el caso más sencillo de ensayos independientes e idénticamente distribuidas (i.i.d.) de dos estados (los llamados “ensayos de Bernoulli”), cada nuevo problema de distribución generalmente tiene que estudiarse caso por caso utilizando el enfoque combinatorio. Por ejemplo, sólo hace relativamente poco tiempo Philippou y Makri (1986) e Hirano (1986), de forma independiente y mediante análisis combinatorio, obtuvieron la distribución exacta de la estadística de racha tradicional \\(\\small{N_{n,k}}\\), del número de rachas de \\(k\\) éxitos consecutivos no-solapados en una secuencia de \\(n\\) ensayos Bernoulli:\n\n\n\\[\\begin{equation}\n\\mathbb{P}(N_{n,k}=x)=\\sum_{m=0}^{k-1}\\sum_{x_1+x_2+\\cdots+\\\\\nkx_k=n-m-km}\\binom{x_1+x_2+\\cdots+x_k+x}{x_1,x_2,\\cdots,x_k,x}p^n\\Big(\\frac{q}{p}\\Big)^{x_1+x_2+\\cdots+x_k}\n\\end{equation}\\]\n\npara \\(x=0,1,\\ldots,[n/k]\\), con probabilidades de éxito y fracaso denotadas por \\(p\\) y \\(q=1-p\\), respectivamente. Otro método para determinar una distribución de probabilidad exacta consiste en derivar la función generadora \\(\\small{\\varphi(s)}\\) para la variable aleatoria entera no negativa \\(\\small{X_n(\\Lambda)}\\) asociada con el patrón \\(\\small{\\Lambda}\\) (por ejemplo, \\(\\small{X_n(\\Lambda)}\\) podría ser el número de apariciones del patrón \\(\\small{\\Lambda}\\) en \\(n\\) ensayos) y, a continuación, diferenciar \\(\\small{\\varphi(s)}\\) \\(x\\) veces para obtener la función de distribución de probabilidad (fdp) dada por \\(\\small{\\mathbb{P}(X_n(\\Lambda) = x)}\\) este enfoque fue introducido por Feller (1968) utilizando la teoría de los sucesos recurrentes. Por ejemplo, para la función generadora del tiempo de espera \\(\\small{W(\\Lambda)}\\), el número de ensayos Bernoulli hasta la primera aparición del patrón \\(\\small{\\Lambda}\\) consistente en \\(k\\) éxitos consecutivos, fue dada por Feller como:\n\n\n\\[\\begin{equation}\n\\varphi_{W}(s)=\\frac{p^ks^k(1-ps)}{1-s+qp^ks^{k+1}}\n\\end{equation}\\]\n\nPara rachas y patrones más complejos, las funciones generadoras pueden ser difíciles de diferenciar un gran número de veces y es posible que sea necesario emplear técnicas de aproximación. Feller utilizó el método de expansión de fracciones parciales, que puede requerir métodos numéricos eficientes para calcular raíces de polinomios. A traves del libro estudiaremos problemas de distribución de rachas y patrones desde un punto de vista, en nuestra opinión, más unificado e intuitivo, alejado de las líneas de la combinatoria tradicional. El enfoque adoptado consiste en incrustar adecuadamente la variable aleatoria \\(\\small{X_n(\\Lambda)}\\) en una cadena de Markov finita \\(\\small{\\{Y_t\\}}\\), de modo que la probabilidad de \\(\\small{X_n(\\Lambda)}=x\\) pueda expresarse en términos de la probabilidad de que el estado de la cadena de Markov al momento \\(\\small{n}\\), \\(\\small{Y_n}\\), se encuentre en un subconjunto \\(\\small{C_x}\\) del espacio de estados, es decir:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\{X_n(\\Lambda)=x\\}=\\mathbb{P}(Y_n \\in C_x)\n\\end{equation}\\]\n\ndonde la probabilidad del lado derecho se puede calcular fácilmente mediante las matrices de probabilidad de transición de la cadena de Markov. Esta representación de la distribución subyacente de \\(\\small{X_n(\\Lambda)}\\) es compacta, fácil de calcular y bastante susceptible de análisis posteriores. El método depende en gran medida de la capacidad de construir una cadena de Markov adecuada asociada con la variable aleatoria \\(\\small{X_n(\\Lambda)}\\), pero una vez construida la cadena, la linealidad de la cadena de Markov reduce la complejidad computacional a menudo asociada con técnicas combinatorias y de funciones generadoras para calcular los fdp’s exactas de rachas y patrones.\nLos primeros resultados de la teoría de la distribución de rachas y patrones se derivaron casi exclusivamente bajo el supuesto de ensayos Bernoulli o ensayos i.i.d. multiestados. Una gran ventaja de la técnica de incrustación de cadenas finitas de Markov es que se puede aplicar no sólo a casos de ensayos i.i.d. , también para ensayos multiestado Markov-dependientes, eso si, con poco esfuerzo adicional. Independientemente de los procedimientos de conteo especificados para patrones superpuestos (conteo superpuesto versus no superpuesto); también se puede extender a varios tipos de rachas y patrones en permutaciones aleatorias. Recientemente, este método ha sido adoptado por varios investigadores para estudiar diversas distribuciones de rachas y patrones: por ejemplo, Antzoulakos (1999, 2001), Boutsikas y Koutras (2000a,b), Doi y Yamamoto (1998), Fu (1985, 1986, 1996), Pu y Koutras (1994), Fu y Lou (2000a,b), Han y Aki (2000a,b), Johnson (2002), Koutras (1996a,b, 1997a,b, 2003), Koutras y Alexandrou (1995), Lou (1996, 2000, 2001) y Nishimura y Sibuya (1997). Tocaremos algunos de estos trabajos recientes, pero nuestras formulaciones correspondientes pueden diferir ligeramente para tratar todos los problemas utilizando un enfoque de incrustación común.\nEste libro no es una revisión de la teoría de rachas y patrones, ni pretende ser utilizado principalmente como un libro de texto de curso; está dirigido principalmente a investigadores en estadística aplicada y probabilidad que estén interesados en utilizar la técnica de incrustación de cadenas finitas de Markov para estudiar las distribuciones de rachas y patrones que surgen en aplicaciones específicas. El contenido del libro se basa en gran medida en desarrollos recientes en esta área, pero se presenta de una manera que no requiere conocimiento de conceptos avanzados en matemáticas o probabilidad; Se supone que se tiene experiencia en teoría de la probabilidad, al nivel de, por ejemplo, el libro de Feller (1968) “Una introducción a la teoría de la probabilidad y sus aplicaciones, Volumen I”. El libro está organizado como sigue. En el Capítulo 2, presentamos las ideas y técnicas básicas de incrustación de cadenas finitas de Markov. Este capítulo sienta las bases para calcular los fdp’s de rachas y patrones, incluidas las distribuciones de tiempo de espera. El Capítulo 3 examina las distribuciones de rachas y patrones asociados con los ensayos de dos estados, y en el Capítulo 4, se trata la extensión a los ensayos de múltiples estados a través del principio de avance y retroceso. El Capítulo 5 estudia principalmente las distribuciones de tiempo de espera de patrones simples y compuestos, así como sus funciones generadoras y aproximaciones de grandes desviaciones. En el Capítulo 6, la técnica de incrustación de cadenas finitas de Markov se extiende al estudio de distribuciones de patrones en permutaciones aleatorias de números enteros, centrándose en detalle en los números de Euler y Simon Newcomb. El Capítulo 7 cubre varias aplicaciones de la teoría de la distribución de rachas y patrones en las áreas de confiabilidad de sistemas de ingeniería, pruebas de hipótesis, medición de continuidad en atención médica y control de calidad.\n\n\n\n\n\nSea \\(\\small{\\Omega=\\{1,2,\\ldots,m\\}}\\quad(m&lt;\\infty)\\) un espacio de estados finito, y \\(\\small{\\mathcal{Y_t}=\\{Y_0,Y_1,\\ldots,Y_t,\\ldots\\}}\\) una familia de variables aleatorias definidas sobre \\(\\small{\\Omega}\\).(proceso estocástico).\nDefinición 2.1 Decimos que la familia/colección de variables aleatorias \\(\\small{\\{\\mathcal{Y_t}\\}}\\) es cadena de Markov si, para toda sucesión \\(\\small{\\{Y_0=i_0,Y_1=i_1,\\ldots,Y_{t-1}=i_{t-1},Y_t=i_t\\}},\\) con \\(\\small{t\\in \\{1,2,\\cdots\\}}\\), se tiene que:\n\n\n\\[\\begin{equation}\n\\mathbb{P}(Y_t=i_t \\mid Y_{t-1}=i_{t-1},\\ldots,Y_0=i_0)=\\mathbb{P}(Y_t=i_t \\mid Y_{t-1}=i_{t-1})\n\\end{equation}\\]\n\nEn otras palabras, la sucesión de variables aleatorias es una cadena de Markov si la probabilidad de que el sistema entre en el estado \\(\\small{i_t}\\) en el momento \\(\\small{t}\\) depende sólo del estado inmediatamente anterior \\(\\small{i_{t-i}}\\) en el momento \\(\\small{t-1}\\). O más sucintamente, visto desde el estado en el momento \\(\\small{t- 1}\\), el futuro es independiente del pasado. Las probabilidades condicionales.\n\n\n\\[\\begin{equation}\n\\mathbb{P}(Y_t=j \\mid Y_{t-1}=i)\\equiv p_{ij}\n\\end{equation}\\]\n\n\\(\\small{i,j \\in \\Omega}\\), se denominan probabilidades de transición de un paso para el sistema en el momento \\(t\\). Las probabilidades de transición \\(\\small{p_{ij}(t), 1 \\leq i,j \\leq m}\\), pueden representarse como una matriz \\(m\\times m\\)\n\n\n\\[\\begin{equation}\n\\boldsymbol{M_t}=(p_{ij(t)})=\\begin{pmatrix}\np_{11}(t) & p_{12}(t) & \\cdots & p_{1m}(t)\\\\\np_{21}(t) & p_{22}(t) & \\cdots & p_{2m}(t)\\\\\n\\vdots & \\ddots & \\ddots & \\cdots\\\\\np_{m1}(t) &p_{m2}(t) & \\cdots & p_{mm}(t)\\\\\n\\end{pmatrix}_{m\\times m}\n\\end{equation}\\]\n\nLas matrices \\(\\small{\\boldsymbol{M_t},\\,\\, t=1,2,\\ldots,}\\) son llamadas matrices de probabilidades de transición de un paso o simplemente matrices de transición de un paso.\nProposición. La matriz de probabilidades de transición \\(\\small{\\boldsymbol{M_t}=(p_{ij}(t))}\\) cumplen las siguientes propiedades, para cada tiempo \\(\\small{t}\\):\n\n\\(\\small{(p_{ij(t)}) \\geq 0}\\) para todo \\(\\small{t}\\).\n\\(\\small{\\displaystyle\\sum_{j}p_{ij}=1}\\), es decir, en cada momento del tiempo \\(\\small{t}\\), el proceso cambia de estado (puede ser permanecer en el mismo estado) con probabibilidad \\(\\small{1}\\).\n\nDefinición 2.2: Una cadena de Markov \\(\\small{\\{Y_0,Y_1,\\dots\\}}\\), es homogenea si las probabilidades de transición son constantes en el tiempo, i.e \\(\\small{\\mathbb{P}(Y_t=j \\mid Y_{t-1}=i)}=p_{ij}\\) para todo par \\(\\small{(i,j)\\in \\Omega \\times \\Omega=\\Omega^2}\\) y todo \\(\\small{t=1,2,\\ldots}\\)\nEsta definición equivale a decir que las matrices de probabilidad de transición de una cadena de Markov homogénea pueden representarse mediante la única matriz:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M=M_t}=(p_{ij}(t)), \\quad \\text{para todo } t=1,2,\\ldots\n\\end{equation}\\]\n\nen donde las probabilidades de transición \\(\\small{p_{ij}}\\) son independientes del índice del tiempo \\(\\small{t}\\).\nEl conjunto de probabilidades en el momento \\(\\small{0}\\), denotada como \\(\\small{\\mathbb{P}(Y_0 = i)}\\) para \\(i = 1,\\ldots,m\\) se conoce como la distribución inicial de la cadena de Markov. Dada una distribución de probablidad inicial y las probabilidades de transición de una cadena de Markov, la distribución conjunta de la cadena se puede calcular de la siguiente manera:\n\n\n\\[\\begin{equation}\n\\begin{split}\n\\mathbb{P}(Y_n=i_n,\\ldots,Y_1=i_1,Y_0=i_0) = &  \\mathbb{P}(Y_n=i_n \\mid Y_{n-1}=i_{n-1})\\cdots \\\\\n& \\cdots \\mathbb{P}(Y_1=i_1 \\mid Y_0=i_0)\\mathbb{P}(Y_{0}=i_{0}).\n\\end{split}\n\\end{equation}\\]\n\nLas cadenas de Markov se han utilizado en el modelado de una gran cantidad de aplicaciones. Aquí damos dos ejemplos simples que se ven a menudo en la teoría de probabilidad aplicada:\nEjemplo 2.1 (El problema de la ruina del jugador). Considere un jugador que gana y pierde un dólar con probabilidades \\(p\\) y \\(q = 1-p\\), respectivamente. Supongamos que el jugador tiene un capital inicial de \\(\\small{a}\\) dólares. El jugador deja de jugar cuando se queda sin capital (“arruinado”) o cuando alcanza una fortuna de \\(\\small{a + b}\\) dólares (con ganancia neta \\(\\small{b &gt; 0}\\)).\nLa sucesión del monto de capital del jugador, \\(\\small{\\{Y_t: t = 0,1,2, \\ldots\\}}\\), forma una cadena de Markov homogénea con espacio de estados \\(\\small{\\Omega= \\{0,1, 2, \\ldots, a-1,a,a + 1,\\ldots, a + b}\\}\\) y las siguientes probabilidades de transición:\n\n\n\\[\\begin{equation}\np_{ij}=\\begin{cases}\np\\quad \\text{si } j=i+1\\\\\nq\\quad \\text{si } j=i-1\n\\end{cases}\n\\end{equation}\\]\n\npara \\(\\small{i=1,2,\\ldots,a+b-1,\\, p_{00}=p_{a+b,a+b}=1}\\) y cero en cualquier otro caso. Los estados \\(\\small{0}\\) y \\(\\small{a+b}\\) se denominan absorbentes, ya que, una vez alcanzados nunca se sale de estos. La Cadena de Markov tine la matriz de problabilidades de transición:\n\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\\begin{array}{cc} &\n\\begin{array}{cccccccc}\n\\end{array}\n\\\\\n\\begin{array}{ccc}\n0 \\\\\n1 \\\\\n\\vdots\\\\\n\\cdot \\\\\na-1 \\\\\na\\\\\na+1\\\\\n\\vdots\\\\\na+b\n\\end{array}\n&\n\\left(\n\\begin{array}{cccccccc}\n1 & 0 & 0 & 0 &  &  &   &   \\\\\nq & 0 & p & 0 &  &  &   &  \\\\\n& \\ddots & \\ddots & \\ddots &   &   &\\boldsymbol{0}   &  \\\\\n&  &  \\ddots & \\ddots & \\ddots &   &   &   \\\\\n&  &   &  q & 0& p &  &   \\\\\n& \\boldsymbol{0} &  &   &   \\ddots & \\ddots & \\ddots & \\\\\n&  &  &  &  & q & 0 & p \\\\\n&  &  &  &  & 0 & 0 & 1 \\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nen donde \\({\\mathbf{0}}\\) representa un matriz de ceros y la cadena tiene distribución de probabilidad inicial \\(\\small{\\mathbb{P}(Y_0=a)=1}\\).\nEjemplo 2.2 (Modelo de Urnas). Considere una sucesión de ensayos independientes, cada uno de los cuales consiste en insertar una bola al azar en una de \\(\\small{k}\\) urnas. Decimos que el sistema \\(\\small{\\{Y_t : t = 0,1,\\ldots\\}}\\) está en estado \\(\\small{i}\\), si exactamente \\(\\small{i}\\) urnas están ocupadas. Este sistema forma una cadena de Markov en el espacio de estados \\(\\small{\\Omega = \\{0,1,\\ldots, k\\}}\\) con probabilidades de transición\n\n\n\\[\\begin{equation}\np_{ij}=\\begin{cases}\n\\frac{i}{k}  \\quad\\quad  \\text{si } j=i\\\\\n\\frac{k-i}{k}\\quad \\text{ si } j=i+1\\\\\n0 \\quad \\quad \\text{en otro caso}\n\\end{cases}\n\\end{equation}\\]\n\npara \\(\\small{i=0,1,\\ldots,k}\\) y distribución de probabilidad inicial \\(\\small{\\mathbb{P}(Y_0=0)=1}\\). La matriz de probabilidades de transición esta dada por: \n\n\\[\\begin{equation}\n\\boldsymbol{M}=\\begin{array}{cc} &\n\\begin{array}{ccccccc}\n\\end{array}\n\\\\\n\\begin{array}{ccc}\n0 \\\\\n1 \\\\\n\\\\\n\\vdots\\\\\ni\\\\\n\\vdots\\\\\nk-1\\\\\nk\n\\end{array}\n&\n\\left(\n\\begin{array}{ccccccc}\n0 & 1 & 0 &   &  &  &     \\\\\n0 & \\frac{1}{k} & \\frac{k-1}{k}  & 0 &  & \\boldsymbol{0} &      \\\\\n&  & \\ddots & \\ddots &   &   &      \\\\\n&  &        & \\frac{i}{k} & \\frac{k-i}{k} &   &       \\\\\n&   &   &  & \\ddots& \\ddots &    \\\\\n&   & \\boldsymbol{0} &   &   & \\frac{k-1}{k} & \\frac{1}{k}  \\\\\n&   &  &   &   & 0 & 1\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nSe pueden encontrar más ejemplos de este tipo en Feller (1968) y Ross (2000). Por supuesto, también habrá muchos más ejemplos de cadenas de Markov en secciones posteriores de este libro.\n\n\n\nPara una cadena de Markov no homogénea \\(\\small{\\{Y_t\\}}\\), las probabilidades de transición de \\(\\small{n}\\) pasos \\(\\small{\\mathbb{P}(Y_t= j \\mid Y_{t-n} = i) = p_{ij}^{(n)}(t)}\\) se pueden obtener a partir de las probabilidades de transición de un paso por una identidad importante conocida como Ecuación de Chapman-Kolmogorov. Si \\(\\small{n = 2}\\), tenemos, para \\(\\small{t \\geq 2}\\),\n\n\n\\[\\begin{equation}\np_{ij}^{(2)}(t) = \\sum_{k\\in \\Omega}\\mathbb{P}(Y_{t-1}=k \\mid  Y_{t-2}=i)\\mathbb{P}(Y_{t}=j \\mid  Y_{t-1}=k)=\\sum_{k\\in \\Omega} p_{ik}(t-1)^{}p_{kj}^{}(t)\n\\end{equation}\\]\n\nque corresponde a sumar todos los posibles \\(\\small{k}\\) estados intermedios en la transición del estado \\(\\small{i}\\) al estado \\(\\small{j}\\).\nSi \\(\\small{\\{Y_t\\}}\\) es una cadena de Markov homogénea, entonces la ecuación anterior (2.4) genera las probabilidades de transición de dos pasos \\(\\small{(n = 2)}\\)\n\n\n\\[\\begin{equation}\np_{ij}^{(2)} = \\sum_{ k \\in \\Omega}\\mathbb{P}(Y_{t-1}=k  \\mid  Y_{t-2}=i)\\mathbb{P}(Y_{t}=j \\mid  Y_{t-1}=k)=\\sum_{k\\in \\Omega} p_{ik}p_{kj}\n\\end{equation}\\]\n\nlas cuales son independientes de \\(\\small{t}\\). Por lo tanto, de la ecuación (2.5), la matriz de probabilidades de transición de dos pasos \\(\\small{\\boldsymbol{M}^{(2)} = (p_{ij}^{(2)})}\\) satisface la identidad \\(\\small{\\boldsymbol{M}^{(2)}= \\boldsymbol{M}^2}\\). De manera analoga, para las probabilidades de transición de \\(\\small{n}\\) pasos de una cadena de Markov homogénea, la identidad de Chapman-Kolmogorov:\n\n\n\\[\\begin{equation}\np_{ij}^{(n)} = \\sum_{k \\in \\Omega} p_{ik}^{(s)}p_{kj}^{(n-s)}\n\\end{equation}\\]\n\nse mantiene para cada paso intermedio \\(\\small{s = 1,\\ldots, n -1}\\). Se deduce de las ecuaciones. (2.5) y arterior-(2.6) que\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}^{(n)}= \\boldsymbol{M}^{(s)}\\boldsymbol{M}^{(n-s)}=\\boldsymbol{M}^{n}\n\\end{equation}\\]\n\nPara una cadena de Markov homogénea \\(\\small{\\{Y_t\\}}\\), y cualquier subconjunto \\(\\small{{C}}\\) del espacio de estados \\(\\small{\\Omega}\\), se deduce de la Ec.(2.7) que la probabilidad condicional del sistema \\(\\small{Y_n}\\) resida en \\(\\small{{C}}\\) en el índice de tiempo \\(\\small{n}\\), dada la distribución de probabilidad inicial \\(\\small{\\boldsymbol{\\mathbf{\\xi}}_0 = \\big(\\mathbb{P}(Y_0 = 1), \\cdots,P(Y_0 = m)\\big)}\\) es:\n\n\n\\[\\begin{equation}\n\\mathbb{P}(Y_n \\in {C} \\mid \\boldsymbol{\\mathbf{\\xi}}_0)=\\boldsymbol{\\mathbf{\\xi}}_0 \\boldsymbol{M}^{n}\\boldsymbol{\\mathbf{U}'}({C})\n\\end{equation}\\]\n\nen donde \\(\\small{\\boldsymbol{\\mathbf{U}'}({C})}\\) es la traspuesta de \\(\\small{\\boldsymbol{\\mathbf{U}}({C})}\\), con \\(\\small{\\boldsymbol{\\mathbf{U}}( {C})=\\displaystyle\\sum_{i \\in C}e_i}\\) y \\(\\small{\\boldsymbol{e}_i=(0,\\ldots,1,\\ldots,0)_{1\\times m}}\\) es un vector canónico con un \\(\\small{1}\\) correspondiente al \\(i\\)-ésimo estado y cero en los otros. De manera más general, si \\(\\small{\\{Y_t\\}}\\) es una cadena de Markov no homogénea, se puede demostrar (ver, Feller 1968) que la probabilidad condicional de \\(\\small{Y_n \\in {C} }\\) dado \\(\\small{\\boldsymbol{\\xi}_0}\\) se puede expresar simplemente como\n\n\n\\[\\begin{equation}\n\\mathbb{P}(Y_n \\in  {C} \\mid \\boldsymbol{\\mathbf{\\xi}}_0)=\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\prod_{t=1}^{n}\\boldsymbol{M_t}\\Big)\\boldsymbol{\\mathbf{U}'}({C})\n\\end{equation}\\]\n\nLas ecuaciones (2.8) y (2.9) son dos herramientas indispensables para evaluar las probabilidades de diversos eventos asociados con cadenas de Markov homogéneas y no homogéneas, respectivamente.\n\n\n\nCon el fin de ampliar las posibles aplicaciones, es útil considerar una extensión simple de la metodología anterior a cadenas de Markov definidas en espacios de estados de diferentes tamaños. Sea \\(\\small\\{Y_t\\}\\) una sucesión de variables aleatorias definidas en una familia de espacios de estados \\(\\small{\\{\\Omega_t\\}}\\), respectivamente. La sucesión \\(\\small{\\{Y_t\\}}\\) se denomina cadena de Markov con estructura de árbol si \\(\\small{\\{Y_t\\}}\\) es una cadena de Markov con matrices de transición\n\n\n\\[\\begin{equation}\n\\boldsymbol{M_t}=(p_{ij}(t)), \\quad \\text{para todo } t=1,2,\\ldots,\n\\end{equation}\\]\n\nen donde, para cada \\(\\small{i \\in {\\Omega}_{t-1}}\\) y \\(\\small{j \\in {\\Omega}_{t}}\\)\n\n\n\\[\\begin{equation}\np_{ij}(t)=\\mathbb{P}(Y_t=j\\mid Y_{t-1}=i).\n\\end{equation}\\]\n\nObsérvese que los espacios de estados de la colección \\(\\small{\\{\\Omega_t\\}}\\) pueden tener tamaños diferentes, las matrices de transición \\(\\small{\\boldsymbol{M_t}}\\) pueden ser rectangulares en lugar de cuadradas; es decir, \\(\\small{\\boldsymbol{M_t},\\, t = 1, 2, \\ldots,}\\) son matrices de orden \\(\\small{\\text{card}(\\Omega_{t-1}) \\times \\text{card}(\\Omega_{t})}\\), donde \\(\\small{\\text{card}(\\Omega)}\\) representa el número cardinal del espacio de estados \\(\\small{\\Omega}\\). La sucesión de matrices de probabilidad de transición \\(\\small{\\{\\boldsymbol{M_t}}\\}\\) sigue determinando la cadena de Markov \\(\\small\\{{Y_t}\\}\\) estructurada en árbol, y la ecuación de Chapman-Kolmogorov sigue siendo aplicable.\nPara cualquier subconjunto \\(\\small{ {C}\\subseteq \\Omega_n}\\), la probabilidad condicional de \\(\\small{Y_n\\in {C}}\\) dada la distribución de probabilidad inicial \\(\\small{\\boldsymbol{\\xi}_0}\\), puede calcularse vía:\n\n\n\\[\\begin{equation}\n\\mathbb{P}(Y_n \\in {C} \\mid \\boldsymbol{\\mathbf{\\xi}}_0)=\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\prod_{t=1}^{n}\\boldsymbol{M_t}\\Big)\\boldsymbol{\\mathbf{U}'}_{n}({C})\n\\end{equation}\\]\n\nsiendo \\(\\small{\\boldsymbol{\\mathbf{U}}_{n}({C})=\\displaystyle\\sum_{i \\in C}\\boldsymbol{e}_i}\\) y \\(\\small{\\boldsymbol{e}_i=(0,\\ldots,1,\\ldots,0)_{1\\times card(\\Omega_n)}}\\) es un vector unitario de tamaño \\(\\small{1\\times card(\\Omega_n)}\\) con un \\(\\small{1}\\) asociado al \\(i\\)-ésimo estado. Si todo los espacios de estados son iguales \\(\\small{(\\Omega_1=\\cdots=\\Omega_n)}\\),entonces la Eq. (2.10) se reduce a Eq. (2.9).\n\n\n\nTradicionalmente, dentro de una sucesión de ensayos Bernoulli (i.i.d. éxito-fracaso), una racha denota una sucesión de éxitos o fracasos consecutivos. Por ejemplo una racha de éxitos de tamaño 4 implica el patrón \\(\\small{SSSS}\\). Varias de las estadísticas de rachas que se utilizan a menudo en estadística y probabilidad aplicada para una sucesión de \\(n\\) ensayos Bernoulli son:\n(i) \\(\\small{N_{n,k}}\\) el número rachas de \\(\\small{k}\\) éxitos consecutivos no solapados, en el sentido del conteo de Feller (1968);\n(ii) \\(\\small{M_{n,k}}\\) el número de rachas de \\(\\small{k}\\) éxitos consecutivos solapados;\n(iii) \\(\\small{E_{n,k}}\\) el número de rachas de éxitos de tamaño exactamente igual a \\(\\small{k}\\), en el sentido del conteo de Mood (1940);\n(iv) \\(\\small{G_{n,k}}\\) el número de rachas de éxitos de tamaño mayor o igual que \\(\\small{k}\\) ;\n(v) \\(\\small{L_{n}(S)}\\) el tamaño de la racha de éxitos más larga.\nQuizás la forma más sencilla de comprender las definiciones dadas de estas estadísticas de rachas y el procedimiento de conteo de solapado/no solapado, sea mediante el siguiente ejemplo. Supongamos que hay \\(\\small{n = 10}\\) ensayos de Bernoulli, con realización \\(\\small{SSFSSSSFFF}\\). Entonces \\(\\small{L_{10}(S) = 4}\\), y para \\(\\small{k = 2}\\), tenemos \\(\\small{N_{10,2} = 3, M_{10,2} = 4, E_{10,2} = 1}\\) y \\(\\small{G_{10,2} = 2}\\)\nDe las definiciones de estas estadísticas de rachas, se deduce por inspección que las siguientes relaciones siempre son verdaderas:\n\n\n\\[\\begin{equation}\nE_{n,k}\\leq G_{n,k} \\leq N_{n,k} \\leq M_{n,k}\\\\\nE_{n,k} = G_{n,k} - G_{n,k+1}\\\\\nL_n(S)&lt;k\\quad\\text{si y solo si }N_{n,k}=0\n\\end{equation}\\]\n\nPara ampliar las definiciones de rachas, consideremos una sucesión de \\(\\small{n}\\) ensayos multiestados \\(\\small{\\{{X}\\}_{t=1}^{n}}\\), cada una de las cuales tiene \\(\\small{m \\geq 2}\\) estados o símbolos como posibles resultados. Estos símbolos se denotan por \\(\\small{b_1,b_2,\\ldots,b_m}\\) y ocurren con probabilidades \\(\\small{p_1,p_2,\\ldots,p_m}\\), respectivamente. A continuación, definimos tres tipos de patrones generales: un patrón simple, un patrón compuesto y un patrón en serie.\nDefinición 2.3 Decimos que \\(\\small{\\Lambda}\\) es un patron simple, si esta conformado por una determinada serie de \\(\\small{k}\\) símbolos, i.e, \\(\\small{\\Lambda=b_{i_1}b_{i_2}\\cdots b_{i_k}}\\) con \\(\\small{i_j\\in \\{1,2,\\ldots,m\\}}\\), para todo \\(\\small{j=1,\\dots,k}\\). La longitud del patrón es fija y los símbolos en el patrón puede repetirse.\nLas rachas de éxito y fracaso de tamaño \\(\\small{k}\\) son por tanto patrones simples según esta definición, y de hecho cualquier sucesión de éxitos y fracasos de longitud fija, digamos \\(\\small{\\Lambda =SSFSF}\\), puede considerarse un patrón simple dentro de una sucesión de de \\(\\small{n}\\) ensayos de dos estados \\(\\small{(m = 2)}\\).\nAhora, sean \\(\\small{\\Lambda_1}\\) y \\(\\small{\\Lambda_2}\\) dos patrones simples de longitudes/tamaños \\(\\small{k_1}\\) y \\(\\small{k_2}\\) , respectivamente. Decimos que \\(\\small{\\Lambda_1}\\) y \\(\\small{\\Lambda_2}\\) son distintos si ni \\(\\small{\\Lambda_1}\\) incluye a \\(\\small{\\Lambda_2}\\) ni \\(\\small{\\Lambda_2}\\) incluye a \\(\\small{\\Lambda_1}\\). Definimos \\(\\small{\\Lambda_1 \\cup\\Lambda_2}\\) como la ocurrencia de uno de los dos patrón \\(\\small{\\Lambda_1}\\) o \\(\\small{\\Lambda_2}\\) , y definimos \\(\\small{\\Lambda_1 \\ast\\Lambda_2}\\) como la ocurrencia de patrón \\(\\small{\\Lambda_1}\\) seguido del patrón \\(\\small{\\Lambda_1}\\) (quizás con una separación entre ellos).\nDefinición 2.4 Decimos que \\(\\small{\\Lambda}\\) es un patrón compuesto si es la unión de \\(\\small{1 &lt; l &lt;\\infty}\\) patrones simples distintos solapados/no solapados, es decir, \\(\\small{\\Lambda=\\displaystyle\\bigcup_{i=1}^{l}\\Lambda_i}\\).\nDefinición 2.5 Decimos \\(\\small{\\Lambda}\\) es un patrón en serie si \\(\\small{\\Lambda}\\) está compuesto por una sucesión ordenada de \\(\\small{1 &lt; l &lt;\\infty}\\) patrones simples distintos no superpuestos \\(\\small{\\Lambda_i}\\), es decir, \\(\\small{\\Lambda=\\Lambda_1 \\ast\\Lambda_2\\ast\\cdots\\Lambda_l}\\)\nA lo largo de este libro, la variable aleatoria \\(\\small{X_n(\\Lambda)}\\) representa el número de ocurrencias del patrón \\(\\small{\\Lambda}\\) en una sucesión de \\(\\small{n}\\) ensayos multiestado, utilizando el recuento con solapamiento o sin solapamiento. Para aclarar las tres definiciones de patrones y los dos métodos de recuento para los ensayos multiestado, presentamos el siguiente ejemplo.\nEjemplo 2.3 Sea \\(\\small{\\{X_t\\}_{t=1}^{16}}\\) una sucesión de dieciséis ensayos de un proceso de cuatro estados, en donde los resultados posibles para cada ensayo son \\(\\small{A, G, C}\\) y \\(\\small{T}\\). Sea \\(\\small{\\Lambda_1=AGAG}\\) y \\(\\small{\\Lambda_2=AGT}\\) dos patrones simples distintos, \\(\\small{\\Lambda=\\Lambda_1 \\cup\\Lambda_2}\\) un patrón compuesto y \\(\\small{\\Lambda^{\\ast}=\\Lambda_1 \\ast\\Lambda_2}\\) un patron en serie. Supongamos que la realización de esta sucesión de dieciséis ensayos es \\(\\small{TAGAGAGTCAGAGTCC}\\), entonces:\n(i) \\(\\small{X_{16}(\\Lambda_1)}\\) es \\(\\small{3}\\) con conteo solapado y es \\(\\small{2}\\) con conteo no solapado,\n(ii) \\(\\small{X_{16}(\\Lambda)}\\) es \\(\\small{5}\\) con conteo solapado y es \\(\\small{3}\\) con conteo no solapado,\n(iii) \\(\\small{X_{16}(\\Lambda^{\\ast})}\\) es igual a \\(\\small{1}\\).\n(iv) \\(\\small{X_{16}(\\Lambda_2)}\\) es \\(\\small{2}\\).\nLas definiciones anteriores de rachas y patrones en una sucesión de ensayos de múltiples estados también se pueden extender a permutaciones aleatorias \\(\\small{\\{\\pi : \\pi=(\\pi (1),\\ldots,\\pi(n)) \\}}\\) de \\(\\small{n}\\) enteros \\(\\small{\\{1, 2, \\ldots, n\\}}\\). Por ejemplo, el número Euleriano \\(\\small{E(\\pi, n)}\\), el número de aumentos en una permutación aleatoria \\(\\small{\\pi}\\) (ver Carlitz 1964, Tanny 1973 y Worpitzky 1883), podría verse como una variable aleatoria \\(\\small{X_n(\\Lambda)}\\) con el patrón \\(\\small{\\Lambda}\\) siendo un aumento. Matemáticamente, el número de Euler se puede definir como\n\n\n\\[\\begin{equation}\nE(\\pi,n)=X_n(\\Lambda)=\\displaystyle \\sum_{i=0}^{n-1}I(\\pi,i),\n\\end{equation}\\]\n\nen donde \n\n\\[\\begin{equation}\nI(\\pi,i)=\\begin{cases}\n1 \\quad \\text{si }\\pi(i)&lt;\\pi(i+1) \\\\\n0 \\quad \\text{en otro caso }\n\\end{cases}\n\\end{equation}\\]\n\n\\[I(\\pi,i)=\\begin{cases}\n1 \\quad \\text{si }\\pi(i)&lt;\\pi(i+1) \\\\\n0 \\quad \\text{en otro caso,}\n\\end{cases}\\]\npara \\(\\small{i=1,\\ldots,n-1}\\), con \\(\\small{I(\\pi,i)=1}\\) por convención (la brecha inicial que precede a la primera permutación siempre se considera un aumento). Por ejemplo, el número de aumentos \\(\\small{E(\\pi, 9)}\\) en la permutación aleatoria \\(\\small{\\pi = (321459768)}\\) de 9 números enteros son 5.\nEn vista de las definiciones y ejemplos anteriores, uno debería esperar que la distribución exacta de la variable aleatoria \\(\\small{X_n(\\Lambda)}\\) dependa en gran medida de tres factores importantes:\n(a) la estructura del patrón \\(\\small{\\Lambda}\\) ,\n (b) la estructura de la sucesión \\(\\small{\\{{X}\\}_{t=1}^{n}}\\) de \\(n\\) ensayos (o permutaciones aleatorias),\n (c) el procedimiento de conteo (conteo superpuesto o no superpuesto).\nDebido a estos factores, la determinación analítica de distribuciones exactas mediante enfoques tradicionales como la combinatoria puede ser bastante desafiante y generalmente compleja, involucrando identidades especiales y un álgebra extensa. En consecuencia, las distribuciones exactas de muchas estadísticas utilizadas en aplicaciones prácticas nunca se han estudiado utilizando tales métodos, especialmente cuando los ensayos subyacentes no son i.i.d. (por ejemplo, Markov-dependientes).\nEn la siguiente subsección, describimos una técnica que permite obtener una representación matricial compacta para la distribución exacta de una manera relativamente simple y universal al incorporar la variable aleatoria \\(\\small{X_n(\\Lambda)}\\) en una cadena de Markov finita; la expresión resultante también es muy adecuada para un análisis más detallado de propiedades estadísticas, para el desarrollo de aproximaciones de grandes desviaciones y para una implementación numérica eficiente para el cálculo de probabilidades exactas.\n\n\n\nLa técnica de Incrustación de Cadenas de Markov Finitas (ICMF) para encontrar la distribución de la variable aleatoria \\(\\small{X_n(\\Lambda)}\\) tiene sus orígenes en una serie de artículos de Fu (1985, 1986), Fu y Hu (1987), Chao y Fu (1989, 1991), y Fu y Lou (1991). El término “Cadena de Markov Finita Incrustable” para describir una variable aleatoria fue introducido formalmente por Fu y Koutras (1994).\nSea \\(\\small{\\Gamma_n=\\{0,1\\ldots,n\\}}\\) un conjunto de indices, y \\(\\small{\\Omega=\\{a_1,a_2,\\ldots,a_m\\}}\\) un espacio de estados finito.\nDefinicion 2.6 La variable aleatoria no negativa de valores enteros \\(\\small{X_n(\\Lambda)}\\), es una cadena de Markov finita incrustable si:\n(a). Existe una cadena de Markov finita \\(\\small{\\{Y_t:t\\in \\Gamma\\}}\\) definida sobre un espacio de estados \\(\\small{\\Omega}\\) finito, con vector de probabilidades inicial \\(\\small{\\boldsymbol{\\xi}_0}\\).\n(b). Existe una partición finita \\(\\small{\\{C_x:x=0,1,\\ldots,l_n\\}}\\) sobre el espacio de estado \\(\\small{\\Omega}\\).\n(c). Para todo \\(\\small{x=0,1,\\ldots,l_m}\\) tenemos: \\[\\small{\\mathbb{P}\\{X_n(\\Lambda)=x\\}=\\mathbb{P}\\{Y_n\\in C_x \\mid \\boldsymbol{\\xi}_0\\}.}\\] Sea \\(\\small{\\{\\boldsymbol{M}_t\\}_{t=1}^{n}}\\) una sucesión de matrices de probabilidades de transición de orden \\(\\small{m\\times m}\\) de una cadena finita de Markov \\(\\small{\\{Y_t\\}}\\) definida sobre un espacio de estados \\(\\small{\\Omega}\\) con distribución de probablidad inicial \\(\\small{\\boldsymbol{\\xi}_0=\\big(\\mathbb{P}\\{Y_0=a_1\\},\\mathbb{P}\\{Y_0=a_2\\},\\ldots,\\mathbb{P}\\{Y_0=a_m\\}\\big)}\\)\nTeorema 2.1 Si \\(\\small{X_n(\\Lambda)}\\) es una cadena finita de Markov incrustable, entoces\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\{ X_n(\\Lambda)=x\\}=\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\prod_{t=1}^{n}\\boldsymbol{M}_t\\Big)\\boldsymbol{\\mathbf{U}'}({C_x})\n\\end{equation}\\]\n\nsiendo \\(\\small{\\boldsymbol{\\mathbf{U}}({C_x})=\\displaystyle\\sum_{r: a_r\\in C_x}\\boldsymbol{e}_r}\\) y \\(\\small{\\boldsymbol{e}_r=(0,\\ldots,1,\\ldots,0)_{1\\times m}}\\) es un vector unitario de tamaño \\(\\small{1\\times m}\\) con un \\(\\small{1}\\) asociado al estado \\(\\small{a_r}\\) e \\(\\small{\\boldsymbol{\\mathbf{\\xi}}_0}\\) vector de probabilidades iniciales, y \\(\\small{\\boldsymbol{M}_t\\,,\\,\\,t=1,\\dots,n}\\) son las matrices de probabilidades de transición de la cadena de Markov incrustada.\nPrueba: Dado que \\(\\small{X_n(\\Lambda)}\\) es una cadena de Markov finita incrustable, se deduce de Definición 2.6(a) de que existe una cadena de Markov finita \\(\\small{\\{Y_t : t\\in \\Gamma_n \\}}\\) con probabilidades iniciales \\(\\small{\\boldsymbol{\\mathbf{\\xi}}_0}\\). Luego por la ecuación de Chapman-Kolmogorov descrita en Sección 2.2, para cada \\(\\small{a_r\\in \\Omega}\\), tenemos\n\n\n\\[\\begin{equation}\n\\mathbb{P}(Y_n =a_r \\mid \\boldsymbol{\\mathbf{\\xi}}_0)=\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\prod_{t=1}^{n}\\boldsymbol{M}_t\\Big)\\boldsymbol{e_r'}\n\\end{equation}\\]\n\nAdemás, de las Definiciones 2.6(b) y (c) se deduce que, para cada \\(\\small{x =0,1\\ldots,l_n}\\),\n\n\n\\[\\begin{equation}\n\\begin{split}\n\\mathbb{P}\\{ X_n(\\Lambda)=x\\} & =  \\mathbb{P}(Y_n \\in C_x \\mid \\boldsymbol{\\mathbf{\\xi}}_0) \\\\\n& = \\sum_{a_r\\in C_x}\\mathbb{P}\\{Y_n=a_r\\mid \\boldsymbol{\\mathbf{\\xi}_0}\\}\\\\\n& = \\sum_{a_r\\in C_x} \\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\prod_{t=1}^{n}\\boldsymbol{M}_t\\Big)\\boldsymbol{e_r'}\\\\\n& = \\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\prod_{t=1}^{n}\\boldsymbol{M}_t\\Big)\\boldsymbol{\\mathbf{U}'}( {C_x})\\quad \\quad \\quad \\quad \\quad \\Box\n\\end{split}\n\\end{equation} \\Box\\]\n\nEl \\(\\small{k-}ésimo\\) momento \\(\\small{\\mathbb{E}\\{X_n^k(\\Lambda)\\},\\,\\,k=1,2,\\ldots,}\\) puede expresarse como:\n\n\n\\[\\begin{equation}\n\\mathbb{E}\\{X_n^k(\\Lambda)\\}=\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\prod_{t=1}^{n}\\boldsymbol{M}_t\\Big)\\boldsymbol{{V}_k'}\n\\end{equation}\\]\n\nen donde\n\n\n\\[\\begin{equation}\n\\boldsymbol{{V}_k'}=\\sum_{x=0}^{l_n}x^{k}\\boldsymbol{U}(\\mathbf{C_x})\n\\end{equation}\\]\n\nDe manera ánaloga la función generadora de probabilidad de la variable aleatoria \\(\\small{X_n(\\Lambda)}\\) puede escribirse como:\n\n\n\\[\\begin{equation}\n\\psi(s)= \\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\prod_{t=1}^{n}\\boldsymbol{M}_t\\Big)\\boldsymbol{W'}(s)\n\\end{equation}\\]\n\nen donde \n\n\\[\\begin{equation}\n\\boldsymbol{W}(s)=\\sum_{x=0}^{l_n}s^{x}\\boldsymbol{U}(\\mathbf{C_x})\n\\end{equation}\\]\n\nLos funciones generadoras de probabilidad y de momentos se discutirán dentro del contexto de aplicaciones específicas en secciones posteriores.\nEjemplo 2.4 (Número de parejas de resultados sucesivos idénticos). Sea \\(\\small{\\{X_t:t = 0,1,\\ldots, n\\}}\\) una sucesión de \\(\\small{n}\\) ensayos Markov-dependientes homogéneos con \\(\\small{m}\\) estados y matriz de probabilidad de transición \\(\\small{\\boldsymbol{A}_{m\\times m} = \\big(P_{ij}\\big)}\\) y una distribución de probabilidad inicial \\(\\small{\\boldsymbol{\\xi}_0=\\big(\\mathbb{P}\\{X_0=1\\},\\mathbb{P}\\{X_0=2\\},\\ldots,\\mathbb{P}\\{X_0=m\\}\\big)=(1/m,1/m,\\ldots,1/m)}\\). Definiendo una sucesión de funciones indicadoras\n\n\n\\[\\begin{equation}\nI_i=\\begin{cases}\n1 \\quad \\text{si }X_t=X_{t-1}\\\\\n0 \\quad \\text{en otro caso}\n\\end{cases}\n\\end{equation}\\]\n\npara todo \\(\\small{t=1,\\ldots,n}\\)\nEn este ejemplo, nos interesa el número de veces que un resultado particular (uno de \\(\\small{m}\\) resultados posibles) en un ensayo determinado se repite en el ensayo inmediatamente siguiente. En términos matemáticos, definimos el patrón \\(\\small{\\Lambda}\\) para denotar dicho resultado repetido, un patrón que está presente en el índice de tiempo \\(\\small{1 \\leq t \\leq n}\\) si \\(\\small{X_{t-1} = X_t}\\) o, de manera equivalente en términos de la función indicadora anterior, si \\(\\small{I_t = 1}\\). La estadística de rachas:\n\n\n\\[\\begin{equation}\nX_n(\\Lambda)= \\sum_{t=1}^{n}I_t\n\\end{equation}\\]\n\ncorresponde al número de veces que ocurrió el patrón \\(\\small{\\Lambda}\\) en la sucesión \\(\\small{\\{X\\}_{t=0}^{n}}\\) de \\(\\small{n}\\) ensayos Markov-dependientes con \\(\\small{m}\\) estados. En el sector sanitario, por ejemplo, la estadística \\(\\small{X_n(\\Lambda)/n}\\) se conoce como \\(SECON\\) y forma la medida principal de continuidad secuencial en una serie de \\(\\small{n}\\) visitas de pacientes a \\(\\small{m}\\) posibles proveedores de atención sanitaria ( Steinwachs 1979).\nUna dificultad aquí es que las variables aleatorias \\(\\small{\\{I_t\\}}\\) no son independientes y no conforman una cadena de Markov, incluso si la sucesión \\(\\small{\\{X\\}_{t=0}^{n}}\\) se extrajera de ensayos i.i.d. de \\(\\small{m}\\) estados. De hecho, se puede demostrar que las variables aleatorias \\(\\small{\\{I_t\\}}\\) son dependientes y están correlacionadas positivamente probando que \\(\\small{Cov(I_i, I_j) &gt; 0}\\) para todo \\(\\small{i}\\) y \\(\\small{j}\\), con \\(\\small{Cov(I_i, I_j) \\rightarrow 0}\\) cuando \\(\\small{\\mid i-j \\mid\\rightarrow 0}\\). Sin embargo, como se indica a continuación, la distribución exacta aún se puede obtener fácilmente utilizando la técnica de incrustación de cadenas de Markov finitas.\nPrimero, descomponemos la matriz de probabilidad de transición \\(\\small{\\boldsymbol{A}}\\) en dos matrices \\(\\small{\\boldsymbol{G}}\\) y \\(\\small{\\boldsymbol{D}}\\), donde la matriz \\(\\small{\\boldsymbol{D}}\\) contiene sólo los elementos diagonales de \\(\\small{\\boldsymbol{A}}\\); es decir:\n\n\n\\[\\begin{equation}\n\\boldsymbol{A}_{m\\times m}=\\boldsymbol{G}_{m\\times m}+\\boldsymbol{D}_{m\\times m}\n\\end{equation}\\]\n\nen donde: \n\n\\[\\begin{equation}\n\\boldsymbol{G}_{m\\times m}=\n\\begin{pmatrix}\n0 & p_{ij} & \\cdots \\\\\n  & \\ddots &        \\\\\n\\cdots & p_{ij} & 0\n\\end{pmatrix}\n\\quad \\text{y} \\quad\n\n\\boldsymbol{D}_{m\\times m}=\n\\begin{pmatrix}\np_{11} &  & \\boldsymbol{0} \\\\\n  & \\ddots &        \\\\\n\\boldsymbol{0} &   & p_{mm}\n\\end{pmatrix}\n\\end{equation}\\]\n\nSea \\(\\small{\\Omega=\\{(u,v): u = 0,\\ldots,n, \\text{ y }v = 1,2,\\ldots, m\\}}\\) el espacio de estados que contiene un total de \\(\\small{(n+1)m}\\) estados. Dado \\(\\small{n}\\), se define una cadena de Markov homogénea y finita \\(\\small{\\{Y_t: t\\in \\Gamma\\}}\\) en el espacio de estados \\(\\small{\\Omega}\\) como\n\n\n\\[\\begin{equation}\nY_t=\\begin{cases}\n\\Big(\\displaystyle\\sum_{i=1}^{t}I_i, X_t \\Big) \\quad \\text{si } 1 \\leq t \\leq n\\\\\n\\big(0,X_0\\big) \\quad t=0\n\\end{cases}\n\\end{equation}\\]\n\ncon matriz de probabilidades de transición:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\\begin{pmatrix}\n\\boldsymbol{G} & \\boldsymbol{D} & \\boldsymbol{O} & \\cdots & \\boldsymbol{O}\\\\\n\\boldsymbol{O} & \\boldsymbol{G} & \\boldsymbol{D} & \\cdots & \\boldsymbol{O} \\\\\n\\vdots & \\ddots & \\ddots & \\ddots & \\vdots \\\\\n\\boldsymbol{O} & \\cdots & \\cdots & \\boldsymbol{G}& \\boldsymbol{D}\\\\\n\\boldsymbol{O} & \\boldsymbol{O} & \\cdots & \\boldsymbol{O}& \\boldsymbol{I}\\\\\n\\end{pmatrix}\n\\end{equation}\\]\n\ndonde \\(\\small{\\boldsymbol{M}}\\) es una matriz \\(\\small{(n + 1)m \\times (n + 1)m}\\), \\(\\small{\\boldsymbol{O}}\\) representa la matriz cero \\(\\small{m\\times m}\\) e \\(\\small{\\boldsymbol{I}}\\) es la matriz identidad \\(\\small{m\\times m}\\). Los estados en \\(\\small{\\boldsymbol{M}}\\) están ordenados en orden lexicográfico (diccionario). Por último, defininiendo la partición \\(\\small{\\{C_x: x=0,1,2,\\ldots,n\\}}\\) en el espacio de estados \\(\\small{\\boldsymbol{\\Omega}}\\) como\n\n\n\\[\\begin{equation}\nC_x=\\{(x,v): v=1,2,\\ldots,m\\}\n\\end{equation}\\]\n\nDadas las definiciones anteriores para la cadena de Markov \\(\\small\\{Y_t\\}\\), la variable aleatoria \\(\\small{X_n(\\Lambda)}\\) es, según la Definición 2.6, una cadena de Markov finita incrustable y su distribución exacta se desprende del Teorema 2.1: para \\(\\small{0 \\leq x \\leq n}\\),\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\{X_n(\\Lambda)=x\\}=\\boldsymbol{\\xi_0}\\begin{pmatrix}\n\\boldsymbol{G} & \\boldsymbol{D} & \\boldsymbol{O} & \\cdots & \\boldsymbol{O}\\\\\n\\boldsymbol{O} & \\boldsymbol{G} & \\boldsymbol{D} & \\cdots & \\boldsymbol{O} \\\\\n\\vdots & \\ddots & \\ddots & \\ddots & \\vdots \\\\\n\\boldsymbol{O} & \\cdots & \\cdots & \\boldsymbol{G}& \\boldsymbol{D}\\\\\n\\boldsymbol{O} & \\boldsymbol{O} & \\cdots & \\boldsymbol{O}& \\boldsymbol{I}\\\\\n\\end{pmatrix}^{n}\\boldsymbol{U'}(C_x)\n\\end{equation}\\]\n\ndonde \\(\\small{\\boldsymbol{\\xi_0}(\\pi_0,0,\\ldots,0)_{(n+1)\\times m}}\\) es la distribución inicial del vector de estado \\(\\small{Y_0}\\), y \\(\\small{\\boldsymbol{U'}(C_x): (0,\\ldots, 0, \\underbrace{1, 1, ..., 1}_{C_x}, 0,\\ldots,0)}\\) es un vector de fila \\(\\small{1 \\times(n+1)m}\\) con \\(\\small{1}\\) en las coordenadas asociadas con los estados en \\(\\small{C_x}\\) y cero en otros posiciones. En el Capítulo 7 se darán más detalles y un ejemplo numérico de este problema.\nKoutras y Alexandrou (1995) introdujeron la noción de variables incrustables en cadenas finitas de Markov de tipo binomial (MVBS), y muchas estadísticas comunes para rachas y patrones caen en esta categoría especial. Sea la partición \\(\\small{ \\{C_x\\}=\\{[(x, v): v=1,...,r], \\text{ para } x = 0, 1,\\ldots, l_n\\}}\\), la partición del espacio de estados \\(\\small{\\Omega}\\).\nDefinición 2.7 Una variable aleatoria \\(\\small{X_n(\\Lambda)}\\) es una cadena de Markov finita incrustable de tipo binomial si:\n(i) \\(\\small{X_n(\\Lambda)}\\) es una cadena de Markov finita incrustable como en la Definición 2.6.\n(ii) \\(\\small{\\mathbb{P}\\{Y_t=(y,j) \\mid Y_{t-1} =(x,i)\\} \\equiv 0}\\) para todo \\(\\small{y\\neq x}\\) o \\(\\small{x + 1}\\).\nPara cualquier \\(\\small{MVB}\\), introduzca dos matrices de probabilidad de transición \\(\\small{r\\times r}\\):\n\n\n\\[\\begin{equation}\n\\boldsymbol{A_t}(x) = \\big(a_{ij}(t)\\big) = \\Big(\\mathbb{P}\\{Y_t = (x,j)\\mid Y_{t−1} = (x, i)\\}\\Big)\n\\end{equation}\\]\n\ny \n\n\\[\\begin{equation}\n\\boldsymbol{B_t}(x) = \\big(b_{ij}(t)\\big) = \\Big(\\mathbb{P}\\{Y_t = (x+1,j)\\mid Y_{t−1} = (x, i)\\}\\Big)\n\\end{equation}\\]\n\nPor tanto las matrices de probabilidad de transición \\(\\small{\\boldsymbol{M_t}}\\) de la cadena de Markov incrustada tienen la siguiente forma: \n\n\\[\\begin{equation}\n\\boldsymbol{M}=\\begin{pmatrix}\n\n\\boldsymbol{A}_t(0) & \\boldsymbol{B}_t(0) & \\boldsymbol{O} & \\cdots &\\cdots  & \\boldsymbol{O} \\\\\n\n\\boldsymbol{O} &\\boldsymbol{A}_t(1) & \\boldsymbol{B}_t(1)  & \\boldsymbol{O} & \\cdots  & \\boldsymbol{O}\\\\\n\n\\vdots & \\boldsymbol{O} & \\ddots & \\ddots & \\ddots & \\vdots \\\\\n\\vdots & \\ddots & \\boldsymbol{O}& \\ddots & \\ddots & \\boldsymbol{O} \\\\\n\\vdots & \\cdots & \\cdots & \\boldsymbol{O}& \\boldsymbol{A}_t(l_n-1) & \\boldsymbol{B}_t(l_n-1) \\\\\n\\boldsymbol{O} & \\boldsymbol{O} & \\cdots &  \\boldsymbol{O}& \\boldsymbol{O} &  \\boldsymbol{A}_t(l_n) \\\\\n\\end{pmatrix}\n\\end{equation}\\]\n\npara \\(\\small{t = 1,\\ldots,n}\\), en donde los estados están ordenados en orden lexicográfico (diccionario). Hay muchas estadísticas para rachas y patrones con matrices de transición que tienen esta forma, como, por ejemplo, las estadísticas de rachas \\(\\small{N_{n,k},\\, M_{n,k}\\, \\text{y}\\, G_{n,k}}\\) introducidas en la Sección 2.4 (y estudiadas más a fondo en el Capítulo 3).\nPara \\(\\small{MVB´s}\\), se puede derivar una ecuación recursiva eficiente para la distribución de \\(\\small{X_n(\\Lambda)}\\), que aprovecha parcialmente la estructura de bandas de las matrices de probabilidad de transición \\(\\small{\\boldsymbol{M}_t}\\). Sea el vector fila \\(\\small{\\boldsymbol{\\alpha}_t(x)=\\big(\\mathbb{P}\\{Y_t=(x,1)\\},\\ldots, \\mathbb{P}\\{Y_t=(x,1)\\}\\big)}\\) , para \\(\\small{t= 1,\\ldots, n}\\), de modo que la probabilidad de \\(\\small{X_n(\\Lambda)=x}\\) se puede representar como\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\{X_n(\\Lambda)=x \\mid \\boldsymbol{\\xi}_0\\}=\n\\boldsymbol{\\alpha}_n(x)\\boldsymbol{1}', \\, \\text{para toda}\\,\\,\nx=0,1,\\dots,l_n\n\\end{equation}\\]\n\ndonde \\(\\small{\\boldsymbol{1}'=(1,\\ldots,1)'}\\). Descomponga \\(\\small{\\boldsymbol{M}_t}\\) como \\(\\small{\\boldsymbol{M}_t=\\boldsymbol{K}_t+\\boldsymbol{H}_t}\\), donde \\(\\small{\\boldsymbol{K}_t}\\) es una matriz diagonal con componentes \\(\\small{\\boldsymbol{A}_t(x)}\\), para \\(\\small{x = 0,1,\\ldots,l_n}\\), y \\(\\small{\\boldsymbol{H}_t}\\) es una matriz diagonal superior con componentes \\(\\small{\\boldsymbol{B}_t(x)}\\), para \\(\\small{x = 0,1,\\ldots,l_{n-1}}\\). A partir de la multiplicación hacia atrás, \\(\\small{\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\displaystyle\\prod_{j=1}^{t}\\boldsymbol{M}_j\\Big)=\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\displaystyle\\prod_{j=1}^{t-1}\\boldsymbol{M}_j\\Big)\\boldsymbol{M}_t=\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\displaystyle\\prod_{j=1}^{t-1}\\boldsymbol{M}_j\\Big)\\big(\\boldsymbol{K}_t+\\boldsymbol{H}_t\\big)}\\), puede demostrarse que se cumplen las siguientes ecuaciones recursivas:\n\n\n\\[\\begin{align*}\n\\boldsymbol{\\alpha_t}(0)&=\\boldsymbol{\\alpha_{t-1}}(0)\\boldsymbol{A_t}(0) \\\\\n\\boldsymbol{\\alpha_t}(X)&=\n\\boldsymbol{\\alpha_{t-1}}(x-1)\\boldsymbol{B_{t-1}}(t-1)+\\boldsymbol{\\alpha_{t-1}}(x)\\boldsymbol{A_t}(x),\\, x=1,\\ldots,l_n.\n\\end{align*}\\]\n\nLa ecuación (2.17) proporciona un algoritmo eficiente para calcular las probabilidades \\(\\small{ \\mathbb{P}\\{X_n(\\Lambda)=x \\mid\\boldsymbol{\\xi}_0\\}=\\boldsymbol{\\alpha}_n(x)\\boldsymbol{1}', \\, \\text{para toda }\\, x=0,1,\\dots,l_n}\\), y esto es especialmente importante cuando la dimensión de las matrices de transición \\(\\small{\\boldsymbol{M_t}}\\) es grande y el esfuerzo computacional para calcular ingenuamente \\(\\small{\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\displaystyle\\prod_{t=1}^{n}\\boldsymbol{M}_t\\Big)\\boldsymbol{U'}(C_x)}\\) se vuelve prohibitivo. A partir de la multiplicación hacia atrás, la técnica de incrustación de cadenas finitas de Markov a menudo proporciona una ecuación recursiva en una forma similar a la ecuación (2.17), una forma que, en general, no puede obtenerse tan fácilmente mediante los métodos combinatorios o de renovación tradicionales.\n\n\n\nEn esta sección se derivan algunas expresiones útiles para la probabilidad de entrar en un estado absorbente. Para mayor claridad de la exposición, nos centraremos en las cadenas de Markov homogéneas, pero las ideas pueden generalizarse fácilmente a casos no homogéneos.\nUn estado \\(\\small{\\alpha \\in \\Omega}\\) se llama estado absorbente si, una vez que el sistema entra en el estado \\(\\small{\\alpha}\\), nunca sale; es decir, \\(\\small{p_{\\alpha\\alpha}\\equiv 1}\\) (y \\(\\small{p_{\\alpha\\beta}\\equiv 0}\\) para cualquier \\(\\small{\\alpha\\neq\\beta}\\)). Sea \\(\\small{A=\\{\\alpha_1,\\ldots,\\alpha_k\\}}\\) el conjunto de todos los estados absorbentes de una cadena de Markov homogénea \\(\\small{\\{Y_t\\}}\\) con una matriz de probabilidad de transición \\(\\small{\\boldsymbol{M}}\\). Bajo una disposición apropiada del espacio de estados, la matriz de probabilidad de transición \\(\\small{\\boldsymbol{M}}\\) siempre se puede escribir de la siguiente forma:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\\left(\\begin{array}{c|c}\n\\boldsymbol{N}_{(m-k)\\times (m-k)} & \\boldsymbol{C}_{(m-k)\\times (m-k)}\\\\\n\\hline  \n\\boldsymbol{O}_{k\\times (m-k)} & \\boldsymbol{1}_{k \\times k}\n\\end{array}\\right)\n\\end{equation}\\]\n\ndonde \\(\\small{m}\\) y \\(\\small{k}\\) \\(\\small{(m&gt;k)}\\) son los números de estados en \\(\\small{\\Omega}\\) y \\(\\small{A}\\), respectivamente. La matriz \\(\\small{\\boldsymbol{N}}\\) definida por la ecuación. (2.18) se conoce como la submatriz de probabilidad de transición esencial de la cadena de Markov. Desempeña un papel importante en el estudio de las distribuciones exactas de variables aleatorias incrustables en cadenas de Markov, especialmente para las distribuciones asociadas de tiempos de espera.\nSea \\(\\small{\\boldsymbol{\\xi_{0}}=\\big(\\boldsymbol{\\xi}:\\boldsymbol{0}\\big)_{1\\times m}}\\) la distribución inicial, donde \\(\\small{\\boldsymbol{\\xi}=(\\xi_1,\\ldots,\\xi_{m-k}), \\, \\boldsymbol{0}=(0,\\ldots,0)_{1\\times k}}\\) y \\(\\small{\\displaystyle{\\sum_{i=1}^{m-k}\\xi_i=1}}\\) y sea \\(\\small{\\big(\\boldsymbol{1:0}\\big)_{1\\times m}}\\) un vector fila, en donde \\(\\small{\\boldsymbol{1}=(1,\\ldots,1)_{1\\times (m-k)}}\\) La razón por la que suponemos que la distribución inicial tiene la forma \\(\\small{\\big(\\boldsymbol{\\xi_0}:\\boldsymbol{0}\\big)}\\) es estrictamente por razones prácticas, ya que la mayoría de los sistemas siempre comienzan en un estado no absorbente.\nTeorema 2.2 Dada una matriz de probabilidad de transición \\(\\small{\\boldsymbol{M}}\\) de una cadena de Markov homogénea \\(\\small{\\{Y_t\\}}\\) en la forma de la ecuación (2.18), la probabilidad para el índice de tiempo \\(\\small{n}\\) cuando el sistema ingresa por primera vez al conjunto de estados absorbentes puede ser obtenida como:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(Y_n\\in A,Y_{n-1}\\notin A,\\ldots,  Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)=\\boldsymbol{\\xi N}^{n-1}\\boldsymbol{(I-N)1'}\n\\end{equation}\\]\n\nDemostración: Dado que \\(\\small{\\boldsymbol{M}}\\) tiene la forma de la Equación 2.18, se sigue que:\n\n\n\\[\\begin{equation}\n\\mathbf{M}^{n-1}=\\left(\\begin{array}{c|c}\n\\boldsymbol{N}^{n-1} & \\boldsymbol{K}_{n-1}\\\\\n\\hline  \n\\boldsymbol{O} & \\boldsymbol{I}\n\\end{array}\\right)\n\\end{equation}\\]\n\nen donde \\(\\small{\\boldsymbol{K}_{n-1}=\\big( \\boldsymbol{I}+\\boldsymbol{N}+\\cdots+\\boldsymbol{N}^{n-2}\\big)\\boldsymbol{C}}\\). Además, como todos los estados en \\(\\small{\\boldsymbol{A}}\\) son estados absorbentes, de la ecuación de Chapman-Kolmogorov se deduce que:\n\n\n\\[\\begin{align*}\n\\mathbb{P}\\big(Y_{n-1}\\notin A,\\cdots,  Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big) & =\\mathbb{P}\\big(Y_{n-1}\\in \\Omega-A\\mid \\boldsymbol{\\xi_0}\\big)\\\\\n& =\\big(\\boldsymbol{\\xi_0}:\\boldsymbol{0}\\big) \\boldsymbol{ M}^{n-1}\\big(\\boldsymbol{1}:\\boldsymbol{0}\\big)'.\n\\end{align*}\\]\n\nLuego la ecuación (2.19) puede entonces deducirse utilizando las ecuaciones (2.20) y (2.21) a traves de:\n\n\n\\[\\begin{align*}\n& \\quad \\, \\, \\mathbb{P}\\big(Y_n\\in A,Y_{n-1}\\notin A,\\ldots,  Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)\\\\\n& =\\mathbb{P}\\big(Y_{n-1}\\notin A,\\ldots,  Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)-\\mathbb{P}\\big(Y_n\\notin A,Y_{n-1}\\notin A,\\ldots,  Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)\\\\\n& = \\big(\\boldsymbol{\\xi_0}:\\boldsymbol{0}\\big) \\boldsymbol{ M}^{n-1}\\big(\\boldsymbol{I-M}\\big)\\big(\\boldsymbol{1}:\\boldsymbol{0}\\big)' \\\\\n& =\\boldsymbol{\\xi N}^{n-1}\\boldsymbol{(I-N)1'}.\\hspace{8cm} \\Box\n\\end{align*}\\]\n\nEn vista de las Ecs. (2.20) y (2.21), los siguientes teoremas son inmediatos.\nTeorema 2.3 Para todo estado \\(\\small{i\\in \\Omega-A}\\)\n\n\n\\[\\begin{align*}\n\\mathbb{P}\\big(Y_{n-1}=i,Y_{n-2}\\notin A,\\ldots,  Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)= \\boldsymbol{\\xi N}^{n-1}\\boldsymbol{e_i'}.\n\\end{align*}\\]\n\nPrueba. Utilizando los mismos argumentos que en la demostración del Teorema 2.2 y reemplazando \\(\\small{\\boldsymbol{1'}}\\) por \\(\\small{\\boldsymbol{e_i'}}\\), la Ec. (2.22) se sigue directamente de las ecuaciones (2.20) y (2.21). \\(\\hspace{1cm} \\Box\\)\nTeorema 2.4 Para cualquier estado absorbente \\(\\small{j \\in A}\\), la probabilidad del sistema para llegar por primera vez al estado absorbente \\(\\small{j}\\) en el \\(\\small{n}-\\)ésimo ensayo es:\n\n\n\\[\\begin{align*}\n\\mathbb{P}\\big(Y_{n}=j,Y_{n-1}\\notin A,\\ldots,  Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)= \\boldsymbol{\\xi N}^{n-1}{C_j'}.\n\\end{align*}\\]\n\nen donde, \\(\\small{C_j'}\\) es la \\(\\small{j}-\\)ésima columna de la matriz \\(\\small{\\boldsymbol{C}}\\).\nPrueba: Para cualquier \\(\\small{j \\in A}\\), de la definición de la cadena de Markov y del Teorema 2.3 se deduce que:\n\n\n\\[\\begin{align*}\n& \\quad \\, \\mathbb{P}\\big(Y_{n-1}=j,Y_{n-1}\\notin A,\\ldots,  Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)\\\\\n& = \\sum_{i\\in \\Omega-A}\\mathbb{P}\\big(Y_{n-1}=i,Y_{n-2}\\notin A,\\ldots,  Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)\\times \\mathbb{P}\\big( Y_n=j\\mid Y_{n-1}=i \\big)\\\\\n&= \\sum_{i\\in \\Omega-A}\\boldsymbol{\\xi N}^{n-1}{e_i'}p_{ij}\\\\\n&= \\boldsymbol{\\xi N}^{n-1}\\sum_{i\\in \\Omega-A}{e_i'}p_{ij}\\\\\n&= \\boldsymbol{\\xi N}^{n-1}{C_j'}\\hspace{8cm}\n\\end{align*}\\]\n\nPara ilustrar los teoremas 2.2 a 2.4 y sus relaciones, proporcionamos el siguiente ejemplo sencillo.\nEjemplo 2.5 Sea \\(\\small{\\{Y_t\\}}\\) una cadena de Markov homogénea definida en el espacio de estados \\(\\small{\\{1, 2, 3, 4\\}}\\) con distribución inicial \\(\\small{\\boldsymbol{\\xi_0}=\\big(\\xi : 0 \\big)=(1,0:0,0)}\\) y matriz de probabilidad de transición\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\\begin{array}{cccc}&\n\\begin{array}{cccc}\n\\end{array}\n\\\\\n\\begin{array}{ccc}\n1 \\\\\n2 \\\\\n3\\\\\n4\\\\\n\\end{array}\n&\n\\left(\n\\begin{array}{cc|cc}\n1/2 & 1/4 & 1/4  &  0 \\\\\n1/3 & 1/3 & 0 &  1/3 \\\\\n\\hline\n0& 0  &  1 & 0 \\\\\n0&  0 & 0 &  1\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nen donde \\(\\small{A=\\{3,4\\}}\\) es el conjunto de estados absorbentes. Para \\(\\small{n = 3}\\) (tercer ensayo), las probabilidades de entrada del sistema en los estados absorbentes \\(\\small{3}\\) y \\(\\small{4}\\) son, respectivamente:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(Y_{3}=3,Y_{2}\\notin A,Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)=(0,1)\n\\left(\\begin{array}{cc}\n1/2 & 1/4\\\\\n1/3 & 1/3\\\\\n\\end{array} \\right)^{2}\n\\left(\\begin{array}{c}\n1/4\\\\\n0\\\\\n\\end{array} \\right)=\\frac{1}{12}\n\\end{equation}\\]\n\ny \n\n\\[\\begin{equation}\n\\mathbb{P}\\big(Y_{3}=4,Y_{2}\\notin A,Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)=(0,1)\n\\left(\\begin{array}{cc}\n1/2 & 1/4\\\\\n1/3 & 1/3\\\\\n\\end{array} \\right)^{2}\n\\left(\\begin{array}{c}\n0\\\\\n1/3\\\\\n\\end{array} \\right)=\\frac{5}{72}.\n\\end{equation}\\]\n\nAdemás, por el Teorema 2.2, la probabilidad de que el sistema entre por primera vez en el subconjunto \\(\\small{A=\\{3,4\\}}\\) en el tercer ensayo es\n\n\n\\[\\begin{align*}\n& \\quad \\,\\, \\mathbb{P}\\{Y_3\\in A,Y_{2}\\notin A,Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\}\\\\\n&=\\boldsymbol{\\xi N}^{3-1}\\boldsymbol{(I-N)1'}\\\\\n&=(0,1)\n\\left(\\begin{array}{cc}\n1/2 & 1/4\\\\\n1/3 & 1/3\\\\\n\\end{array} \\right)^{2}\n\\left[\n\\left(\\begin{array}{cc}\n1 & 0\\\\\n0 & 1\\\\\n\\end{array} \\right)-\n\\left(\\begin{array}{cc}\n1/2 & 1/4\\\\\n1/3 & 1/3\\\\\n\\end{array} \\right)\n\\right]\n\\left(\\begin{array}{c}\n1\\\\\n1\\\\\n\\end{array} \\right)\\\\\n& =\\frac{11}{72}\n\\end{align*}\\]\n\nComo verificación de los resultados anteriores, observemos que:\n\n\n\\[\\begin{align*}\n\\mathbb{P}\\big(Y_3\\in A,Y_{2}\\notin A,Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)& =\n\\mathbb{P}\\big(Y_3= 3,Y_{2}\\notin A,Y_1\\notin A \\mid \\boldsymbol{\\xi_0} \\big)\\\\\n&+ \\mathbb{P}\\big(Y_3= 4,Y_{2}\\notin A,Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\\\\n&= \\frac{11}{72} \\hspace{5cm}\\Diamond\n\\end{align*}\\]\n\nDe forma más general, puesto que para cada \\(\\small{i\\in \\Omega-A}\\)\n\n\\[\\begin{align*}\n\\sum_{j\\in A}p_{ij}= 1- \\sum_{j \\in \\Omega- A}p_{il}\n\\end{align*}\\]\n\nluego se deduce que \\(\\small{\\displaystyle\\sum_{j\\in A}C_j'=\\boldsymbol{(I-N)1'}}\\), y por tanto\n\n\n\\[\\begin{align*}\n\\sum_{j\\in A}\\boldsymbol{\\xi N}^{n-1}C_j'=\\boldsymbol{\\xi N}^{n-1}\\boldsymbol{(I-N)1'}\n\\end{align*}\\]\n\n\n\n\nUtilizando las ideas de la sección 2.6, podemos encontrar la probabilidad de que se produzca la primera entrada para cualquier subconjunto \\(\\small{B\\subset \\Omega}\\). Dado el subconjunto \\(\\small{B}\\), la matriz de probabilidad de transición \\(\\small{\\boldsymbol{M}}\\) de una cadena de Markov \\(\\small{\\{Y_t\\}}\\) homogénea siempre puede disponerse de la siguiente forma:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\n\\begin{array}{cc}\n{\\Omega-B} \\\\B \\end{array}\n\\left(\\begin{array}{c|c}\n\\boldsymbol{N} & \\boldsymbol{B}\\\\\n\\hline\n\\boldsymbol{J} &  \\boldsymbol{Q}\n\\end{array}\n\\right)\n\\end{equation}\\]\n\nTeorema 2.5 Sea \\(\\small{\\{Y_t\\}}\\) una cadena de Markov homogénea con matriz de probabilidad de transición \\(\\small{\\boldsymbol{M}}\\), en la forma de la ecuación (2.25), y con distribución inicial \\(\\small{\\boldsymbol{\\xi=(1:0)}}\\). Entonces, para un subconjunto \\(\\small{B}\\) de tamaño \\(\\small{k}\\) contenido en el espacio de estados \\(\\small{\\Omega}\\) de tamaño \\(\\small{m}\\), se cumplen las siguientes relaciones:\n(i) Para todo \\(\\small{j \\in B}\\)\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(Y_n =j,Y_{n-1}\\notin B,\\cdots,Y_1\\notin B \\mid \\boldsymbol{\\xi_0}\\big)=\\boldsymbol{\\xi N}^{n-1}\\boldsymbol{B_j'},\n\\end{equation}\\]\n\nen donde \\(\\small{B_j'}\\) es la \\(\\small{j}-\\)ésima columna de la matriz \\(\\small{\\boldsymbol{B}_{(m-k)\\times k}}\\) y\n(ii)\n\n\n\\[\\begin{align*}\n& \\quad \\,\\, \\mathbb{P}\\big(Y_n \\in B,Y_{n-1}\\notin B,\\cdots,Y_1\\notin B \\mid \\boldsymbol{\\xi_0}\\big)\\\\\n&=\\boldsymbol{\\xi N}^{n-1}\\boldsymbol{(I-N)1'}\\\\\n&=\\sum_{j\\in B}\\boldsymbol{\\xi N}^{n-1}{B'}_j,\n\\end{align*}\\]\n\nPrueba. Defina una nueva cadena de Markov \\(\\small{\\{Z_t\\}}\\) en el espacio de estados \\(\\small{\\Omega}\\), donde \\(\\small{\\{Z_t\\}}\\) es igual a \\(\\small{\\{Y_t\\}}\\)para todos los estados \\(\\small{i \\in \\Omega-B}\\) y donde todos los estados \\(\\small{j \\in B}\\) se toman como estados absorbentes. Entonces la matriz de probabilidad de transición \\(\\small{\\boldsymbol{M^{\\star}}}\\) para la cadena de Markov \\(\\small{\\{Z_t\\}}\\) tiene la forma\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}^{\\star}=\\big(p_{ij}^{\\ast}\\big)=\n\\left(\\begin{array}{c|c}\n\\boldsymbol{N} & \\boldsymbol{B}   \\\\\n\\hline\n\\boldsymbol{O} &  \\boldsymbol{I}\n\\end{array}\n\\right).\n\\end{equation}\\]\n\nDado que, para cada \\(\\small{n}\\) \n\n\\[\\begin{equation}\n\\mathbb{P}\\big(Y_n =j,Y_{n-1} \\notin B,\\cdots, Y_1\\notin B,Y_1\\notin B \\mid \\boldsymbol{\\xi_0}\\big)=\\mathbb{P}\\big(Z_n =j,Z_{n-1} \\notin B,\\cdots, Y_1\\notin B,Z_1\\notin B \\mid \\boldsymbol{\\xi_0}\\big),\n\\end{equation}\\]\n\nEl resultado (i) se desprende del teorema 2.4. De manera similar, el resultado (ii) se sigue inmediatamente a partir de (i) y el hecho de que \\(\\small{\\boldsymbol{(I-N)1'}=\\displaystyle\\sum_{j\\in B}{B'}_j}\\). \\(\\hspace{1cm}\\Box\\)\nLa prueba anterior está guiada por el hecho de que todos los estados en \\(\\small{B}\\) son estados absorbentes con respecto a la nueva cadena de Markov \\(\\small{\\{Z_t\\}}\\) y, por lo tanto, por ejemplo, para cada \\(\\small{i \\in \\Omega-B}\\), la probabilidad \\(\\small{\\mathbb{P}(Z_{n-1}=i)}\\) se puede dividir en dos partes de la siguiente manera:\n\n\n\\[\\begin{align*}\n\\mathbb{P}\\big(Z_{n-1} = i \\mid \\boldsymbol{\\xi_0}\\big) & =\n\\mathbb{P}\\big(Z_{n-1} =i, Z_{n-2} \\notin B,\\cdots, Z_1\\notin B \\mid \\boldsymbol{\\xi_0}\\big)\\\\\n& + \\mathbb{P}\\big(Z_{n-1} =i \\text{ y por lo menos uno de } Z_{n-2},\\cdots ,Z_1 \\text{ esta dentro de } B \\mid \\boldsymbol{\\xi_0}\\big)\n\\end{align*}\\]\n\nen donde la segunda parte es siempre cero (ya que \\(\\small{i \\in \\Omega-B}\\) y \\(\\small{p_{ij}^{\\ast}\\equiv 0}\\) para todos \\(\\small{j \\in B}\\)). Tenga en cuenta que, en el teorema 2.5, asumimos la distribución inicial \\(\\small{(\\boldsymbol{\\xi:0})}\\)), lo que equivale a decir \\(\\small{\\mathbb{P}\\big(Y_0\\in B\\big)\\equiv 1}\\). En consecuencia, la probabilidad \\(\\small{\\mathbb{P}\\big(Y_n \\in B,Y_{n-1}\\notin B,\\cdots,Y_1 \\notin B \\mid \\boldsymbol{\\xi_0}\\big)}\\) se conoce como probabilidad de primera entrada.\nEjemplo 2.6 Sea \\(\\small{\\{Y_t\\}}\\) una cadena de Markov homogénea definida en el espacio de estados \\(\\small{\\Omega=\\{1,2,3,4,5\\}}\\) con matriz de probabilidad de transición\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\n\\begin{array}{ccccc}&\n\\begin{array}{ccccc}\n\\end{array}\n\\\\\n\\begin{array}{ccccc}\n1 \\\\\n2 \\\\\n3\\\\\n4\\\\\n5\n\\end{array}\n&\n\\left(\n\\begin{array}{ccccc}\n1/2 & 1/4 & 1/4  & 0 &  0 \\\\\n1/4 & 1/2  & 0  &  1/4 & 0 \\\\\n1/4 & 1/4  &  0 & 0 & 1/2 \\\\\n0&  0 & 0 &  1 &0 \\\\\n0&  0 & 0 &  0 & 1 \\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nSupongamos que \\(\\small{B = \\{3, 4\\}}\\), entonces la matriz de probabilidad de transición de \\(\\small{B = \\{Y_t\\}}\\) se puede reorganizar como:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\n\\begin{array}{ccccc}&\n\\begin{array}{ccccc}\n\\end{array}\n\\\\\n\\begin{array}{ccccc}\n1 \\\\\n2 \\\\\n3\\\\\n4\\\\\n5\n\\end{array}\n&\n\\left(\n\\begin{array}{ccc|cc}\n1/2 & 1/4 & 0  & 1/4 &  0 \\\\\n1/4 & 1/2  & 0  &  0 & 1/4 \\\\\n0 & 0 &  1 & 0 & 0 \\\\\n\\hline\n1/4 &  1/4 & 1/2 &  0 & 0 \\\\\n0&  0 & 0 &  0 & 1 \\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nDada una distribución inicial de \\(\\small{Y_0}\\), digamos \\(\\small{\\mathbb{P}(Y_0=1)=1}\\), la probabilidad de primera entrada para \\(\\small{Y_n=3}\\), es\n\n\n\\[\\begin{align*}\n& \\quad \\,\\mathbb{P}\\big(Y_n =3,Y_{n-1} \\notin B,\\cdots,Y_1\\notin B \\mid Y_0 = 1\\big)\n\\\\\n& =(0,0,1)\n\\left(\\begin{array}{ccc}\n1/2 & 1/4 & 0\\\\\n1/4 & 1/2 & 0\\\\\n0 & 0 & 1\n\\end{array} \\right)^{n-1}\n\\left(\\begin{array}{c}\n1/4\\\\\n0\\\\\n0\n\\end{array} \\right)\\\\\n\\end{align*}\\]\n\nPara \\(\\small{n = 3}\\), obtenemos que \\(\\small{\\mathbb{P}\\big(Y_n =3,Y_{3} \\notin B,Y_1\\notin B \\mid Y_0 = 1\\big)=5/64}\\). Tenga en cuenta que dado que el estado “\\(\\small{5}\\)” es un estado absorbente, los cálculos se pueden reducir aún más a:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(Y_n =3,Y_{n-1} \\notin B,\\cdots,Y_1\\notin B \\mid Y_0 = 1\\big)=(1,0)\n\\left(\\begin{array}{ccc}\n1/2 & 1/4 \\\\\n1/4 & 1/2\n\\end{array} \\right)^{n-1}\n\\left(\\begin{array}{c}\n1/4\\\\\n0\n\\end{array} \\right) \\hspace{5cm}\\Diamond\n  \\end{equation}\\]\n\nSea \\(\\small{A}\\) el conjunto que contenga todos los estados absorbentes de \\(\\small{\\{Y_t\\}}\\) y sea \\(\\small{B^{\\ast}= A \\cup B}\\). La matriz de probabilidad de transición \\(\\small{\\boldsymbol{M^{*}}}\\) , correspondiente a la cadena de Markov asociada \\(\\small{\\{Z_t\\}}\\) en la que todos los estados en \\(\\small{B^{\\ast}}\\) se toman como estados absorbentes, puede entonces reordenarse como:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M^{\\ast}}=\n\\begin{array}{cc}\n{\\Omega-B^{\\ast}} \\\\B^{\\ast} \\end{array}\n\\left(\\begin{array}{c|c}\n\\boldsymbol{N^{\\ast}} & \\boldsymbol{B^{\\ast}}\\\\\n\\hline\n\\boldsymbol{J} &  \\boldsymbol{Q}\n\\end{array}\n\\right)\n\\end{equation}\\]\n\nen donde \\(\\small{\\boldsymbol{N^{*}}}\\) es la submatriz esencial de \\(\\small{\\boldsymbol{M^{*}}}\\), y \\(\\small{\\boldsymbol{B^{*}}}\\) es la matriz formada a partir de \\(\\small{\\boldsymbol{M^{*}}}\\) mediante la eliminación de todas las columnas asociadas con los estados en \\(\\small{\\Omega-B^{*}}\\) y de todas las filas asociadas con los estados en \\(\\small{B^{*}}\\). Entonces se cumple el siguiente corolario.\nColorario: Para todo \\(\\small{j\\in B}\\)\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(Y_n =j,Y_{n-1} \\notin B,\\cdots,Y_1\\notin B \\mid (\\boldsymbol{\\xi}:\\boldsymbol{0}) \\big)= \\boldsymbol{\\xi^{\\ast}}(\\boldsymbol{N^{\\ast}})^{n-1}B_{j}^{*'},\n\\end{equation}\\]\n\nsiendo \\(\\small{B_{j}^{*'}}\\) la \\(j-\\)ésima columna de la matriz \\(\\small{\\boldsymbol{B^{\\ast}}}\\)\nLa prueba del corolario anterior es sencilla y se deja en manos del lector. Tenga en cuenta que el tamaño de la matriz \\(\\small{\\boldsymbol{N^{\\ast}}}\\) es menor o igual que el tamaño de \\(\\small{\\boldsymbol{N}}\\).\n\n\n\n\n\n\nAunque las rachas y patrones en una sucesión de ensayos de Bernoulli son casos especiales de los ensayos multiestados, merecen un capítulo aparte debido a su larga historia, la gran cantidad de resultados asociados y su amplia aplicación a numerosos campos. El enfoque de este capítulo será derivar las distribuciones para las estadísticas de rachas más comunes y útiles en ensayos de Bernoulli mediante la técnica de incrustación de cadenas finitas de Markov, y también en extender estos resultados a secuencias de ensayos de dos estados dependientes de Markov. También se presentan técnicas para obtener ecuaciones recursivas y funciones generadoras de probabilidad de estadísticas de rachas a través del enfoque de incrustación de cadenas finitas de Markov. Estas herramientas pueden ser muy útiles para estudiar ciertas características de las distribuciones de rachas, como la media, la varianza y los momentos superiores.\nEn este capítulo se tratan las siguientes estadísticas de rachas, definidas tradicionalmente en una secuencia de \\(\\small{n}\\) ensayos de Bernoulli:\n(i) \\(\\small{N_{n,k}}\\) el número de \\(\\small{k}\\) éxitos consecutivos no superpuestos;\n(ii) \\(\\small{G_{n,k}}\\) el número de rachas exitosas de tamaño mayor o igual a \\(\\small{k}\\).\n(iii) \\(\\small{M_{n,k}}\\) el número de \\(\\small{k}\\) éxitos consecutivos solapados.\n(iv) \\(\\small{E_{n,k}}\\) el número de rachas de exctamente \\(\\small{k}\\) éxitos.\n(v) \\(\\small{L_{n,k}}\\) el tamaño de la racha de exitos más larga;\n(vi) \\(\\small{S_{n,k}}\\) el número total de éxitos en rachas exitosas de longitud mayor o igual a \\(\\small{k}\\) .\nTambién se trata la distribución del tiempo de espera de una racha de éxitos y se incluyen algunos resultados numéricos para las distribuciones de las estadísticas de las rachas anteriores.\n\n\n\nEl número de rachas de \\(\\small{k}\\) éxitos consecutivos no superpuestos, \\(\\small{N_{n,k}}\\), en una secuencia de \\(\\small{n}\\) ensayos de Bernoulli es probablemente la estadística de ejecuciones más importante, no sólo por su amplia aplicación a diversas áreas sino también por su conexión con otras estadísticas de rachas; En teoría de la distribución, la distribución de \\(\\small{N_{n,k}}\\) se conoce como distribución binomial de orden \\(\\small{k}\\). Philippou y Makri (1986) e Hirano (1986) dieron de forma independiente una fórmula para la distribución exacta de \\(\\small{N_{n,k}}\\) en una secuencia de \\(\\small{n}\\) ensayos de Bernoulli como:\n\n\n\\[\\begin{equation}\n\\mathbb{P}(N_{n,k}=x)=\\sum_{m=0}^{k-1}\\sum_{x_1+x_2+\\cdots+\\\\\nkx_k=n-m-km}\\binom{x_1+x_2+\\cdots+x_k+x}{x_1,x_2,\\cdots,x_k,x}p^n\\Big(\\frac{q}{p}\\Big)^{x_1+x_2+\\cdots+x_k},\n\\end{equation}\\]\n\nen donde, \\(\\small{x=0,1,\\ldots,[n/k]}\\,\\) (\\(\\small{[n/k]}\\) la parte entera de \\(\\small{n/k}\\)) y con probabilidades de éxito \\(\\small{p}\\) y fracaso \\(\\small{p=1-p}\\). Godbole (1990) dio una fórmula alternativa para la función de probabilidad de \\(\\small{N_{n,k}}\\) con \\(\\small{k&gt;1}\\):\n\n\n\\[\\begin{align*}\n\\mathbb{P}(N_{n,k}=x) &=\\sum_{[(n-kx)/k]\\leq y \\leq n-kx} \\binom{y+x}{x}q^yp^{n-y}\\\\\n& \\times \\sum_{0 \\leq j \\leq  [(n-kx-y)/k]}(-1)^j \\binom{y+1}{j} \\binom{n-kx-jk}{y},\n\\end{align*}\\]\n\npara \\(\\small{x=0,1,\\ldots,[n/k]}\\,\\). La fórmula (3.2) tiene la ventaja sobre la (3.1) de que es más fácil de evaluar por computadora para \\(\\small{n}\\,\\) grande. Hirano y Aki (1987, 1993) estudiaron algunas propiedades de esta distribución y ampliaron los resultados al caso de ensayos de Markov dependientes de dos estados.\nPara comenzar nuestro estudio de \\(\\small{N_{n,k}}\\) utilizando el método de incrustación de cadenas finitas de Markov, consideremos el espacio de estados\n\n\n\\[\\begin{equation}\n\\Omega =\\{(x,i):x=0,1,\\cdots,l_n\\, \\text{y}\\, 0,1,\\cdots,k-1\\},\n\\end{equation}\\]\n\nen donde, \\(\\small{l_n=[n/k]}\\,\\) es el número máximo de rachas exitosas no superpuestas de longitud \\(\\small{k}\\) que pueden ocurrir en \\(\\small{n}\\) ensayos. Ahora definamos la Cadena de Markov finita homogenea \\(\\small{\\{Y_t:t=0,1,\\ldots,n\\}}\\,\\) sobre \\(\\small{\\Omega}\\,\\) como sigue:\n\n\n\\[\\begin{equation}\nY_t=(N_{t,k},E_{t}),\\quad \\text{para }1\\leq t \\leq n,\n\\end{equation}\\]\n\ndonde \\(\\small{N_{n,k}}\\) es el número de \\(\\small{k}\\) éxitos consecutivos no superpuestos que ocurrieron durante los primeros \\(\\small{t}\\) ensayos \\(\\small{X_1,X_2,\\ldots,X_n}\\). El “bloque final” \\(\\small{E_t}\\) es igual a \\(\\small{m}\\) módulo \\(\\small{k}\\), donde \\(\\small{m}\\) representa el número de éxitos finales (posiblemente cero) que existen en la sucesión después de las primeros \\(\\small{t}\\) ensayos:\n\n\n\\[\\begin{equation}\nFFSSF\\underbrace{SS\\cdots S}_{m}.\n\\end{equation}\\]\n\nObservemos que \\(\\small{E_t=0}\\) si \\(\\small{m}\\) es un múltiplo positivo de \\(\\small{k}\\) o si el \\(\\small{t-}\\)ésimo resultado es \\(\\small{F}\\). Esta variable de bloque final realiza un seguimiento del número de éxitos en una posible racha parcial asociada con en el \\(\\small{t-}\\)ésimo ensayo. Por ejemplo, dados \\(\\small{n=10}\\) ensayos de Bernoulli con resultados \\(\\small{\\{FSFFSSSFSS\\}}\\) y una duración de ejecución exitosa elegida de \\(\\small{k=2}\\), la realización de la cadena de Markov incorporada \\(\\small{\\{Y_t: t = 1,2,\\ldots, 10\\}}\\) con respecto a estos diez resultados es: \\(\\small{\\{Y_1=(0,0), Y_2 = (0, 1), Y_3=(0,0), Y_4=(0,0),Y_5= (0,1),Y_6 = (1,0), Y_7=(1, 1), Y_8=(1,0),Y_9=(1,1), Y_{10}=(2,0)\\}}\\). Tenga en cuenta que para una secuencia dada de resultados \\(\\small{\\{FS\\cdots SF\\}}\\), la realización de \\(\\small{\\{Y_t\\}}\\) es siempre única.\nDefinir los subconjuntos\n\n\n\\[\\begin{equation}\nC_x =\\{(x,i): i=0,1,\\cdots,k-1\\},\\quad 0\\leq x \\leq l_n\n\\end{equation}\\]\n\nLa colección de subconjuntos \\(\\small{\\{C_x:x = 0,1,\\ldots,l_n\\}}\\) forma una partición del espacio de estados \\(\\small{\\Omega}\\). Dado que \\(\\small{\\{X_t\\}}\\) es, por el momento, una sucesión de ensayos Bernoulli, de las definiciones anteriores se deduce que \\(\\small{Y_t}\\) tiene una matriz de probabilidad de transición \\(\\small{\\boldsymbol{M_t} = (p_{(x,i)(y,j)})}\\) para todo \\(\\small{t=1,2,\\ldots,n}\\), con las probabilidades de transición \\(\\small{(p_{(x,i)(y,j)})}\\) dadas por la siguiente ecuación: para \\(\\small{1 \\leq t \\leq n}\\) y \\(\\small{0 \\leq x \\leq l_n}\\) \n\n\\[\\begin{align*}\np_{(x,i)(y,j)} & = \\mathbb{P}\\big(Y_t=(y,j)\\mid Y_{t-1}=(x,i)\\big)\\\\\n& =\\begin{cases}\nq \\quad \\text{si }y=x\\,\\text{y }j=0,\\,\\text{para }i=0,1,\\ldots, k-1\n\\\\\np \\quad \\text{si }y=x\\,\\text{y }j=i+1,\\,\\text{para }i=0,1,\\ldots, k-2\n\\\\\np \\quad \\text{si }y=x+1\\,\\text{y }j=0,\\,\\text{para }i=k-1\\,\\text{y },x=0,1,\\ldots, l_{n}-1\n\\\\\n1 \\quad \\text{si }y=x=l_{n}\\,\\text{y }j=i=k-1\n\\\\\n0 \\quad \\text{en otro caso}\n\\end{cases}\n\\end{align*}\\]\n\nA modo de ilustración, la matriz de probabilidad de transición \\(\\small{\\boldsymbol{M_t}}\\) de la cadena de Markov incrustada \\(\\small{{Y_t}}\\) asociada con la variable aleatoria \\(\\small{N_{5,2}}\\) viene dada por\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\n\\begin{array}{cccccc}&\n\\begin{array}{cccccc}\n\\end{array}\n\\\\\n\\begin{array}{cccccc}\n(0,0)\\\\\n(0,1)\\\\\n(1,0)\\\\\n(1,1)\\\\\n(2,0)\\\\\n(2,1)\n\\end{array}\n&\n\\left(\n\\begin{array}{cc|cc|cc}\nq&p&0&0&0&0\\\\\nq&0&p&0&0&0\\\\\n\\hline\n0&0&q&p&0&0\\\\\n0&0&q&0&p&0\\\\\n\\hline\n0&0&0&0&q&p\\\\\n0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}_{6\\times6}\n\\end{equation}\\]\n\npara \\(\\small{1\\leq t \\leq 5.}\\)\nPara el caso donde \\(\\small{\\{X_t\\}}\\) es una sucesión de ensayos de dos estados independientes pero no idénticamente distribuidos con probabilidades \\(\\small{\\mathbb{P}(X_t=S)=p_t}\\) y \\(\\small{\\mathbb{P}(X_t=F)=q_t}\\) , para \\(\\small{t=1,2,\\ldots,n}\\), las matrices de transición \\(\\small{\\boldsymbol{M_t}}\\) para la cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) permanece sin cambios excepto que la probabilidad \\(\\small{p}\\) se reemplaza por \\(\\small{p_t}\\) y \\(\\small{q}\\) se reemplaza por \\(\\small{q_t}\\). En general, para ensayos de dos estados independientes pero no idénticamente distribuidos, las matrices de probabilidad de transición se pueden escribir como\n\n\n\\[\\begin{equation}\n\\boldsymbol{M_t}(N_{n,k})=\n\\left(\\begin{array}{cccc}\n\\boldsymbol{A_t}&\\boldsymbol{B_t}&&&\\boldsymbol{0}\\\\\n&&\\ddots&\\ddots&\\\\\n\\boldsymbol{0}&&&\\boldsymbol{A_t}&\\boldsymbol{B_t}\\\\\n&&&&\\boldsymbol{A_{t}^{\\ast}}\\\\\n\\end{array}\\right)_{d\\times d},\n\\end{equation}\\]\n\npara \\(\\small{t=1,2,\\dots,n}\\), en donde:\n\n\n\\[\\begin{equation}\n\\boldsymbol{A_t}=\n\\left(\\begin{array}{ccccc}\nq_t&p_t&0&\\cdots&0\\\\\nq_t&0&p_t&\\cdots&0\\\\\n\\vdots& &\\ddots&\\ddots&\\\\\n\\vdots& & &\\ddots&p_t\\\\\nq_t&0&0&\\cdots&0\\\\\n\\end{array}\\right)_{k\\times k},\n\\end{equation}\\]\n\n\\(\\small{\\boldsymbol{B_t}}\\) es una matriz \\(\\small{k\\times k}\\) que tiene \\(\\small{p_t}\\) en la entrada \\(\\small{(k,1)}\\) y cero en el resto, \\(\\small{\\boldsymbol{A_t}^{\\ast}}\\) es igual que \\(\\small{\\boldsymbol{A_t}}\\) excepto que su última fila se reemplaza con \\(\\small{(0,0,...,0,1)}\\), y la dimensión de \\(\\small{\\boldsymbol{M_t}(N_{n,k})}\\) viene dado por \\(\\small{d = k(l_n+1)}\\). Por tanto, en virtud del teorema 2.1, podemos afirmar que\n\n\n\\[\\begin{equation}\n\\small{\\mathbb{P}\\big( N_{n,k}=x\\big)=\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\prod_{t=1}^{n}\\boldsymbol{M}_t(N_{n,k})\\Big)\\boldsymbol{\\mathbf{U}'}(\\mathbf{C_x})},\\,\\,  x=1,2,\\ldots,l_n,\n\\end{equation}\\]\n\nen donde, \\(\\small{\\boldsymbol{\\mathbf{\\xi}}_0=(1,0,\\ldots,0)_{1\\times d}}\\) y \\(\\small{\\boldsymbol{\\mathbf{U}'}({C_x})}\\) es la transpuesta del vector \\(\\small{\\boldsymbol{\\mathbf{U}'}({C_x})=(0,\\ldots,0, 1,\\ldots, 1, 0,\\ldots,0)}\\) con unos en las ubicaciones asociadas con los estados en \\(\\small{C_x}\\). La ecuación (3.8) representa la distribución exacta de \\(\\small{N_{n,k}}\\) para ensayos independientes de dos estados distribuidos tanto de forma idéntica como no idéntica. En vista de la matriz de probabilidad de transición en la ecuación (3.7), \\(\\small{N_{n,k}}\\) es una cadena finita de Markov incrustable de tipo binomial en el sentido de la Definición 2.7 (Koutras y Alexandrou 1995).\nSi \\(\\small{\\{X_t\\}}\\) es una Cadena de Markov no homogenea com matriz de probabilidades de transición:\n\n\n\\[\\begin{equation}\n\\left(\\begin{array}{cc}\np_{FF}(t)&p_{SS}(t)\\\\\np_{FF}(t)&p_{SS}(t)\n\\end{array}\\right),\n\\end{equation}\\]\n\nentonces, es necesaria una modificación menor en el procedimiento de incrustación para obtener la distribución de \\(\\small{N_{n,k}}\\). Dado que el resultado de \\(\\small{X_{t+1}}\\), y por tanto también de \\(\\small{Y_{t+1}}\\), ahora depende de \\(\\small{X_t}\\), cada estado de la cadena de Markov \\(\\small{Y_t}\\) debe implicar un cierto resultado de \\(\\small{X_t}\\). Este ya es el caso en nuestra definición anterior de \\(\\small{Y_t}\\), salvo para los estados con un bloque final de \\(\\small{E_t=0}\\), que puede surgir para cualquier resultado de \\(\\small{X_t}\\). Para resolver esta ambigüedad, definimos un estado de bloque final adicional, \\(\\small{E_t=\\gamma}\\), para corresponder al caso donde la serie de éxitos finales es un múltiplo distinto de cero de \\(\\small{k}\\) éxitos, y reservamos el estado \\(\\small{E_t=0}\\) para el caso donde el resultado \\(\\small{t-}\\)ésimo es un fracaso. La cadena de Markov incrustada se define entonces de la siguiente manera:\n\n\n\\[\\begin{equation}\nY_t =\n\\begin{cases}\n(x,\\gamma) & \\begin{array}{l} \\text{Si existen } x \\text{ rachas de } k \\text{ aciertos} \\\\\n\\text{consecutivos en los primeros } t \\\\\n\\text{ensayos con } m &gt; 0 \\text{ aciertos finales}\\\\\n\\text{tales que } m \\equiv k \\pmod{k} \\end{array} \\\\\n\\\\\n(x,0) & \\begin{array}{l}\\text{Si existen } x \\text{ rachas de } k \\text{ aciertos}\\\\\n\\text{consecutivos en los primeros } t\\text{ ensayos} \\\\ \\text{con } m = 0 \\text{ aciertos finales} \\text{ (}X_t=F\\text{)} \\end{array}\n\\end{cases}\n\\end{equation}\\]\n\ny \\(\\small{Y_t=(x,i)}\\), para \\(\\small{i=1,2,\\ldots,k-1}\\) se define como se indica en la ecuación (3.3). La diferencia entre los estados \\(\\small{(x,\\gamma)}\\) y \\(\\small{ (x,0)}\\) se puede ver en el siguiente ejemplo: para una racha exitosa de longitud \\(\\small{k=2}\\), \\(\\small{Y_8=(SFFFSSSS) = (2,\\gamma)}\\) y \\(\\small{Y_8=(SFSSFSSF)= (2,0)}\\). Tenga en cuenta que el bloque final \\(\\small{E_t}\\) ahora contiene no solo la información requerida sobre los subpatrones sino que también implica el resultado de \\(\\small{X_t}\\), lo que permite la asignación de probabilidades de transición para la Cadena de Markov incustada.\nLas matrices de probabilidad de transición correspondientes a estas definiciones pueden deducirse fácilmente. La cadena de Markov incrustada asociada con la variable aleatoria \\(\\small{N_{5,2}}\\) como se considera en la Ecuación (3.6) para ensayos de Bernoulli, tiene las siguientes matrices de transición \\(\\small{\\boldsymbol{M_t^{\\ast}}}\\) bajo ensayos dependientes de Markov no homogéneos: para \\(\\small{t=1,2,\\ldots,n}\\)\n\n\n\\[\\begin{equation}\n\\boldsymbol{M_t^*}(N_{5,2})=\n\\begin{array}{cc}\n\\begin{array}{c}\n(0,0)\\\\\n(0,1)\\\\\n(1,c)\\\\\n(1,0)\\\\\n(1,1)\\\\\n(2,c)\\\\\n(2,1)\\\\\n(2,1)\n\\end{array}&\n\\left(\n\\begin{array}{cc|ccc|ccc}\np_{FF}(t)&p_{FS}(t)&0&0&0&0&0&0\\\\\np_{FS}(t)&0&p_{SS}(t)&0&0&0&0&0\\\\\n\\hline\n0&0&0&p_{SF}(t)&p_{SS}(t)&0&0&0\\\\\n0&0&0&p_{FF}(t)&p_{FS}(t)&0&0&0\\\\\n0&0&0&p_{SF}(t)&0&p_{SS}(t)&0&0\\\\\n\\hline\n0&0&0&0&0&&p_{SF}(t)&p_{SS}(t)\\\\\n0&0&0&0&0&0&p_{FF}(t)&p_{FS}(t)\\\\\n0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nNote que la estructura de “franja/banda” de \\(\\small{\\boldsymbol{M_t^{\\ast}}(N_{5,2})}\\) es similar con \\(\\small{\\boldsymbol{M_t}(N_{5,2})}\\) de la ecuación (3.6) para ensayos de Bernoulli. Como es sencillo derivar la forma general de \\(\\small{\\boldsymbol{M_t^{\\ast}}(N_{n,k})}\\) análoga a la ecuación (3.7), esto lo dejamos al lector interesado.\nCuando la secuencia \\(\\small{\\{X_t\\}}\\) es i.i.d., la distribución inicial \\(\\small{\\boldsymbol{\\xi}_0}\\) puede definirse como \\(\\small{\\mathbb{P}\\big(Y_0=(0,0)\\big)=1}\\), y luego para \\(\\small{k&gt;1}\\), las probabilidades de transición \\(\\small{\\mathbb{P}\\big(Y_1=(0,1)\\mid Y_0=(0,0)\\big)=p}\\) y \\(\\small{\\mathbb{P}\\big(Y_1=(0,0)\\mid Y_0=(0,0)\\big)=q=(1-p)}\\). Sin embargo, cuando \\(\\small{\\{X_t\\}}\\) es una sucesión de variables aleatorias Markov-Dependientes , se debe tener cuidado al asumir \\(\\small{\\mathbb{P}\\big(Y_0=(0,0)\\big)=1}\\), lo que implicaría que las probabilidades de transición entre \\(\\small{Y_0}\\) e \\(\\small{Y_1}\\) están dadas por \\(\\small{\\mathbb{P}\\big(Y_1=(0,1)\\mid Y_0=(0,0)\\big)=p_{FS}(1)}\\) y \\(\\small{\\mathbb{P}\\big(Y_1=(0,0)\\mid Y_0=(0,0)\\big)=p_{FF}=1}\\), independiente de \\(\\small{p_{SF}}\\) y \\(\\small{p_{FF}}\\). Para evitar este tipo de sesgo, es útil crear un estado ficticio \\(\\small{\\emptyset}\\) como estado inicial para \\(\\small{Y_0}\\). Luego definimos \\(\\small{\\mathbb{P}\\big(Y_0=\\emptyset\\big)=1}\\), y las probabilidades de transición \\(\\small{\\mathbb{P}\\big(Y_1=(0,1)\\mid Y_0=\\emptyset\\big)=p_{s}}\\), y \\(\\small{\\mathbb{P}\\big(Y_1=(0,0)\\mid Y_0=\\emptyset\\big)=p_{f}}\\). Por tanto, para \\(\\small{N_{5,2}}\\) la correspondiente cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) se define en el espacio de estados expandido \\(\\small{\\Omega=\\{\\emptyset,(0,0),(0,1),(1,0),\\ldots\\}}\\) con matrices de probabilidad de transición:\n\n\n\\[\\begin{equation}\n\\begin{array}{cc} &\n\\begin{array}{cccccc}(0,0)&(0,1)&(1,c)&(1,0)&(1,1)&\\cdots\n\\end{array}\\\\\n\\begin{array}{cccccccc}\n\\end{array}\n&\n\\left(\n\\begin{array}{c|ccccc}\n0 &  p_{f}  & p_{s} &  0  &   0 & \\cdots \\\\\n\\hline\n\\, 0&&&&&\\\\\n0&&&\\boldsymbol{M_t}^{\\ast}(N_{5,2})&&\\\\\n0&&&&&\\\\\n\\end{array}\n\\right)\\end{array}\n\\end{equation}\\]\n\nTenga en cuenta que el procedimiento de incrustación de cadenas finitas de Markov utilizado para obtener la distribución exacta de \\(\\small{N_{n,k}}\\) sigue siendo el mismo, excepto por diferencias menores en las matrices de probabilidad de transición, independientemente de si la secuencia de ensayos \\(\\small{\\{X_t\\}}\\) es i.i.d., independiente pero no idéntica distribuida o si es Markov-Dependiente.\n\n\n\nPara una sucesión de ensayos de dos estados, la variable aleatoria \\(\\small{G_{n,k}}\\) se define como el número de rachas exitosas de longitud mayor o igual a \\(\\small{G_{n,k}}\\). Consideremos una cadena de Markov finita \\(\\small{\\{Y_t:t=0,1,2,\\ldots,n\\}}\\) definida en el espacio de estados:\n\n\n\\[\\begin{equation}\n\\Omega =\\{(x,i):x=0,1,\\cdots,l_n\\,\\, \\text{y}\\,\\, i= \\gamma,0,1,\\cdots,k-1\\}-{\\{(0,\\gamma)\\}},\n\\end{equation}\\]\n\nen donde, \\(\\small{l_n=[(n+1)/(k+1)]}\\). Para una sucesión de resultados de los primeros \\(\\small{t}\\) ensayos con \\(\\small{m}\\) éxitos finales, digamos \\(\\small{FS \\cdots F \\underbrace{SS \\cdots}_{m}S}\\), definimos la cadena de Markov:\n\n\n\\[\\begin{equation}\nY_t=(G_{n,k},E_t) \\quad 1\\leq t\\leq n,\n\\end{equation}\\]\n\ndonde \\(\\small{G_{n,k}}\\), es el número de rachas exitosas de longitud mayor o igual a \\(\\small{k}\\) en la sucesión \\(\\small{\\{X_t\\}}\\), y \\(\\small{E_t}\\) es la variable del bloque final con \\(\\small{E_t=m}\\) si \\(\\small{m=0,1,2,\\ldots,k-1}\\), y \\(\\small{E_t=\\gamma}\\) si \\(\\small{m\\geq k}\\). Para ilustrar esta definición, considere una longitud de racha mínima de \\(\\small{k=2}\\) y los siguientes doce resultados, de un ensayo de dos estados: \\(\\small{FSFFSSFSSSFS}\\), para los cuales \\(\\small{G_{12,2}=2}\\). Se deduce de la Ec.(3.9) que la realización de la Cadena de Markov \\(\\small{\\{Y_t:t=0,1,2,\\ldots,14\\}}\\) es : \\(\\small{\\{Y_1=(0,0),Y_2=(0,1),Y_3=(0,0),Y_4=(0,0),Y_5=(0,1),Y_6=(1,\\gamma),Y_7=(1,0),Y_8=(1,1),Y_9=(2,\\gamma),Y_{10}=(2,\\gamma),Y_{11}=(2,0),Y_{12}=(2,0)\\}}\\). Note que el bloque final \\(\\small{E_t=\\gamma}\\) puede ocurrir sólo cuando hay al menos \\(\\small{k}\\) éxitos finales, en cuyo caso \\(\\small{G_{n,k}\\geq k}\\) por esta razón, el estado \\(\\small{(0,\\gamma)}\\) fue excluido en la definición anterior del espacio de estados \\(\\small{\\Omega}\\).\nDe la definición de la cadena de Markov incrustada dada por la Ecu. (3.9), las probabilidades de transición de un paso en \\(\\small{\\boldsymbol{M_t}(G_{n,k})}\\) para ensayos independientes pero no identicamente distribuidos se especifican mediante la siguiente ecuación: para \\(\\small{t=1,2,\\ldots,n}\\)\n\n\n\\[\\begin{equation}\np_{(x,i)(y,i)}(t) =\n\\begin{cases}\nq_t & \\begin{array}{l} \\text{Si}\\,\\, y=x \\,\\, \\text{y}\\,\\, j=0 \\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n \\,\\text{y}\\, i=\\gamma,0,1,\\ldots,k-1  \\end{array} \\\\\np_t & \\begin{array}{l} \\text{Si}\\,\\, y=x \\,\\, \\text{y}\\,\\, j=i=\\gamma\\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n  \\end{array}\n\\\\\np_t & \\begin{array}{l} \\text{Si}\\,\\, y=x \\,\\, \\text{y}\\,\\, j=i+1\\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n \\,\\text{y}\\, i=\\gamma,0,1,\\ldots,k-2  \\end{array}\n\\\\\np_t & \\begin{array}{l} \\text{Si}\\,\\, y=x+1,\\,i=k-1 \\,\\, \\text{y}\\, j=\\gamma \\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n-1  \\end{array}\n\\\\\n1 & \\begin{array}{l} \\text{Si}\\,\\, y=x=l_n,\\,j=x=k-1\\end{array} \\\\\n0 & \\begin{array}{l} \\text{Otro caso} \\end{array}\n\\end{cases}\\\\\n\\end{equation}\\]\n\nEn el caso especial de \\(\\small{n=5}\\) y \\(\\small{k=2}\\) la matriz de probabilidades de transición \\(\\small{\\boldsymbol{M_t}(G_{n,k})}\\) esta dada por:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M_t}(G_{5,2})=\n\\begin{array}{cc}&\n\\begin{array}{cccccc}\n\\end{array}\n\\\\\n\\begin{array}{cccccc}\n(0,0)\\\\\n(0,1)\\\\\n(1,\\gamma)\\\\\n(1,0)\\\\\n(1,1)\\\\\n(2,\\gamma)\\\\\n(2,0)\\\\\n(2,1)\n\\end{array}\n&\n\\left(\n\\begin{array}{cc|c|cc|c|cc}\nq_t&p_t&0&0&0&0&0&0\\\\\nq_t&0&p_t&0&0&0&0&0\\\\\n\\hline\n0&0&p_t&q_t&0&0&0\\\\\n\\hline\n0&0&0&q_t&p_t&0&0&0\\\\\n0&0&0&q_t&0&p_t&0&0\\\\\n\\hline\n0&0&0&0&0&p_t&q_t&0\\\\\n\\hline\n0&0&0&0&0&0&q_t&p_t\\\\\n0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\npara \\(\\small{t=1,2,\\ldots,5}\\). En general \\(\\small{\\boldsymbol{M_t}(G_{n,k})}\\) es una matriz bidiagonal de bloques de la forma: \n\n\\[\\begin{equation}\n\\left(\n\\begin{array}{ccccccc}\n\\boldsymbol{A_t}&p_t\\boldsymbol{e_k'}&&&&&\\boldsymbol{O}\\\\\n&p_t&q_t\\boldsymbol{e_1}&&\\boldsymbol{O}&&\\\\\n&&\\boldsymbol{A_t}&p_t\\boldsymbol{e_k'}&&&\\\\\n&&&\\ddots&\\ddots&&\\\\\n&&&&\\ddots&\\ddots&\\\\\n&&\\boldsymbol{O}&&&p_t&q_t\\boldsymbol{e_1}\\\\\n\\boldsymbol{O}&&&&&&\\boldsymbol{A_t^{\\ast}}\\\\\n\\end{array}\n\\right)\n\\end{equation}\\]\n\nen donde \\(\\small{\\boldsymbol{e_1}=(1,0,\\ldots,0)}\\) y \\(\\small{\\boldsymbol{e_1}=(0,\\ldots,0,1)}\\) son vectores fila unitarios \\(\\small{1\\times k}\\), y \\(\\small{\\boldsymbol{A_t}}\\) es dada por:\n\n\n\\[\\begin{equation}\n\\boldsymbol{A_t} =\\left(\n\\begin{array}{ccccc}\nq_t & p_t & 0  & \\ldots &  0 \\\\\n\\vdots & \\ddots & \\ddots  &    &   \\\\\n\\vdots &  &  \\ddots& \\ddots &   \\\\\n\\vdots&  &   &  \\ddots &p_t \\\\\nq_t&  0 & 0 &  \\cdots & 1 \\\\\n\\end{array}\n\\right)\n\\end{equation}\\]\n\nLa matriz de probabilidad de transición \\(\\small{\\boldsymbol{A_t}}\\), en el contexto de la demografía, a menudo se denomina matriz de Leslie o, más generalmente, matriz de tipo renovación (véase Seneta, 1981). La dimensión de \\(\\small{\\boldsymbol{A_t}(G_{n,k})}\\) es igual a \\(\\small{(l_n+1)(k+1)-1}\\). La matriz \\(\\small{\\boldsymbol{A_t^{\\ast}}}\\) en la Ec. (3.11) es igual que \\(\\small{\\boldsymbol{A_t}}\\) excepto por la última fila, que se reemplaza por \\(\\small{(0,\\ldots,0,1)}\\)\nSi definimos la partición \\(\\small{\\{C_x:i=0,1,2,\\ldots,l_n\\}}\\) sobre \\(\\small{\\Omega}\\)\n\n\n\\[\\begin{align*}\nC_0&=\\{(0,i):i=0,1,\\ldots,k-1\\} \\\\\nC_x&=\\{(0,i):i=\\gamma,0,1,\\ldots,k-1\\},\\,\\text{para}\\, x=1,2,\\ldots,l_n\n\\end{align*}\\]\n\ny en consecuencia \\(\\small{\\mathbb{P}\\big(G_{n,k}=x\\big)=\\mathbb{P}\\big(Y_n \\in C_x \\big)}\\) para todo \\(\\small{x=0,1,2,\\ldots,l_n}\\). La función de distribución, los momentos y la función generadora de probabilidad ahora se pueden calcular fácilmente mediante las ecuaciones (2.11), (2.12) y (2.13), respectivamente.\nPara el caso de ensayos i.i.d., todas las probabilidades de transición serían constantes y se podría llevar a cabo una extensión a los ensayos de Markov-Dependientes como se describe para el estadístico \\(\\small{N_{n,k}}\\) en la sección anterior; En el resto de este capítulo sobre ensayos en dos Estados, nos centraremos principalmente en el caso de ensayos independientes pero no idénticamente distribuidos.\n\n\n\nLa variable aleatoria \\(\\small{M_{n,k}}\\) se define como el número \\(\\small{k}\\) de éxitos consecutivos superpuestos en una sucesión de \\(\\small{n}\\) ensayos independientes de dos estados. La cadena de Markov incrustada \\(\\small{\\{Y_t:t=0,1,2,\\ldots,n\\}}\\) asociada a \\(\\small{M_{n,k}}\\) puede definirse como\n\n\n\\[\\begin{align*}\nY_t=(M_{t,k},E_t),\\quad t=1,2,\\ldots,n\n\\end{align*}\\]\n\nsobre el espacio de estados\n\n\n\\[\\begin{align*}\n\\Omega &=\\{(x,i):x=0,1,\\cdots,l_n-1\\,\\, \\text{e}\\,\\, i=\\gamma, 0,1,\\cdots,k-1\\} \\\\\n& \\cup \\{(l_n,\\gamma)\\}-\\{(0,\\gamma)\\},\n\\end{align*}\\]\n\ndonde \\(\\small{l_n=n-k+1,\\, M_{n,k}}\\) es el número de \\(\\small{k}\\) éxitos consecutivos superpuestos en las primeros \\(\\small{t}\\) ensayos, y \\(\\small{E_t}\\) es la variable del bloque final que lleva la cuenta del número \\(\\small{m}\\) de éxitos finales:\n\n\n\\[\\begin{equation}\nE_t=\\begin{cases}\n\\gamma & \\text{si}\\, m\\geq k\\\\\nm & \\text{si}\\, m=0,1,\\ldots,k-1.\n\\end{cases}\n\\end{equation}\\]\n\nCon conteo superpuesto, es fácil verificar que las probabilidades para las matrices de probabilidad de transición \\(\\small{\\boldsymbol{M_t}=p_{(x,i)(y,j)}(t)}\\) se pueden obtener a partir de la siguiente ecuación:\n\n\n\\[\\begin{equation}\np_{(x,i)(y,j)}(t) =\n\\begin{cases}\nq_t & \\begin{array}{l} \\text{Si}\\,\\, y=x \\,\\, \\text{y}\\,\\, j=0 \\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n \\,\\,\\text{e}\\, i=\\gamma,0,1,\\ldots,k-1 \\end{array} \\\\\np_t & \\begin{array}{l} \\text{Si}\\,\\, y=x \\,\\, \\text{y}\\,\\, j=i+1\\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n \\,\\, \\text{e}\\,\\,i=0,1,\\ldots,k-2 \\end{array}\n\\\\\np_t & \\begin{array}{l} \\text{Si}\\,\\, y=x+1 \\,\\, \\text{y}\\,\\, j=\\gamma\\,\\,\\text{e}\\,\\,i=k-1,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n-1 \\end{array}\n\\\\\np_t & \\begin{array}{l} \\text{Si}\\, y=x+1,\\,j=i=\\gamma\\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n-1  \\end{array}\n\\\\\n1 & \\begin{array}{l} \\text{Si} \\,\\, y=x=l_n,\\,\\text{y}\\ j=i=\\gamma\\end{array} \\\\\n0 & \\begin{array}{l} \\text{Otro caso} \\end{array}\n\\end{cases}\\\\\n\\end{equation}\\]\n\nLa partición correspondiente del espacio de estados \\(\\small{\\Omega}\\) se puede especificar de la siguiente manera:\n\n\n\\[\\begin{align*}\nC_0 &=\\{(x,i):i=0,1,\\cdots,k-1\\}\\\\\nC_x &=\\{(x,i):i=\\gamma,0,1,\\cdots,k-1\\},\\, x=1,\\cdots,l_n,\\\\\nC_{l_n} &= \\{(l_n,\\gamma)\\}\n\\end{align*}\\]\n\nComo ejemplo considerese, \\(\\small{n=4}\\) y \\(\\small{k=2}\\), luego las matrices de probabilidades de transición \\(\\small{\\boldsymbol{M_t}(M_{4,2})}\\) para \\(\\small{t=1,2,3,4}\\) son:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M_t}(M_{4,2})=\n\\begin{array}{cc}&\n\\begin{array}{cccccc}\n\\end{array}\n\\\\\n\\begin{array}{cccccc}\n(0,0)\\\\\n(0,1)\\\\\n(1,\\gamma)\\\\\n(1,0)\\\\\n(1,1)\\\\\n(2,\\gamma)\\\\\n(2,0)\\\\\n(2,1)\\\\\n(3,\\gamma)\n\\end{array}\n&\n\\left(\n\\begin{array}{cc|c|cc|c|cc|c}\nq_t&p_t&0&0&0&0&0&0&0\\\\\nq_t&0&p_t&0&0&0&0&0&0\\\\\n\\hline\n0&0&0&q_t&0&p_t&0&0&0\\\\\n\\hline\n0&0&0&q_t&p_t&0&0&0&0\\\\\n0&0&0&q_t&0&p_t&0&0&0\\\\\n\\hline\n0&0&0&0&0&0&q_t&0&p_t\\\\\n\\hline\n0&0&0&0&0&0&q_t&p_t&0\\\\\n0&0&0&0&0&0&q_t&0&p_t\\\\\n\\hline\n0&0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nEn general para \\(\\small{n}\\) y \\(\\small{k}\\) arbitrareos, las matrices de probabilidad de transición continúan teniendo una forma de bandas similar a \\(\\small{\\boldsymbol{M_t}(M_{4,2})}\\) en la ecuación (3.15), y son de dimensión \\(\\small{l_n(k+1)}\\). La distribución y los momentos de la variable aleatoria \\(\\small{M_{n,k}}\\) se pueden calcular nuevamente mediante las ecuaciones (2.11) y (2.12), respectivamente.\n\n\n\nLa Cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) asociada con la variable aleatoria, \\(\\small{E_{n,k}}\\), del número de rachas exitosas de tamaño exactamente \\(\\small{k}\\) en \\(\\small{n}\\) ensayos independientes de dos estados, se define por:\n\n\n\\[\\begin{equation}\nY_t=(E_{t,k},E_t)\n\\end{equation}\\]\n\nsobre el espacio de estados:\n\n\n\\[\\begin{equation}\n\\Omega =\\{(x,i):x=0,1,\\cdots,l_n\\,\\, \\text{e}\\,\\, i=\\beta,\\gamma,0,1,\\cdots,k-1\\}-\\{(0,\\gamma)\\},\n\\end{equation}\\]\n\nen donde, \\(\\small{l_n=[(n+1)/(k+1)]}\\), \\(\\small{E_{t,k}}\\) es el número de rachas éxitosas de longitud igual a \\(\\small{k}\\) en los primeros \\(\\small{t}\\) ensayos, y el bloque final \\(\\small{E_{t}}\\) se define en función del número de éxitos finales \\(\\small{m}\\), en los primeros \\(\\small{t}\\) ensayos de la siguiente manera:\n\n\n\\[\\begin{equation}\nE_t=\\begin{cases}\nm & \\text{Si}\\,\\, m=0,1,\\ldots,k-1\\\\\n\\gamma & \\text{Si}\\,\\, m = k\\\\\n\\beta & \\text{Si}\\,\\, m&gt;k\n\\end{cases}\n\\end{equation}\\]\n\nLos dos estados del bloque final \\(\\small{\\beta}\\) e \\(\\small{\\gamma}\\) tienes la siguiente interpretación:\n(i) Estado de espera \\(\\small{(x,\\gamma),\\,\\,x=1,2,\\dots,l_n}\\):\n\\(\\small{ Y_t=(x,\\gamma)}\\) significa que \\(\\small{m=k}\\) y que \\(\\small{x-}\\)ésima racha exitosa de tamaño \\(\\small{k}\\) ha ocurrido en el \\(\\small{t-}\\)ésimo ensayo, y\n(ii) Estado de desbordamiento \\(\\small{(x,\\beta),\\,\\,x=1,2,\\dots,l_n}\\):\n\\(\\small{ Y_t=(x,\\beta)}\\) significa que \\(\\small{m&gt;k}\\) y que exactamente \\(\\small{x}\\) rachas exitosas de tamaño \\(\\small{k}\\) han aparecido antes de los últimos \\(\\small{m+1}\\) resultados \\(\\small{(F\\underbrace{S\\cdots S}_{m})}\\).\nCon estos bloques finales en mente, podemos construir fácilmente la partición para el espacio de estados \\(\\small{\\Omega:\\, C_0=\\{(0,i):i=\\beta,0,1,\\ldots, k-1\\} }\\) y \\(\\small{C_x=\\{(x,i):i=\\gamma,\\beta,0,1,\\ldots, k-1\\} }\\), para \\(\\small{x=1,\\ldots,l_n}\\).\nLas probabilidades para las matrices de transición \\(\\small{\\boldsymbol{M_t}(E_{t,k})}\\) de la cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\), se especifican mediante la siguiente ecuación:\n\n\n\\[\\begin{equation}\np_{(x,i)(y,j)}(t) =\n\\begin{cases}\nq_t & \\begin{array}{l} \\text{Si}\\,\\, y=x \\,\\, \\text{y}\\,\\, j=0 \\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n \\,\\,\\text{e}\\,\\, i=\\gamma,\\beta,0,1,\\ldots,k-1 \\end{array} \\\\\np_t & \\begin{array}{l} \\text{Si}\\,\\, y=x \\,\\, \\text{y}\\,\\, j=i+1\\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n \\,\\, \\text{e}\\,\\,i=0,1,\\ldots,k-2 \\end{array}\n\\\\\np_t & \\begin{array}{l} \\text{Si}\\,\\, y=x+1 \\,\\, \\text{y}\\,\\, j=\\gamma\\,\\,\\text{e}\\,\\,i=k-1,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n-1 \\end{array}\n\\\\\np_t & \\begin{array}{l} \\text{Si}\\,\\, y=x-1,\\,\\,j=\\beta\\,\\, \\,\\,\\text{e}\\,\\, i=\\gamma\\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n  \\end{array}\n\\\\\np_t & \\begin{array}{l} \\text{Si}\\,\\, y=x,\\,\\,\\text{e}\\,\\, j=i=\\beta\\,, \\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n  \\end{array}\n\\\\\n1 & \\begin{array}{l} \\text{Si} \\,\\, y=x=l_n\\,\\,\\text{y}\\,\\, j=i=k-1\\end{array} \\\\\n0 & \\begin{array}{l} \\text{Otro caso}. \\end{array}\n\\end{cases}\\\\\n\\end{equation}\\]\n\nA modo de ilustración, consideremos el caso \\(\\small{n=5}\\) y \\(\\small{k=2}\\), para lo cual tenemos las matrices de probabilidad de transición:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M_t}(E_{5,2})=\n\\begin{array}{cc}&\n\\begin{array}{c}\n(0,\\beta)\\\\\n(0,0)\\\\\n(0,1)\\\\\n(1,\\gamma)\\\\\n(1,\\beta)\\\\\n(1,0)\\\\\n(1,1)\\\\\n(2,\\gamma)\\\\\n(2,\\beta)\\\\\n(2,0)\\\\\n(2,1)\n\\end{array}\n&\n\\left(\n\\begin{array}{c|cc|cc|cc|cc|cc}\nq_t&p_t&0&0&0&0&0&0&0&0&0\\\\\n\\hline\n0&q_t&p_t&0&0&0&0&0&0&0&0\\\\\n0&q_t&0&p_t&0&0&0&0&0&0&0\\\\\n\\hline\np_t&0&0&0&0&q_t&0&0&0&0&0\\\\\n0&0&0&0&p_t&q_t&0&0&0&0&0\\\\\n\\hline\n0&0&0&0&0&q_t&p_t&0&0&0&0\\\\\n0&0&0&0&0&q_t&0&p_t&0&0&0\\\\\n\\hline\n0&0&0&0&p_t&0&0&0&0&q_t&0\\\\\n0&0&0&0&0&0&0&0&p_t&q_t&0\\\\\n\\hline\n0&0&0&0&0&0&0&0&0&q_t&p_t\\\\\n0&0&0&0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nEn general, las matrices de probabilidad de transición de la cadena de Markov \\(\\small{\\{Y_t\\}}\\) asociadas con \\(\\small{E_{n,k}}\\) tienen la forma dada por la ecuación (3.19) con dimensión \\(\\small{(l_n + 1)(k+1)+l_n}\\).\n\n\n\nSea \\(\\small{L_n(S)}\\), la duración de la racha exitosa más larga en una sucesión de ensayos de dos estados. Para el caso de \\(\\small{n}\\) lanzamientos independientes de una moneda justa, sea \\(\\small{A_n(k)}\\) el número de secuencias de longitud \\(\\small{n}\\) en las que la racha más larga de éxitos (cara) es menor o igual a \\(\\small{k}\\). Dado que todas las sucesiones son igualmente probables con probabilidad \\(\\small{(1/2)^n}\\), la distribución del racha más largo es:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(L_n(S)\\leq k\\big)=2^{-n}A_n(k)\n\\end{equation}\\]\n\ndonde \\(\\small{A_n(k)}\\) satisface la ecuación recursiva (Schilling 1990)\n\n\n\\[\\begin{equation}\nA_n(k)=\\begin{cases}\n\\displaystyle\\sum_{j=0}^{k}A_{n-1-j}(k) & \\text{si}\\, n &gt; k\\\\\n2^{n} & \\text{si}\\,\\, n \\leq k\\\\\n1 & \\text{si}\\,\\, k = 0\\\\\n\\end{cases}\n\\end{equation}\\]\n\nPara monedas sesgadas \\(\\small{(p\\neq1/2)}\\), el análisis combinatorio es:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(L_n(S)\\leq k\\big)=\\displaystyle\\sum_{x=0}^{k}C_{n}^{(x)}(k)p^{x}q^{n-x},\n\\end{equation}\\]\n\npara \\(\\small{1 \\leq k \\leq n}\\), y \\(\\small{\\mathbb{P}\\big(L_n(S)=0 \\big)=q^{-n}}\\), donde \\(\\small{C_n^{(x)}(k)}\\) es el número de secuencias de longitud \\(\\small{n}\\) en las que ocurren exactamente \\(\\small{x}\\) éxitos, pero en las que no más de \\(\\small{k}\\) de estos éxitos ocurren consecutivamente. \\(\\small{C_n^{(x)}(k)}\\) se puede obtener a través de la ecuación recursiva:\n\n\n\\[\\begin{equation}\nC_n^{(x)}(k)=\\begin{cases}\n\\displaystyle\\sum_{j=0}^{k}C_{n-1-j}^{x-j}(k) & \\text{si}\\,\\,  k&lt;x&lt;n\\\\\n\\binom{n}{x} & \\text{si}\\,\\,  x \\leq k \\leq n\\\\\n\\, 0 & \\text{si}\\,\\,k&lt;x= n\\\\\n\\end{cases}\n\\end{equation}\\]\n\nDe manera más general, supongamos que las probabilidades de éxito y fracaso podrían ser diferentes en cada ensayo, iguales a \\(\\small{p_t}\\) y \\(\\small{q_t}\\), respectivamente, para \\(\\small{t=1,2,\\ldots,n}\\). El siguiente teorema deriva la distribución de \\(\\small{L_n(S)}\\):\nTeorema 3.1 Para \\(\\small{0\\leq k\\leq n}\\),\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(L_n(S)\\leq k\\big)=\\boldsymbol{\\mathbf{\\xi}} \\Big(\\prod_{t=1}^{n}\\boldsymbol{N}_t\\Big)\\boldsymbol{\\mathbf{1}'}_{1 \\times(k+1)}\n\\end{equation}\\]\n\nen donde \\(\\small{\\boldsymbol{\\mathbf{\\xi}}=(1,0,\\ldots,0)}\\) es un vector fila unitario de tamaño \\(\\small{1\\times (k+1)}\\) y \\(\\small{\\boldsymbol{N_t}}\\) es como se indica a continuación, la submatriz esencial \\(\\small{(k+1)\\times (k+1)}\\) de la matriz de probabilidades de transición:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M_t}=\n\\begin{array}{cc}&\n\\begin{array}{c}\n0\\\\\n1\\\\\n\\vdots\\\\\n\\vdots\\\\\nk\\\\\n\\alpha\n\\end{array}\n&\\left(\n\\begin{array}{ccccc|c}\nq_t&p_t&0&\\cdots&0&0\\\\\nq_t&0&p_t&\\cdots&0&0\\\\\n\\vdots&&\\ddots&\\ddots&&\\vdots\\\\\n\\vdots&&\\ddots&\\ddots&\\ddots&\\vdots\\\\\nq_t&0&\\cdots&\\cdots&0&p_t\\\\\n\\hline\n0&0&\\cdots&\\cdots&0&1\\\\\n\\end{array}\n\\right)_{(k+2) \\times (k+2)}\n\\end{array}=\\left(\\begin{array}{c|c}\n\\boldsymbol{N_t} &  {C_t}\\\\\n\\hline\n\\boldsymbol{0}&  {1}\\\\\n\\end{array}\n\\right)\n\\end{equation}\\]\n\nDemostración: La racha exitosa más larga en una sucesión de ensayos de dos estados está relacionada con las estadísticas de ejecución \\(\\small{N_{n,k}}\\), \\(\\small{G_{n,k}}\\) y \\(\\small{M_{n,k}}\\) de la siguiente manera sencilla:\n\n\n\\[\\begin{equation}\nL_n(S)\\leq k \\,\\, \\text{si y solo si}\\,\\, N_{n,k+1} = G_{n,k+1}=M_{n,k+1}=0\n\\end{equation}\\]\n\nPor tanto, \\(\\small{\\mathbb{P}\\big(L_n(S)\\leq k\\big)=\\mathbb{P}\\big(N_{n,k+1}=0\\big)}\\), y podemos completar la demostración considerando la Ecuación (3.8) para \\(\\small{\\mathbb{P}\\big(N_{n,k+1}=x\\big)}\\) con \\(\\small{x=0}\\). Cambiando los estados \\(\\small{(0,0),(0,1),\\ldots,(0,k)}\\) en esta aplicación de la Ecuación (3.8) a los estados \\(\\small{0,1,2,\\ldots,k}\\) respectivamente, y combinando todos los demás estados en el estado absorbente \\(\\small{\\alpha}\\), obtenemos:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(L_n(S)\\leq k\\big)=\\mathbb{P}\\big(N_{n,k+1}=0\\big)=\\boldsymbol{\\mathbf{\\xi}_0} \\Big(\\prod_{t=1}^{n}\\boldsymbol{M}_t\\Big)(1,\\ldots,1,0)'\n\\end{equation}\\]\n\nen donde \\(\\small{\\boldsymbol{\\xi_0}=(1,0\\ldots,0)_{1\\times(k+2)}=(\\boldsymbol{\\xi}:0)}\\). Con la notación \\(\\small{(1,\\ldots,1,0)_{1\\times(k+2)}=(\\boldsymbol{1}:0)}\\) y haciendo uso del hecho que las matrices de transición de probabilidad tienen la forma:\n\n\n\\[\\begin{equation}\n\\prod_{t=1}^{n}\\boldsymbol{M_t}=\n\\left(\n\\begin{array}{c|c}\n\\displaystyle\\prod_{t=1}^{n}\\boldsymbol{N_t}& C_t(n)\\\\\n\\hline\n\\boldsymbol{0}&1\n\\end{array}\n\\right)\n\\end{equation}\\]\n\nluego, el teorema se sigue inmediatamente. \\(\\hspace{3cm}\\Box\\)\nColorario Dados \\(\\small{1 \\leq k \\leq n}\\) se satisface la siguiente ecuación recursiva:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(L_n(S)\\leq k\\big)=q_n\\cdot\\mathbb{P}\\big(L_{n-1}(S)\\leq k\\big)+\\displaystyle\\sum_{i=1}^{k}q_{n-i} \\prod_{j=n-i+1}^{n}p_{j}\\cdot\\mathbb{P}\\big(L_{n-i-1}(S)\\leq k\\big)\n\\end{equation}\\]\n\ncon \\(\\small{\\mathbb{P}\\big(L_n(S)=0\\big)=\\displaystyle\\prod_{j=1}^{n}q_j}\\) y \\(\\small{\\mathbb{P}\\big(L_n(S)\\leq n\\big)\\equiv1}\\) para \\(\\small{k=m}.\\)\nDemostración De la estructuradada dada por la Ec.(3.25) para las matrices de probabilidades de transición \\(\\small{\\boldsymbol{M_t}}\\), se sigue que:\n\n\n\\[\\begin{align*}\n\\text{(i)}\\,\\, \\boldsymbol{M_te_0'} &=q_t(1,\\ldots,1,0)'_{1\\times(k+2)}\\,\\, \\text{y} \\\\\n\\text{(ii)}\\,\\,\\boldsymbol{M_te_i'} &=p_t\\boldsymbol{e_{i-1}'},\\,\\,\\text{para}\\,\\, i=1,2,\\ldots,k,\n\\end{align*}\\]\n\nen donde \\(\\small{\\boldsymbol{e_i}=(0,\\ldots,0,1,0,\\ldots,0)}\\) es un vector fila unitario con un uno en la coordenada asociada al estado \\(\\small{i}\\), para \\(\\small{i=0,1,2,\\ldots,k}\\).\nDado que \\(\\small{\\displaystyle\\sum_{i=0}^{k}\\boldsymbol{e_i'}}\\), nuestro resultado es una consecuencia directa de (i),(ii) y multiplicaciones hacia atrás de la ecuación (3.24).\nTomando \\(\\small{p_t=q_t=1/2}\\) para todo \\(\\small{t=1,2,\\ldots,n}\\) y multiplicando \\(\\small{\\mathbb{P}\\big(L_n(S)\\leq k\\big)=1}\\) por \\(\\small{2^n}\\), la ecuación (3.26) produce la ecuación recursiva (3.21) para \\(\\small{A_n(k)}\\). El teorema 3.1 también se puede extender para la rachas de falla más larga \\(\\small{L_n(F)}\\) y a la estadística de racha más larga \\(\\small{L_n = \\max\\{L_n(S), L_n(F)\\}}\\). Para el caso i.i.d. y para \\(\\small{n}\\) grande, hay varios resultados sobresalientes sobre la duración de la racha exitosa más larga. Rényi (1970), Csörgö (1979), Erdös y Rényi (1970) y Erdös y Révész (1975) muestran que, cuando \\(\\small{n \\rightarrow \\infty}\\)\n\n\n\\[\\begin{equation}\n\\frac{L_n(S)}{\\log_{1/p}(n)} \\xrightarrow{a.s} 1\n\\end{equation}\\]\n\nA este resultado se le suele denominar la nueva ley de los grandes números.\nEn el Capítulo 5, desarrollaremos una aproximación de grande desviación para la probabilidad de \\(\\small{L_n(S)}\\) bajo ensayos i.i.d. (y Markov-Dependientes homogéneos):\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(L_n(S)\\leq  k\\big)\\sim \\exp\\{-n\\beta\\}\n\\end{equation}\\]\n\nen donde \\(\\small{\\beta=-\\log(\\lambda_{[1]})}\\) y \\(\\small{\\lambda_{[1]}}\\) es el valor propio más grande de la submatriz de probabilidad de transición esencial \\(\\small{\\boldsymbol{N_t}}\\) (con \\(\\small{p_t}\\) y \\(\\small{q_t}\\) constantes) dada por la ecuación (3.25).\n\n\n\nSea \\(\\small{\\Lambda=S\\cdots S}\\) el patrón simple de \\(\\small{k}\\) éxitos consecutivos y defina la variable aleatoria \\(\\small{W(\\Lambda)}\\) como el tiempo de espera para que ocurra el patrón \\(\\small{\\Lambda}\\), es decir \n\n\\[\\begin{equation}\nW(\\Lambda)=\\inf\\{n:X_{n-k+1}=X_{n-k+2}=\\cdots=X_{n}=S\\}.\n\\end{equation}\\]\n\nPor ejemplo, dado \\(\\small{k=3}\\), \\(\\small{W(\\Lambda)=6}\\) significa que el patrón \\(\\small{SSS}\\) ocurre por primera vez después de seis intentos, como en \\(\\small{SFFSSS}\\). La distribución de \\(\\small{W(\\Lambda)}\\) para los ensayos de Bernoulli a menudo se denomina distribución geométrica de orden \\(\\small{k}\\) (ver Aki 1985 e Hirano 1986).\nTeorema 3.2 Dado un patrón de longitud \\(\\small{k\\geq 1}\\) y una sucesión de ensayos Bernoulli \\(\\small{\\{X_t\\}}\\), la distribución de \\(\\small{W(\\Lambda)}\\) esta dada por:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(W(\\Lambda)=n\\big)=\\boldsymbol{\\xi} \\boldsymbol{N_t}^{n-1}(\\Lambda)\\big(\\boldsymbol{I-N}(\\Lambda)\\big)\\boldsymbol{1'}\n\\end{equation}\\]\n\nen donde \\(\\small{\\boldsymbol{\\xi}=(1,0,\\ldots,0)}\\) es un vector fila \\(\\small{1\\times k}\\) y \\(\\small{\\boldsymbol{N}(\\Lambda)}\\) es la submatriz de probabilidades de transición esencial:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}(\\Lambda)=\n\\begin{array}{cc}&\n\\begin{array}{c}\n0\\\\\n1\\\\\n\\vdots\\\\\n\\vdots\\\\\nk-1\\\\\n\\alpha\n\\end{array}\n&\\left(\n\\begin{array}{ccccc|c}\np&q&0&\\cdots&0&0\\\\\nq&0&p&\\cdots&0&0\\\\\n\\vdots& &\\ddots&\\ddots&&\\vdots\\\\\n\\vdots&&\\ddots&\\ddots&\\ddots&\\vdots\\\\\nq&0&\\cdots&\\cdots&0&p\\\\\n\\hline\n0&0&\\cdots&\\cdots&0&1\\\\\n\\end{array}\n\\right)_{(k+1)\\times(k+1)}\n\\end{array}=\n\\left(\n\\begin{array}{c|c}\n\\boldsymbol{N}(\\Lambda)&C\\\\\n\\hline\n\\boldsymbol{0} & 1\n\\end{array}\\right)\n\\end{equation}\\]\n\nSe deduce además que la función generadora de probabilidad de \\(\\small{W(\\Lambda)}\\) está dada por:\n\n\n\\[\\begin{equation}\n\\varphi_{W}(s)=\\frac{p^ks^k(1-ps)}{1-s+qp^ks^{k+1}}\n\\end{equation}\\]\n\nPrueba. Dados \\(\\small{\\Lambda}\\),\\(\\small{}\\) y \\(\\small{k \\leq n}\\), de la definición de \\(\\small{W(\\Lambda)}\\) y \\(\\small{N_{n,k}}\\), se deduce que estas dos variables aleatorias tienen la siguiente relación:\n\n\n\\[\\begin{equation}\nW(\\Lambda) \\leq n \\quad \\text{si y solo si}\\quad N_{n,k}\\geq 1 \\,\\,\\text{para todo }\\, n \\geq k.\n\\end{equation}\\]\n\nPor tanto \\(\\small{\\mathbb{P}\\big(W(\\Lambda)\\leq n\\big)=\\mathbb{P}\\big(N_{n,k}\\geq 1\\big)}\\) y\n\n\n\\[\\begin{align*}\n\\mathbb{P}\\big(W(\\Lambda)\\leq n\\big) &= \\mathbb{P}\\big(N_{n,k}\\geq 1\\big)-\\mathbb{P}\\big(N_{n-1,k}\\geq 1\\big), \\\\\n&=  \\mathbb{P}\\big(N_{n-1,k}= 0\\big)-\\mathbb{P}\\big(N_{n,k}= 0\\big).\n\\end{align*}\\]\n\nPuesto que sólo necesitamos el resultado general de \\(\\small{\\mathbb{P}\\big(N_{n,k}= 0\\big)}\\) para completar la prueba, podemos, como en la sección anterior sobre la racha exitosa más larga, reemplazar los estados \\(\\small{(0,0),\\cdots,(0,k-1)}\\) definidos en la Sección 3.2 por los estados \\(\\small{0,1,2,\\ldots,k-1}\\) y combinar todos los demás estados en un estado absorbente \\(\\small{\\alpha}\\). Bajo este espacio de estados reducido, la matriz de probabilidad de transición \\(\\small{\\boldsymbol{M_t}(N_{n,k})}\\) se simplifica a \\(\\small{\\boldsymbol{M}(\\Lambda)}\\). La ecuación (3.27) del teorema 3.2 es entonces una consecuencia inmediata de las ecuaciones (3.8), (3.30) y Teorema 3.1.\nNote que, para \\(\\small{0\\leq i\\leq k-1,}\\)\n\n\n\\[\\begin{equation}\n\\boldsymbol{e_iN}(\\Lambda)=q\\boldsymbol{e_0}+p\\boldsymbol{e_{i+1}}.\n\\end{equation}\\]\n\nDado \\(\\small{\\boldsymbol{\\xi=e}_0}\\), y usando del resultado de multiplicación hacia adelante obtenemos la siguiente ecuación recursiva:\n\n\n\\[\\begin{align*}\n\\mathbb{P}\\big(W(\\Lambda)= n\\big) &= \\boldsymbol{\\xi N}^{n-1}(\\Lambda)\\big(\\boldsymbol{I-N}(\\Lambda)\\big)\\boldsymbol{1'} \\\\\n&= \\sum_{i=1}^{k}qp^{i-1}\\mathbb{P}\\big(W(\\Lambda)=n-i\\big).\n\\end{align*}\\]\n\nLa anterior ecuación recursivay la condición de frontera \\(\\small{\\mathbb{P}\\big(W(\\Lambda)=k\\big)=p^{k}}\\) conducen a la siguiente ecuación recursiva para la función generadora de probabilidad \\(\\small{\\varphi_{W}(s)}\\):\n\n\n\\[\\begin{equation}\n\\varphi_{W}(s)= s^kp^k+\\sum_{i=1}^{k}qp^{i-1}s^{i}\\varphi_{W}(s)\n\\end{equation}\\]\n\nSumando las series de potencias finitas se obtiene el resultado explícito para \\(\\small{\\varphi_{W}(s)}\\) dado en la Ec. (3.29), resultado que fue derivado por primera vez por Feller (1968) utilizando la teoría de la renovaciones.\\(\\hspace{3cm}\\Box\\)\nSi definimos las matrices:\n\n\n\\[\\begin{equation}\n\\boldsymbol{A}=\\left(\n\\begin{array}{ccccc}\nq&p&0&\\cdots&0\\\\\nq&0&p& &0\\\\\n\\vdots& &\\ddots&\\ddots& \\\\\nq& & &0&p\\\\\nq&0&\\cdots&&0\\\\\n\\end{array}\n\\right)_{k\\times k},\\,\n\\boldsymbol{B}=\\left(\n\\begin{array}{ccccc}\n0&0&0&\\cdots&0\\\\\n0&0&0& &\\\\\n\\vdots& &\\ddots&\\ddots& \\\\\n0& & &0&0\\\\\np&0&\\cdots&&0\\\\\n\\end{array}\n\\right)_{k\\times k}\n\\end{equation}\\]\n\n\n\n\\[\\begin{equation}\n\\boldsymbol{A}^{\\ast}=(1)_{1\\times 1}\\,\\, \\text{y}\\,\\, \\boldsymbol{B}^{\\ast}=(0\\,\\,0\\,\\,\\cdots \\, 0\\,\\,p)'_{k\\times 1}\n\\end{equation}\\]\n\ny sea \\(\\small{W(m,\\Lambda)}\\) el tiempo de espera para la \\(\\small{m-}\\)ésima racha de \\(\\small{k}\\) éxitos consecutivos (sin solapamiento). De forma similar al desarrollo anterior para \\(\\small{W(\\Lambda)}\\), la distribución de la variable aleatoria \\(\\small{W(m,\\Lambda)}\\) puede ser obtenida usando la Ecuación (3.27) al remplazar la matriz de probabilidades de transición \\(\\small{W(\\Lambda)}\\), por:\n\n\n\\[\\begin{equation}\n\\boldsymbol{W}(m,\\Lambda)=\\left(\n\\begin{array}{ccccc}\n\\boldsymbol{A}&\\boldsymbol{A}& &\\boldsymbol{O}&\\\\\n&\\ddots & \\ddots& &\\\\\n& &\\boldsymbol{A}&\\boldsymbol{B}& \\\\\n&\\boldsymbol{O} &&\\boldsymbol{A}&\\boldsymbol{B^{\\ast}}\\\\\n& & &&\\boldsymbol{A^{\\ast}}\\\\\n\\end{array}\n\\right)_{(mk+1)\\times (mk+1)}\n\\end{equation}\\]\n\nObsérvese que la matriz de probabilidad de transición \\(\\small{\\boldsymbol{M}(\\Lambda)}\\) de la Ec. (3.28) es el caso especial de \\(\\small{\\boldsymbol{M}(m,\\Lambda)}\\) con \\(\\small{m=1}\\). Puesto que \\(\\small{W(m,\\Lambda)=\\displaystyle\\sum_{i=1}^{m}W_i(\\Lambda)}\\), donde \\(\\small{W_i(\\Lambda)}\\) representa el tiempo de espera desde la \\(\\small{(i-1)-}\\)ésima ocurrencia hasta la \\(\\small{(i)-}\\)ésima ocurrencia del patrón \\(\\small{\\Lambda}\\), y puesto que las variables aleatorias \\(\\small{W(\\Lambda)}\\) son i.i.d., se deduce de la Ec. (3.29) que la función generadora de probabilidad de \\(\\small{W(m,\\Lambda)}\\) es:\n\n\n\\[\\begin{equation}\n\\varphi_{W(m,\\Lambda)}^{m}(s)=\\varphi_{W}^{m}(s)=\\Bigg(\\frac{p^ks^k(1-ps)}{1-s+qp^ks^{k+1}}\\Bigg)^{m}.\n\\end{equation}\\]\n\nLa función generadora de probabilidad \\(\\small{\\varphi_{W}(s)}\\) siempre existe para todo \\(\\small{|s| \\leq 1}\\)\nEsto se desprende de su definición y del hecho de que:\n\n\n\\[\\begin{equation}\n|\\varphi_{W}(s)|\\leq\\sum_{n=1}^{\\infty}|s^{n}|\\cdot\\mathbb{P}(W=n)\\leq\\sum_{n=1}^{\\infty}\\mathbb{P}(W=n)=1.\n\\end{equation}\\]\n\nSin embargo, la función generadora de probabilidad \\(\\small{\\varphi_{W}(s)}\\) puede existir más allá de la región \\(\\small{|s| \\leq 1}\\). La región exacta varía de un problema a otro. Volveremos a discutir la mayor región de existencia de \\(\\small{\\varphi_{W}(s)}\\) en la sección 5.7.\nLa distribución de \\(\\small{W(m,\\Lambda)}\\) también puede obtenerse mediante la ecuación\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(W(m,\\Lambda)=n\\big)=\\frac{1}{n!}\\frac{d^{n}}{ds^{n}}\\varphi_{W(m,\\Lambda)}(s)\\Bigr|_{s=0}.\n\\end{equation}\\]\n\nenfoque que puede obtenerse más fácilmente utilizando software de manipulación simbólica (por ejemplo, MAPLE o MATLAB). En el capítulo 5 se ofrece un tratamiento más detallado de las distribuciones de tiempo de espera para patrones simples y compuestos en ensayos i.i.d. y Markov-Dependientes multiestado.\n\n\n\nAntes de estudiar estadísticas de rachas más complejas, en esta sección proporcionamos algunos resultados numéricos para las estadísticas de rachas y los tiempos de espera descritos en las secciones anteriores con el fin de ilustrar los resultados teóricos. Dada la matriz (o matrices) de probabilidad de transición de la cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) , en general sólo necesitamos dos tipos de fórmulas, en las formas de las Ecs. (3.8) y (3.27), para evaluar las distribuciones de \\(\\small{X_n(\\Lambda)}\\) y \\(\\small{W(\\Lambda)}\\), respectivamente. Las fórmulas son sencillas y eficientes desde el punto de vista computacional, adecuadas incluso para \\(\\small{n}\\) muy grandes. Los resultados numéricos que aquí se presentan también pueden servir para comprobar los propios cálculos de programación. En todos los ejemplos considerados, el tiempo de cálculo para obtener cada distribución es mínimo, una fracción de segundo en un PC actual.\nEn la Tabla 3.1 se presentan las distribuciones exactas y las medias de las variables aleatorias \\(\\small{E_{15,2},\\, G_{15,2},\\,N_{15,2},\\, M_{15,2}}\\) y \\(\\small{L_{15}(S)}\\) bajo el supuesto de que \\(\\small{\\{X_t\\}}\\)es una secuencia de ensayos independientes de dos estados con probabilidades \\(\\small{p_t=1/(t+1)}\\) para \\(\\small{t=1,2,\\ldots,15}\\).\nLa Tabla 3.2 muestra las distribuciones del tiempo de espera de la primera racha con éxito de longitud \\(\\small{k}\\), para varios valores de \\(\\small{k}\\) y probabilidades de estado \\(\\small{p_t}\\). En los capítulos 5 y 7 se ofrecen más resultados numéricos sobre las distribuciones del tiempo de espera.\n\n\n\nSea \\(\\small{S_{n,k}}\\) el número total de éxitos en rachas de éxitos de longitud mayor o igual que \\(\\small{}\\), para \\(\\small{k=1,2,\\ldots,n}\\). Puede escribirse como\n\n\n\\[\\begin{equation}\nS_{n,k}=\\sum_{i=k}^{n}iR_n(i),\n\\end{equation}\\]\n\nen donde \\(\\small{R_n(i)}\\), para \\(\\small{i=k,\\ldots,n}\\) es el número de rachas éxitosas de longitud exactamente igual a \\(\\small{i}\\) en una sucesión \\(\\small{\\{X_t\\}}\\). Para \\(\\small{k=1}\\), la Ec. (3.33) es equivalente al número total de éxitos en la sucesión \\(\\small{\\{X_t\\}}\\), es decir:\n\n\n\\[\\begin{equation}\nS_{n,1}=\\sum_{i=k}^{n}I_{X_i},\n\\end{equation}\\]\n\nen donde \\(\\small{I_{X_i}=1}\\) cuando el \\(\\small{i-}\\)ésimo ensayo es éxito y cero en otro caso. Si \\(\\small{\\{X_t\\}}\\) es una sucesión de ensayos Bernoulli, entonces \\(\\small{S_{n,1}}\\) tiene distribuciones binomial exacta y normal en el límite, respectivamente. De manera más general, para el caso \\(\\small{\\{X_t\\}}\\) es una sucesión de variables aleatorias Markov-Dependientes, la estadística \\(\\small{S_{n,k}}\\) también tiene una distrubución límite normal, como determino Nagaev (1957) para \\(\\small{k=1}\\) y Fu, Lou, Bai y Li (2002) para \\(\\small{k \\geq 2}\\). En esta sección, sólo estudiamos la distribución exacta de \\(\\small{S_{n,k}}\\) con \\(\\small{k \\geq 2}\\).\nSea \\(\\small{L_j}\\), para \\(\\small{j \\geq 2}\\), la longitud de la racha de éxitos situada entre el \\(\\small{(j-1)-}\\)ésimo y el \\(\\small{j-}\\) ésimo fallo en la sucesión \\(\\small{\\{X_t\\}}\\), con \\(\\small{L_1=0}\\) si el primer ensayo es un fallo y \\(\\small{L_1=l}\\) si los primeros \\(\\small{l}\\) ensayos son éxitos y el \\(\\small{(j+1)-}\\)ésimo ensayo es un fallo. Para un índice de tiempo \\(\\small{t}\\) dado, sea \\(\\small{m_t}\\) el número de fracasos en la subsecuencia \\(\\small{X_1, X_2,\\ldots, X_t}\\) y sea \\(\\small{L_t^{\\star}}\\) el número de éxitos que se producen después del \\(\\small{m_t-}\\)ésimo fracaso en esta subsecuencia. Nótese que \\(\\small{0 \\leq L_{t}^{\\star} \\leq t}\\) y \\(\\small{0\\leq L_t^{\\star} \\leq L_{m_t+1}}\\). Por otra parte, \\(\\small{S_{t,k}}\\), tal como se define en la Ec. (3.33), también se puede escribir como:\n\n\n\\[\\begin{equation}\nS_{t,k}=\\sum_{j=1}^{m_t}L_{j}(k)+L_t^{\\star}(t),\n\\end{equation}\\]\n\ncon \n\n\\[\\begin{equation}\nL_{j}(k)=L_j\\cdot I_{\\{L_j\\geq k\\}}\\quad \\text{y}\\quad L_{j}^{\\star}(k)=L_j^{\\star}\\cdot I_{\\{L_j^{\\star} \\geq k\\}}.\n\\end{equation}\\]\n\nAcá \\(\\small{I_{\\{L_j \\geq k\\}}}\\), es la función indicadora del evento \\(\\small{\\{L_j \\geq k\\}}\\), es decir, es igual a uno cuando (\\(\\small{I_{\\{L_j^{\\star} \\geq k\\}}}\\), se define de manera análoga) Para capturar la información relevante en la subsucesión \\(\\small{\\{X_1,X_2,\\cdots, X_t\\}}\\) definimos una nueva sucesión de variables aleatorias en la forma del vector de dos componentes\n\n\n\\[\\begin{equation}\nY_t=\\big( S_{t,k},E_{t}(t)\\big),\\,\\, t=1,2,\\ldots,n,\n\\end{equation}\\]\n\nen donde \\(\\small{S_{t,k}}\\) indica el número total de éxitos en rachas exitosas de longitud mayor o igual a \\(\\small{k}\\) en los primeros \\(\\small{t}\\) ensayos, y \\(\\small{E_{t}(k)}\\) es la variable aleatoria de bloque final dada por:\n\n\n\\[\\begin{equation}\nE_{t}(k)= L_{t}^{\\star}\\big(1-I_{\\{L_j^{\\star}\\geq k\\}}\\big)+k^{+}\\cdot I_{\\{L_j^{\\star} \\geq k\\}}.\n\\end{equation}\\]\n\nEn esta expresión, el símbolo \\(\\small{k^{+}}\\) representa el estado donde \\(\\small{L_t}\\) es mayor o igual que \\(\\small{k}\\).\nEl bloque final \\(\\small{E_t(k)}\\) representa la longitud de la racha de éxitos contando hacia atrás desde el \\(\\small{t-}\\)ésimo ensayo, con \\(\\small{E_t(k)=0}\\) si el \\(\\small{t-}\\)ésimo ensayo es un fracaso y \\(\\small{E_t(k)=k^{+}}\\) si la longitud es mayor o igual a \\(\\small{k}\\). Más específicamente, considere que desde el 1 \\(\\small{ m_t-}\\)ésimo (o más reciente) fracaso \\(\\small{F}\\) hasta el final de la subsucesión \\(\\small{\\{X_1,X_2,\\cdots, X_t\\}}\\) sólo podemos tener los siguientes resultados posibles: \\(\\small{\\{F,FS,\\cdots,FS\\cdots S,\\,\\text{or}\\, S\\cdots S\\, \\text{si } m_t = 0\\}}\\); la variable aleatoria \\(\\small{E_t(k)}\\) es igual al número de éxitos en estos resultados si el número es menor que \\(\\small{k}\\), y \\(\\small{E_t(k)=k^{+}}\\) si es igual o mayor que \\(\\small{k}\\). Este bloque final de los primeros \\(\\small{t}\\) ensayos proporciona información esencial sobre las probabilidades de transición de \\(\\small{Y_t}\\) a \\(\\small{Y_{t+1}}\\).\nDefinimos el espacio de estados\n\n\n\\[\\begin{equation}\n\\Omega =\\{(u,v):u=0,k,\\cdots,n-1,n\\,\\, \\text{y}\\,\\, v=0,1,\\cdots,k-1,k^{+}\\},\n\\end{equation}\\]\n\ncon tamaño \\(\\small{d=\\text{card}(\\Omega)=(n-k+2)(k+1)}\\), y consideraremos aquí el caso en que la sucesión \\(\\small{\\{X_t\\}}\\) es una cadena de Markov homogénea con probabilidades de transición \\(\\small{p_{FF},p_{Fs},p_{SF}}\\) y \\(\\small{p_{SS}}\\). En nuestro procedimiento de recuento, la sucesión de vectores aleatorios \\(\\small{Y_t=\\big( S_{t,k},E_{t}(t)\\big),\\,\\, t=1,2,\\ldots,n,}\\) definida en \\(\\small{\\Omega}\\) obedece las siguientes reglas:\n(i) Dado \\(\\small{Y_{t-1}=(x,0)}\\), entonces \\(\\small{Y_{t}=(x,0)}\\) con probabilidad \\(\\small{p_{FF}}\\) si el resultado del \\(\\small{t-}\\)ésimo ensayo es \\(\\small{F}\\), e \\(\\small{Y_{t}=(x,1)}\\) con probabilidad \\(\\small{p_{FS}}\\) si el resultado del \\(\\small{t-}\\)ésimo ensayo es \\(\\small{S}\\).\n(ii) Dado \\(\\small{Y_{t-1}=(x,y)}\\) para \\(\\small{1\\leq y \\leq k-2}\\) entonces \\(\\small{Y_{t}=(x,0)}\\) con probabilidad \\(\\small{p_{SF}}\\) si el resultado del \\(\\small{t-}\\)ésimo ensayo es \\(\\small{F}\\), e \\(\\small{Y_{t}=(x,y+1)}\\) con probabilidad \\(\\small{p_{SS}}\\) si el resultado del \\(\\small{t-}\\)ésimo ensayo es \\(\\small{S}\\).\n(iii) Dado \\(\\small{Y_{t-1}=(x,k-1)}\\), entonces \\(\\small{Y_{t}=(x,0)}\\), con probabilidad \\(\\small{p_{SF}}\\) si el resultado del \\(\\small{t-}\\)ésimo ensayo es \\(\\small{F}\\), e \\(\\small{Y_{t-1}=(x+k,k^{+})}\\), con probabilidad \\(\\small{p_{SS}}\\) si el resultado del \\(\\small{t-}\\)ésimo ensayo es \\(\\small{S}\\).\n(iv) Dado \\(\\small{Y_{t-1}=(x,k^{+})}\\), entonces \\(\\small{Y_{t}=(x,0)}\\) con probabilidad \\(\\small{p_{SF}}\\) si el resultado del \\(\\small{t-}\\)ésimo ensayo es \\(\\small{F}\\), e \\(\\small{Y_{t}=(x+1,k^{+})}\\) con probabilidad \\(\\small{p_{SS}}\\) si el resultado del \\(\\small{t-}\\)ésimo prueba es \\(\\small{S}\\).\nA la vista de nuestra construcción, la sucesión \\(\\small{\\{Y_t = \\big( S_{t,k}, E_t(k) \\big) : t = 1, 2,..., n\\}}\\) forma una cadena de Markov homogénea con matriz de probabilidad de transición:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\\big( p_{(x,y)\\times(u,v)}\\big)_{d\\times d}\n\\end{equation}\\]\n\ndonde las probabilidades de transición \\(\\small{p_{(x,y)\\times(u,v)}}\\), bajo orden lexicográfico de los estados \\(\\small{(\\cdot,\\cdot)}\\), se pueden especificar explícitamente de la siguiente manera. Dado \\(\\small{(x,y)\\in \\Omega}\\),\n\n\n\\[\\begin{equation}\np_{(x,y)(u,v)}(t) =\n\\begin{cases}\np_{FF} & \\begin{array}{l} \\text{Si}\\,\\, y=v=0 \\,\\, \\text{y}\\,\\, u=x, \\end{array} \\\\\np_{FS} & \\begin{array}{l} \\text{Si}\\,\\, y=0,\\,v=1 \\,\\, \\text{y}\\,\\, u=x, \\end{array}\n\\\\\np_{SF} & \\begin{array}{l} \\text{Si}\\,\\, y\\neq 0,\\,v=0\\,\\, \\text{y}\\,\\, u=x, \\end{array}\n\\\\\np_{SS} & \\begin{array}{l} \\text{Si}\\,\\, 1 \\leq y \\leq k-2,\\,\\,v=y+1\\,\\, \\,\\,\\text{e}\\,\\, u=x,\\\\\n\\text{o si}\\,\\, y=k-1,\\,\\, v=k^{+}\\,\\,\\text{e}\\,\\, u=x+k,\\\\\n\\text{o si}\\,\\, y=k^{+},\\,\\, v=k^{+}\\,\\,\\text{e}\\,\\, u=x+1\\\\\n\\end{array}\n\\\\\n1 & \\begin{array}{l} \\text{Si} \\,\\, y=v\\,\\,\\text{y}\\,\\, u=x=n\\end{array} \\\\\n0 & \\begin{array}{l} \\text{Otro caso}. \\end{array}\n\\end{cases}\n\\end{equation}\\]\n\nPor lo tanto, la variable aleatoria \\(\\small{S_{n,k}}\\) es una Cadena de Markov incrustable y las probabilidades exactas se pueden obtener de:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(S_{n,k}= x\\big) = \\boldsymbol{\\xi_0 M}^{n-1}\\boldsymbol{U}(C_x),\\,\\, x=0,k,\\ldots,n\n\\end{equation}\\]\n\ndonde el vector fila \\(\\small{\\boldsymbol{\\xi_0}=(q_0,p_0,0,\\ldots,0)_{1 \\times d}}\\) es la distribución inicial de \\(\\small{Y_1}\\), la partición \\(\\small{\\{C_x\\}}\\) se define como:\n\n\n\\[\\begin{equation}\nC_x =\\{(x,y):y=0,1,\\cdots,k-1,k^{+}\\},\\,\\,x=0,k,\\cdots,n,\n\\end{equation}\\]\n\ny \\(\\small{\\boldsymbol{U}'(C_x)}\\) es la transposición del vector fila \\(\\small{\\boldsymbol{U}(C_x)=(0,\\ldots,0,1,\\ldots,1,0,\\ldots,0)}\\) con unos en las coordenadas correspondientes a los estados de \\(\\small{C_x}\\).\nPara comprender mejor los efectos de los distintos parámetros, en la Figura 3.1 se muestran gráficamente las distribuciones de \\(\\small{S_{n,k}}\\) para algunos casos representativos con \\(\\small{n=15,30,60}\\), en los que se supone la distribución inicial \\(\\small{\\boldsymbol{\\xi_0}=(1,0,\\ldots,0)}\\). Cuando \\(\\small{p_{SS}}\\) es pequeño (por ejemplo, \\(\\small{p_{SS}=0.2}\\)), los efectos de los parámetros sobre la distribución son menos pronunciados, por lo que en la Figura 3.1 sólo se presentan casos con valores grandes de \\(\\small{p_{SS}\\,(=0.8)}\\). A efectos de comparación, también se incluyen las esperanzas.\nPara \\(\\small{n}\\) fijo, el efecto de \\(\\small{k}\\) y \\(\\small{p_{FS}}\\) puede resumirse como sigue. Para \\(\\small{k}\\) pequeño \\(\\small{(k=2)}\\) , la distribución de \\(\\small{S_{n,k}}\\) se suaviza y adquiere forma de campana a medida que aumenta \\(\\small{n}\\) (de la Figura 3.1(a) a (d) a (g)), y esta tendencia se amplifica con valores mayores de \\(\\small{p_{FS}}\\). A medida que \\(\\small{k}\\) aumenta, las distribuciones se alejan de la forma normal y se vuelven muy sesgadas hacia la derecha (por ejemplo, de la Figura 3.1(d) a (e) a (f)). La distribución de \\(\\small{S_{n,k}}\\) sólo puede aproximarse a una distribución normal cuando \\(\\small{k}\\) es mucho menor que \\(\\small{n}\\), y las aproximaciones normales deben utilizarse con precaución. En Fu, Lou, Bai y Li (2002) se ofrecen más detalles sobre la distribución límite de \\(\\small{S_{n,k}}\\).\n\n\n\n\n\n\nEn el capítulo 3, analizamos las ideas clave de la técnica de Incrustación de Cadenas de Markov Finitas (ICMF) para obtener las distribuciones exactas del número de rachas y patrones con éxitos en una sucesión de ensayos de dos estados. El objetivo principal de este capítulo es ampliar la técnica de ICMF para estudiar el número de rachas y patrones en una secuencia de ensayos multiestado. Podría parecer que, en principio, la ampliación debería ser sencilla y requerir sólo pequeñas modificaciones. Sin embargo, no es así, especialmente cuando el patrón es complejo y la sucesión \\(\\small{\\{X_t\\}}\\) está formada por ensayos multiestado Markov-Dependientes. Las principales dificultades se deben a la complejidad de construir una cadena de Markov finita adecuada asociada a la variable aleatoria \\(\\small{X_n(\\Lambda)}\\), especialmente en el proceso de obtención de las probabilidades de transición. Para superar estas dificultades, introducimos el principio de avance y retroceso. En este capítulo nos centraremos en la utilización del principio de avance y retroceso para obtener las distribuciones de patrones simples y compuestos. De hecho, el principio de avance y retroceso desempeña un papel indispensable en la construcción de la Cadena de Markov Incrustada para casi todas las aplicaciones cubiertas por este libro.\n\n\n\nComencemos con el caso simple de que \\(\\small{\\{X_t\\}_{t=1}^{n}}\\) es una secuencia de i.i.d. ensayos miltiestados. Cada ensayo tiene \\(\\small{m\\,\\, (m\\geq 2)}\\) resultados posibles (estados o símbolos), etiquetados como \\(\\small{\\mathscr{S} =\\{b_1,\\ldots, b_m\\}}\\) y que ocurren con probabilidades \\(\\small{p_1,p_2,\\ldots,p_m,}\\) respectivamente. Denotamos \\(\\small{X_n(\\Lambda)}\\) al número de patrones simples \\(\\small{\\Lambda}\\) no-superpuestos en la sucesión \\(\\small{\\{X_t\\}}\\). Primero, nos gustaría presentar el principio de avance y retroceso para la técnica de incrustación de cadenas de Markov finitas, un principio que guiará la construcción de una cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) y la determinación de sus matrices de probabilidad de transición. Para facilitar la discusión, el principio de avance y retroceso se introduce mediante el siguiente ejemplo.\nEjemplo 4.1 Consideremos el patrón simple \\(\\small{\\Lambda=\\{b_{1}b_{1}b_{2}\\}}\\) en una sucesión de ensayos de tres estados (\\(\\small{\\mathscr{S} =\\{b_1,b_{2}, b_{3}\\}}\\)).\n(i) Descompongamos el patrón \\(\\small{\\Lambda=b_{1}b_{1}b_{2}}\\) en un conjunto de subpatrones secuenciales \\(\\small{\\mathscr{S}(\\Lambda) =\\{b_1,b_{1}b_{1}, b_{1}b_{1}b_{2}\\}}\\). Definiendo\n\n\n\\[\\begin{equation}\n\\mathscr{E}=\\mathscr{S}\\, \\cup \\,\\mathscr{S}(\\Lambda)=\\{b_{1},b_{2},b_{3},b_{1}b_{1}, b_{1}b_{1}b_{2}\\}\n\\end{equation}\\]\n\ncomo un conjunto de bloques finales inducidos por el patrón \\(\\small{ b_{1}b_{1}b_{2}}\\) con respecto a sucesión de ensayos \\(\\small{\\{X_t\\}}\\)\n(ii) Sea \\(\\small{{\\omega} =(x_{1},\\ldots, x_n)}\\) una realización de una sucesión de \\(\\small{n}\\) ensayos de tres estados. Definiendo el espacio de estados:\n\n\n\\[\\begin{equation}\n\\Omega =\\{(u,v):u=0,1,\\cdots,[n\n/3],\\,\\, v\\in \\mathscr{E}\\}\\,\\cup \\,\\{\\emptyset\\}\\, -\\,\\{(0,b_{1}b_{1}b_{2})\\}\n\\end{equation}\\]\n\ny una cadena de Markov\n\n\n\\[\\begin{equation}\n\\big\\{Y_t=\\big(X_n(\\Lambda), E_t\\big),\\,t=0,1,2,\\ldots,n\\big\\}\n\\end{equation}\\]\n\noperando sobre \\(\\small{\\omega}\\) como\n\n\n\\[\\begin{equation}\nY_t(\\omega)=(u,v),\\,\\, \\text{para}\\,\\, t=1,\\ldots,n\n\\end{equation}\\]\n\nen donde: \n\n\\[\\begin{align*}\nu &=\\begin{cases}\n\\begin{array}{l}\nX_n(\\Lambda)(\\omega)=\\,\\text{el número total de patrones no-solapados}\\,\\Lambda\\,\\\\\n\\text{en los primeros}\\,\\, t\\,\\, \\text{ensayos contando hacia delante desde} \\\\\n\\text{el primer ensayo hasta el}\\,\\, t-ésimo\\,\\, \\text{ensayo, y}\n\\end{array}\n\\end{cases}\\\\\n\\\\\nv &=\\begin{cases}\n\\begin{array}{l}\nE_t(w) =\\,\\text{el bloque final más largo en}\\ \\mathscr{S},\\\\\n\\text{contando hacia atrás desde}\\, X_t.\n\\end{array}\n\\end{cases}\n\\end{align*}\\]\n\nLas definiciones de \\(\\small{u}\\) y \\(\\small{v}\\) para la sucesión de los primeros \\(\\small{t}\\) ensayos se ilustran gráficamente en la figura 4.1. Para que la cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) y el concepto de bloque final más largo sean más transparentes, consideremos la siguiente realización, \\(\\small{\\omega=(b_{3}b_{1}b_{2}b_{1}b_{1}b_{2}b_{1})}\\), de una sucesión de siete ensayos de tres estados. Aplicando el principio de avance y retroceso, la correspondiente del la cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) sobre \\(\\small{\\omega}\\) viene dada por \\(\\small{\\{Y_{1}(\\omega)=(0,b_{3}), Y_{2}(\\omega)=(0, b_{1}), Y_{3}(\\omega) = (0, b_{2}), Y_{4}(\\omega)= (0, b_{1}), Y_{5}(\\omega)=(0, b_{1}b_{1}), Y_{6}(\\omega) = (1, b_{1}b_{1}b_{2})\\,\\text{y}\\, Y_{7}(\\omega)=(1, b_{1})\\}}\\). Tenga en cuenta que para cada \\(\\small{\\omega}\\) dada, la realización de la cadena de Markov incrustada \\(\\small{Y_t(\\omega) = (u, v)}\\) está determinada únicamente por lo anterior procedimientos (i) y (ii) bajo conteo sin superposición. En palabras sencillas, el el bloque final \\(\\small{v}\\) representa el estado de formación del siguiente patrón \\(\\small{\\Lambda}\\) para el subsecuencia \\(\\small{\\{{x_1,., ,x_t} \\}}\\) que contiene \\(\\small{u}\\) patrones completos.\n(iii) La cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) es homogénea y su matriz de probabilidad de transición \\(\\small{\\boldsymbol{M_t}= \\big(p_{(x,z),(u,v)}\\big)}\\) puede determinarse del siguiente modo. Por ejemplo, dado \\(\\small{Y_5(\\omega)=(0,b_{1}b_{1})}\\), como \\(\\small{X_{6}}\\) sólo puede ser uno de los tres resultados posibles \\(\\small{b_{1}, b_{2}}\\) y \\(\\small{b_{3}}\\), el procedimiento de recuento hacia delante y hacia atrás da como resultado\n\n\n\\[\\begin{align*}\nY_{5}(\\omega) & \\rightarrow \\quad \\quad Y_{6}(\\omega)\n\\\\\n(0,b_{1}b_{1}) &\\rightarrow  \\begin{cases}\n\\begin{array}{cl}\n(0,b_{1}b_{1}) & \\text{si}\\,\\, X_6= b_{1}\\,\\,(\\text{con probabilidad}\\, p_{1})\\\\\n(1,b_{1}b_{1}b_{2}) & \\text{si}\\,\\, X_6= b_{2}\\,\\,(\\text{con probabilidad}\\, p_{2})\\\\\n(0,b_{3}) & \\text{si}\\,\\, X_6= b_{3}\\,\\,(\\text{con probabilidad}\\, p_{3}),\n\\end{array}\n\\end{cases}\n\\end{align*}\\]\n\ne \\(\\small{Y_5(\\omega)}\\) pasa a cualquier otro estado con probabilidad cero. De esta forma se obtienen todas las probabilidades de transición \\(\\small{\\mathbb{P}\\big(Y_t=(u,v)\\mid Y_{t-1}=(x,z)\\big)}\\). El estado ficticio \\(\\small{\\emptyset}\\) se añadirá como estado inicial con \\(\\small{\\mathbb{P}\\big(Y_{0}=\\emptyset\\big)=1}\\) y con probabilidades de transición \\(\\small{\\mathbb{P}\\big(Y_{1}=b_{i}\\mid Y_0=\\emptyset\\big)=p_{i}}\\) para \\(\\small{i=1,2,3}\\). Obsérvese que el estado \\(\\small{(0,\\Lambda=b_{1}b_{1}b_{2})}\\) se eliminó del espacio de estados, ya que siempre que el bloque final \\(\\small{v}\\) sea igual a \\(\\small{\\Lambda}\\) debe haber al menos una ocurrencia de el patrón en la secuencia (es decir, \\(\\small{u\\geq1}\\) si \\(\\small{v=\\Lambda}\\)).\n(iv) Dado \\(\\small{n}\\), tenemos la siguiente partición en el espacio de estados \\(\\small{\\Omega}\\):\n\n\n\\[\\begin{align*}\n\\big\\{C_{\\emptyset} &=[\\emptyset], C_{0}=[(0,b_{1}),(0,b_{2}),(0,b_{3}),(0,b_{1}b_{1})], \\\\\n& \\,\\,\\text{y}\\,\\,C_{x}=[(x,v),v\\in \\mathscr{E}],\\, x=1,\\ldots,[n/3] \\big\\}.\n\\end{align*}\\]\n\nPara \\(\\small{n=5}\\) y la probabilidad inicial \\(\\small{\\mathbb{P}\\big(Y_0=\\emptyset \\big)\\equiv 1}\\), se deduce de los procedimientos (i) a (iv) anteriores que la cadena de Markov incrustada \\(\\small{\\{Y_t\\}_{t=0}^{5}}\\) está definida en el espacio de estados \\(\\small{\\Omega=\\{\\emptyset, (0, b_{1}), (0, b_{2}), (0, b_{3}), (0, b_{1}b_{1}), (1, b_{1}b_{1}b_{2}), (1, b_{1}), (1, b_{2}), (1, b_{3}), (1, b_{1}b_{1})\\}}\\) con matriz de probabilidad de transición\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\n\\begin{array}{cc}&\n\\begin{array}{c}\n\\emptyset\\\\\n(0,b_{1})\\\\\n(0,b_{2})\\\\\n(0,b_{3})\\\\\n(0,b_{1}b_{1})\\\\\n(1,b_{1}b_{1}b_{2})\\\\\n(1,b_{1})\\\\\n(1,b_{2})\\\\\n(1,b_{3})\\\\\n(1,b_{1}b_{1})\n\\end{array}\n&\n\\left(\n\\begin{array}{c|cccc|ccccc}\n0&p_{1}&p_{2}&p_{3}&0&0&0&0&0&0\\\\\n\\hline\n0&0&p_{2}&p_{3}&0&0&0&0&0&0\\\\\n0&p_{1}&p_{2}&p_{3}&0&0&0&0&0&0\\\\\n0&p_{1}&p_{2}&p_{3}&0&0&0&0&0&0\\\\\n0&0&0&p_{3}&p_{1}&p_{2}&0&0&0\\\\\n\\hline\n0&0&0&0&0&0&p_{1}&p_{2}&p_{3}&0\\\\\n0&0&0&0&0&0&0&p_{2}&p_{3}&p_{1}\\\\\n0&0&0&0&0&0&p_{1}&p_{2}&p_{3}&0\\\\\n0&0&0&0&0&0&p_{1}&p_{2}&p_{3}&0\\\\\n0&0&0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nLas probabilidades \\(\\small{\\mathbb{P}\\big(X_n(\\Lambda)=5\\big)=\\boldsymbol{\\xi_0M}^5\\boldsymbol{U'}(C_x),\\, x=0,1,}\\), pueden computarse facilmente.\nPara demostrar la aplicabilidad del principio de avance y retroceso a los patrones compuestos, consideremos el siguiente ejemplo.\nEjemplo 4.2 Dado \\(\\small{n=4}\\) y un patrón compuesto \\(\\small{\\Lambda= \\Lambda_{1} \\cup \\Lambda_{2}}\\), que consiste en la unión de dos patrones simples distintos \\(\\small{ \\Lambda_{1}=b_{1}b_{2}}\\) y \\(\\small{ \\Lambda_{1}=b_{3}b_{1}}\\), estamos interesados en encontrar la distribución de la variable aleatoria \\(\\small{X_4(\\Lambda)}\\), el número de ocurrencias de \\(\\small{\\Lambda_{1}}\\) o \\(\\small{\\Lambda_{2}}\\) en una secuencia de cuatro ensayos i.i.d. de tres estados. Procediendo como en el ejemplo anterior, se obtiene la cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) definida en el espacio de estados\n\n\n\\[\\begin{align*}\n\\Omega &=\\big\\{\\emptyset,(0,b_{1}),(0,b_{2}),(0,b_{3}),(1,b_{1}b_{2}), (1,b_{3}b_{1}), \\\\\n& \\quad \\quad (1,b_{1}),(1,b_{2}),(1,b_{3}),(2,b_{1}b_{2}),(2,b_{3}b_{1})\\big\\}.\n\\end{align*}\\]\n\ncon matriz de probabilidades de transición:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\n\\begin{array}{cc}&\n\\begin{array}{c}\n\\emptyset\\\\\n(0,b_{1})\\\\\n(0,b_{2})\\\\\n(0,b_{3})\\\\\n(1,b_{1}b_{2})\\\\\n(1,b_{3}b_{1})\\\\\n(1,b_{1})\\\\\n(1,b_{2})\\\\\n(1,b_{3})\\\\\n(2,b_{1}b_{2})\\\\\n(2,b_{3}b_{1})\n\\end{array}\n&\n\\left(\n\\begin{array}{c|ccc|ccccc|cc}\n0&p_{1}&p_{2}&p_{3}&0&0&0&0&0&0&0\\\\\n\\hline\n0&p_{1}&0&p_{3}&p_{2}&0&0&0&0&0&0\\\\\n0&p_{1}&p_{2}&p_{3}&0&0&0&0&0&0&0\\\\\n0&0&p_{2}&p_{3}&0&p_{1}&0&0&0&0&0\\\\\n\\hline\n0&0&0&0&p_{1}&0&0&p_{2}&p_{3}&0&0\\\\\n0&0&0&0&0&0&p_{1}&p_{2}&p_{3}&0&0\\\\\n0&0&0&0&0&0&p_{1}&0&p_{3}&p_{2}&0\\\\\n0&0&0&0&0&0&p_{1}&p_{2}&p_{3}&0&0\\\\\n0&0&0&0&0&0&0&p_{2}&p_{3}&0&p_{1}\\\\\n\\hline\n0&0&0&0&0&0&0&0&0&1&0\\\\\n0&0&0&0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nLas probabilidades \\(\\small{\\mathbb{P}\\big(X_n(\\Lambda)=4\\big)=\\boldsymbol{\\xi_0M}^4\\boldsymbol{U'}(C_x),\\, x=0,1,2}\\), pueden computarse facilmente.\nEl método también puede extenderse, con modificaciones simples, a la caso donde \\(\\small{\\{X_t\\}}\\) es una sucesión de ensayos multiestado Markov-Dependientes.\nEjemplo 4.3 Volvamos al Ejemplo 4.1, pero consideremos aquí que \\(\\small{\\{X_t\\}}\\) es una secuencia de ensayos de tres estados Markov-Dependientes con matriz de probabilidad de transición:\n\n\n\\[\\begin{equation}\n\\boldsymbol{A}=\\left(\n\\begin{array}{ccc}\np_{11}&p_{12}&p_{13}\\\\\np_{21}&p_{22}&p_{23}\\\\\np_{31}&p_{32}&p_{33}\\\\\n\\end{array}\n\\right)\n\\end{equation}\\]\n\nNuestro objetivo es determinar la distribución del patrón \\(\\small{\\Lambda=b_{1}b_{1}b_{2}}\\) en una secuencia de cinco ensayos. De forma análoga al Ejemplo 4.1, las probabilidades de transición de la cadena de Markov incrustada pueden obtenerse para cada estado mediante el siguiente argumento. Dado \\(\\small{Y_3 = (0, b_{1}b_{1})}\\), por ejemplo, tenemos:\n\n\n\\[\\begin{align*}\nY_3 & \\rightarrow \\quad \\quad \\, Y_{4}\\\\\n(0,b_{1}b_{1}) &\\rightarrow  \\begin{cases}\n\\begin{array}{cl}\n(0,b_{1}b_{1}) & \\text{si}\\,\\, X_{4}= b_{1}\\,\\,(\\text{con probabilidad}\\, p_{11})\\\\\n(1,b_{1}b_{1}b_{2}) & \\text{si}\\,\\, X_{4}= b_{2}\\,\\,(\\text{con probabilidad}\\, p_{12})\\\\\n(0,b_{3}) & \\text{si}\\,\\, X_{4}= b_{3}\\,\\,(\\text{con probabilidad}\\, p_{13}).\n\\end{array}\n\\end{cases}\n\\end{align*}\\]\n\nLas ecuaciones (4.4) y (4.9) son equivalentes, salvo que las probabilidades \\(\\small{p_{1}}\\),\\(\\small{p_{2}}\\) y \\(\\small{p_{3}}\\) se sustituyen por \\(\\small{p_{11}}\\),\\(\\small{p_{12}}\\) y \\(\\small{p_{13}}\\) respectivamente. Por lo tanto, la cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) se define aquí en el mismo espacio de estados \\(\\small{\\Omega}\\) y con matriz de probabilidad de transición:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\n\\begin{array}{cc}&\n\\begin{array}{c}\n\\emptyset\\\\\n(0,b_{1})\\\\\n(0,b_{2})\\\\\n(0,b_{3})\\\\\n(0,b_{1}b_{1})\\\\\n(1,b_{1}b_{1}b_{2})\\\\\n(1,b_{1})\\\\\n(1,b_{2})\\\\\n(1,b_{3})\\\\\n(1,b_{1}b_{1})\n\\end{array}\n&\n\\left(\n\\begin{array}{c|cccc|ccccc}\n0&p_{1}&p_{2}&p_{3}&0&0&0&0&0&0\\\\\n\\hline\n0&0&p_{12}&p_{13}&p_{11}&0&0&0&0&0\\\\\n0&p_{21}&p_{22}&p_{23}&0&0&0&0&0&0\\\\\n0&p_{31}&p_{32}&p_{33}&0&0&0&0&0&0\\\\\n0&0&0&p_{13}&p_{11}&p_{12}&0&0&0\\\\\n\\hline\n0&0&0&0&0&0&p_{21}&p_{22}&p_{23}&0\\\\\n0&0&0&0&0&0&0&p_{12}&p_{13}&p_{11}\\\\\n0&0&0&0&0&0&p_{21}&p_{22}&p_{23}&0\\\\\n0&0&0&0&0&0&p_{31}&p_{32}&p_{33}&0\\\\\n0&0&0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\ndonde las probabilidades de transición \\(\\small{\\mathbb{P}\\big(Y_{t}(u,v)=Y_{t-1}(x,z)\\big)}\\) se obtienen como se ilustra en la Ec. (4.9). Obsérvese que la matriz de probabilidades de transición de la Ec. (4.10) tiene exactamente la misma forma que la matriz de la Ec. (4.6) para el caso i.i.d..\nEn vista de las transiciones de estado esbozadas por las Ecs. (4.4) y (4.9), que conducen a las matrices de probabilidad de transición de los Ejemplos 4.1 a 4.3, dadas en las Ecs. (4.6), (4.8) y (4.10) respectivamente, definimos la siguiente notación: dado \\(\\small{Y_{t-1} = (x, z) \\in \\Omega}\\) y \\(\\small{X_t = j\\in \\mathscr{S}}\\), \n\n\\[\\begin{equation}\n(u,v)\\equiv &lt;(x,z),j&gt;_{\\Omega}\n\\end{equation}\\]\n\ndonde el estado \\(\\small{(u,v)\\in \\Omega}\\) es el resultado del recuento hacia delante y hacia atrás (no solapado) cuando se incluye un resultado adicional \\(\\small{X_t=j}\\). Para cada \\(\\small{(x, z)\\in \\Omega}\\), definimos también \\(\\small{L(z)\\in \\mathscr{S}}\\) como el último elemento del bloque final \\(\\small{z}\\). Entonces, para el caso general, las probabilidades de transición de la cadena de Markov incrustada \\(\\small{Y_t}\\) se especifican mediante la siguiente ecuación:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(Y_t=(u,v)\\mid Y_{t-1}=(x,z)\\big) =\\begin{cases}\np_{ij} & \\quad\n\\begin{array}{l}\n\\text{si}\\,\\, X_{t}=j\\in\\mathscr{S},\\, L(z)=i\\\\\n\\text{y}\\,\\,(u,v)= &lt;(x,z),j&gt;_{\\Omega}\n\\end{array}\\\\\nm & \\quad \\text{en otro caso}\n\\end{cases}\n\\end{equation}\\]\n\ndonde \\(\\small{p_{ij}}\\) son las probabilidades de transición de la cadena de Markov \\(\\small{\\{X_t\\}}\\). Si \\(\\small{\\{X_t\\}}\\) es una secuencia de ensayos multiestado i.i.d., la Ec.(4.12) se convierte en\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(Y_t=(u,v)\\mid Y_{t-1}=(x,z)\\big) =\\begin{cases}\np_{j} & \\quad\n\\begin{array}{l}\n\\text{si}\\,\\, X_{t}=j\\in\\mathscr{S},\\\\\n\\text{y}\\,\\,(u,v)= &lt;(x,z),j&gt;_{\\Omega}\n\\end{array}\\\\\n0 & \\quad \\text{en otro caso}\n\\end{cases}\n\\end{equation}\\]\n\nTeorema 4.1 Suponiendo que \\(\\small{\\{X_t\\}}\\) es una cadena de Markov homogénea con matriz de probabilidad de transición \\(\\small{\\boldsymbol{A} = \\big(p_{ij}\\big)_{m\\times m}}\\), y \\(\\small{\\Lambda=\\displaystyle{\\bigcup_{i=1}^{l}\\Lambda_{i}}}\\) es un patrón compuesto generado por \\(\\small{l}\\) patrones simples distintos \\(\\small{\\Lambda_{i}}\\) que tienen la misma longitud \\(\\small{k}\\), entonces la cadena de Markov incrustada \\(\\small{\\big\\{Y_t=\\big(X_{t}(\\Lambda),E_{t} \\big),\\,t=1,2,\\,\\ldots,n\\big\\}}\\) correspondiente a la variable aleatoria \\(\\small{X_{n}(\\Lambda)}\\)\n(i) se define sobre el espacio de estados:\n\n\n\\[\\begin{align*}\\Omega &=\\{\\emptyset\\}\\, \\cup\\,\\{(x,z):x=0,1,\\cdots,[n\n/k],\\,\\, z\\in \\mathscr{E}\\}\\\\\n&\\quad- \\{(0,\\Lambda_{i}):i=1,\\cdots,l\\}\n-\\,\\{([n/k],z):k[n/k]+z(k)&gt;n\\},\\end{align*}\\]\n\nen donde \\(\\small{\\mathscr{E} =\\mathscr{S}\\,\\cup\\Bigg(\\displaystyle\\bigcup_{i=1}{\\mathscr{S}(\\Lambda_{i})\\Bigg)}}\\) y \\(\\small{z(k)\\equiv [\\text{longitud de}\\,z] \\pmod k}\\)\n(ii) tiene la matriz de probabilidades de transición: \n\n\\[\\begin{equation}\n\\boldsymbol{M}=\\big(p_{(x,z)(u,v)}\\big)_{d\\times d}\n\\end{equation}\\]\n\nen donde las probabilidades de transición estan dadas por: \n\n\\[\\begin{equation}\np_{(x,z)(u,v)}=\\begin{cases}\np_{j} & \\,\\text{si}\\, (x,z)=\\emptyset,\\,u=0,\\,v=j,\\, \\text{para todo}\\, j \\in \\mathscr{S}\\\\ \\\\\np_{ij} &\n\\begin{array}{l}\n\\text{si}\\,(u,v)=&lt;(x,z),j&gt;_{\\Omega},\\, x\\leq [n/k],\\, j\\in \\mathscr{S},\\\\\nL(z)=i,\\,\\text{y}\\,\\, kx+z(k)&lt;n\n\\end{array} \\\\ \\\\\n1 &\n\\begin{array}{l}\n\\text{si}\\,(u,v)= (x,z) ,\\, x= [n/k]\\\\\n\\,\\text{y}\\,\\, k[n/k]+z(k)=n\n\\end{array} \\\\\\\\\nm & \\text{en otro caso.}\n\\end{cases}\n\\end{equation}\\]\n\ncon \\(\\small{d=\\text{card}(\\Omega)}\\), el tamaño del espacio de estados \\(\\small{\\Omega}\\), igual a:\n\n\n\\[\\begin{align*}d =1 & +([n/k]+1)\\times \\text{card}\\big(\\mathscr{E}\\big)-l\\\\\n& -\\text{card}\\Big(\\big\\{([n/k],z):\\,z \\in \\mathscr{E}, \\,k[n/k]+z(k)&gt;n\\big\\}\\big),\\end{align*}\\]\n\ny (iii) se obtiene la distribución:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big( X_n(\\Lambda)=x\\big)=\\boldsymbol{\\mathbf{\\xi}}_0\\boldsymbol{M}^{n}\\boldsymbol{\\mathbf{U}'}( {C_x}),\\,\\,  x=1,2,\\ldots,[n/k],\n\\end{equation}\\]\n\nen donde \\(\\small{\\boldsymbol{\\xi}_0}\\) es la distribución inicial especificada por \\(\\small{\\mathbb{P}\\big(Y_{0}=\\emptyset\\big)\\equiv 1}\\) y \n\n\\[\\begin{align*}\nC_{\\emptyset} &=[\\emptyset],\\, C_{0}=[(0,z):z\\in\\mathscr{S}]-[(0,\\Lambda_{i}):i=1,2,\\ldots,l], \\\\\nC_{x} &=  [(x,z):z\\in \\mathscr{E}],\\, 1\\leq x \\leq [n/k], \\, \\text{y}\\\\\nC_{[n/x]}&=[([n/k],z):z\\in \\mathscr{E},\\,k[n/k]+z(k)\\leq n]\n\\end{align*}\\]\n\nson las particiones del espacio de estados \\(\\small{\\Omega}\\).\nNótese que el espacio de estados \\(\\small{\\Omega}\\) y su tamaño \\(\\small{d}\\) son funciones de \\(\\small{n}\\), la estructura de los patrones \\(\\small{\\Lambda_{i},\\,i=1,\\ldots,l}\\) y la longitud del patrón común \\(\\small{k}\\). El lector puede comprobar que los resultados de los Ejemplos 4.1 a 4.3 se deducen directamente del Teorema 4.1.\nDemostración. Dado \\(\\small{n}\\), como la longitud de cada patrón es \\(\\small{k}\\), el número máximo de patrones es \\(\\small{[n/k]}\\) (bajo conteo no solapado). El conjunto \\(\\small{\\mathscr{E} =\\mathscr{S}\\,\\cup\\Bigg(\\displaystyle\\bigcup_{i=1}{\\mathscr{S}(\\Lambda_{i})\\Bigg)}}\\) contiene todos los posibles bloques finales generados por \\(\\small{\\mathscr{S}}\\) y todos los patrones, y se deduce que para recuento hacia delante y hacia atrás sin solapamiento, el espacio de estados tiene la forma \\(\\small{\\big\\{(x,z): x=0,\\ldots,[n/k]},\\,z\\in\\mathscr{E}\\big\\}\\). Los estados \\(\\small{\\big\\{(0,\\Lambda_{i}): i=1,\\ldots,l}\\big\\}\\) se eliminan porque si el bloque final es \\(\\small{\\Lambda_{i}}\\), entonces debe haber al menos un patrón \\(\\small{\\Lambda_{i}}\\), en la secuencia \\(\\small{(x\\geq 1)}\\), por lo que los estados \\(\\small{\\big\\{(0,\\Lambda_{i})\\big\\}}\\) son inalcanzables; por la misma razón, los estados \\(\\small{\\big\\{([n/k],z):k[k/z]+z(k)&gt;n\\big\\}}\\) tampoco pueden darse y pueden eliminarse. Así, el espacio de estados \\(\\small{\\Omega}\\) de la cadena de Markov incrustada tiene la forma dada por la Ec. (4.14), y su tamaño \\(\\small{d}\\) viene determinado por la Ec.(4.17).\nDados \\(\\small{(x,z)\\in \\Omega,\\,0\\leq x \\leq [n/n]}\\), y \\(\\small{kx + z(k) &lt; n}\\), si \\(\\small{X_{t}=j\\in \\mathscr{S}}\\) y \\(\\small{(u, v) = &lt; (x, z), j &gt;_{\\Omega}}\\) , entonces, como se describe en las Ecs. (4.9) y (4.12), se deduce que\n\n\n\\[\\begin{align*}\np_{(x,z)(u,v)}=\\mathbb{P}\\big(Y_t=(u,v)\\mid Y_{t-1}=(x,z)\\big)=p_{ij},\n\\end{align*}\\]\n\ndonde \\(\\small{i=L(z)}\\). Si \\(\\small{Y_{t-1}=([n/k], z) }\\), y \\(\\small{[kn/k] + z(k) = n}\\) entonces \\(\\small{t-1\\equiv n}\\); por conveniencia, asignamos las probabilidades de transición para estos estados como \\(\\small{\\mathbb{P}\\big(Y_t=([n/k],z)\\mid Y_{t-1}=([n/k],z)\\big)\\equiv1}\\) . Esto completa la construcción de la Ec. (4.16) y la matriz de probabilidad de transición \\(\\small{\\boldsymbol{M}}\\) . Las particiones en el espacio de estados \\(\\small{\\Omega}\\) , dadas por la Ec. (4.19), son una consecuencia directa de la definición de la cadena de Markov incrustada introducida en la Ec. (4.3). Por lo tanto, la distribución para el patrón compuesto \\(\\small{\\Lambda}\\) en la Ec. (4.18) es una consecuencia inmediata del Teorema 2.1. Esto completa la demostración. \\(\\hspace{1cm}\\Box\\)\nEl teorema 4.1 anterior también es válido para patrones simples, el caso especial cuando \\(\\small{l=1}\\) . Cuando las longitudes de los patrones \\(\\small{k_{i},\\, i=1,\\ldots,l}\\) no son todas iguales, el principio de avance y retroceso puede seguir utilizándose para hallar la distribución del patrón compuesto \\(\\small{\\Lambda}\\) . En principio, el procedimiento de recuento de avance y retroceso es aplicable a cualquier número de patrones \\(\\small{l}\\) de tamaños \\(\\small{k_{i}}\\) variables, pero no es sencillo escribir la forma general del espacio de estados y la matriz de probabilidad de transición de la cadena de Markov incrusrada. Trataremos este problema en el capítulo 5 utilizando la relación de dualidad entre \\(\\small{X_{n}(\\Lambda)}\\) y el tiempo de espera \\(\\small{W(\\Lambda)}\\).\n\n\n\nConsideremos que la secuencia \\(\\small{\\{X_t\\}}\\) es una cadena de Markov homogénea definida sobre el espacio de estados \\(\\small{\\mathscr{S}=\\{a, b, c\\}}\\) con matriz de probabilidades de transición\n\n\n\\[\\begin{equation}\n\\boldsymbol{A}=\\big(p_{ij}\\big),\\, i,j=a,b,c\n\\end{equation}\\]\n\nSea \\(\\small{\\Lambda}\\) un patrón simple de longitud \\(\\small{k}\\). La diferencia básica entre el recuento por solapamiento y el recuento sin solapamiento es que cuando se forma el patrón \\(\\small{\\Lambda}\\), una parte de A se contará para formar el siguiente patrón \\(\\small{\\Lambda}\\) bajo el recuento por solapamiento, hasta los últimos \\(\\small{(k-1)}\\) ensayos.\nDefinición 4.1 Un bloque final \\(\\small{E^°}\\) generado por el patrón \\(\\small{\\Lambda}\\) es el bloque final más largo \\(\\small{(E^{°} \\neq \\Lambda)}\\) que, después de cada aparición de \\(\\small{\\Lambda}\\) bajo conteo superpuesto, se puede asignar como bloque final inicial para la siguiente aparición de \\(\\small{\\Lambda}\\). Escribimos \\(\\small{(E^{°} \\cong \\Lambda}\\) , con respecto al conteo de superposición.\nPor ejemplo, bajo el conteo superpuesto:\n\nSi \\(\\small{\\Lambda=aca}\\), entonces \\(\\small{E^{°}=a}\\),\nSi \\(\\small{\\Lambda=abcab}\\), entonces \\(\\small{E^{°}=ab}\\), y\nSi \\(\\small{\\Lambda=\\underbrace{a\\cdots a}_{k}}\\), entonces \\(\\small{E^{°}=\\underbrace{a\\ldots a}_{k-1}}\\).\n\nPara un patrón como \\(\\small{\\Lambda=abc}\\), no existe un \\(\\small{E^{°}}\\), en cuyo caso el conteo superpuesto y no superpuesto es el mismo. Tenga en cuenta que bajo el conteo superpuesto, dado que el primer patrón requiere \\(\\small{k}\\) elementos y cada patrón adicional requiere solo \\(\\small{k-\\text{Card}(E^{°})}\\) elementos, el mayor número posible de patrones \\(\\small{\\Lambda}\\) que pueden ocurrir en \\(\\small{n (n \\geq k)}\\) ensayos es\n\n\n\\[\\begin{equation*}\nl_{n}^{o}=1+\\bigg[\\frac{n-k}{k-\\text{Card}(E^{°})}\\bigg].\n\\end{equation*} \\]\n\nPara ilustrar las diferencias menores que surgen de los dos tipos de conteo, se proporciona el siguiente ejemplo.\nEjemplo 4.4 Consideremos el número de patrones \\(\\small{\\Lambda=aca}\\) que ocurren en \\(\\small{n=5}\\) ensayos i.i.d. de tres estados. Bajo el conteo no superpuesto, la matriz de transición de probabilidades \\(\\small{\\boldsymbol{M}}\\) asociada con la cadena de Markov incrustada\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\n\\begin{array}{cc}&\n\\begin{array}{c}\n(0,a)\\\\\n(0,b)\\\\\n(0,c)\\\\\n(0,ab)\\\\\n(1,\\Lambda)\\\\\n(1,a)\\\\\n(1,b)\\\\\n(1,c)\\\\\n(1,ac)\\\\\n\\end{array}\n&\n\\left(\n\\begin{array}{ccccccccc}\np_{a}&p_{b}&0&p_{c}&0&0&0&0&0\\\\\np_{a}&p_{b}&p_{c}&0&0&0&0&0&0\\\\\np_{a}&p_{b}&p_{c}&0&0&0&0&0&0\\\\\n0&p_{b}&p_{c}&0&p_{a}&0&0&0&0\\\\\n0&0&0&0&0&p_{a}&p_{b}&p_{c}&0\\\\\n0&0&0&0&0&p_{a}&p_{b}&0&p_{c}\\\\\n0&0&0&0&0&p_{a}&p_{b}&p_{c}&0\\\\\n0&0&0&0&0&p_{a}&p_{b}&p_{c}&0\\\\\n0&0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\ndonde \\(\\small{(1,\\Lambda)\\equiv (1,aca)}\\) . Bajo conteo de superpuesto, la matriz de probabilidad de transición \\(\\small{\\boldsymbol{M^{°}}}\\) asociada con la cadena de Markov incrustada es\n\n\n\\[\\begin{equation}\n\\boldsymbol{M^{°}}=\n\\begin{array}{cc}&\n\\begin{array}{c}\n(0,a)\\\\\n(0,b)\\\\\n(0,c)\\\\\n(0,ab)\\\\\n(1,\\Lambda)\\\\\n(1,a)\\\\\n(1,b)\\\\\n(1,c)\\\\\n(1,ac)\\\\\n(2,\\Lambda)\n\\end{array}\n&\n\\left(\n\\begin{array}{ccccc|cccc}\np_{a}&p_{b}&0&p_{c}&0&0&0&0&0&0\\\\\np_{a}&p_{b}&p_{c}&0&0&0&0&0&0&0\\\\\np_{a}&p_{b}&p_{c}&0&0&0&0&0&0&0\\\\\n0&p_{b}&p_{c}&0&p_{a}&0&0&0&0&0\\\\\n\\hline\n0&0&0&0&0&p_{a}&p_{b}&0&p_{c}&0\\\\\n\\hline\n0&0&0&0&0&p_{a}&p_{b}&0&p_{c}&0\\\\\n0&0&0&0&0&p_{a}&p_{b}&p_{c}&0&0\\\\\n0&0&0&0&0&p_{a}&p_{b}&p_{c}&0&0\\\\\n0&0&0&0&0&0&p_{b}&p_{c}&0&p_{a}\\\\\n0&0&0&0&0&0&0&0&1&0\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nLa principal diferencia entre las dos matrices surge después de que ha ocurrido el primer patrón. Con probabilidad \\(\\small{p_{c}}\\) , el estado \\(\\small{(1,\\Lambda)}\\) pasa al estado \\(\\small{(1,c)}\\) bajo conteo no superpuesto, mientras que \\(\\small{(1,\\Lambda)}\\) pasa a \\(\\small{(1,ac)}\\) bajo conteo superpuesto, lo que también implica el estado adicional \\(\\small{l_{n}^{°}=(2,\\Lambda)}\\). \\(\\hspace{1cm}\\Diamond\\)\nSi \\(\\small{\\{X_t\\}}\\) es una cadena de Markov homogénea con probabilidades de transición dadas por la Ecuación. (4.20), la matriz de probabilidad de transición \\(\\small{\\boldsymbol{M^{°}}}\\) del anterior ejemplo (bajo conteo superpuesto) se convierte en:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M^{°}}=\n\\begin{array}{cc}&\n\\begin{array}{c}\n\\emptyset\\\\\n(0,a)\\\\\n(0,b)\\\\\n(0,c)\\\\\n(0,ab)\\\\\n(1,\\Lambda)\\\\\n(1,a)\\\\\n(1,b)\\\\\n(1,c)\\\\\n(1,ac)\\\\\n(2,\\Lambda)\n\\end{array}\n&\n\\left(\n\\begin{array}{cccccc|ccccc}\n0&p_{a}&p_{b}&p_{c}&0&0&0&0&0&0&0\\\\\n0&p_{aa}&p_{ab}&0&p_{ac}&0&0&0&0&0&0\\\\\n0&p_{ba}&p_{bb}&p_{bc}&0&0&0&0&0&0&0\\\\\n0&p_{ca}&p_{cb}&p_{cc}&0&0&0&0&0&0&0\\\\\n0&0&p_{bb}&p_{bc}&0&p_{ab}&0&0&0&0&0\\\\\n\\hline\n0&0&0&0&0&0&p_{aa}&p_{ab}&0&p_{ac}&0\\\\\n\\hline\n0&0&0&0&0&0&p_{aa}&p_{ab}&0&p_{ac}&0\\\\\n0&0&0&0&0&0&p_{ba}&p_{bb}&p_{bc}&0&0\\\\\n0&0&0&0&0&0&p_{ca}&p_{cb}&p_{cc}&0&0\\\\\n0&0&0&0&0&0&0&p_{cb}&p_{cc}&0&p_{ca}\\\\\n0&0&0&0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\ndonde \\(\\small{p_{a},\\, p_{b}}\\), y \\(\\small{p_{c}}\\) son las probabilidades de transición dadas del estado \\(\\small{\\emptyset}\\) a los estados \\(\\small{(0, a), (0,b)}\\) y \\(\\small{(0, c)}\\), respectivamente. Nuevamente, la extensión de i.i.d. a los emnsayos Markov-Dependientes sigue siendo sencillo. El concepto considerado en el ejemplo anterior se puede extender al caso de superposición hasta los últimos \\(\\small{d}\\) ensayos \\(\\small{(1 \\leq d \\leq k − 1)}\\), como lo introdujeron Aki e Hirano (2000). Una ventaja significativa de la técnica de incrustación de cadenas finitas de Markov es que la extensión del conteo sin superposición al conteo superpuesto es directa y simple.\n\n\n\nLa distribución del número de patrones en serie \\(\\small{\\Lambda=\\Lambda_{1}\\ast\\Lambda_{2}}\\) se puede obtener casi de la misma manera que para un patrón simple, con modificaciones menores en el estado después de que se haya producido el primer patrón \\(\\small{\\Lambda_{1}}\\).\nEjemplo 4.5 Consideremos una secuencia de \\(\\small{n=5}\\) ensayos i.i.d. de tres estados extraídos de \\(\\small{\\mathscr{S}=\\{a,b,c\\}}\\), y el patrón de serie \\(\\small{\\Lambda}=ab\\ast cc\\) generado por los dos patrones simples \\(\\small{\\Lambda_{1}=ab}\\) y \\(\\small{\\Lambda_{2}=cc}\\). Definiendo el conjunto de bloques finales \\(\\small{\\mathscr{E}=\\{a,\\bar{a},ab\\ast,ab{\\ast}c,ab{\\ast}cc\\}}\\) y el espacio de estados\n\n\n\\[\\begin{equation}\n\\Omega=\\{\\emptyset,(0,a),(0,\\bar{a}),(0,ab{\\ast}),(0,ab{\\ast}c),(1,ab{\\ast}cc),(1,a),(1,\\bar{a})\\}\n\\end{equation}\\]\n\ndonde \\(\\small{\\bar{a}}\\) representa \\(\\small{b}\\) o \\(\\small{c}\\), y \\(\\small{ab{\\ast}}\\) representa \\(\\small{ab{\\ast}a}\\) o \\(\\small{ab{\\ast}b}\\). La correspondiente cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) tiene la matriz de probabilidad de transición \\(\\small{\\boldsymbol{M}}\\) dada por:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\n\\begin{array}{cc}&\n\\begin{array}{c}\n\\emptyset\\\\\n(0,a)\\\\\n(0,\\bar{a})\\\\\n(0,ab{\\ast})\\\\\n(0,ab{\\ast}c)\\\\\n(1,ab{\\ast}cc)\\\\\n(1,a)\\\\\n(1,\\bar{a})\\\\\n\\end{array}\n&\n\\left(\n\\begin{array}{cccccccc}\n0&p_{a}&p_{b}+p_{c}&0&0&0&0&0\\\\\n0&p_{a}&p_{c}&p_{b}&0&0&0&0\\\\\n0&p_{a}&p_{b}+p_{c}&0&0&0&0&0\\\\\n0&0&0&p_{a}+p_{b}&p_{c}&0&0&0\\\\\n0&0&0&p_{a}+p_{b}&0&p_{c}&0&0\\\\\n0&0&0&0&0&0&p_{a}&p_{b}+p_{c}\\\\\n0&0&0&0&0&0&1&0\\\\\n0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nPor lo tanto:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(X_{n}(\\Lambda)=x\\big)=\\boldsymbol{\\xi}_{0}\\boldsymbol{M}^{5}\\boldsymbol{U}(C_{x}),\\,x=0,1.\n\\end{equation}\\]\n\nObsérvese que si \\(\\small{\\{Y_t\\}}\\) está en el estado \\(\\small{(0, ab{\\ast})}\\) o \\(\\small{(0,ab{\\ast}c)}\\), significa que el patrón \\(\\small{\\Lambda_{1}=ab}\\) ha ocurrido antes o en el \\(\\small{t-}\\)ésimo ensayo. Ahora bien, si la realización de \\(\\small{X_{t+1}}\\) es \\(\\small{a}\\) o \\(\\small{b}\\) , entonces \\(\\small{Y_{t+1}}\\) tiene que estar en el estado \\(\\small{(0, ab{\\ast})}\\), suceso que ocurre con probabilidad de transición \\(\\small{p_{a}+p_{b}}\\) , y si la realización de \\(\\small{X_{t+1}}\\) es \\(\\small{c}\\), entonces \\(\\small{Y_{t+1}}\\) avanza al estado \\(\\small{(0, ab{\\ast}c)}\\) o \\(\\small{(1, ab{\\ast}cc)}\\), respectivamente, sucesos que ocurren con probabilidad de transición \\(\\small{p_{c}}\\).\nEl ejemplo anterior pone de manifiesto las diferencias entre los patrones en series y los patrones simples en lo que respecta a sus matrices de probabilidad de transición de las cadenas de Markov incrustadas. Ampliando ligeramente el espacio de estados \\(\\small{\\Omega}\\), sustituyendo \\(\\small{(i,\\bar{a}),\\, i=0,1}\\), por \\(\\small{(i,b)}\\) y \\(\\small{(i, c)}\\), y sustituyendo \\(\\small{(0, ab{\\ast})}\\) por \\(\\small{(0, ab{\\ast}a)}\\) y \\(\\small{(0, ab{\\ast}b)}\\), el ejemplo anterior puede ampliarse fácilmente al caso de ensayos de tres estados Markov-Dependientes.\n\n\n\nHallar la distribución conjunta de dos números de rachas, digamos \\(\\small{X_n(\\Lambda_{1})}\\) y \\(\\small{X_n(\\Lambda_{2})}\\) , en una secuencia de ensayos de dos o varios estados \\(\\small{\\{X_t\\}}\\) utilizando la técnica de incrustación de cadenas de Markov finitas es similar a hallar la distribución exacta de \\(\\small{X_n(\\Lambda)}\\) introducida en la Sección 4.2. En general, la cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) asociada a la distribución conjunta de \\(\\small{X_n(\\Lambda_{1})}\\) y \\(\\small{X_n(\\Lambda_{2})}\\) tiene la forma\n\n\n\\[\\begin{equation}\nY_{t}=\\big(X_{t}(\\Lambda_{1}),X_{t}(\\Lambda_{2}),E_{t}\\big),\\,t=1,2,\\ldots,n.\n\\end{equation}\\]\n\nEl espacio de estados \\(\\small{\\Omega}\\) y el bloque final \\(\\small{E_{t}}\\) para \\(\\small{\\{Y_t\\}}\\) dependen en gran medida de la estructura de los patrones \\(\\small{\\Lambda_{1}}\\) y \\(\\small{\\Lambda_{2}}\\). Las matrices de probabilidad de transición \\(\\small{\\boldsymbol{M}_{t}}\\) de la cadena de Markov inscrustada pueden construirse utilizando los mismos principios descritos en secciones anteriores. A continuación, damos un ejemplo para demostrar el procedimiento para encontrar la distribución conjunta.\nEjemplo 4.6 Sea \\(\\small{X_{n}}\\) el número total de rachas de éxito \\(\\small{X_{n}(S)}\\) y de fracaso \\(\\small{X_{n}(S)}\\) en una secuencia de \\(\\small{n}\\) ensayos de dos estados. Para cada \\(\\small{X_{n} = X_{n}(S) + X_{n}(F)}\\), y los números de rachas \\(\\small{X_{n}(S)}\\) y \\(\\small{X_{n}(F)}\\) están relacionados de la siguiente manera: si hay \\(\\small{x}\\) rachas de éxito, entonces sólo puede haber \\(\\small{x+1, x}\\), o \\(\\small{x-1}\\) rachas de fracaso. De ello se deduce que sólo puede haber cuatro tipos de estados \\(\\small{Y_{t}=(X_{t}(S), X_{t}(F), E_{t})}\\), donde el bloque final \\(\\small{E_{t}}\\) es \\(\\small{S}\\) o \\(\\small{F}\\) : (i) \\(\\small{(x, x-1, S)}\\), (ii) \\(\\small{(x, x + 1, F)}\\), (iii) \\(\\small{(x, x, S)}\\) y (iv) \\(\\small{(x, x, F)}\\).\nConsideremos los resultados de diez ensayos de dos estados \\(\\small{w = (SSFFSFSSSF)}\\). La realización de la cadena de Markov imbricada \\(\\small{\\{Y_t\\}}\\) es \\(\\small{\\{Y_{1}=(1,0, S), Y_{2}=(1,0,S), Y_{3}=(1,1,F), Y_{4}=(1,1,F), Y_{5}=(2,1,S), Y_{6}= (2,2,F),Y_{7}=(3,2,S),Y_{8}=(3,2, S),Y_{9}=(3,2,S), Y_{10} = (3,3, F)\\}}\\). El espacio de estados \\(\\small{\\Omega}\\) tiene la forma \\(\\small{\\Omega=\\{(1,0,S), (0,1,F), (1,1,S), (1,1,F),\\ldots, (l_{n},l_{n}S), (l_{n}, l_{n},F)\\}}\\), donde \\(\\small{l_{n}=[(n+1)/2]}\\). Para el caso de ensayos de dos estados independientes pero no idénticamente distribuidos, la definición de \\(\\small{Y_{t}}\\) da como resultado las matrices de probabilidad de transición, para \\(\\small{t=2,3,\\ldots,n,}\\)\n\n\n\\[\\begin{equation}\n\\boldsymbol{M_{t}}=\n\\begin{array}{cc}&\n\\begin{array}{c}\n(1,0,S)\\\\\n(0,1,S)\\\\\n(1,1,S)\\\\\n(1,1,S)\\\\\n\\cdot\\\\\n\\cdot\\\\\n\\cdot\\\\\n(l_{n},l_{n}-1,S)\\\\\n(l_{n}-1,l_{n},F)\\\\\n(l_{n},l_{n},S)\\\\\n(l_{n},l_{n},F)\\\\\n\\end{array}\n&\n\\left(\n\\begin{array}{ccccccccccc}\np_{t}&0&0&q_{t}&&&&&&&\\\\\n&q_{t}&p_{t}&0&0&&&&&&\\\\\n&&p_{t}&0&0&q_{t}&&&&&\\\\\n&&&q_{t}&p_{t}&0&0&&&&\\\\\n&&&&\\ddots&\\ddots&\\ddots&\\ddots&&&\\\\\n&&&&&\\cdot&\\cdot&\\cdot&\\cdot&&\\\\\n&&&&&&\\ddots&\\ddots&\\ddots&\\ddots&\\\\\n&&&&&&&p_{t}&0&0&q_{t}\\\\\n&&&&&&&&q_{t}&p_{t}&0\\\\\n&&&&&&&&&1&0\\\\\n&&&&&&&&&&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nDado \\(\\small{\\boldsymbol{\\xi}_{1}=(p_{1},q_{1},0,\\ldots,0)}\\) , se deduce que la distribución conjunta de \\(\\small{X_n(S)}\\) y \\(\\small{X_n(F)}\\) está dada por:\n\n\n\\[\\begin{equation}\n\\small{\\mathbb{P}\\big( X_{n}(S)=x,X_{n}(F)=y\\mid \\boldsymbol{\\xi}_{1}\\big)=\\boldsymbol{\\mathbf{\\xi}}_{1} \\Big(\\prod_{t=1}^{n}\\boldsymbol{M}_{t}\\Big)\\boldsymbol{\\mathbf{U}'}(\\mathbf{C}_{(x,y)})},\n\\end{equation}\\]\n\ndonde, si \\(\\small{y= x+1}\\), entonces \\(\\small{C_{(x,x+1)}=\\{{(x, x + 1, F)}\\}}\\), si \\(\\small{y=x-1}\\), entonces \\(\\small{C_{(x, x-1)}=\\{(x, x-1, S)\\}}\\), si \\(\\small{y=x}\\) entonces \\(\\small{C_{(x,x)}=\\{(x, x, S), (x, x, F)\\}}\\), y \\(\\small{C_{(x,y)}=\\{\\emptyset\\}}\\) en cualquier otro caso.\nUna vez más, con algunas modificaciones sencillas de las matrices de probabilidades de transición, los resultados anteriores también son válidos tanto para ensayos de dos estados i.i.d., como Markov-Dependientes homogéneos y no homogéneos. Las distribuciones marginales de \\(\\small{X_{n}(S)}\\) y \\(\\small{X_{n}(F)}\\) pueden obtenerse proyectando la distribución conjunta sobre las particiones generadas por las variables aleatorias \\(\\small{X_{n}(S)}\\) y \\(\\small{X_{n}(F)}\\), respectivamente. De forma más general, la distribución conjunta de \\(\\small{l&gt;2}\\) variables aleatorias \\(\\small{X_{n}(\\Lambda_{1}),X_{n}(\\Lambda_{2}),\\ldots,X_{n}(\\Lambda_{l})}\\) puede obtenerse del mismo modo con una cadena de Markov \\(\\small{(l+1)-}\\)dimensional \\(\\small{\\{Y_{t} = \\big(X_{t}(\\Lambda_{1}),\\cdots, X_{t}(\\Lambda_{l}), E_{t}\\big)\\}}\\).\nFin 05 de Nov\n\n\n\n\n\n\n\nAbramson, M. and Moser, W. O. J. (1967). Permutations without rising or falling w-sequences. Annals of Mathematical Statistics 38, 1245-1254.\nAki, S. (1985). Discrete distributions of order k on a binary sequence. Annals of the Institute of Statistical Mathematics 37, 205-224.\nAki, S. (1997). On sooner and later problems between success and failure runs.Advances in Combinatorial Methods and Applications to Probability and Statistics (ed. N. Balakrishnan), Birkhäuser, Boston, 385-400.\nAki, S. (1999). Distributions of runs and consecutive systems on directed trees. Annals of the Institute of Statistical Mathematics 51, 1-15.\nAki, S., Balakrishnan, N. and Mohanty, S. G. (1996). Sooner and later waiting time problems for success and failure runs in higher order Markov dependent trials. Annals of the Institute of Statistical Mathematics 48, 773-787.\nAki, S. and Hirano, K. (1988). Some characteristics of the binomial distribution of order k and related distributions. Statistical Theory and Data Analysis II (ed. K. Matusita), North-Holland, Amsterdam, 211-222.\nAki, S. and Hirano K. (1999). Sooner and later waiting time problems for runs in Markov dependent bivariate trials. Annals of the Institute of Statistical Mathematics 51, 17-29.\nAki, S. and Hirano K. (2000). Numbers of success-runs of specified length until certain stopping time rules and generalized binomial distributions of order k. Annals of the Institute of Statistical Mathematics 52, 767-777.\nAki, S., Kuboki, H. and Hirano, K. (1984). On discrete distributions of order k. Annals of the Institute of Statistical Mathematics 36, 431-440.\nAntzoulakos, D. L. (1999). On waiting time problems associated with runs in Markov dependent trials. Annals of the Institute of Statistical Mathematics 51, 323-330.\nAntzoulakos, D. L. (2001). Waiting times for patterns in a sequence of multistate trials. Journal of Applied Probability 38, 508-518.\nBalakrishnan, N. and Koutras, M. V. (2002). Runs and Scans with Applications, Wiley, New York\nBalasubramanian, K., Viveros, R. and Balakrishnan, N. (1993). Sooner and later waiting time problems for Markovian Bernoulli trials. Statistics and Prob- ability Letters 18, 153–161.}\nBarnard, G. A. (1959). Control charts and stochastic processes. Journal of the Royal Statistical Society, Series B 21, 239-271.\nBarton, D. E. and David, F. N. (1958). Non-randomness in a sequence of two alternatives: II. Runs test. Biometrika 45, 253-256.\nBateman, G. (1948). On the power function of the longest run as a test for randomness in a sequence of alternatives. Biometrika 35, 97-112.\nBoutsikas, M. V. and Koutras, M. V. (2000a). Generalized reliability bounds for coherent structures. Journal of Applied Probability 37, 778-794.\nBoutsikas, M. V. and Koutras, M. V. (2000b). Reliability approximation for Markov chain imbeddable systems. Methodology and Computing in Applied Probability 2, 393-411.\nBrook, D. and Evans, D. A. (1972). An approach to the probability distribution of cusum run length. Biometrika 59, 539-549.\nCai, J. (1994). Reliability of a large consecutive-k-out-of-r-from-n:F system with unequal component-reliability. IEEE Transactions on Reliability 43, 107– 111.\nCarlitz, L. (1964). Extended Bernoulli and Eulerian numbers. Duke Mathematical Journal 31, 667-689.\nChao, M. T. (1999). Applications of Markov chains in quality-related matters. Statistical Process Monitoring and Optimization (eds. S. H. Park and G. G. Vining), Marcel Dekker, New York, 175-188.\nChao, M. T. and Fu, J. C. (1989). A limit theorem of certain repairable systems. Annals of the Institute of Statistical Mathematics 41, 809–818.\nChao, M. T. and Fu, J. C. (1991). The reliability of large series system under a Markovian structure. Advances in Applied Probability 23, 894-908.\nChao, M. T., Fu, J. C. and Koutras, M. V. (1995). Survey of reliability stud- ies of consecutive-k-out-of-n: F and related systems. IEEE Transactions on Reliability 44, 120-127.\nChao, M. T. and Lin, G. D. (1984). Economical design of large consecutive-k- out-of-n:F systems. IEEE Transactions on Reliability 33, 411-413.\nChen, J. and Glaz, J. (1997). Approximations and inequalities for the distribution of a scan statistic for 0-1 Bernoulli trials. Advances in the Theory and Practice of Statistics (eds. N. L. Johnson and N. Balakrishnan), Wiley, New York, 285-298.\nChen, J. and Glaz, J. (1999). Approximations for the distribution and the moments of discrete scan statistics. Scan Statistics and Applications (eds. J. Glaz and N. Balakrishnan), Birkhäuser, Boston, 27-66.\nCheung, L. K. W. (2002). Statistical Pattern Recognition in Genomic DNA Sequences. Ph.D. Dissertation, Department of Statistics, University of Manitoba, Canada.\nChiang, D. T. and Niu, S. C. (1981). Reliability of consecutive-k-out-of-n:F sys- tems. IEEE Transactions on Reliability 30, 87-89.\nChrysaphinou, O. and Papastavridis, S. (1988). A limit theorem on the number of overlapping appearances of a pattern in a sequence of independent trials. Probability Theory and Related Fields 79, 129-143.\nCochran, W. G. (1938). An extension of Gold’s method for examining the apparent persistence of one type of weather. Quarterly Journal of the Royal Meteorological Society 64, 631-634.\nCsörgö, S. (1979). Erdös-Rényi laws. Annals of Statistics 7, 772-787. David, F. N. (1947). A power function for tests of randomness in a sequence of alternatives. Biometrika 34, 335-339.\nDavid, F. N. and Barton, D. E. (1962). Combinatorial Chance, Hafner, New York. Derman, G., Lieberman, G. J. and Ross, S. M. (1982). On the consecutive-k-out- of-n:F system. IEEE Transactions on Reliability 31, 57-63.\nDillon, J. F. and Roselle, D. P. (1969). Simon Newcomb’s problem. SIAM Journal on Applied Mathematics 17, 1086-1093.\nDoi, M. and Yamamoto, E. (1998). On the joint distribution of runs in a sequence of multi-state trials. Statistics and Probability Letters 39, 133-141.\nDwass, M. (1973). The number of increases in a random permutation. Journal of Combinatorial Theory, Series A 15, 192-199.\nEbneshahrashoob, M. and Sobel, M. (1990). Sooner and later problems for Bernoulli trials: frequency and run quotas. Statistics and Probability Letters 9, 5-11.\nErdös, P. and Rényi, A. (1970). On a new law of large numbers. Journal d’Analyse Mathématique 23, 103-111.\nErdös, P. and Révész, P. (1975). On the length of the longest head-run. Topics in Information Theory, Colloquia Mathematica Societatis János Bolyai, 16 (eds. I. Csiszar and P. Elias; Keszthely, Hungary), North-Holland, Amster- dam, 219-228.\nEwan, W. D. and Kemp, K. W. (1960). Sampling inspection of continuous pro- cesses with no autocorrelation between successive results. Biometrika 47, 363-380.\nFeller, W. (1968). An Introduction to Probability Theory and Its Applications (Vol. I, 3rd ed.), Wiley, New York.\nFu, J. C. (1985). Reliability of consecutive-k-out-of-n:F system. IEEE Transac- tions on Reliability 34, 127-130.\nFu, J. C. (1986). Reliability of consecutive-k-out-of-n:F systems with (k-1) step Markov dependence. IEEE Transactions on Reliability 35, 602-606.\nFu, J. C. (1995). Exact and limiting distributions of the number of successions in a random permutation. Annals of the Institute of Statistical Mathematics 47, 435-446.\nFu, J. C. (1996). Distribution theory of runs and patterns associated with a sequence of multi-state trials. Statistica Sinica 6, 957-974.\nFu, J. C. (2001). Distribution of scan statistics for a sequence of bi-state trials Journal of Applied Probability 38, 1-9.\nFu, J. C. and Chang, Y. M. (2002). On probability generating functions for wait- ing time distributions of compound patterns in a sequence of multistate trials. Journal of Applied Probability 39, 70-80.\nFu, J. C. and Hu, B. (1987). On reliability of a large consecutive-k-out-of-n:F sys- tem with k-1 step Markov dependence. IEEE Transactions on Reliability 36, 75-77.\nFu, J. C. and Koutras, M. V. (1994). Distribution theory of runs: a Markov chain approach. Journal of the American Statistical Association 89, 1050-1058.\nFu, J. C. and Lou, W. Y. W. (1991). On reliabilities of certain large linearly connected engineering systems. Statistics and Probability Letters 12, 291-296.\nFu, J. C. and Lou, W. Y. W. (2000a). On the exact distribution of SECON and its application. Statistica Sinica 10, 999-1010.\nFu, J. C. and Lou, W. Y. W. (2000b). Joint distribution of rises and falls. Annals of the Institute of Statistical Mathematics 52, 415-425.\nFu, J. C., Lou, W. Y. W., Bai, Z. D. and Li, G. (2002). The exact and limiting distributions for the number of successes in success runs within a sequence of Markov-dependent two-state trials. Annals of the Institute of Statistical Mathematics 54, 719-730.\nFu, J. C., Lou, W. Y. W. and Chen, S. C. (1999). On the probability of pattern matching in nonaligned DNA sequences: a finite Markov chain imbedding approach. Scan Statistics and Applications (eds. J. Glaz and N. Balakrish- nan), Birkhäuser, Boston, 287-302.\nFu, J. C., Lou, W. Y. W. and Wang, Y. J. (1999). On the exact distributions of Eulerian and Simon Newcomb numbers associated with random permuta- tions. Statistics and Probability Letters 42, 115–125.\nFu, J. C., Shmueli, G. and Chang, Y. M. (2002). A unified Markov chain approach for computing the run length distribution for control charts with simple or compound rules. Technical Report, Department of Statistics, University of Manitoba.\nFu, J. C., Spiring, F. A. and Xie, H. (2002). On the average run lengths of quality control schemes using a Markov chain approach. Statistics and Probability Letters 56, 369-380.\nGlaz, J. (1989). Approximations and bounds for the distribution of the scan statistic. Journal of the American Statistical Association 84, 560-566.\nGlaz, J. (1992). Approximations for tail probabilities and moments of the scan statistic. Computational Statistics and Data Analysis 14, 213-227.\nGlaz, J., Naus, J. I. and Wallenstein, S. (2001). Scan Statistics, Springer-Verlag, New York.\nGodbole, A. P. (1990). Specific formulae for some success run distributions. Statistics and Probability Letters 10, 119-124.\nGodbole, A. P. (1991). Poisson approximations for runs and patterns of rare events. Advances in Applied Probability 23, 851-865.\nGoncharov, V. L. (1944). On the field of combinatory analysis. Isvestija Akad. Nauk. SSSR. Ser. Math. 8, 3-48 (in Russian); English translation: Translations of the AMS Ser. Math. 19 (1962), 1-46.\nGoodman, L. A. (1958). Simplified runs tests and likelihood ratio tests for Markoff chains. Biometrika 45, 181-197.\nHan, Q. and Aki, S. (1998). Formulae and recursions for the joint distributions of success runs of several lengths in a two-state Markov chain. Statistics and Probability Letters 40, 203-214.\nHan, Q. and Aki, S. (2000a). Sooner and later waiting time problems based on a dependent sequence. Annals of the Institute of Statistical Mathematics 52, 407-414.\nHan, Q. and Aki, S. (2000b). Waiting time problems in a two-state Markov chain. Annals of the Institute of Statistical Mathematics 52, 778-789.\nHirano, K. (1986). Some properties of the distributions of order k. Fibonacci Numbers and Their Applications (eds. A. N. Philippou, G. E. Bergum, and A. F. Horadam), Reidel, Dordrecht, 43-53.\nHirano, K. and Aki, S. (1987). Properties of the extended distributions of order k. Statistics and Probability Letters 6, 67-69.\nHirano, K. and Aki, S. (1993). One number of occurrences of success runs of specified length in a two-state Markov chain. Statistica Sinica 3, 313-320.\nHuntington, R. J. and Naus, J. I. (1975). A simpler expression for kth nearest neighbor coincidence probabilities. Annals of Probability 3, 894-896.\nHwang, F. K. (1982). Fast solutions for consecutive-k-out-of-n:F system. IEEE Transactions on Reliability 31, 447-448.\nHwang, F. K. (1986). Simplified reliabilities for consecutive-k-out-of-n systems.SIAM Journal on Algebraic and Discrete Methods 7, 258-264.\nJackson, D. M. and Reilly, J. W. (1976). Permutations with a prescribed number of p-runs. Ars Combinatoria 1, 297-305.\nJohnson, B. C. (2001). Distribution of increasing l-sequences in a random permutation. Methodology and Computing in Applied Probability 3, 35-49.\nJohnson, B. C. (2002). The distribution of increasing 2-sequences in random per- mutations of arbitrary multi-sets. Statistics and Probability Letters 59, 67-74.\nJohnson, B. C and Fu, J. C. (2000). The distribution of increasing l-sequences in random permutations: A Markov chain approach. Statistics and Probability Letters 49, 337-344.\nKaplansky, I. (1944). Symbolic solution of certain problems in permutations. Bul- letin of the American Mathematical Society 50, 906-914.\nKarlin, S. and McGregor, J. (1959). Coincident probabilities. Pacific Journal of Mathematics 9, 1141-1164.\nKontoleon, J. M. (1980). Reliability determination of a r-successive-out-of-n:F system. IEEE Transactions on Reliability 29, 437.\nKossow, A. and Preuss, W. (1989). Reliability of consecutive-k-out-of-n:F system with nonidentical component reliabilities. IEEE Transaction on Reliability 38, 229-233.\nKoutras, M. V. (1996a). On a Markov chain approach for the study of reliability structures. Journal of Applied Probability 33, 357-367.\nKoutras, M. V. (1996b). On a waiting time distribution in a sequence of Bernoulli trials. Annals of the Institute of Statistical Mathematics 48, 789-806.\nKoutras, M. V. (1997a). Waiting time distributions associated with runs of fixed length in two-state Markov chains. Annals of the Institute of Statistical Mathematics 49, 123-139.\nKoutras, M. V. (1997b). Waiting times and number of appearances of events in a sequence of discrete random variables. Advances in Combinatorial Meth- ods and Applications to Probability and Statistics (ed. N. Balakrishnan), Birkhäuser, Boston, 363-384.\nKoutras, M. V. (2003). Applications of Markov chains to the distribution the- ory of runs and patterns. Handbook of Statistics 21: Stochastic Processes, Modeling and Simulation (eds. D. N. Shanbhag and C. R. Rao), Elsevier, Amsterdam, in press.\nKoutras, M. V. and Alexandrou, V. (1995). Runs, scans and urn model distributions: a unified Markov chain approach. Annals of the Institute of Statistical Mathematics 47, 743-766.\nKoutras, M. V. and Alexandrou, V. (1997a). Non-parametric randomness tests based on success runs of fixed length. Statistics and Probability Letters 32, 393-404.\nKoutras, M. V. and Alexandrou, V. (1997b). Sooner waiting time problems in a sequence of trinary trials. Journal of Applied Probability 34, 593–609.\nKoutras, M. V. and Papastavridis, S. G. (1993). Application of the Stein-Chen method for bounds and limit theorems in the reliability of coherent struc- tures. Naval Research Logistics 40, 617-631.\nLing, K. D. (1992). A generalization of the sooner and later waiting time problems for Bernoulli trials: frequency quota. Statistics and Probability Letters 14, 401-405.\nLing, K. D and Low, T. Y. (1993). On the soonest and the latest waiting time distributions: succession quotas. Communications in Statistics Theory and Methods 22, 2207-2221.\nLou, W. Y. W. (1996). On runs and longest run tests: method of finite Markov chain imbedding. Journal of the American Statistical Association 91, 1595– 1601.\nLou, W. Y. W. (1997). An application of the method of finite Markov chain imbedding to runs tests. Statistics and Probability Letters 31, 155–161.\nLou, W. Y. W. (2000). The exact distribution of the continuity of care measure NOP. Statistics and Probability Letters 48, 361–368.\nLou, W. Y. W. (2001). The distribution of the usual provider continuity index under Markov dependence. Statistics and Probability Letters 54, 269–276.\nLou, W. Y. W. (2003). The exact distribution of the K-tuple statistic for sequence homology. Statistics and Probability Letters 1, 51-59.\nLucas, J. M. and Crosier, R. B. (1982). Fast initial response for CUSUM quality control schemes: Give your CUSUM a head start. Technometrics 24, 199-205.\nMacMahon, P. A. (1915). Combinatory Analysis, Cambridge University Press, London.\nMohanty, S. G. (1994). Success runs of length k in Markov dependent trials. Annals of the Institute of Statistical Mathematics 46, 777-796.\nMontgomery, D. C. (2001). Introduction to Statistical Quality Control (4th ed.). Wiley, New York.\nMood, A. M. (1940). The distribution theory of runs. Annals of Mathematical Statistics 11, 367–392.\nMosteller, F. (1941). Note on an application of runs to quality control charts. Annals of Mathematical Statistics 12, 228-232.\nMuselli, M. (2000). Useful inequalities for the longest run distribution. Statistics and Probability Letters 46, 239-249.\nNagaev, S. V. (1957). Some limit theorems for stationary Markov chains. Theory of Probability and its Applications 2, 378-406.\nNaus, J. I. (1965). The distribution of the size of the maximum cluster of points on a line. Journal of the American Statistical Association 60, 532-538.\nNaus, J. I. (1974). Probabilities for a generalized birthday problem. Journal of the American Statistical Association 69, 810-815\nNaus, J. I. (1982). Approximations for distributions of scan statistics. Journal of the American Statistical Association 77, 177-183.\nNishimura, K. and Sibuya, M. (1997). Extended Stirling family of discrete probability distributions. Communications in Statistics Theory and Methods 26, 1727-1744.\nPapastavridis, S. G. (1988). A Weibull limit for the reliability of a consecutive k-within-m-out-of-n system. Advances in Applied Probability 20, 690-692.\nPapastavridis, S. G. and Koutras, M. V. (1993). Bounds for reliability of consec- utive k-within-m-out-of-n:F systems. IEEE Transactions on Reliability 42, 156-160.\nPhilippou, A. N. (1986). Distributions and Fibonacci polynomials of order k, longest runs, and reliability of consecutive-k-out-of-n:F systems. Fibonacci Numbers and Their Applications (eds. A. N. Philippou, G. E. Bergum and A. F. Horadam), Reidel, Dordrecht, 203-227.\nPhilippou, A. N., Georghiou, C. and Philippou, G. N. (1983). A generalized geometric distribution and some of its properties. Statistics and Probability Letters 1, 171–175.\nPhilippou, A. N. and Makri, F. S. (1986). Success runs and longest runs. Statistics and Probability Letters 4, 211–215.\nPyke, R. (1961). Markov renewal processes: definitions and preliminary proper- ties. Annals of Mathematical Statistics 32, 1231-1242.\nReilly, J. W. and Tanny, S. M. (1979). Counting successions in permutations. Studies in Applied Mathematics 61, 73-81.\nRényi, A (1970). Probability Theory, American Elsevier Publishing Company Inc., New York.\nRiordan, J. (1958). An Introduction to Combinatorial Analysis, Wiley, New York.\nRoselle, D. P. (1968). Permutations by number of rises and successions. Proceed- ings of the American Mathematical Society 19, 8-16. Ross, S. M. (2000). Introduction to Probability Models (7th ed.), Academic Press, San Diego.\nRubin, G., McCulloch, C. E. and Shapiro, M. A. (1990). Multinomial runs tests to detect clustering in constrained free recall. Journal of the American Sta- tistical Association 85, 315-320.\nSaperstein, B. (1972). The generalized birthday problem. Journal of the American Statistical Association 67, 425-428.\nSchilling, M. F. (1990). The longest run of heads. The College Mathematics Jour- nal 21, 196-207.\nSeneta, E. (1981). Non-negative Matrices and Markov Chains (2nd ed.), Springer- Verlag, New York.\nSheng, K. N. and Naus, J. I. (1994). Pattern matching between two non-aligned random sequences. Bulletin of Mathematical Biology 56, 1143-1162.\nSteinwachs, D. M. (1979). Measuring provider continuity in ambulatory care. Medical Care 17, 551-565.\nSwed, F. S. and Eisenhart, C. (1943). Tables for testing randomness of grouping in a sequence of alternatives. Annals of Mathematical Statistics 14, 66-87.\nTanny, S. (1973). A probabilistic interpretation of Eulerian numbers. Duke Math- ematical Journal 40, 717-722.\nTanny, S. M. (1976). Permutations and successions. Journal of Combinatorial Theory, Series A 21, 196-202.\nVaggelatou, E. (2003). On the length of the longest run in a multi-state Markov chain. Statistics and Probability Letters 62, 211–221.\nUchida, M. and Aki, S. (1995). Sooner and later waiting time problems in a two- state Markov chain. Annals of the Institute of Statistical Mathematics 47, 415-433\nWald, A. and Wolfowitz, J. (1940). On a test whether two samples are from the same population. Annals of Mathematical Statistics 11, 147-162.\nWigle, D. T. (1982). Prevalence of selected chronic diseases in Canada, 1978-1979. Chronic Disease in Canada 3, 9.\nWishart, J. and Hirshfeld, H. O. (1936). A theorem concerning the distribution of joins between line segments. Journal of the London Mathematical Society 11, 227-235.\nWolfowitz, J. (1943). On the theory of runs with some applications to quality control. Annals of Mathematical Statistics 14, 280-288.\nWorpitzky, J. (1883). Studien über die Bernoullischen und Eulerschen Zahlen. Journal für die reine und angewandte Mathematik 94, 203-232.",
    "crumbs": [
      "Trabajo Grado"
    ]
  },
  {
    "objectID": "Trabajo_Grado.html#rachas-y-escaners-con-aplicaciones",
    "href": "Trabajo_Grado.html#rachas-y-escaners-con-aplicaciones",
    "title": "Vladimir Sanchez Tenjo",
    "section": "Rachas y Escaners con Aplicaciones",
    "text": "Rachas y Escaners con Aplicaciones\n\nPrefacio\nEl concepto de rachas se entiende fácilmente y los procedimientos inferenciales basados en rachas son a menudo heurísticamente simples de seguir e implementar. Sin embargo, un estudio teórico de rachas requiere cuidado y uso de una amplia gama de técnicas especiales. Este volumen proporciona una descripción completa y exhaustiva de varios desarrollos teóricos y aplicados sobre problemas que involucran rachas y escaners\nEste volumen contiene doce capítulos y puede clasificarse en términos generales en tres partes: la Parte A, que comprende los Capítulos 2 y 3, y se ocupa principalmente del tiempo de espera para la primera aparición de rachas y sus aplicaciones; La Parte B, que comprende los Capítulos 4 a 8, se ocupa del tiempo de espera para la ocurrencia múltiple de rachas, el número de ocurrencia de rachas, problemas de tiempo de espera tardia y temprana relacionados con rachas, distribuciones de rachas multivariadas y sus aplicaciones; y la Parte C, que comprende los Capítulos 9 a 12, y se ocupa principalmente del tiempo de espera para el primer escaner, escaners múltiples, el número de escaners y sus aplicaciones.\nLa extensión de este volumen, así como la extensa bibliografía al final del mismo (la mayor parte de los últimos veinte años) proporciona un amplio testimonio del notable crecimiento que este tema de investigación ha experimentado en el pasado reciente. Aunque hemos analizado varias aplicaciones diferentes de estadistícas de rachas y escaneo (con tres capítulos dedicados a ellas),creemos que hay mucho más potencial para muchas más aplicaciones diversas y espero sinceramente que este volumen permita y anime a los investigadores aplicados en esta dirección. Para ayudar a los lectores interesados en este proceso, también hemos incluido en la Bibliografía algunas referencias adicionales que se relacionan con esta área de investigación pero que no han sido citadas directamente en el texto.\nEn un volumen de esta naturaleza y tamaño, inevitablemente habrá omisión de algunos resultados que deberían haberse incluido en este volumen. Aseguramos que tal omisión es sólo accidental y de ninguna manera se debe a una antipatía personal no científica.\nAlentamos a los lectores a comentar sobre el contenido de este volumen y les agradecemos de antemano por informarnos sobre cualquier error, tergiversación u omisión.\nNos complace reconocer el apoyo y el aliento del Sr. Steve Quigley de John Wiley & Sons, Inc., durante todo el transcurso de este proyecto. Se agradece la ayuda administrativa y editorial brindada por la Sra. Heather Haselkorn y el Sr. Andrew Prince de John Wiley & Sons, Inc. También agradecemos a la Sra. Debbie Iscoe (Mississauga, Ontario, Canadá) por componer todo el volumen, a la Sra. Roza Garden (Atenas, Grecia) por mecanografiar algunas partes del volumen y al Dr. Michael Boutsikas por ayudarnos a la preparación de figuras.\nLa redacción de este volumen comenzó en 1995 y concluyó en el verano de 2001. Durante este período bastante largo, disfrutamos del apoyo, la cooperación y la inmensa paciencia de nuestras familias. A todos ellos va nuestro agradecimiento muy especial.\n\n\nIntroducción y comentarios históricos\n\n¿QUÉ SON LAS RACHAS?\nEl concepto y el uso potencial de las rachas se pueden explicar incluso a un principiante en estadística en términos simples, ya que el término racha se usa en el campo de la probabilidad y la estadística de la misma manera que se usa en el lenguaje común. Un significado no técnico comúnmente entendido del término racha es una sucesión ininterrumpida y así es exactamente como definiremos y usaremos las rachas en el libro. Concretamente, en un experimento que involucra diferentes elementos (o resultados), una racha de un determinado tipo de elemento(s) es una sucesión ininterrumpida de dichos elementos delimitada en cada extremo por otros tipos de elementos o por el principio o el final de la sucesión completa. Por ejemplo, en la secuencia binaria \\(\\small{1100011101}\\), primero tenemos una racha de dos \\(\\small{1}'\\)s, luego una racha de tres \\(\\small{0}'\\)s, una racha de tres \\(\\small{1}'\\)s, una racha de un \\(\\small{0}\\) y finalmente una racha de un \\(\\small{1}\\). Por tanto, tenemos cinco rachas en esa sucesión binaria.\nAunque aquí hemos ilustrado el número de rachas como una estadística, es posible, por supuesto, definir algunas otras estadísticas basadas en las rachas. Por ejemplo, podemos considerar la longitud máxima de racha (que es \\(\\small{3}\\)), o la longitud mínima de rachas (que es \\(\\small{1}\\)), o la diferencia entre el número de rachas de \\(\\small{1}'\\)s y de \\(\\small{0}'\\)s (que es \\(\\small{3 - 2 = 1}\\))\nLa definición anterior de racha es simple y fácil de introducir con una sola forma de contar. Sin embargo, si consideramos rachas de una longitud específica (digamos, \\(\\small{2}\\)), es posible introducir diferentes formas de contar. Por ejemplo, si permitimos el conteo superpuesto, entonces la segunda racha de tres \\(\\small{0}'\\)s en la anterior sucesión binaria puede considerarse como dos rachas de dos \\(\\small{0}'\\)s. Por otro lado, si utilizamos un conteo no superpuesto, entonces la segunda rachas de tres \\(\\small{0}'\\)s puede considerarse como una única racha de \\(\\small{0}'\\)s.\n\n\n¿POR QUÉ RACHAS?\nLas rachas y los problemas asociados siempre han atraído la atención de probabilistas y estadísticos desde el principio. Ya en \\(\\small{1738}\\), De Moivre discutió el siguiente problema: ¿Cuál es la probabilidad de obtener una racha de longitud \\({r}\\) o más en \\(n\\) ensayos? Sin embargo, hubo un error en la fórmula de De Moivre (\\(\\small{1738}\\), Doctrine of Chance, Problema 88); pero De Moivre había utilizado la fórmula correcta en sus ejemplos numéricos. Simpson (1740), Laplace (1812) y Todhunter (1865) realizaron más debates sobre este problema. Curiosamente, Marbe (1916, 1934) utilizó observaciones sobre rachas para respaldar la teoría que propuso de que si una moneda da “cara” con mucha frecuencia, entonces la probabilidad de obtener “cruz” en el lanzamiento disminuye.\nA pesar de que los problemas relacionados con las rachas se estaban discutiendo en probabilidad y combinatoria desde la publicación de Doctrine of Chance por De Moivre en \\(\\small{1738}\\), se necesitaron más de dos siglos para desarrollar una buena aplicación de las rachas en estadística. Wald y Wolfowitz (1940) utilizaron rachas para establecer una prueba de dos muestras que es intuitivamente simple y puede explicarse fácilmente de la siguiente manera.\nSea \\(\\small{X_1,X_2,\\ldots, X_m}\\) una muestra aleatoria de una población con función de distribución acumulativa \\(\\small{F_X(x)}\\), y sea \\(\\small{Y_1, Y_2,..., Y_n}\\) otra muestra aleatoria independiente de una población con función de distribución acumulativa \\(\\small{F_Y(x)}\\). El problema inferencial de interés es contrastar las hipótesis \\(\\small{H_0 : F_X(x) = F_Y(x)}\\) para todo \\(x\\), frente a la alternativa \\(\\small{H_a: F_X(x) \\neq F_Y(x)}\\) para algún \\(x\\). Wald y Wolfowitz (1940) luego sugirieron combinar las dos muestras, organizar las observaciones \\(\\small{m+n}\\) en orden creciente de magnitud, reemplazar los valores ordenados por \\(\\small{0}\\) o \\(1\\) dependiendo de si se originaron a partir de la muestra \\(\\small{X}\\) o la muestra \\(\\small{Y}\\), respectivamente, y utilizar el número total de rachas en esa sucesión binaria como estadística de prueba. Dado que se espera que los valores de \\(\\small{X}\\) y \\(\\small{Y}\\) estén completamente mezclados entre sí bajo la hipótesis nula, lo que resulta en un valor grande para el número total de racha, Wald y Wolfowitz (1940) propusieron rechazar la hipótesis nula para valores pequeños del número total de rachas; los valores críticos se pueden determinar fácilmente para los valores dados de los tamaños de muestra \\(m\\) y \\(n\\) y el nivel deseado de significancia \\(\\small{\\alpha}\\). Wald y Wolfowitz (1940) lograron demostrar que esta prueba de rachas de dos muestras es, de hecho, consistente, lo que significa que la potencia de la prueba tiende a \\(\\small{1}\\) cuando los tamaños de muestra \\(m\\) y \\(n\\) tienden a \\(\\infty\\).\nDesde entonces, se han desarrollado con éxito una variedad de aplicaciones diferentes de rachas y estadísticas basadas en rachas en una amplia gama de áreas de la estadística, así como en disciplinas aplicadas. En este libro, nuestro objetivo es reunir varios desarrollos teóricos que se han realizado sobre rachas y estadísticas relacionadas y muchas aplicaciones diferentes de estos resultados. Una aplicación estadística significativa de las rachas, anterior al trabajo de Wald y Wolfowitz (1940), se debe a De Forest (1876), quien sugirió usar rachas en la sucesión de signos de los residuos para evaluar la adecuación de una curva ajustada a un conjunto de datos observados; Véase Stigler (1978) para algunos detalles sobre este tema.\nAunque esta sección ha proporcionado una breve reseña histórica del trabajo sobre rachas y sus aplicaciones, se presentarán más detalles en varios lugares pertinentes de este libro. Los lectores interesados también pueden consultar el artículo de Weiss (1985) y los libros de Stigler (1986) y Hald (1990) para obtener información adicional.\n\n\n\n¿Para qué sirven las rachas?\nSiguiendo la línea de la prueba de rachas de dos muestras descrita en la última sección, el número de rachas también se puede utilizar para desarrollar algunas pruebas de aleatoriedad. Específicamente, sean \\(\\small{X_1,X_2,\\ldots,X_n}\\), \\(n\\) variables aleatorias con una función de distribución acumulativa conjunta \\(\\small{F(x_2,x_2,\\ldots, x_n)}\\). El problema de interés es probar la hipótesis \\(\\small{H_0: X_i's}\\) son independientes y están distribuidas idénticamente (i.i.d.), es decir, \\(\\small{F(x_1, ...,x_n) = \\displaystyle\\prod_{i=1}^{n}F ^{*}_i(x)}\\), donde \\(\\small{F^{*}_i(x)}\\) es una función de distribución acumulativa univariada continua. Podemos considerar la secuencia de signos de las diferencias \\(\\small{X_2-X_2, X_3 - X_2,\\ldots, X_n - X_{n-1}}\\) y definir una racha positiva como una racha de signos correspondientes a diferencias sucesivas positivas y una racha negativa como una racha de signos correspondientes a diferencias sucesivas negativas. Ahora se pueden proponer diferentes procedimientos de prueba en función del número de rachas positivas y negativas o de la longitud de estas. Dependiendo de la alternativa considerada, se puede elegir una región crítica apropiada. Por ejemplo, si el problema es probar la aleatoriedad frente a la alternativa de que hay una tendencia en \\(\\small{X_1, X_2,\\ldots, X_n}\\), será razonable rechazar \\(\\small{H_0}\\) si los números de rachas positivas y negativas son demasiado pequeñas. Si la alternativa fuera especificar la dirección de la tendencia, entonces podríamos optar por utilizar una de ellas (la que sea apropiada). Por otro lado, si el problema es probar la aleatoriedad frente a la alternativa de que hay muchos ciclos cortos presentes en \\(\\small{X_1,X_2,\\ldots, X_n}\\), entonces será razonable rechazar \\(\\small{H_0}\\) si el número de racahs positivas y negativas son demasiado grandes.\nOtra aplicación de similar naturaleza surge en el control estadístico de calidad o monitoreo de procesos. Aquí, asumimos que tenemos una característica medible en los artículos que se producen y que esta característica tiene límites de control superior e inferior (a veces, solo uno de esos límites). Se supone que el proceso de producción está bajo control si produce muchos artículos conformes y se declara fuera de control si en cualquier momento se produce una cantidad inusualmente grande de artículos no conformes. En concreto, podemos considerar que el proceso de producción está fuera de control si, entre las mediciones realizadas en \\(n\\) artículos consecutivos, la longitud máxima de racha positiva o negativa es demasiado grande. Por ejemplo, Deming (1972) ha sugerido una tolerancia hasta una longitud máxima de \\(\\small{6}\\) y más allá para concluir que el proceso de producción se está saliendo de control. Deming (1972) también ha planteado otro esquema de monitoreo de procesos en el que observamos la longitud máxima de la racha positiva y negativa respecto de la media, es decir, longitud de racha por encima y por debajo de la media, respestivamente. De manera similar, Kitagawa y Seguchi (1956, 1957) han señalado la importancia del estudio de las distribuciones relacionadas con rachas múltiples en relación con los métodos de control estadístico.\nCon base en ideas similares, también se han utilizado el número y la longitud de las rachas para desarrollar pruebas no paramétricas de simetría de la distribución de la cual se obtuvieron datos de muestra; véanse, por ejemplo, Cohen y Menjoge (1988), McWilliams (1990), Henze (1993) y Modarres y Gastwirth (1996, 1998). En este contexto, suponiendo que se conoce la mediana poblacional \\(\\small{\\mu}\\) (y se toma como cero, sin pérdida de generalidad), los valores absolutos de las observaciones negativas y positivas se juntan, se hace un recuento de las rachas de valores de un mismo lado y luego se proponen las estadísticas de prueba en función de estas rachas. Sin embargo, observe una diferencia clave en este problema: el número de valores a un lado de la mediana es una variable aleatoria aunque el tamaño de la muestra \\(n\\) en sí sea fijo. El trabajo de Balakrishnan y Frattina (2000) y Balakrishnan y Ng (2001) sobre pruebas de precedencia máxima, en las que dos muestras de unidades se someten a una prueba de vida útil y sólo se observan unos pocos fallos tempranos de las unidades en ambas muestras, también utilizan de manera similar el longitud máxima de racha (correspondiente a fallas de la muestra “control”) como estadística de prueba.\nLas rachas también desempeñan un papel fundamental en las pruebas de demostración iniciales (start-up demonstration testing, en ingles). En esta experimentación, un dispositivo (como un generador de energía, una cortadora de césped o una batería de automóvil) se prueba repetidamente y después de cada ensayo simplemente se observa si ha tenido un aranque exitoso o no. El plan/diseño de muestreo de aceptación utilizado por el minorista (o el consumidor) puede aceptar ese equipo si se logra un número prescrito de arranques exitosos consecutivos (es decir, una rachas de éxitos) antes de una cierta cantidad de pruebas, y rechazar ese equipo en caso contrario; véase, por ejemplo, Hahn y Gage (1983).\nNuestra aplicación final es en sistemas de confiabilidad. Así como las estadísticas de orden son fundamentales para los sistemas \\(k\\)-out-of-\\(n:F\\), las rachas(de hecho, la longitud de la racha más larga) son fundamentales para los sistemas \\(k\\)-out-of-\\(n:F\\) consecutivos. Imaginemos que tenemos un sistema que consta de \\(n\\) componentes y todos los \\(n\\) componentes funcionan de forma independiente. En cualquier momento sólo existen dos estados posibles para los componentes y para todo el sistema: operativo o averiado. Así, se dice que dicho sistema es un sistema \\(k\\)-out-of-\\(n:F\\), consecutivo si falla sólo cuando al menos \\(k\\) componentes consecutivos han fallado, y funcionará mientras no hayan fallado \\(k\\) componentes sucesivos; véase, por ejemplo, Chiang y Niu (1981) o el artículo de revisión de Chao, Fu y Koutras (1995).\n\nDE LAS RACHA A LOS ESCANERS\nEn el análisis de ensayos experimentales cuyos resultados pueden clasificarse en dos categorías exclusivas, una pregunta que surge naturalmente es si se podrían establecer criterios razonables que proporcionen evidencia de agrupamiento de cualquiera de las dos categorías. Estos criterios podrían luego usarse para detectar cambios en el proceso subyacente que genera la serie de resultados.\nConsideremos una sucesión \\(\\small{X_1,\\cdots, X_n}\\) de \\(n=lm\\) \\(\\small{(m \\geq 2)}\\) y \\(\\small{l &gt; 1}\\) enteros) resultados binarios. El problema de interés es nuevamente probar la hipótesis nula de que \\(\\small{X_i}\\) son independientes con probabilidad de éxito constante. Un criterio simple y comúnmente utilizado es dividir los \\(n\\) ensayos en \\(l\\) grupos separados de \\(m\\) ensayos consecutivos cada uno y observar el número de éxitos dentro de cada grupo. Si algún grupo tiene “demasiados” éxitos (digamos, \\(k\\) o más), se recibirá una señal de que se ha producido un cambio en el proceso subyacente. Si \\(k\\) es cercano a \\(m\\), entonces podemos denominar al grupo de \\(m\\) ensayos consecutivos una racha de éxitos “casi perfecta”.\nOtro criterio muy utilizado se basa en la superposición de grupos de \\(m\\) ensayos sucesivos. Con esta configuración, en cada ensayo contamos el número de éxitos en los últimos \\(m\\) ensayos, y la frecuente aparición de ventanas de rachas “casi perfectas” podría servir como un indicio de un cambio en el proceso subyacente. Es claro que el caso aquí discutido consiste en una generalización natural del concepto de racha; Además, ofrece una estadística de prueba alternativa eficiente y fascinante en una variedad de campos donde tradicionalmente se han utilizado los criterios clásicos de rachas.\nConsideremos, por ejemplo, el siguiente modelo que tiene su origen en la biología molecular. Al estudiar secuencias de aminoácidos se utilizan varios esquemas de clasificación, incluido un alfabeto químico de ocho letras, un alfabeto funcional de cuatro letras, un alfabeto de carga de tres letras, etc.; véase, por ejemplo, Karlin y Ghandour (1985), Karlin y MacKen (1991), Karlin y Altschul (1993), Karlin y Cardon (1994) y Waterman (2000). Con el fin de desarrollar medidas cuantitativas para evaluar e interpretar las heterogeneidades genómicas entre diferentes especies o unidades sujetas a diferentes químicos infecciosos y/o varios niveles de corrupción, los biólogos moleculares comparan sus secuencias de ADN y buscan subsecuencias alineadas largas que coincidan en la mayoría de sus posiciones. Aparentemente, una coincidencia inusualmente larga, es decir, la ocurrencia de una racha “casi perfecto” o escaner, ofrece una fuerte evidencia de similitud entre los sujetos bajo inspección.\nCon el objetivo de establecer un modelo matemático para aplicaciones de esta naturaleza, denotemos por \\(\\small{Z_{i1}, Z_{i2}, i = 1,2,\\ldots}\\), dos secuencias de aminoácidos de un alfabeto finito. Se dirá que las dos secuencias coinciden en posición (\\(i\\geq 1\\)) si \\(\\small{Z_{i1}= Z_{i1}}\\), en cuyo caso dejamos que \\(\\small{X_i}\\) sea \\(\\small{1}\\) (y \\(\\small{0}\\) en caso contrario). Entonces, el número de coincidencias en una ventana de longitud \\(m\\) se describe mediante el proceso de sumas móviles \\(\\small{S_i =}\\tiny{\\displaystyle\\sum_{j=1}^{i+m-1}X_i}\\) con \\(\\small{i \\in\\{1,2,\\ldots\\}}\\) y la coincidencia “casi perfecta” en la posición \\(\\small{i}\\) se puede describir mediante el evento \\(\\small{S_i \\geq k}\\) (\\(\\small{k}\\) es un número entero, lo suficientemente cercano a \\(\\small{m}\\)).\nLos resultados teóricos sobre el tiempo de espera para la primera (o más generalmente, la \\(r\\)-ésima) ocurrencia de tal evento, o el número de ocurrencias de ellos en una secuencia de tamaño dado, son de gran importancia práctica para establecer e investigar pruebas estadísticas apropiadas que detectarían la hipótesis nula de que las dos secuencias son idénticas; véanse, por ejemplo, Karlin y Ost (1988), Glaz y Naus (1991) y Glaz y Balakrishnan (1999).\nLos escaners también desempeñan un papel fundamental en varias otras áreas científicas. Por ejemplo, en un modelo de confiabilidad que se introdujo recientemente con el nombre de sistema \\(k-within-consecutive-out-of-n\\), la ocurrencia de un escaner (ejecución “casi perfecta” de componentes fallidos) indica una falla del sistema; véase Papastavridis y Koutras (1994). En la teoría del control de calidad estadístico, un modelo más sensible (en comparación con el modelo basado en rachas descrito anteriormente en la Sección 1.3) se obtiene al declarar que un proceso está fuera de control siempre que \\(\\small{k}\\) de \\(\\small{n}\\) puntos consecutivos caigan en la zona crítica; ver Greenberg (1970) y Saperstein (1973). Del mismo modo, en las pruebas de demostración de inicio ( startup demonstration testing, en ingles), el concepto de escaner puede explotarse para establecer procedimientos eficientes de aceptación/rechazo para la unidad bajo inspección.\nEn este libro, además de presentar todos los detalles teóricos relacionados con rachas, escaners y estadísticas relacionadas, también consideraremos todas estas aplicaciones, elaboraremos metodologías apropiadas y las ilustraremos con muchos ejemplos numéricos. Mientras lo hacemos, también discutiremos algunas modificaciones, extensiones y generalizaciones de estos problemas que pueden hacerlos más útiles y aplicables a situaciones prácticas de la vida real.\n\n\nQUE ESPERAR\nAunque todas las aplicaciones citadas en las dos últimas secciones se basan en rachas de diferentes maneras, está bastante claro que algunos problemas de tiempo de espera están asociados con todas ellas. También es evidente que las distribuciones de probabilidad de la variable tiempo de espera (hasta que ocurran algunas rachas de cierto tipo, por ejemplo) y el número de rachas están bastante relacionadas. Por lo tanto, es útil y revelador estudiar las distribuciones de los tiempos de espera asociados con las rachas y luego utilizar estas distribuciones para abordar los diversos problemas aplicados mencionados en las dos últimas secciones. Éste es precisamente el objetivo y propósito de este libro. Para facilitar la presentación de todos los desarrollos relevantes, el resto de este libro se ha dividido en tres partes naturales de la siguiente manera:\n\nParte A: incluye los Capítulos 2 y 3 que se ocupa principalmente del tiempo de espera para la primera aparición de rachas y su aplicación a una variedad de problemas. En el Capítulo 3 se detallan varias aplicaciones interesantes en áreas tan diversas como confiabilidad, control de calidad, estadística no paramétrica, meteorología y ciencias ambientales.\nParte B: incluye los Capítulos 4 a 8 y se centra principalmente en algunas extensiones y generalizaciones de los resultados discutidos en la Parte A. Específicamente, incluye discusiones detalladas sobre el tiempo de espera para la ocurrencia múltiple de rachas, sobre el número de ocurrencias de rachas, sobre problemas de tiempo de espera tardia y temprana que involucran racha y sobre distribuciones multivariadas relacionadas con la ocurrencia de rachas. Finalmente, se describen algunas aplicaciones diversas de estos resultados.\nParte C: incluye los capítulos 9 a 12 y se ocupa de las distribuciones relacionadas con las estadísticas de escaneo, que son generalizaciones naturales del principio de rachas. La organización de la Parte C es similar a la utilizada para la Parte B, es decir, comenzamos nuestra discusión con la distribución del tiempo de espera para la primera ocurrencia de escaners, procedemos a los problemas de tiempo de espera de múltiples escaners y finalmente discutimos la distribución del número de ocurrencias de escaners en un número fijo de resultados. El libro concluye con el Capítulo 12, donde se describen las aplicaciones de escaners a una variedad de problemas.",
    "crumbs": [
      "Trabajo Grado"
    ]
  },
  {
    "objectID": "Series_Tesuvr.html",
    "href": "Series_Tesuvr.html",
    "title": "Series de tiempo univariadas: Análisis descriptivo",
    "section": "",
    "text": "Inflación total de Colombia (Variación anual)\n\nIntrodución\nEn economía es habitual el interés sobre el ritmo al que los precios de los bienes y servicios de consumo cambian de un periodo a otro, tales cambios afectan el poder adquisitivo real de los ingresos de los consumidores y su bienestar. Debido a que no todos los precios de los distintos bienes y servicios cambian en la misma proporción, un índice de precios que sintetice los cambios en los precios en una canasta lo suficientemente general es el Índice de Precios al Consumidor (IPC).\nLos IPC son estadísticas oficiales comúnmente producidas por las oficinas nacionales de estadística, los ministerios de trabajo o los bancos centrales, en Colombia la operación estadística está a cargo del Departamento Administrativo Nacional de Estadística (DANE). Cuando existe un aumento generalizado y sostenido de los precios de los bienes y servicios más representativos del consumo de los hogares de un país se dice que se experimenta inflación.\nEsta tasa de cambio constituye un indicador general de la inflación total, por lo tanto, tiene un papel clave para la toma de decisiones en política monetaria, la definición de la variación en los salarios, el ajuste de estados financieros, la resolución de procesos jurídicos, para calcular la pérdida de poder adquisitivo de la moneda, como uno de los indicadores usados para estimar los equilibrios en partidas de Cuentas Nacionales y como factor de análisis del comportamiento coyuntural de la economía.\nPara este estudio, el interés se centra en el análisis descriptivo de la inflación total mensual como variación anual, en otras palabras, el cambio porcentual de los precios al consumidor IPC de un mes (o periodo) frente al mismo periodo doce (12) meses antes. El periodo de análisis de los datos recopilados inicia desde el 31 de enero del 2000 hasta el 31 de julio de 2022, con 271 registros.\nAhora gráficamos la serie de tiempo para identificar posibles caracteristicas o patrones de comportamiento del fenómeno de la inflación.\n\n\n\n\n\n\n\n\n\nEl gráfico anterior permite apreciar la dinamica del comportamiento de la inflación total mensual medida como variación anual para Colombia en los periodos del 31 de enero de 2000 hasta el 31 de julio de 2022. Esta serie presenta tres periodos de tendencia decreciente, a saber, el periodo de aproximadamente seis años que comprende de mayo del 2000 hasta junio de 2006, donde la inflación decreció aproximadamente 6.1 puntos porcentuales de 10% a 3.9%, esto posiblemente asociado con una rapida recuperación de Colombia de la crisis de 1999 en donde el producto interno bruto decreció en 4% siendo el peor registro en la historia colombiana y uno de los mayores registros de inflación con 10% para los años inmediatamente posteriores. Por otro lado, el periodo que comprende entre octubre del 2008 hasta marzo de 2010, donde la inflación comparada contra el año inmediatamente anterior disminuyó 6.1 puntos porcentuales de un 7.93% a 1.83%, dado como resultado de la crisis financiera internacional y resultados positivos en el comercio interno que beneficiaron a país disminuyendo el impacto en la tasa representativa del mercado frente al dolar. El ultimo periodo de descenso abarca desde agosto de 2016 a febrero de 2019 el cual disminuyó un auge de inflación en aproximadamente 5.7 puntos porcentuales de 8.96% a 3.24%, asociado con el fin de negociaciones en un paro campesino de 2016 y la realización del acuerdo de paz entre grupos insurgentes que resultó en una mayor confianza inversionista y un crecimiento en la inversión extranjera a proyectos de largo aliento dentro del país.\nPor otro lado, historicamente la inflación para estos periodos presenta 4 eventos que contribuyeron al aumento más que proporcional en rapidos periodos que se asocian con crisis economicas en 1999, crisis del mercado de capitales en 2008 a 2010, factores en las cadenas de producción y protestas sociales para 2016 y finalmente la pandemia de Sars-Cov-2 en 2020. Entre estos periodos podemos apreciar crecimiento en el nivel deprecios en los auges hasta una cima que estan acotadas por un valor maximo de 10.2% que se registró en julio de 2022.\nCaracteristicas de la serie de inflación total\n\nLa serie presenta una varianza marginal que varía a lo largo del tiempo, esto a razón de que la serie parece tener un rango de valores diferente a lo largo del tiempo iniciando en un registro de 8.5%, tomando su valor mínimo en 1.61% y retomando su valor final y maximo en el periodo de estudio en 10.2%. De esta serie se puede percibir que la volatilidad a lo largo del tiempo aumenta de manera monotona, en otras palabras el rango en donde fluctuan los valores aumenta mientras el tiempo transcurre. Por lo tanto, se podría decir que la varianza marginal de la serie no es independiente del tiempo, se suguiere trabajar con una transformación de potencia para estabilizar la varianza de la serie vía Box-Cox.\nA simple vista, la inflación en el periodo de estudio no cambia sus valores a lo largo del tiempo alrededor de un unico nivel, es decir, su valor promedio no es independiente del tiempo para el periodo de analisis de este estudio, por lo tanto presenta un componente tendencial o nivel de la serie dependiente del periodo de tiempo. Asimismo, se puede apreciar el parecido de la serie con una caminata aleatoria que inicia en 8.24% de inflación.\nExiste presencia de una componente cíclica (estacional o no estacional) que puede percibirse cada 30 y 54 meses lo cual puede dar luz sobre componentes de ciclos economicos largos en la serie, esto también puede implicar que la media del proceso no sea constante y que se enmascare en presencia de tendencia.\n\nDe acuerdo, a las caracteristicas que presenta la serie se procede a realizar la transformación Box-Cox, se suguiere transformarla serie con un valor de lamda equivalente a 0.812 de tal manera que la serie se estabilice en varianza a lo largo del tiempo. De la misma forma se puede comparar en cambio en escala de medidas de la serie con varianza estabilizada, el método utilizado fue la aproximación de Guerrero para llegar a este valor, sin embargo, los valores de la serie pierden interpretabilidad.\n\n\n\n\n\n\n\n\n\n[1] 0.9918422\n\n\nAdemas, inmediatamente a la transformación de Box-Cox se realizan las estimaciones muestrales de las autocorrelaciones simples y parciales (FAS) y (FAP), en donde se puede observar que la FAS muestra un decaimiento lento que indica que la serie presenta tendencia que se consideró estocastica, sin embargo la serie no presenta un comportamiento repetitivo en una periodicidad a simple vista, luego no se puede afirmar que exista un componente estacional o periodico deterministico. Finalmente, se realiza sobre la serie transformada una busqueda de otro lamda de transfomación para asegurar que la transformación es apropiada y sugiere un lamda que asciende a 0.9918422, que es practicamente 1.\nAnálisis de tendencia o nivel de la serie\nLa inflación en el periodo de estudio no cambia sus valores a lo largo del tiempo alrededor de un unico nivel, es decir, su valor promedio no es independiente del tiempo para el periodo de analisis de este estudio, por lo tanto presenta un componente tendencial o nivel de la serie dependiente del periodo de tiempo.\nAsimismo, se puede apreciar el parecido de la serie con una caminata aleatoria que inicia en 8.24% de inflación y que la tendencia existente en los registros no obedece a una funcion matematica exacta, luego se puede considerar una tendencia estocastica. Bajo un enfoque descriptivo se procede a contrastar la estimación de la tendencia vía estimación polinómica local (LOESS), a continuación, se presentan 4 gráficas que evidencian la estimación de la tendencia.\n\n\n\n\n\n\n\n\n\nSe puede apreciar en la gráfica superior izquiera que la estimación de la tendencia que considera una ventana del 75% de los datos (aproximadamente 204 meses) señala la existencia de una tendencia decreciente en la primera decada del periodo de estudio, para posteriormente cambiar su pendiente y crecer lentamente durante la segunda decada de manera suave. Para la gráfica superior derecha, se puede evidenciar que la estimación de la tendencia que considera una ventana del 35% de los datos (aproximadamente 95 meses) dentro de las 2 decadas del estudio presentan periodos en donde la inflación alcanza un valle y posteriormente tiene un auge que en ambas decadas es cercano al 7%. Asimismo, la transición hacia la gráfica inferior izquierda muestra la estimación de la tendencia que considera una ventana del 20% de los datos (aproximadamente 204 meses) que presenta posibles ciclos de 2 a 3 años dentro de cada decada que pueden verse enmascarados por la tendencia pero que con una ventana de menos observaciones se puede sospechar de posibles ciclos no periodicos (no necesariamente de duración constante). Finalmente, en la gráfica inferior derecha se observa la estimación de la tendencia que considera una ventana del 8% de los datos (aproximadamente 24 meses) presenta posibles ciclos de 2,5 años dentro de cada decada que pueden verse enmascarados por la tendencia pero que con una ventana de menos observaciones se puede sospechar de posibles ciclos no periodicos\nSustracción de la tendencia estimada\nUna vez estimada la tendencia a traves de una aproximación no parametrica por polinomios locales, se procede a eliminar la estimación de la serie con la varianza estabilizada. Es decir, una manera de asegurar que la tendencia estimada es la correcta se observa el resultado del valor real de la serie frente a su tendencia y finalmente este resultado no debe poseer tendencia. Este componente sin tendencia tiene un papel clave para identificar y determinar patrones, comportamientos y ciclos dentro de la serie que posiblemente se enmascaraban con la tendencia.\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n\nLas gráficas anteriores permiten contrastar el metodo de eliminación de tendencia por polinomios locales frente a la metodologia Box-Jenkins, con el objetivo de detectar estabilidad en el valor promedio y una varianza constante a lo largo del periodo de tiempo. Asimimo, se puede apreciar ambas metodologías producen una serie que estable en media pero que a simple vista no parece muy constante en varianza, es decir, ambas series presentan una volatilidad que subjetivamente generan dudas sobre la estacionariedad de la serie, esto puede ser generado por un componente estacional o ciclio que no es capturado por la tendencia vía LOESS o diferenciando la serie.\nAnálisis de estacionalidad\nMediante la suposición clasica de un modelo aditivo vemos presencia de tendencia, pero no se identifica un componente estacional que contraste a simple vista. Por otro lado, se realiza una busqueda de componentes que muestren estacionalidad usando medidas descriptivas como herramientas para detección de este fenomeno en distintos periodos del tiempo. En primera instancia, se realiza un gráfico de suberies para enfatizar los patrones estacionales es aquel en el que los datos de cada estación se recogen juntos en mini gráficos temporales separados.\n\n\n\n\n\n\n\n\n\nLas líneas azules horizontales indican las medias de cada mes, se puede observar que no existen medias que se ubiquen en valores extremos. Este tipo de gráfico permite ver claramente el patrón estacional subyacente y también muestra los cambios en la estacionalidad a lo largo del tiempo, en este caso no se evidencia a simple vista un componente estacional. En este ejemplo, el gráfico no es especialmente revelador.\n\nUn gráfico para promedios agrupando por meses…\n\n\n\n\n\n\n\n\nUn gráfico para promedios agrupando por meses y desv\n\n\nExploración de multiples estacionalidades (ciclos estacionales?)\n\n\n\n'data.frame':   271 obs. of  2 variables:\n $ infla: num  -0.901 -0.423 0.173 0.372 0.455 ...\n $ Fecha: Date, format: \"2000-01-31\" \"2000-02-29\" ...\n\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nDe manera individual…\n\n\n\n\n\n\n\n\n\n\nPuede usar el argumento period=12 y da el mismo resultado, lo que significa es que se pueden agrupar las observaciones que están cada 12.\n\n\nGráficos de densidades para explorar la estacionalidad.\n\nA\n\n\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous.\n\n\n\n\n\n\n\n\n\n\n\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous.\n\n\n\n\n\n\n\n\n\nNo parece haber patrón estacional en la serie, puesto que las funciones de densidad estan superpuestas entre si y por tanto los valores medios de la inflación parecen tener valores que no depende del mes. Por otro lado, podemos observar que el comportamiento en varianza tampoco es estacional.\nAhora repetimos el procedimiento pero eliminando previamente la tendencia de la serie Inflación\nPara este gráfico observamos que las colas de las densidades de distribución estimadas son mas cortas.\nPueden hacer lo mismo pero en vez de quitar la tendencia, hacemos una diferenciación\nAhora un gráfico de lineas\nProcedemos a extraer las subseries por años. Para identificar posibles comportamientos que permitan describir el comportamiento de la Inflación\nAnálisis de Rezagos\nDiagrama de dispersión de las observaciones originales con sus respectivos retardos…\n\n\n\n\n\n\n\n\n\nA color\n\nObservando la figura enterior de concluye que las relaciones de la variable original con los primeros 4 resagos presenta son fuertes y positivas (\\(\\rho&gt; 0.8\\)) y para los resagos más lejanos ttata… lo que significa que los valores inmediados anteriores afectan de manera directo y fenoméno con memoria\n\nTomando cuatrenios (Rezagos estacionales) (por rehacer)\n\n\n\n\n\n\n\n\nAnálisis del ACF y AMI muestral\n\n\nVersión interractiva:\n\n\n\n\n\n\nPor otro lado para el AMI\n\n\n\n\n\n\n\n\n\n\n\nAnálisis de Ciclos y  Estacionalidades \n\n\n\nDel gráfico vemos que el flujo de calor de la Inflación para Colombia ocurre de manera vertical indicando la dispocición del ciclo. En color oscuro se marca los los picos de dicho ciclo. Además esto podría sugerir que el comportamiento de tal ciclo no es estacional.\n\n\nAnálisis de ciclos y estacionalidad utilizando el periodograma:\n\nPara detectar el componente de estacionalidad y de ciclicidad se hará uso del periodograma:…\n\nCon el formato formato base\n\n\nCon el  formato mvspec\n\n\n\n[1] \"El valor de la frecuencia donde se máximiza el periodograma para z1 es: 0.541666666666667\"\n\n\n[1] \"El valor de la frecuencia donde se alcanza el segundo máximo para el periodograma para REC es: 0.375\"\n\n\n[1] \"El valor de la frecuencia donde se alcanza el tercer máximo para el periodograma para REC es: 0.75\"\n\n\n\n\n\n\n\n\n\n###residuos dos\n\n\n\n\n\n\n\n\n\nMétodos de predicción\nMetodología de suavizamiento exponencial\n\n\nWarning: `data_frame()` was deprecated in tibble 1.1.0.\nℹ Please use `tibble()` instead.\n\n\n\n\n\n\n\n\n\n\n\n                      ME      RMSE      MAE         MPE      MAPE      MASE\nTraining set  0.09006216 0.8090687 0.599161   -3.039447  28.14596 0.5910791\nTest set     -4.43578479 5.4735750 4.860388 -314.839799 322.85061 4.7948270\n                  ACF1 Theil's U\nTraining set 0.9467384        NA\nTest set     0.9764721  27.37423\n\n\n                     ME      RMSE       MAE        MPE     MAPE      MASE\nTraining set -0.0869448 0.6762059 0.5202551  -9.475969 23.57609 0.5132375\nTest set     -0.1857017 1.6579692 1.4010652 -60.886943 83.40865 1.3821665\n                  ACF1 Theil's U\nTraining set 0.9232893        NA\nTest set     0.9415096  7.300588\n\n\n\n\n\n\n\n\n\nModelo con todo menos 5\n\nz3_com &lt;- window(z3, end = c(2022,2))\nz3_r&lt;-window(z3, start = c(2022,3))\n\n\nhw.expo_com &lt;- ets(z3_com, \"AAN\",damped = T)\nholt.com &lt;- forecast(hw.expo_com, h = 5)\nsprintf(\"El RMSE para el modelo de Holt con damped es de %f \", accuracy(holt.com, z3_r)[2,2])\n\n[1] \"El RMSE para el modelo de Holt con damped es de 0.388826 \"\n\np&lt;-hw.expo_com %&gt;%\n  forecast(h = 5) %&gt;%\n  autoplot()+ autolayer(z3_r)+\n  labs(title = \"Australian food expenditure\",\n       y = \"$ (billions)\")\np\n\n\n\n\n\n\n\n\n\ncheckresiduals(hw.expo_com)\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ETS(A,Ad,N)\nQ* = 68.526, df = 24, p-value = 3.647e-06\n\nModel df: 0.   Total lags used: 24\n\n\n\n##Z1 Y Z3  SON LA SERIE VARIANZA ESTABILIZADA Y OBJETO TS\n##Z2 ES LA SERIE SIN TENDENCIA \n##tsibble_infla1[,\"infdif\"] ES LA SERIE PERO SIN INDICES",
    "crumbs": [
      "Serie de Tiempo - Ejercicio"
    ]
  },
  {
    "objectID": "Recursos3.html",
    "href": "Recursos3.html",
    "title": "Encuesta de Movilidad 2023",
    "section": "",
    "text": "Este tablero desarrollado dentro de PowerBi, es un ejercicio descriptivo a partir de datos abiertos de la Secretaría de Movilidad.\nEl objetivo del ejercicio fue procesar, limpiar y visualizar la información**\n\n\n\nAlistamiento de datos: integración y cargue de tablas.\nProcesamiento: transformación, cruce y creación de variables relevantes.\nVisualización: construcción de indicadores y gráficos interactivos.\nTablero final: integración de todo en una herramienta dinámica .",
    "crumbs": [
      "Power BI"
    ]
  },
  {
    "objectID": "Recursos3.html#contexto",
    "href": "Recursos3.html#contexto",
    "title": "Encuesta de Movilidad 2023",
    "section": "",
    "text": "Este tablero desarrollado dentro de PowerBi, es un ejercicio descriptivo a partir de datos abiertos de la Secretaría de Movilidad.\nEl objetivo del ejercicio fue procesar, limpiar y visualizar la información**\n\n\n\nAlistamiento de datos: integración y cargue de tablas.\nProcesamiento: transformación, cruce y creación de variables relevantes.\nVisualización: construcción de indicadores y gráficos interactivos.\nTablero final: integración de todo en una herramienta dinámica .",
    "crumbs": [
      "Power BI"
    ]
  },
  {
    "objectID": "Recursos1.html",
    "href": "Recursos1.html",
    "title": "Libros",
    "section": "",
    "text": "A lo largo de mi formación académica, las matemáticas, la estadística y la computación han sido pilares fundamentales. Durante mis estudios reuní una serie de libros y recursos que me ayudaron a comprender mejor estas áreas (en verdad aún lo hacen) y que, en su momento, marcaron mi aprendizaje.\nEste espacio es una manera sencilla de compartir esas referencias, con la idea de que puedan servirle a otros estudiantes, investigadores o curiosos que estén explorando estas disciplinas.\n\n📘 Matemáticas\n\n\nCurso matemáticas básicas- Margarita Ospina Pulido\nPrecálculo — R. Larson, R. P. Hostetler\nMatemáticas generales álgebra, análisis - C. Pisot, M. Zamansky\nCurso de Matemáticas Básicas — M. Ospina\n\nIntroducción a la Teoría de Conjuntos — Lia Oubiña\n\nTeoría Intuitiva de los Conjuntos — P. Halmos\n\nBook of Proof — R. Hammack\nThe Number Systems: Foundations of Algebra and Analysis -S. Feferman\nCálculo Diferencial en una Variable — H. Dueñas & I. Rubio\n\nIntroducción al Cálculo — Kazimierz Kuratowski\n\nCálculo Diferencial e Integral (Tomo I) — N.S. Piskunov\n\nÁlgebra Lineal y sus Aplicaciones — G. Strang\n\nMatrix Algebra Useful for Statistics — Searle\n\nCalculus of Vector Functions — R. E. Williamson\n\nIntroducción a la Teoría de Probabilidades y sus Aplicaciones — W. Feller\n\nProbabilidad — L. Blanco\n\nCurso Intermedio de Probabilidad — L. Rincón\n\nIntroducción a los Procesos Estocásticos — L. Rincón\n\nProblemas de Ecuaciones Diferenciales Ordinarias — G. N. Kiselev\n\nEcuaciones Diferenciales — Kreider, Kuller & Ostberg\n\n\n📊 Estadística\n\n\nEstadística descriptiva - L. Rincón\nIntroducción a la Estadística Inferencial - L. Rincón\n\nStatistical Inference - G. Casella\n\nAnálisis Multivariante de Datos - D. Peña\n\nAnálisis de Series Temporales - D. Peña\n\nSampling and Estimation from Finite Populations — Yves Tillé\n\nStatistical Quality Control - D. Montgomery\n\nDesign and Analysis of Experiments — D. Montgomery\n\nHands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow — Aurélien Géron\n\nAn Introduction to Statistical Learning — T. Hastie, R. Tibshirani et al. \n\n\n💻 Computación\n\n\nFundamentos de diseño de bases de datos - A. Silberschatz, H. F. Korth, S. Sudarshan\nIntroduction to Algorithms - Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest & Clifford Stein\n\nStructure and Interpretation of Computer Programs - Harold Abelson & Gerald Jay Sussman\n\nArtificial Intelligence: A Modern Approach - Stuart Russell & Peter Norvig\nThe Art of Computer Programming - Donald Knuth\nMachine Learning - Tom M. Mitchell\nDatabase System Concepts - A.Silberschatz, H.F. Korth ,S. Sudarshan\nHow to Design Programs - M.Felleisen, R. B. Findler, M. Flatt, S. Krishnamurthi",
    "crumbs": [
      "Libros de Texto"
    ]
  },
  {
    "objectID": "Podcast_lexfridman.html",
    "href": "Podcast_lexfridman.html",
    "title": "Preguntas, ideas, pensamientos a partir de podcast.",
    "section": "",
    "text": "Acá residen algunas de las cosas que mas me llamaron la atención de lo que escuche en cada uno de estos textos. Mucho de esto serán citas textuales/literales, en algunas ocaciones hare comentarios desde mi ignoracia tratado de enriquecer esto…\n\n\n\nLex Fridman Podcast\n\n\n\n\n Episodio #393. Andrew Huberman: Relaciones, Drama, Traición, Sexo y Amor \n\n\n\nComo podemos acceder a nuestra conciencia…\n\n\nTea\n\n\nSobre tener hijos en familia:  Los hijos aportan un tremendo significado a nuestras vidas, seriamos unos idiotas si no formamos familia…\n\n\n\nPalabras de A. Camus citadas por Lex:  En medio del invierno descubri que dentro de mi existia un verano invencible \n\nA continuación, me permito extender el texto, ya que esta cita pertenece a uno de mis autores de referencia. Se trata de uno de sus libros más personales, tanto a nivel biográfico como en cuanto a la calidad de la prosa…\n\n A mediodía, sobre las laderas medio arenosas y cubiertas por heliotropos como por una espuma que hubieran dejado al retirarse las olas furiosas de los últimos días, miraba el mar, que a esa hora se agitaba apenas con un movimiento fatigado, y calmaba esa doble sed que no se puede engañar mucho tiempo sin que el ser se seque, quiero decir amar y admirar. En no ser amado sólo hay mala suerte: en no amar hay desgracia. Hoy en día todos morimos de esa desgracia. Porque la sangre, los odios, descarnan el corazón; la prolongada reivindicación de la justicia agota el amor que, sin embargo, la hizo nacer. En el clamor en que vivimos, el amor es imposible y la justicia no basta. Por eso Europa odia el día y no sabe más que oponer injusticia a la injusticia. Pero para impedir que la justicia, hermoso fruto naranja que no contiene más que una pulpa amarga y seca, se agoste, volvía a descubrir en Tipasa que había que guardar intactas dentro de uno mismo una frescura, una fuente de alegría; amar el día que escapa a la injusticia y volver al combate con esa luz conquistada. Volvía a encontrar allí la antigua belleza, un cielo joven, y ponderaba mi suerte, comprendiendo por fin que en los peores años de nuestra locura el recuerdo de este cielo no me había abandonado nunca. Era él quien, para concluir, me había impedido perder la esperanza. Yo había sabido siempre que las ruinas de Tipasa eran más jóvenes que nuestras obras en construcción o nuestros escombros. El mundo empezaba allí cada día con una luz siempre nueva. ¡Oh, luz!, ése es el grito de todos los personajes enfrentados, en el drama antiguo, a su destino. Ese último recurso era también el nuestro y ahora yo lo sabía. En mitad del invierno aprendía por fin que había en mí un verano invencible.  Tomado de “Retorno a Tipasa” en su libro “El verano” \n\n\n\n\nEpisodio #403 - Lisa Randall: Materia Oscura, Física Teórica y Eventos de Extinción\n\n\n\n¿Como se antropomorfisa la materia oscura?\n\n\n¿La materia oscura tiene alguina estructura que le permite interactua internamente, como lo hace la materia estandar con las fuerzar/interacciones conocidas (gravitacional, nuclear débil, electromagnética, nuclear fuerte)?\n\n\n¿Que forma tiene la materia oscura?\n\n\n¿Como podemos medir aquello que no vemos?\n\n\n¿Es mas probable que perescamos debido a una extincion causada por acontecimientos/eventos generados por humanos o por otros exteriores al nivel solar/galactico ?\n\n\n¿Como experimentaron los dinosuarios la extinción? (Esta pregunta planteada por Lex va mas hacia la experiencia visula del impacto del meteorito)\n\n\nCita mencionada por sobre el libro de la autora acerca de abordar lo bello/sublime en la fisica (y en el conocimiento en geeral, agregaria):\n\n ¿Quién, si gritara yo, me escucharía  en los celestes coros? Y si un ángel inopinadamente me ciñera contra su corazón, la fuerza de su ser me borraría; porque la belleza no es sino el nacimiento de lo terrible; un algo que nosotros podemos admirar y soportar tan sólo en la medida en que se aviene, desdeñoso, a existir sin destruirnos. Todo ángel es terrible. \n\nTomado de la Primera Eliegía del libro Elegías de Duino de R. M. Rilke\n\n\n\n\n¿Puede existir algo analogo a lo que es la vida-inteligente en el campo de la materia oscura? Es decir, si bien en el plano de la materia ordinaria (materia bariónica), se ha generado todo lo que posemos observar y nombramos como realidad. ¿ Que implicaria que esto pasara dentro de la materia oscura, algun tipo de interaciones complejas que dieran origen a sistemas mas elaborados?\n\n\n¿ Qué es el modelo estándar de particulas, como genera/sostiene todo el funcionamiento de la realidad y como encaja la materia oscura en este modelo?\n\n\n¿Puede la ciencia descubrir la realidad?\n\n\nLa respuesta dada por Lissa a la pregunta retórica echa por Lex (¿Cuales crees son los limites de la ciencia?) me parece muy sugestiva y convincente.\n\n - Soy lo suficientemente inteligente como para saber que no tengo idea, y además ni siquiera esta claro que es/significa ‘ciencia’. Porque existe la ciencia que hacemos, que la fisica de particulas en la que tratamos encontrar cosas fundamentales y descubrir cuales son sus efectos. Hay ciencias como la biología, que se encuentra en un nivel superior en la que el tipo de preguntas que aborda/hace y formas de medir/contrastar es diferentes. Ahora bien el tipo de ciencia que sucedera en una epoca/era mas númerica o incluso de IA o algo así; ¿que significará responder una pregunta: significa que podemos predecirlo, significa que reproducirlo? Por tanto creo que nos estamos encontrando con una especie de redefinición de lo entendemos de ciencia como seres humanos. Entonces en términos de la ciencia que actualmente se hace no creo que podamos responder a esa pregunta hasta que llegemos allí… Si piensas en cuanto a avanzado la ciencia en el último siglo o siglo y medio, es increible…  Creeria que es prematuro, decir que se conocen las limitaciones… \n\n\n\n¿Cual es para ti, la diferencia entre fisica y matemáticas, en la forma en que nos ayudan a comprender el mundo?\n\n\n - Creo que existe mucha más superposición entre estas dos, de la que realmente se aprecia…  Una vez más las preguntas que se abordan son diferentes en cada área. A los matemáticos les gusta la estructura misma, los físicos se tratan de concentrar en las consecuncias para el mundo… Se convierte casi en una cuestión sociologica, de cuanto deberia ser uno u otro. Creo que uno puede quedar atrapado en los problemas mismos, y aveces en los metodos y simplemente hacer otros ejemplos. Por lo tanto los verdaderos conocimientos sobre fisica, a menudo provienen de personas que piensan tanto en fisicas como en matemáticas. \n\n\n57:25 Acerca de las implicanciones de la IA la forma en que va afectar el futuro y la ciencia en particular, Lex plantea la siguiente pregunta que me resulta muy importante y curiosa: ¿Que tan especiales son los humanos, para poder descubrir ideas/conocimientos nuevas sobre el universo/cosmos?\n\n\n Depende de que tipo de conocimiento y que vamos a descubrir, porque es dificil pensar el algo que no existe…digo se podria dar un paso atras con internet (es como un poco intentar manejar cuatro dimensiones, volver a tres dimensiones para regresar a algo que puedes imaginar), así que puedes decir muchas cosas en un nivel muy diferente acerca de internet. Se puede decir que a ayudado a muchas cosas, tomo vida en cierto sentido; pero es algo que podemos domesticar… Yo misma no hubiese podido escribir libros si internet no existiera, porque no abria tenido tiempo de ir a la biblioteca y buscarlo todo… En cierto sentido la IA podria ser una herramienta que nos ayude a ir un paso mas allá de lo que hacemos y de una forma mas eficiente, como ya lo esta haciendo. O bien podria ser la parte opuesta, como la parte de internet que no podemos controlar que esta arruinando la politica… Luego existen cosas más grandes sobre las cuales la gente especula, acerca que la IA puede hacer sus propias cosas… pero en términos de resolver las cosas estamos en las primeras etapas \n\n\nLos grandes modelos de lenguaje son mas o menos generalizaciones de cosas qeu tenemos\n\n\n1:02:35(Pregunta de Lex a Lisa) ¿Cual es para ti, el problema sin resolver mas hermoso/interesante de la fisica?\n\n\n - La mayoria de las preguntas, las grandes preguntas, tienen que ver con lo que subyace a las cosas como: ¿Cual fue su origen? ¿Que hay en su base?… Tambien existen preguntas basicas: ¿A donde nos llevara la ciencia? ¿Cuanto podemos enterder?… Hay preguntas del corte ¿Como llegamos aquí? ¿Que subyace a esto?… Hay preguntas muy profundas como: ¿Que fracción estamos viendo realmente? ¿Si existe otras fuerzas, si hay otra forma de ver lo que nos rodea? ¿Existen universos mas allá del nuestro? Si son tan diferentes, ¿Como podemos siquiera comprenderlos, detectarlos?… Hay mucho que ver con ir más allá. Siempre se trata de ir mas allá de nuestra experiencia y visión limitadas, y tratar de ver lo que hay detrás, tanto a pequeña como gran escala…Simplemente no sabemos las respuestas… Me gustaria pensar que entendemos más sobre materia oscura, energia oscura, dimensiones adicionales, etc; Cosas en la que se esta trabajando, porque probablemente existe mucho más allá de lo que se ha encontrado y que esta por decubrir.\n\n\n\n¿La física puede cambiar mas alla del universo observable?\n\n\n1:05:25Consejo para los jovenes cientificos.\n\n\n - Deben creer firmemente en lo que haces y al mismo tiempo cuestionarlo a todo momento…Lograr ese equilirio, a veces ayuda colaborar con otros… Saber que puedes tener buenas y sabiendo que todas puedesn estar equivocadas… Una cuarda floja dificil de caminar, pero se debe hacer.  - Intentar descubrir por qué las cosas son como son…es bueno hacerlo desde un punto de vista teórico eficaz y un paso a la vez.  \n\n\n¿Lo que percibimos como bello/sublime se debe a como hemos evolucionado, ?\n\n\n“Lo importante es no dejar de cuestionarse. La curiosidad tiene su propia razón de ser.”\n\n\n\nEpisodio #404 -\n\n\n Esto estara en otro sitio a futuro"
  },
  {
    "objectID": "Peliculas.html",
    "href": "Peliculas.html",
    "title": "Peliculas",
    "section": "",
    "text": "Películas en las que encontre muchas preguntas nuevas y algunas respuestas que necesitaba justificar\n\n10000 A.C.\nMatriz (La Trilogía)\n2001: Odisea en el espacio\nHannibal\nLa llegada\nMad Max\nEl club de la pelea\nGladiador\n300\nHannibal\nUna mente brillante\nInmortales\nEl apostador\nWatchmen\nLa ciudad del pecado\nKick-Ass\nTransformer 1\nPulp Fiction\nEl gran Lebowski\nFargo\nAsesinos por naturaleza\nEl silencio de los inocentes\nBlade Runner\nEx-Machina\nAtlas de las nubes\nVecinos invasores\nEl gran truco\nOrigen\nSin límites\nElysium\nEterno resplandor\nRango\nMi vecino Totoro\nLa naranja mecánica\nLagrimas de sol\nSucker Punch",
    "crumbs": [
      "Películas"
    ]
  },
  {
    "objectID": "Libros_0001.html",
    "href": "Libros_0001.html",
    "title": "Preguntas, ideas, pensamientos a partir de libros.",
    "section": "",
    "text": "Acá ire agregando algunas de las cosas que más me llegan de lo que este leyendo, algunas que ya tengo anotadas (o releyendo)… Mucho y todo de esto serán citas textuales/literales, en algunas ocaciones hare comentarios desde mi ignoracia tratado de enriquecer esto…no abra noveda. O trayendo una referencia/cita de Borges a Bacon en el Inmortal: …toda novedad no es más que olvido.\n\n\nCritical Meme Reader III: Breaking the Meme\n\n\n\n\nContexto/Intro\n\n\nEl término/concepto ‘meme’ como objeto de estudio lo vi por primera vez en R. Dawkins (en su libro El gen egoísta de 1976), por allá en en el 2014-2015. Allí el autor utiliza el término para describir una unidad de información cultural que se transmite de una persona a otra, similar a cómo los genes transmiten información biológica. En este sentido, los memes pueden ser ideas, historias, hábitos, comportamientos, estilos, o prácticas que se propagan dentro de una cultura. Argumenta que así como los genes compiten por su supervivencia a través de la selección natural/evolución, los memes compiten por ser difundidos y adoptados por individuos dentro de una sociedad. Por tanto los memes más exitosos son aquellos que son más eficaces/eficientes en entenderse y ser replicados. Ejemplos de memes pueden ser melodías pegajosas, obras de arte, lemas publicitarios, modas, mitos, rituales religiosos,pinturas rupestre, obras arquitectónicas …Acá me atrevo a votar una idea : que los memes en todas sus expresiones son estados hacia donde la informacion/materia converge en el sentido de función y forma, i.e., si una forma de comunicación es funcional y operativa esta se integrara a los sistemas vivos.\n\n\nOtro autor que conozco que explora el concepto desde otra perpectiva (la antropología) es Michael Taussig en  Mímesis and Alterity - 1993, estudia/explora la forma en que las miembros de una cultura adoptan la naturaleza, comportamientos y la cultura de otra lo que el autor llama el proceso de mimesis, al mismo tiempo que la niegan y se distancian de ella,  el proceso de alteridad. Me llegan imagenes de las paginas de Cien años de soledad, puntualmente en las que el gitano Melquíades trae inventos científicos a Macondo de otros lugares que no pasan atren la atención José Arcadio (proceso de mímesis), llevandole a la locura. Por otro lado esta el papel de Úrsula (proceso de alteridad). Nota: Taussig toma una postura limitante hacia el alcance de método de estudio de la antropología, para acceder/explicar a una cultura a través de otra.\n\n\nUna autora de referencia es Susan Blackmore, que en su libro  La máquina de los memes-1999, expandió la idea de Dawkins y exploró cómo los memes influyen en la evolución cultural. Según Blackmore, los seres humanos no solo son replicadores biológicos sino también replicadores meméticos, y esto ha tenido un impacto significativo en la evolución de nuestras sociedades y culturas. Una de las tesis principales es que ‘la cultura es una masa de memes’. Señala los mitos, los inventos, el lenguaje y los sistemas políticos como estructuras hechas de memes. No todo es un meme.En el contexto cultural y social, los memes se ven como vehículos de comunicación y expresión que reflejan y a menudo critican la realidad social. En las redes sociales, por ejemplo, los memes a menudo son imágenes o videos con texto superpuesto que transmiten ideas, humor o críticas de manera rápida y accesible. Desde una perspectiva evolutiva, la propagación de memes puede ser vista como una forma de evolución cultural paralela a la evolución biológica. Los memes exitosos pueden influir en el comportamiento y las creencias de grandes grupos de personas, y, por lo tanto, pueden tener un impacto significativo en la dirección en la que una cultura evoluciona.",
    "crumbs": [
      "Otros"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Sobre Mí",
    "section": "",
    "text": "Aprendí a leer a los seis/siete años y desde entonces nunca dejé de hacerlo. La lectura me enseñó a acercarme al mundo con curiosidad y a buscar en cada línea un significado. Más adelante, cuando descubrí las matemáticas de forma más formal, ocurrió algo parecido: comprendí que era otra manera de leer la realidad, con estructuras, patrones y lógica.\nEsa conexión me llevó a la estadística, una disciplina que me permite interpretar datos, contrastar hipótesis y generar conclusiones útiles. Para mí, trabajar con datos es una extensión de esa primera experiencia: leer, comprender y transformar información en conocimiento.\nHoy me interesa especialmente la arquitectura de datos, inteligencia artificial, modelamiento estadístico y el desarrollo de soluciones que unan el análisis estadístico con problemas reales. Creo firmemente que los datos no solo describen el mundo, sino que también nos ayudan a tomar mejores decisiones sobre él.\n\nFuera de lo estrictamente profesional, me interesa cómo distintas formas de conocimiento se entrelazan. Por ejemplo, en uno de los textos más antiguos de la humanidad, Las mil y una noches, hay un guiño matemático escondido: ¿por qué 1001 y no 1000 o 1002 noches ‘canto’ Sherazade ?\nEn aquellos tiempos, los sacerdotes matemáticos (grandes visires, magos) poseían un poder increíble, pues poseían los secretos matemáticos necesarios para la navegación y el comercio, así como para la contabilidad, la creación de calendarios y muchas cosas que hoy damos por sentado. En aquel entonces, por ejemplo, los ciudadanos comunes, y a menudo incluso el rey/gobernante, no sabían sumar, restar, multiplicar ni realizar otros cálculos.\nUna forma en que los sacerdotes mantenían a la población en la ignorancia era contando historias elaboradas o engañosas para ocultar la verdad y el conocimiento. Una de esas historias era el mito de Sherazade y sus Mil y una Noches.\nLa respuesta está en la aritmética. 1001 es un número especial porque se descompone como 7 × 11 × 13, y ese juego de factores se relaciona con la tradición de considerar algunos números como de ‘mala suerte’. Para mí, detalles como este son recordatorios de que tanto la literatura como la matemática son, en el fondo, distintas formas de leer el mundo y de encontrar patrones en él… Este blog es también un espacio para compartir esos intereses.\n\n# 1000^1 \n# 1000^2 = 1002001 \n# 1000^3 = 1003003001\n# 1000^4 = 1.004006e+12\n\n## Cada nuevo número total contiene un número que representa cada potencia.\n## La verdadera importancia de usar el 1001 reside en que permite una especie \n## de abreviatura matemática (recursión?)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Vladimir Sánchez Tenjo",
    "section": "",
    "text": "Hola gente!\nGracias por visitar mi sitio en internet, estoy animado de conocerte y poder ayudarte en cuestiones estadísticas y de datos. Espero encuentres algo de interés acá.\n\n\n\nEducación\nPregrado en Estadística (2023) | Universidad Nacional de Colombia, Sede Bogotá. Bogotá, D.C.\n\n\nExperiencia\nEstadístico (May 2024 - Feb 2025) | TransMilenio Bogotá, D.C.\nInternship (Ene 2023 - Jul 2023) | Refinancia S.A.S. Bogotá, D.C.\nEstudiante de Investigación en Semillero análisis de datos ómicos (2022 - 2023) | UNAL\n\n\n\nThe two greatest inventions of the human mind are writing and money—the common language of intelligence, and the common language of self-interest.\n\n\nVictor Riqueti, Marques de Mirabeau\n\n\n\nThere are two ways to write error-free programs; only the third one works.\n\n\n\nAlan J. Perlis"
  },
  {
    "objectID": "Libros_02.html",
    "href": "Libros_02.html",
    "title": "Literatura",
    "section": "",
    "text": "La literatura ha sido otro de mis grandes intereses, una forma de diálogo con las grandes ideas, la filosofía y la belleza del lenguaje. Estos son algunos de los libros y autores que más me han marcado:",
    "crumbs": [
      "Libros"
    ]
  },
  {
    "objectID": "Libros_02.html#nota-personal",
    "href": "Libros_02.html#nota-personal",
    "title": "Literatura",
    "section": "Nota personal",
    "text": "Nota personal\nEsta lista no es exhaustiva ni pretende ser un canon, sino un registro de aquellas lecturas que han dejado huella en mi forma de pensar y sentir.",
    "crumbs": [
      "Libros"
    ]
  },
  {
    "objectID": "Podcast.html",
    "href": "Podcast.html",
    "title": "Podcast",
    "section": "",
    "text": "En esta sección comparto algunos de los podcasts que escucho, una mezcla de los que siguen activos y otros que ya no producen episodios, pero que siguen siendo muy valiosos.\n\n\n\nLex Fridman Podcast\nConversaciones profundas sobre inteligencia artificial, tecnología, ciencia y filosofía.\nThe Diary of a CEO (Stephen Bartlett)\nEntrevistas inspiradoras con líderes, emprendedores y creadores de impacto.\nRadio Ambulante\nHistorias latinoamericanas narradas con gran calidad periodística y humana.\nTED Talks Daily\nIdeas y conferencias de TED en formato breve y accesible.\nDiana Uribe.fm\nHistoria, cultura y análisis contados con un estilo cercano y narrativo.\nBBVA Aprendemos juntos 2030\nEntrevistas inspiradoras con diferentes personas a cerca de como afrontar la vida de la mejor manera a partir de herramientas, conocimientos y experiencias.\nmixxi.io\nPodcast diario de tecnología que explica la actualidad de una forma amena, clara y consisa.\nQuillete Podcast\nDebates academicos sobre ciencia, política,filosofia y cultura.\nLa Fonda Filosófica\nIdeas de la filosofia explicadas de manera clara.\nLa Muralla y los Libros\nConversaciones sobre producción literararia, ferias, talleres, editoriales, libros, eventos. (Argentina)\nDescarga Cultura (UNAM)\nLiteratura contemporanea, clásicos universales, música, teatro, etc.\nLa filosofía no sirve para nada\nRefexiones sobre temas actuales desde la ciencia y la filosofía.\nLa biblioteca de Julio\nSobre el universo de Julio Cortazar\nHuberman Lab\nExploración de temas de neurociencia.\n\n\n\n\n\nEl Test de Turing\nConversaciones sobre inteligencia artificial, filosofía y futuro tecnológico.\nEl Oficio de leer\nExploración crítica de temas actuales en ciencia y sociedad.\nEl resto es literatura\nBiografías y libros.\nComo funcionan las cosas\nNarraciones singularidades sobre como ‘funcionan’ diferentes cosas/temas desde la soledad hasta ‘dejar de funcionar’.\nA Fondo Recopilación de los audios de las entrevistas del programa “A Fondo” emitido por la televisión pública española (TVE) entre los años 1976 y 1981, dirigido y presentado por el periodista Joaquín Soler Serrano.\nIdea Millonaria\nCiencia, tecnología, filosofía, cultura pop (y no pop), y muchos sinsentidos.",
    "crumbs": [
      "Podcast"
    ]
  },
  {
    "objectID": "Podcast.html#actuales",
    "href": "Podcast.html#actuales",
    "title": "Podcast",
    "section": "",
    "text": "Lex Fridman Podcast\nConversaciones profundas sobre inteligencia artificial, tecnología, ciencia y filosofía.\nThe Diary of a CEO (Stephen Bartlett)\nEntrevistas inspiradoras con líderes, emprendedores y creadores de impacto.\nRadio Ambulante\nHistorias latinoamericanas narradas con gran calidad periodística y humana.\nTED Talks Daily\nIdeas y conferencias de TED en formato breve y accesible.\nDiana Uribe.fm\nHistoria, cultura y análisis contados con un estilo cercano y narrativo.\nBBVA Aprendemos juntos 2030\nEntrevistas inspiradoras con diferentes personas a cerca de como afrontar la vida de la mejor manera a partir de herramientas, conocimientos y experiencias.\nmixxi.io\nPodcast diario de tecnología que explica la actualidad de una forma amena, clara y consisa.\nQuillete Podcast\nDebates academicos sobre ciencia, política,filosofia y cultura.\nLa Fonda Filosófica\nIdeas de la filosofia explicadas de manera clara.\nLa Muralla y los Libros\nConversaciones sobre producción literararia, ferias, talleres, editoriales, libros, eventos. (Argentina)\nDescarga Cultura (UNAM)\nLiteratura contemporanea, clásicos universales, música, teatro, etc.\nLa filosofía no sirve para nada\nRefexiones sobre temas actuales desde la ciencia y la filosofía.\nLa biblioteca de Julio\nSobre el universo de Julio Cortazar\nHuberman Lab\nExploración de temas de neurociencia.",
    "crumbs": [
      "Podcast"
    ]
  },
  {
    "objectID": "Podcast.html#pausados-o-finalizados",
    "href": "Podcast.html#pausados-o-finalizados",
    "title": "Podcast",
    "section": "",
    "text": "El Test de Turing\nConversaciones sobre inteligencia artificial, filosofía y futuro tecnológico.\nEl Oficio de leer\nExploración crítica de temas actuales en ciencia y sociedad.\nEl resto es literatura\nBiografías y libros.\nComo funcionan las cosas\nNarraciones singularidades sobre como ‘funcionan’ diferentes cosas/temas desde la soledad hasta ‘dejar de funcionar’.\nA Fondo Recopilación de los audios de las entrevistas del programa “A Fondo” emitido por la televisión pública española (TVE) entre los años 1976 y 1981, dirigido y presentado por el periodista Joaquín Soler Serrano.\nIdea Millonaria\nCiencia, tecnología, filosofía, cultura pop (y no pop), y muchos sinsentidos.",
    "crumbs": [
      "Podcast"
    ]
  },
  {
    "objectID": "Recursos.html",
    "href": "Recursos.html",
    "title": "Recursos",
    "section": "",
    "text": "Descargo de reponsabilidad y consejos de estudiante\n\n\n\nAca va todo es todo lo relacionado …"
  },
  {
    "objectID": "Recursos2.html",
    "href": "Recursos2.html",
    "title": "Recursos de interés (enlaces)",
    "section": "",
    "text": "Algunos sitios/canales/enlaces con recursos de temas referentes a mis intereses\n\nLuis Rincón\nProfesor del Departamento de Matemáticas en la Facultad de Ciencias de la UNAM México - El sitio personal (Opción 1) - El sitio personal (Opción 2) - Canal de YouTube\n\n\nRandom Services\nRandom Services es un sitio web dedicado a la probabilidad, la estadística matemática y los procesos estocásticos, y está destinado a profesores y estudiantes de estas materias.\n\n\nBookdown | bookdown.org\nEl sitio web bookdown.org es un servicio de RStudio, PBC, para alojar libros.\n\n\nIntroduction to Data Technologies de Paul Murrell\nIntroduction to Data Technologies Este libro/sitio trata sobre cuestiones y tecnologías relacionadas con el almacenamiento y uso de conjuntos de datos.\n\n\nMichael Clark\nSitio personal de Michael Clark",
    "crumbs": [
      "Recursos de Multimedia"
    ]
  },
  {
    "objectID": "R_Tutorial_01.html",
    "href": "R_Tutorial_01.html",
    "title": "Back to Basics R",
    "section": "",
    "text": "Primer acercamiento a R\n\nEste es un tutorial básico de R. Si ya sabes algo de R no creo que encuentres mucho acá. Las expresiones, sentencias y procedimientos mostrados se ejecutaron en el IDE de RStudio\n\n\nNota: En programación, una sentencia y una expresión son conceptos diferentes:\n\nExpresión: Es una combinación de valores, variables y operadores que da como resultado un valor único. Las expresiones en la mayoría de los lenguajes de programación pueden ser simples (como 3 + 5) o más complejas (como 2 * (3 + 5)). En R, un ejemplo de expresión podría ser:\n\n\nresultado &lt;- sqrt(3) + 5\n\nEn esta expresión, sqrt(3) + 5 es la parte que produce el valor, y luego ese valor puede ser asignado a la variable, e.g., resultado.\n\nSentencia: Es una unidad de código que realiza una acción específica. Una sentencia en un lenguaje de programación generalmente realiza una tarea, como asignar un valor a una variable, llamar a una función, o realizar una operación de control de flujo (como una instrucción if o un bucle for). En R, una sentencia simple podría ser:\n\n\nresultado &lt;- sqrt(3) + 5\n\nEsta línea de código es tanto una expresión como una sentencia. Es una sentencia porque realiza la acción de asignar el resultado de sqrt(3) + 5 a la variable resultado, y es una expresión porque la expresión sqrt(3) + 5 produce un valor que se asigna a resultado.\nObserve que, todas las expresiones son sentencias, pero no todas las sentencias son expresiones. Las expresiones producen valores, mientras que las sentencias realizan acciones en el programa.\n\n\nLo clásico\n\n\n\n\nHistoria patria: Inicios y una anecdota…\n\n\nSobre la instalación: Para seguir este tutorial debe tener instalado tanto R (programa que hace el trabajo sucio, cálculos y demas), como RStudio ( un entorno de trabajo que permite interactuar con el leguaje de manera mas eficiente e intuitiva). Para esto sugiero los siguientes tutoriales que resultan facil de seguir.\n\n\nSobre la instalación: Explorando RStudio, conociendo los paneles de trabajo: Consola, Editor, Panel de entornos, y Panel de vista. Estos dos últimos iran tomando sentido y la importancia que merecen a medida que se avance en el conocimiento de lo que es R. Nota: En un inicio lo mas importante es saber los usos de la Consola, scripts ( Editor) y la fución de ayuda (en la pestaña de Help) en el Panel Vista\n\nLa magia de R: Programación de objetos\n\n\n Instalando paquetes: Para usar un paquete en R debemos hacer dos cosas, instalar el paquete (solo se hace una vez, por el momento) install.packages() y cargarlo  library(), esto ultimo cada vez que se use en una sesión\n\n\nAcontinuación se muestra como hacerlo digitando código:\n\n# El nombre del paquete a instalar, siempre entre comillas\ninstall.packages('nombre_paquete')\n# Suponiendo que se ha instalado, lo cargamos y no deberia generar error\nlibrary(nombre_paquete)\n\n\nConsejo profesional (No lo soy, pero igual): Por más pequeño que sea en lo que estes trabajando, siempre siempre crea un proyecto y luego crea internamente tus documentos para trabajar sobre estos.\n\n\n\nR Como Cálculadora (algo original :V)\n\n\nComo en todo lenguaje de programación, es usual empezar a interactuar con este en forma de calculadora, y lo haremos con R. A continuación se listan las operaciones más basicas (su símbolo, descripción y ejemplo junto con su salida), las cuales bastaran para nuestro fin.\n\n\n\n\n\nSímbolo\n\n\nDescripción\n\n\nEjemplo\n\n\nSalida\n\n\n\n\n+\n\n\nOperador binario para sumar\n\n\n5 + 17\n\n\n 22\n\n\n\n\n-\n\n\nOperador binario para restar\n\n\n10 - 3\n\n\n7\n\n\n\n\n*\n\n\nOperador binario para multiplicar\n\n\n4 * 6\n\n\n 24\n\n\n\n\n/\n\n\nOperador binario para dividir\n\n\n20 / 5\n\n\n 4\n\n\n\n\n^\n\n\nOperador binario para potencia\n\n\n2^3\n\n\n 8\n\n\n\n\n%/%\n\n\nOperador binario para obtener el cociente en una división (número entero)\n\n\n10%/%3 \n\n\n 3\n\n\n\n\n%%\n\n\nOperador binario para obtener el residuo en una división\n\n\n10 %% 3\n\n\n 1\n\n\n\n\nAhora vamos a R, acá se supone que las expresiones estan siendo ingresadas en consola, poe el momento. Importante para evaluar una expresión se ingrasa en la consola y damos enter (). Así las cosas para la primera expresión a continuación tenemos: ‘5 + 17’ + (enter)\n\n\n&gt; # Suma  \n&gt; 5 + 17\n[1] 22\n&gt; # Resta \n&gt; 10 - 3\n[1] 7\n&gt; # Multiplicación \n&gt; 4 * 6\n[1] 24\n&gt; # División usual \n&gt; 20 / 5\n[1] 4\n&gt; # Potenciación \n&gt; 2^3\n[1] 8\n&gt; # Cociente de la división \n&gt; 10 %/% 3\n[1] 3\n&gt; # Residuo de la división  \n&gt; 10 %% 3\n[1] 1\n\n\nNota: R usa un punto (\\(\\cdot\\)), como separador decimal. Es importante tener esto en cuenta para evitar confusiones y errores innecesarios. Veamoslo:\n\n\n&gt; 2,25 + 2.45\nError: inesperado ',' en \"2,\"\n\n\nPrecedencia de operaciones y usos de parentesis\n\n\nTabla y notas sobre presedencia de operaciones…\n\n\nFunciones matemáticas ususales\n\n\nRevisaremos como se llaman y se operan algunas funciones matemáticas presentes en R por defecto.\n\n\nArgumentos de funciones\n\n\nArgumentos de funciones, seno, logaritmosss\n\n\nNotación cientifica en R y funciones de redondeo: round(), trunc(), floor(), ceiling(). \n\n\nSobre notación cientifica\n\nQue es notación cientifica…\n\nDependiendo el contexto de\n\nTabla de funciones… Sobre el nonbre se variables Remover variables de memoria\n\n\nFunciones y variables en R: Definición y usos. \n\n\n\nVariables\n\n\nLas variables como su nombre lo dice son simplemente variables, en R estas corresponderan a nombres de objetos (números, vectores, matrices, funciones, listas, tablas, arrays…) que guardan algún valor, estas iran variando de acuerdo a las asignaciones que se le hagan sobre la marcha. Esto será muy util a la hora de hacer algún script para solucionar una tarea o problema.\n\n\nEn otras palabras, una variable es el nombre que le damos un objeto que guarda un valor de un dato y con el cual haremos referencia a este para operar dentro del entorno\n\n\nVeamos las diferentes formas de definir variables en R:\n\n\nvar &lt;- valor\nvalor -&gt; var\nvar = valor\n\n\nNota: el operador de asignación por defecto que utilizaremos sera  &lt;- , i.e.,  Var &lt;- valor \n\n\nDefinición de funciones:\n\n\nnombre_funcion &lt;- function(var1,var2,...,varn){definición y estructura}\n\n\nSobre los nombres de funciones y variables:\n\nLos nombres tanto de variables como de funciones deben empezar por una letra o un punto (no se admiten letras o caracteres), ademas los símbolos/carácteres permitidos para comformar estos serán:\n\n\nLetras: mayúsculas, minúsculas, acentos (se recomienda no utilizar).\n\n\nDigitos:0,1,2,. . .,9\n\n\nCaracteres: . y _\n\n\n\nRemoviendo/eliminado objetos en memoria: funciones y variables:\n\n\nPara borrar un objeto particilar presente en memoria, usamos el comando rm()\n\n\nEjemplo de función: La raíz n-ésima de un número real\n\n\nraiz_n_esima &lt;- function(x,y){if(x &gt;0){x^(1/y)}\n                              else if(x==0){print(\"Es uno\")}\n                              else{print(\"Su numero es menor a cero\")}}\n\nPara una definición de la raíz \\(n-\\text{ésima}\\) de un número real positivo \\(\\mathbb{R}^{+}\\), como una función del conjunto de los números reales positivo \\(\\mathbb{R}^{+}\\), en los complejos \\(\\mathbb{C}^{}\\), es decir \\(f:\\mathbb{R}^{+} \\rightarrow \\mathbb{C}\\)\nAsí, para un número real \\(x \\in \\mathbb{R}^{+}\\) y un exponente entero positivo \\(n \\in \\mathbb{N}^{+}\\):\n\\[\nf(x) =\n\\begin{cases}\n\\text{El único número complejo } z \\text{ tal que } z^n = x & \\text{si } x \\geq 0 \\\\\n\\text{No está definido} & \\text{si } x &lt; 0 \\\\\n\\end{cases}\n\\]\n\nSi \\(x\\) es negativo: En el conjunto de los números complejos, la raíz n-ésima de \\(x\\) puede ser definida como un conjunto de \\(n\\) números complejos distintos \\(z_k\\) para \\(k = 0, 1, 2, ..., n-1\\), donde \\(z_{k} = r_{k} \\cdot e^{i\\theta_{k}}\\), con \\(r_{k} = \\sqrt[n]{|x|}\\) y \\(\\theta_{k} = \\frac{\\arg(x) + 2\\pi k}{n}\\), para \\(k = 0, 1, 2,\\ldots, n-1\\), siendo \\(\\arg(x)\\) el argumento principal de \\(x\\).\n\n\\[\nf(x) =\n\\begin{cases}\n\\{ z_0, z_1, z_2, ..., z_{n-1} \\} & \\text{si } x &lt; 0 \\\\\n\\end{cases}\n\\]\nEsta definición se aplica a los números reales negativos.\nLa función raíz \\(n-ésima\\) de un número real a los números complejos se define de la siguiente manera:\nSea \\(f: \\mathbb{R} \\rightarrow \\mathbb{C}\\) una función que asigna a cada número real su raíz n-ésima en el conjunto de los números complejos:\n\\[\nf(x) =\n\\begin{cases}\n\\sqrt[n]{x} & \\text{si } x \\geq 0 \\\\\n\\sqrt[n]{|x|} \\cdot e^{i\\pi} & \\text{si } x &lt; 0 \\\\\n\\end{cases}\n\\]\nDonde \\(e^{i\\pi}\\) es la unidad imaginaria \\(i\\) multiplicada por \\(\\pi\\), que representa un ángulo de \\(\\pi\\) radianes en la forma polar. Esta expresión se obtiene al considerar que la raíz n-ésima de un número negativo en los números complejos se puede escribir como el módulo de ese número multiplicado por \\(e^{i\\pi}\\), lo que representa una rotación de \\(\\pi\\) radianes en el plano complejo.\nEsta función mapea los números reales no negativos en los números complejos de manera directa, mientras que para los números reales negativos, devuelve un número complejo cuyo módulo es la raíz n-ésima del valor absoluto de \\(x\\) y cuyo argumento (ángulo) es \\(\\pi\\).\n\n\n\nEstructura de datos\n\n\n\nLas estructuras de datos son objetos que contienen datos almacenados y organizados de una manera particular. Una estructuras tienen diferentes características, como su dimensión y si son homogeneas o hereterogeneas respecto al tipo de datos que contienen almacenados.\n\n\nLa siguiente imagen contiene las estructuras de datos más comunes en R, junto con su representacion intuitiva de su configuración interna.\n\n\n\n\nEstructuras de datos en R\n\n\n\nParrrafo de texro 2\n\nLa siguiente tabla muestra las principales estructuras de datos que maneja R.\n\nEscalares:\n\nchat\n\nVectores:\n\nchat\n\nMatrices:\n\nchat\n\nParrrafo de texro 3\n\n\nTrabajano con un  dataframe \n\n\nUtilizaremos el conjunto de datos ToothGrowth, este dataframe viene almacenado por defecto en R. Siempre que se este trabajando con datos es importante conocer el contexto en el que los datos fueron registrados y sus fines, o al menos que tipo de datos tenemos.\n\n\nDescripción:  El dataframe contine la respuesta es la longitud de los odontoblastos (células responsables del crecimiento de los dientes) en 60 cobayas/cuyes. Cada animal recibió uno de los tres niveles de dosis de vitamina C  (0,5, 1 y 2 mg/día) mediante uno de dos métodos de administración: jugo de naranja o ácido ascórbico (una forma de vitamina C codificada como VC). El tamaño del conjunto de datos es de 60 observaciones sobre 3 variables.\n\n[,1] len numérico Longitud del diente [,2] supp factor Tipo de suplemento (VC o DO). [,3] dose numérico Dosis en miligramos/día\n\nPara conocer el contenido y estructura de una variable almacenada en R, existen algunas funcion definidas por defencto. Las mas usuales son:  str(), class(), head().\n\n\nhead(ToothGrowth)\n\n   len supp dose\n1  4.2   VC  0.5\n2 11.5   VC  0.5\n3  7.3   VC  0.5\n4  5.8   VC  0.5\n5  6.4   VC  0.5\n6 10.0   VC  0.5\n\nrequire(graphics)\ncoplot(len ~ dose | supp, data = ToothGrowth, panel = panel.smooth,\n       xlab = \"Datos de crecimiento de diente : longitud vs dosis, dado el tipo de suplemento VC/OJ\")\n\n\n\n\n\n\n\n\n\nUn modelo clásico de estadística: regresión lineal\n\n-buscar ejemplo con chat…\n\n\nCargando datos: diferentes fuente y formatos\n\n\nchat\nClaro, vamos a profundizar en la función walk del paquete purrr en R.\n\n\nIntroducción a purrr::walk\nEl paquete purrr es parte del conjunto de paquetes tidyverse y se utiliza para realizar operaciones funcionales de manera eficiente y elegante. Proporciona funciones para trabajar con listas y vectores de una manera más intuitiva que las funciones base de R.\n\n\nFunción walk\nLa función walk en purrr es una función de orden superior utilizada para aplicar una función a cada elemento de una lista o vector de manera que se ejecuten efectos secundarios. Es similar a lapply o sapply en el sentido de que aplica una función a cada elemento de una lista, pero se diferencia en que walk no devuelve nada (o más precisamente, devuelve la lista de entrada invisiblemente). Es útil cuando necesitas aplicar una función que realiza una acción, como imprimir o escribir en un archivo, y no necesitas los resultados.\n\n\nSintaxis\nLa sintaxis básica de walk es:\nwalk(.x, .f, ...)\nDonde:\n\n.x es la lista o vector sobre el cual se va a iterar.\n.f es la función que se aplicará a cada elemento de .x.\n... son argumentos adicionales que se pasan a .f.\n\n\n\nEjemplo con walk\nVeamos un ejemplo simple para entender cómo funciona walk:\nlibrary(purrr)\n\n# Lista de objetos sobre los cuales se va a iterar (nombres, en nuestro ejemplo)\nnombres &lt;- c(\"Lizeth\", \"Daniel\", \"Carlos\")\n\n# Función básica para imprimir un saludo\nsaludar &lt;- function(nombres) {\n  cat(\"Hola\",nombres,\"!\\n\")\n}\n\n# Usando 'walk' para aplicar la función 'saludar' a cada nombre en la lista\nwalk(nombres,saludar)\nAsí, walk aplica la función saludar a cada elemento de la lista nombres y ejecuta el efecto secundario de imprimir un saludo para cada nombre.\n\n\nEjemplo de uso de walk (verificación de paquetes)\nFrecuentemente olvidamos si tenemos o no algunos paquetes instalados, y seriá de utilidad tener una manera rapidad de comprobar y hacer la instalación. Luego utilizaremos walk para iterar sobre una lista de paquetes y verificar si cada uno está instalado, o no lo está. Esta nos permitirá iterar sobre la lista de paquetes de interes y aplicar una función que verifica e instala los paquetes listados sin preocuparnos por los valores de retorno, enfocándonos solo en los efectos secundarios (la instalación de paquetes). Para el ejemplo listaremos paquetes de uso común en análisis de datos, modelado predictivo y procesamiento de texto.\npackages &lt;- c( \n              \"broom\", \"forcats\", \"hcandersenr\", \"janitor\", \"LDAvis\", \"lubridate\", \n              \"magrittr\", \"naivebayes\", \"polite\", \"ranger\", \"rtweet\", \"rvest\", \"sotu\", \n              \"spacyr\", \"stm\", \"stmBrowser\", \"stmCorrViz\", \"textdata\", \"textrecipes\", \n              \"tidymodels\", \"tidytext\", \"topicmodels\", \"tune\", \"wordcloud\", \"workflows\", \n              \"yardstick\"\n              )\n\npurrr::walk(\n            packages, \n            ~{if (!.x %in% installed.packages()[, 1]) install.packages(.x)}\n            )\n\n\nA tener en cuenta en lo anterior:\n\nLista de paquetes: Se define una lista packages con los nombres de los paquetes que deseamos tener disponibles.\nFunción anónima en walk:\n\npurrr::walk(packages, ~{ ... }): walk itera sobre cada elemento en packages.\n~{ ... }: La tilde (~) se usa para definir una función anónima (lambda) en purrr. Es una forma corta de definir una función en línea.\n.x es el argumento implícito que representa el elemento actual de packages durante cada iteración.\nif (!.x %in% installed.packages()[, 1]) install.packages(.x): Para cada paquete .x, verifica si está instalado (.x %in% installed.packages()[, 1]). Si no lo está, lo instala (install.packages(.x)).",
    "crumbs": [
      "RStudio Básico"
    ]
  },
  {
    "objectID": "Trabajos.html",
    "href": "Trabajos.html",
    "title": "Trabajos",
    "section": "",
    "text": "Aca irian varios cuadernos .Rmd .ipynb"
  }
]