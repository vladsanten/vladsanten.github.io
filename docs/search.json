[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Vladimir S√°nchez Tenjo",
    "section": "",
    "text": "Hola gente!\nGracias por visitar mi sitio en internet, estoy animado de conocerte y poder ayudarte en cuestiones estad√≠sticas y de datos. Espero encuentres algo de inter√©s ac√°.\n\n\n\nEducaci√≥n\nPregrado en Estad√≠stica (2023) | Universidad Nacional de Colombia, Sede Bogot√°. Bogot√°, D.C.\n\n\nExperiencia\nEstad√≠stico (May 2024 - Feb 2025) | TransMilenio Bogot√°, D.C.\nInternship (Ene 2023 - Jul 2023) | Refinancia S.A.S. Bogot√°, D.C.\nEstudiante de Investigaci√≥n en Semillero an√°lisis de datos √≥micos (2022 - 2023) | UNAL\n\n\n\nThe two greatest inventions of the human mind are writing and money‚Äîthe common language of intelligence, and the common language of self-interest.\n\n\nVictor Riqueti, Marques de Mirabeau\n\n\n\nThere are two ways to write error-free programs; only the third one works.\n\n\n\nAlan J. Perlis"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Sobre M√≠",
    "section": "",
    "text": "Aprend√≠ a leer a los seis/siete a√±os y desde entonces nunca dej√© de hacerlo. La lectura me ense√±√≥ a acercarme al mundo con curiosidad y a buscar en cada l√≠nea un significado. M√°s adelante, cuando descubr√≠ las matem√°ticas de forma m√°s formal, ocurri√≥ algo parecido: comprend√≠ que era otra manera de leer la realidad, con estructuras, patrones y l√≥gica.\nEsa conexi√≥n me llev√≥ a la estad√≠stica, una disciplina que me permite interpretar datos, contrastar hip√≥tesis y generar conclusiones √∫tiles. Para m√≠, trabajar con datos es una extensi√≥n de esa primera experiencia: leer, comprender y transformar informaci√≥n en conocimiento.\nHoy me interesa especialmente la arquitectura de datos, inteligencia artificial, modelamiento estad√≠stico y el desarrollo de soluciones que unan el an√°lisis estad√≠stico con problemas reales. Creo firmemente que los datos no solo describen el mundo, sino que tambi√©n nos ayudan a tomar mejores decisiones sobre √©l.\n\nFuera de lo estrictamente profesional, me interesa c√≥mo distintas formas de conocimiento se entrelazan. Por ejemplo, en uno de los textos m√°s antiguos de la humanidad, Las mil y una noches, hay un gui√±o matem√°tico escondido: ¬øpor qu√© 1001 y no 1000 o 1002 noches ‚Äòcanto‚Äô Sherazade ?\nEn aquellos tiempos, los sacerdotes matem√°ticos (grandes visires, magos) pose√≠an un poder incre√≠ble, pues pose√≠an los secretos matem√°ticos necesarios para la navegaci√≥n y el comercio, as√≠ como para la contabilidad, la creaci√≥n de calendarios y muchas cosas que hoy damos por sentado. En aquel entonces, por ejemplo, los ciudadanos comunes, y a menudo incluso el rey/gobernante, no sab√≠an sumar, restar, multiplicar ni realizar otros c√°lculos.\nUna forma en que los sacerdotes manten√≠an a la poblaci√≥n en la ignorancia era contando historias elaboradas o enga√±osas para ocultar la verdad y el conocimiento. Una de esas historias era el mito de Sherazade y sus Mil y una Noches.\nLa respuesta est√° en la aritm√©tica. 1001 es un n√∫mero especial porque se descompone como 7 √ó 11 √ó 13, y ese juego de factores se relaciona con la tradici√≥n de considerar algunos n√∫meros como de ‚Äòmala suerte‚Äô. Para m√≠, detalles como este son recordatorios de que tanto la literatura como la matem√°tica son, en el fondo, distintas formas de leer el mundo y de encontrar patrones en √©l‚Ä¶ Este blog es tambi√©n un espacio para compartir esos intereses.\n\n# 1000^1 \n# 1000^2 = 1002001 \n# 1000^3 = 1003003001\n# 1000^4 = 1.004006e+12\n\n## Cada nuevo n√∫mero total contiene un n√∫mero que representa cada potencia.\n## La verdadera importancia de usar el 1001 reside en que permite una especie \n## de abreviatura matem√°tica (recursi√≥n?)"
  },
  {
    "objectID": "Recursos.html",
    "href": "Recursos.html",
    "title": "Recursos",
    "section": "",
    "text": "Descargo de reponsabilidad y consejos de estudiante\n\n\n\nAca va todo es todo lo relacionado ‚Ä¶"
  },
  {
    "objectID": "Recursos2.html",
    "href": "Recursos2.html",
    "title": "Estad√≠stica",
    "section": "",
    "text": "Algunos sitios/canales/enlaces con recursos de temas referentes a mis intereses\n\nLuis Rinc√≥n \n\n El sitio personal (Opci√≥n 1) &lt;a https://sites.google.com/ciencias.unam.mx/luis-rincon‚Äù&gt; El sitio personal (Opci√≥n 2) &lt;a https://www.youtube.com/@LuisRinconUNAM‚Äú&gt; Canal de YouTube\n\nRandom Services \n\nRandom es un sitio web dedicado a la probabilidad, la estad√≠stica matem√°tica y los procesos estoc√°sticos, y est√° destinado a profesores y estudiantes de estas materias.\n\nBOOKDOWN | bookdown.org \n\nEl sitio web bookdown.org es un servicio de RStudio, PBC, para alojar libros.\n\nIntroduction to Data Technologies de Paul Murrell \n\n\nMichael Clark",
    "crumbs": [
      "Recursos de Multimedia"
    ]
  },
  {
    "objectID": "Recursos1.html",
    "href": "Recursos1.html",
    "title": "Libros",
    "section": "",
    "text": "A lo largo de mi formaci√≥n acad√©mica, las matem√°ticas, la estad√≠stica y la computaci√≥n han sido pilares fundamentales. Durante mis estudios reun√≠ una serie de libros y recursos que me ayudaron a comprender mejor estas √°reas (en verdad a√∫n lo hacen) y que, en su momento, marcaron mi aprendizaje.\nEste espacio es una manera sencilla de compartir esas referencias, con la idea de que puedan servirle a otros estudiantes, investigadores o curiosos que est√©n explorando estas disciplinas.\n\nüìò Matem√°ticas\n\n\nCurso matem√°ticas b√°sicas- Margarita Ospina Pulido\nPrec√°lculo ‚Äî R. Larson, R. P. Hostetler\nMatem√°ticas generales √°lgebra, an√°lisis - C. Pisot, M. Zamansky\nCurso de Matem√°ticas B√°sicas ‚Äî M. Ospina\n\nIntroducci√≥n a la Teor√≠a de Conjuntos ‚Äî Lia Oubi√±a\n\nTeor√≠a Intuitiva de los Conjuntos ‚Äî P. Halmos\n\nBook of Proof ‚Äî R. Hammack\nThe Number Systems: Foundations of Algebra and Analysis -S. Feferman\nC√°lculo Diferencial en una Variable ‚Äî H. Due√±as & I. Rubio\n\nIntroducci√≥n al C√°lculo ‚Äî Kazimierz Kuratowski\n\nC√°lculo Diferencial e Integral (Tomo I) ‚Äî N.S. Piskunov\n\n√Ålgebra Lineal y sus Aplicaciones ‚Äî G. Strang\n\nMatrix Algebra Useful for Statistics ‚Äî Searle\n\nCalculus of Vector Functions ‚Äî R. E. Williamson\n\nIntroducci√≥n a la Teor√≠a de Probabilidades y sus Aplicaciones ‚Äî W. Feller\n\nProbabilidad ‚Äî L. Blanco\n\nCurso Intermedio de Probabilidad ‚Äî L. Rinc√≥n\n\nIntroducci√≥n a los Procesos Estoc√°sticos ‚Äî L. Rinc√≥n\n\nProblemas de Ecuaciones Diferenciales Ordinarias ‚Äî G. N. Kiselev\n\nEcuaciones Diferenciales ‚Äî Kreider, Kuller & Ostberg\n\n\nüìä Estad√≠stica\n\n\nIntroducci√≥n a la Estad√≠stica Inferencial - L. Rinc√≥n\n\nStatistical Inference - G. Casella\n\nAn√°lisis Multivariante de Datos - D. Pe√±a\n\nAn√°lisis de Series Temporales - D. Pe√±a\n\nSampling and Estimation from Finite Populations ‚Äî Yves Till√©\n\nStatistical Quality Control - D. Montgomery\n\nDesign and Analysis of Experiments ‚Äî D. Montgomery\n\nHands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow ‚Äî Aur√©lien G√©ron\n\nAn Introduction to Statistical Learning ‚Äî T. Hastie, R. Tibshirani et al.¬†\n\n\nüíª Computaci√≥n\n\n\nFundamentos de dise√±o de bases de datos - A. Silberschatz, H. F. Korth, S. Sudarshan\nIntroduction to Algorithms - Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest & Clifford Stein\n\nStructure and Interpretation of Computer Programs - Harold Abelson & Gerald Jay Sussman\n\nArtificial Intelligence: A Modern Approach - Stuart Russell & Peter Norvig\nThe Art of Computer Programming - Donald Knuth\nMachine Learning - Tom M. Mitchell\nDatabase System Concepts - A.Silberschatz, H.F. Korth ,S. Sudarshan\nHow to Design Programs - M.Felleisen, R. B. Findler, M. Flatt, S. Krishnamurthi",
    "crumbs": [
      "Libros de Texto"
    ]
  },
  {
    "objectID": "Recursos3.html",
    "href": "Recursos3.html",
    "title": "Computaci√≥n",
    "section": "",
    "text": "Ac√° va lo de Computaci√≥n\n\nProbabilidad Nivel I",
    "crumbs": [
      "Otros"
    ]
  },
  {
    "objectID": "Series_Tesuvr.html",
    "href": "Series_Tesuvr.html",
    "title": "Series de tiempo univariadas: An√°lisis descriptivo",
    "section": "",
    "text": "Inflaci√≥n total de Colombia (Variaci√≥n anual)\n\nIntroduci√≥n\nEn econom√≠a es habitual el inter√©s sobre el ritmo al que los precios de los bienes y servicios de consumo cambian de un periodo a otro, tales cambios afectan el poder adquisitivo real de los ingresos de los consumidores y su bienestar. Debido a que no todos los precios de los distintos bienes y servicios cambian en la misma proporci√≥n, un √≠ndice de precios que sintetice los cambios en los precios en una canasta lo suficientemente general es el √çndice de Precios al Consumidor (IPC).\nLos IPC son estad√≠sticas oficiales com√∫nmente producidas por las oficinas nacionales de estad√≠stica, los ministerios de trabajo o los bancos centrales, en Colombia la operaci√≥n estad√≠stica est√° a cargo del Departamento Administrativo Nacional de Estad√≠stica (DANE). Cuando existe un aumento generalizado y sostenido de los precios de los bienes y servicios m√°s representativos del consumo de los hogares de un pa√≠s se dice que se experimenta inflaci√≥n.\nEsta tasa de cambio constituye un indicador general de la inflaci√≥n total, por lo tanto, tiene un papel clave para la toma de decisiones en pol√≠tica monetaria, la definici√≥n de la variaci√≥n en los salarios, el ajuste de estados financieros, la resoluci√≥n de procesos jur√≠dicos, para calcular la p√©rdida de poder adquisitivo de la moneda, como uno de los indicadores usados para estimar los equilibrios en partidas de Cuentas Nacionales y como factor de an√°lisis del comportamiento coyuntural de la econom√≠a.\nPara este estudio, el inter√©s se centra en el an√°lisis descriptivo de la inflaci√≥n total mensual como variaci√≥n anual, en otras palabras, el cambio porcentual de los precios al consumidor IPC de un mes (o periodo) frente al mismo periodo doce (12) meses antes. El periodo de an√°lisis de los datos recopilados inicia desde el 31 de enero del 2000 hasta el 31 de julio de 2022, con 271 registros.\nAhora gr√°ficamos la serie de tiempo para identificar posibles caracteristicas o patrones de comportamiento del fen√≥meno de la inflaci√≥n.\n\n\n\n\n\n\n\n\n\nEl gr√°fico anterior permite apreciar la dinamica del comportamiento de la inflaci√≥n total mensual medida como variaci√≥n anual para Colombia en los periodos del 31 de enero de 2000 hasta el 31 de julio de 2022. Esta serie presenta tres periodos de tendencia decreciente, a saber, el periodo de aproximadamente seis a√±os que comprende de mayo del 2000 hasta junio de 2006, donde la inflaci√≥n decreci√≥ aproximadamente 6.1 puntos porcentuales de 10% a 3.9%, esto posiblemente asociado con una rapida recuperaci√≥n de Colombia de la crisis de 1999 en donde el producto interno bruto decreci√≥ en 4% siendo el peor registro en la historia colombiana y uno de los mayores registros de inflaci√≥n con 10% para los a√±os inmediatamente posteriores. Por otro lado, el periodo que comprende entre octubre del 2008 hasta marzo de 2010, donde la inflaci√≥n comparada contra el a√±o inmediatamente anterior disminuy√≥ 6.1 puntos porcentuales de un 7.93% a 1.83%, dado como resultado de la crisis financiera internacional y resultados positivos en el comercio interno que beneficiaron a pa√≠s disminuyendo el impacto en la tasa representativa del mercado frente al dolar. El ultimo periodo de descenso abarca desde agosto de 2016 a febrero de 2019 el cual disminuy√≥ un auge de inflaci√≥n en aproximadamente 5.7 puntos porcentuales de 8.96% a 3.24%, asociado con el fin de negociaciones en un paro campesino de 2016 y la realizaci√≥n del acuerdo de paz entre grupos insurgentes que result√≥ en una mayor confianza inversionista y un crecimiento en la inversi√≥n extranjera a proyectos de largo aliento dentro del pa√≠s.\nPor otro lado, historicamente la inflaci√≥n para estos periodos presenta 4 eventos que contribuyeron al aumento m√°s que proporcional en rapidos periodos que se asocian con crisis economicas en 1999, crisis del mercado de capitales en 2008 a 2010, factores en las cadenas de producci√≥n y protestas sociales para 2016 y finalmente la pandemia de Sars-Cov-2 en 2020. Entre estos periodos podemos apreciar crecimiento en el nivel deprecios en los auges hasta una cima que estan acotadas por un valor maximo de 10.2% que se registr√≥ en julio de 2022.\nCaracteristicas de la serie de inflaci√≥n total\n\nLa serie presenta una varianza marginal que var√≠a a lo largo del tiempo, esto a raz√≥n de que la serie parece tener un rango de valores diferente a lo largo del tiempo iniciando en un registro de 8.5%, tomando su valor m√≠nimo en 1.61% y retomando su valor final y maximo en el periodo de estudio en 10.2%. De esta serie se puede percibir que la volatilidad a lo largo del tiempo aumenta de manera monotona, en otras palabras el rango en donde fluctuan los valores aumenta mientras el tiempo transcurre. Por lo tanto, se podr√≠a decir que la varianza marginal de la serie no es independiente del tiempo, se suguiere trabajar con una transformaci√≥n de potencia para estabilizar la varianza de la serie v√≠a Box-Cox.\nA simple vista, la inflaci√≥n en el periodo de estudio no cambia sus valores a lo largo del tiempo alrededor de un unico nivel, es decir, su valor promedio no es independiente del tiempo para el periodo de analisis de este estudio, por lo tanto presenta un componente tendencial o nivel de la serie dependiente del periodo de tiempo. Asimismo, se puede apreciar el parecido de la serie con una caminata aleatoria que inicia en 8.24% de inflaci√≥n.\nExiste presencia de una componente c√≠clica (estacional o no estacional) que puede percibirse cada 30 y 54 meses lo cual puede dar luz sobre componentes de ciclos economicos largos en la serie, esto tambi√©n puede implicar que la media del proceso no sea constante y que se enmascare en presencia de tendencia.\n\nDe acuerdo, a las caracteristicas que presenta la serie se procede a realizar la transformaci√≥n Box-Cox, se suguiere transformarla serie con un valor de lamda equivalente a 0.812 de tal manera que la serie se estabilice en varianza a lo largo del tiempo. De la misma forma se puede comparar en cambio en escala de medidas de la serie con varianza estabilizada, el m√©todo utilizado fue la aproximaci√≥n de Guerrero para llegar a este valor, sin embargo, los valores de la serie pierden interpretabilidad.\n\n\n\n\n\n\n\n\n\n[1] 0.9918422\n\n\nAdemas, inmediatamente a la transformaci√≥n de Box-Cox se realizan las estimaciones muestrales de las autocorrelaciones simples y parciales (FAS) y (FAP), en donde se puede observar que la FAS muestra un decaimiento lento que indica que la serie presenta tendencia que se consider√≥ estocastica, sin embargo la serie no presenta un comportamiento repetitivo en una periodicidad a simple vista, luego no se puede afirmar que exista un componente estacional o periodico deterministico. Finalmente, se realiza sobre la serie transformada una busqueda de otro lamda de transfomaci√≥n para asegurar que la transformaci√≥n es apropiada y sugiere un lamda que asciende a 0.9918422, que es practicamente 1.\nAn√°lisis de tendencia o nivel de la serie\nLa inflaci√≥n en el periodo de estudio no cambia sus valores a lo largo del tiempo alrededor de un unico nivel, es decir, su valor promedio no es independiente del tiempo para el periodo de analisis de este estudio, por lo tanto presenta un componente tendencial o nivel de la serie dependiente del periodo de tiempo.\nAsimismo, se puede apreciar el parecido de la serie con una caminata aleatoria que inicia en 8.24% de inflaci√≥n y que la tendencia existente en los registros no obedece a una funcion matematica exacta, luego se puede considerar una tendencia estocastica. Bajo un enfoque descriptivo se procede a contrastar la estimaci√≥n de la tendencia v√≠a estimaci√≥n polin√≥mica local (LOESS), a continuaci√≥n, se presentan 4 gr√°ficas que evidencian la estimaci√≥n de la tendencia.\n\n\n\n\n\n\n\n\n\nSe puede apreciar en la gr√°fica superior izquiera que la estimaci√≥n de la tendencia que considera una ventana del 75% de los datos (aproximadamente 204 meses) se√±ala la existencia de una tendencia decreciente en la primera decada del periodo de estudio, para posteriormente cambiar su pendiente y crecer lentamente durante la segunda decada de manera suave. Para la gr√°fica superior derecha, se puede evidenciar que la estimaci√≥n de la tendencia que considera una ventana del 35% de los datos (aproximadamente 95 meses) dentro de las 2 decadas del estudio presentan periodos en donde la inflaci√≥n alcanza un valle y posteriormente tiene un auge que en ambas decadas es cercano al 7%. Asimismo, la transici√≥n hacia la gr√°fica inferior izquierda muestra la estimaci√≥n de la tendencia que considera una ventana del 20% de los datos (aproximadamente 204 meses) que presenta posibles ciclos de 2 a 3 a√±os dentro de cada decada que pueden verse enmascarados por la tendencia pero que con una ventana de menos observaciones se puede sospechar de posibles ciclos no periodicos (no necesariamente de duraci√≥n constante). Finalmente, en la gr√°fica inferior derecha se observa la estimaci√≥n de la tendencia que considera una ventana del 8% de los datos (aproximadamente 24 meses) presenta posibles ciclos de 2,5 a√±os dentro de cada decada que pueden verse enmascarados por la tendencia pero que con una ventana de menos observaciones se puede sospechar de posibles ciclos no periodicos\nSustracci√≥n de la tendencia estimada\nUna vez estimada la tendencia a traves de una aproximaci√≥n no parametrica por polinomios locales, se procede a eliminar la estimaci√≥n de la serie con la varianza estabilizada. Es decir, una manera de asegurar que la tendencia estimada es la correcta se observa el resultado del valor real de la serie frente a su tendencia y finalmente este resultado no debe poseer tendencia. Este componente sin tendencia tiene un papel clave para identificar y determinar patrones, comportamientos y ciclos dentro de la serie que posiblemente se enmascaraban con la tendencia.\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n\nLas gr√°ficas anteriores permiten contrastar el metodo de eliminaci√≥n de tendencia por polinomios locales frente a la metodologia Box-Jenkins, con el objetivo de detectar estabilidad en el valor promedio y una varianza constante a lo largo del periodo de tiempo. Asimimo, se puede apreciar ambas metodolog√≠as producen una serie que estable en media pero que a simple vista no parece muy constante en varianza, es decir, ambas series presentan una volatilidad que subjetivamente generan dudas sobre la estacionariedad de la serie, esto puede ser generado por un componente estacional o ciclio que no es capturado por la tendencia v√≠a LOESS o diferenciando la serie.\nAn√°lisis de estacionalidad\nMediante la suposici√≥n clasica de un modelo aditivo vemos presencia de tendencia, pero no se identifica un componente estacional que contraste a simple vista. Por otro lado, se realiza una busqueda de componentes que muestren estacionalidad usando medidas descriptivas como herramientas para detecci√≥n de este fenomeno en distintos periodos del tiempo. En primera instancia, se realiza un gr√°fico de suberies para enfatizar los patrones estacionales es aquel en el que los datos de cada estaci√≥n se recogen juntos en mini gr√°ficos temporales separados.\n\n\n\n\n\n\n\n\n\nLas l√≠neas azules horizontales indican las medias de cada mes, se puede observar que no existen medias que se ubiquen en valores extremos. Este tipo de gr√°fico permite ver claramente el patr√≥n estacional subyacente y tambi√©n muestra los cambios en la estacionalidad a lo largo del tiempo, en este caso no se evidencia a simple vista un componente estacional. En este ejemplo, el gr√°fico no es especialmente revelador.\n\nUn gr√°fico para promedios agrupando por meses‚Ä¶\n\n\n\n\n\n\n\n\nUn gr√°fico para promedios agrupando por meses y desv\n\n\nExploraci√≥n de multiples estacionalidades (ciclos estacionales?)\n\n\n\n'data.frame':   271 obs. of  2 variables:\n $ infla: num  -0.901 -0.423 0.173 0.372 0.455 ...\n $ Fecha: Date, format: \"2000-01-31\" \"2000-02-29\" ...\n\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nDe manera individual‚Ä¶\n\n\n\n\n\n\n\n\n\n\nPuede usar el argumento period=12 y da el mismo resultado, lo que significa es que se pueden agrupar las observaciones que est√°n cada 12.\n\n\nGr√°ficos de densidades para explorar la estacionalidad.\n\nA\n\n\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous.\n\n\n\n\n\n\n\n\n\n\n\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous.\n\n\n\n\n\n\n\n\n\nNo parece haber patr√≥n estacional en la serie, puesto que las funciones de densidad estan superpuestas entre si y por tanto los valores medios de la inflaci√≥n parecen tener valores que no depende del mes. Por otro lado, podemos observar que el comportamiento en varianza tampoco es estacional.\nAhora repetimos el procedimiento pero eliminando previamente la tendencia de la serie Inflaci√≥n\nPara este gr√°fico observamos que las colas de las densidades de distribuci√≥n estimadas son mas cortas.\nPueden hacer lo mismo pero en vez de quitar la tendencia, hacemos una diferenciaci√≥n\nAhora un gr√°fico de lineas\nProcedemos a extraer las subseries por a√±os. Para identificar posibles comportamientos que permitan describir el comportamiento de la Inflaci√≥n\nAn√°lisis de Rezagos\nDiagrama de dispersi√≥n de las observaciones originales con sus respectivos retardos‚Ä¶\n\n\n\n\n\n\n\n\n\nA color\n\nObservando la figura enterior de concluye que las relaciones de la variable original con los primeros 4 resagos presenta son fuertes y positivas (\\(\\rho&gt; 0.8\\)) y para los resagos m√°s lejanos ttata‚Ä¶ lo que significa que los valores inmediados anteriores afectan de manera directo y fenom√©no con memoria\n\nTomando cuatrenios (Rezagos estacionales) (por rehacer)\n\n\n\n\n\n\n\n\nAn√°lisis del ACF y AMI muestral\n\n\nVersi√≥n interractiva:\n\n\n\n\n\n\nPor otro lado para el AMI\n\n\n\n\n\n\n\n\n\n\n\nAn√°lisis de Ciclos y  Estacionalidades \n\n\n\nDel gr√°fico vemos que el flujo de calor de la Inflaci√≥n para Colombia ocurre de manera vertical indicando la dispocici√≥n del ciclo. En color oscuro se marca los los picos de dicho ciclo. Adem√°s esto podr√≠a sugerir que el comportamiento de tal ciclo no es estacional.\n\n\nAn√°lisis de ciclos y estacionalidad utilizando el periodograma:\n\nPara detectar el componente de estacionalidad y de ciclicidad se har√° uso del periodograma:‚Ä¶\n\nCon el formato formato base\n\n\nCon el  formato mvspec\n\n\n\n[1] \"El valor de la frecuencia donde se m√°ximiza el periodograma para z1 es: 0.541666666666667\"\n\n\n[1] \"El valor de la frecuencia donde se alcanza el segundo m√°ximo para el periodograma para REC es: 0.375\"\n\n\n[1] \"El valor de la frecuencia donde se alcanza el tercer m√°ximo para el periodograma para REC es: 0.75\"\n\n\n\n\n\n\n\n\n\n###residuos dos\n\n\n\n\n\n\n\n\n\nM√©todos de predicci√≥n\nMetodolog√≠a de suavizamiento exponencial\n\n\nWarning: `data_frame()` was deprecated in tibble 1.1.0.\n‚Ñπ Please use `tibble()` instead.\n\n\n\n\n\n\n\n\n\n\n\n                      ME      RMSE      MAE         MPE      MAPE      MASE\nTraining set  0.09006216 0.8090687 0.599161   -3.039447  28.14596 0.5910791\nTest set     -4.43578479 5.4735750 4.860388 -314.839799 322.85061 4.7948270\n                  ACF1 Theil's U\nTraining set 0.9467384        NA\nTest set     0.9764721  27.37423\n\n\n                     ME      RMSE       MAE        MPE     MAPE      MASE\nTraining set -0.0869448 0.6762059 0.5202551  -9.475969 23.57609 0.5132375\nTest set     -0.1857017 1.6579692 1.4010652 -60.886943 83.40865 1.3821665\n                  ACF1 Theil's U\nTraining set 0.9232893        NA\nTest set     0.9415096  7.300588\n\n\n\n\n\n\n\n\n\nModelo con todo menos 5\n\nz3_com &lt;- window(z3, end = c(2022,2))\nz3_r&lt;-window(z3, start = c(2022,3))\n\n\nhw.expo_com &lt;- ets(z3_com, \"AAN\",damped = T)\nholt.com &lt;- forecast(hw.expo_com, h = 5)\nsprintf(\"El RMSE para el modelo de Holt con damped es de %f \", accuracy(holt.com, z3_r)[2,2])\n\n[1] \"El RMSE para el modelo de Holt con damped es de 0.388826 \"\n\np&lt;-hw.expo_com %&gt;%\n  forecast(h = 5) %&gt;%\n  autoplot()+ autolayer(z3_r)+\n  labs(title = \"Australian food expenditure\",\n       y = \"$ (billions)\")\np\n\n\n\n\n\n\n\n\n\ncheckresiduals(hw.expo_com)\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ETS(A,Ad,N)\nQ* = 68.526, df = 24, p-value = 3.647e-06\n\nModel df: 0.   Total lags used: 24\n\n\n\n##Z1 Y Z3  SON LA SERIE VARIANZA ESTABILIZADA Y OBJETO TS\n##Z2 ES LA SERIE SIN TENDENCIA \n##tsibble_infla1[,\"infdif\"] ES LA SERIE PERO SIN INDICES",
    "crumbs": [
      "Test UVR"
    ]
  },
  {
    "objectID": "Trabajos.html",
    "href": "Trabajos.html",
    "title": "Trabajos",
    "section": "",
    "text": "Aca irian varios cuadernos .Rmd .ipynb"
  },
  {
    "objectID": "R_Tutorial_01.html",
    "href": "R_Tutorial_01.html",
    "title": "Back to Basics R",
    "section": "",
    "text": "Primer acercamiento a R\n\nEste es un tutorial b√°sico de R. Si ya sabes algo de R no creo que encuentres mucho ac√°. Las expresiones, sentencias y procedimientos mostrados se ejecutaron en el IDE de RStudio\n\n\nNota: En programaci√≥n, una sentencia y una expresi√≥n son conceptos diferentes:\n\nExpresi√≥n: Es una combinaci√≥n de valores, variables y operadores que da como resultado un valor √∫nico. Las expresiones en la mayor√≠a de los lenguajes de programaci√≥n pueden ser simples (como 3 + 5) o m√°s complejas (como 2 * (3 + 5)). En R, un ejemplo de expresi√≥n podr√≠a ser:\n\n\nresultado &lt;- sqrt(3) + 5\n\nEn esta expresi√≥n, sqrt(3) + 5 es la parte que produce el valor, y luego ese valor puede ser asignado a la variable, e.g., resultado.\n\nSentencia: Es una unidad de c√≥digo que realiza una acci√≥n espec√≠fica. Una sentencia en un lenguaje de programaci√≥n generalmente realiza una tarea, como asignar un valor a una variable, llamar a una funci√≥n, o realizar una operaci√≥n de control de flujo (como una instrucci√≥n if o un bucle for). En R, una sentencia simple podr√≠a ser:\n\n\nresultado &lt;- sqrt(3) + 5\n\nEsta l√≠nea de c√≥digo es tanto una expresi√≥n como una sentencia. Es una sentencia porque realiza la acci√≥n de asignar el resultado de sqrt(3) + 5 a la variable resultado, y es una expresi√≥n porque la expresi√≥n sqrt(3) + 5 produce un valor que se asigna a resultado.\nObserve que, todas las expresiones son sentencias, pero no todas las sentencias son expresiones. Las expresiones producen valores, mientras que las sentencias realizan acciones en el programa.\n\n\nLo cl√°sico\n\n\n\n\nHistoria patria: Inicios y una anecdota‚Ä¶\n\n\nSobre la instalaci√≥n: Para seguir este tutorial debe tener instalado tanto R (programa que hace el trabajo sucio, c√°lculos y demas), como RStudio ( un entorno de trabajo que permite interactuar con el leguaje de manera mas eficiente e intuitiva). Para esto sugiero los siguientes tutoriales que resultan facil de seguir.\n\n\nSobre la instalaci√≥n: Explorando RStudio, conociendo los paneles de trabajo: Consola, Editor, Panel de entornos, y Panel de vista. Estos dos √∫ltimos iran tomando sentido y la importancia que merecen a medida que se avance en el conocimiento de lo que es R. Nota: En un inicio lo mas importante es saber los usos de la Consola, scripts ( Editor) y la fuci√≥n de ayuda (en la pesta√±a de Help) en el Panel Vista\n\nLa magia de R: Programaci√≥n de objetos\n\n\n Instalando paquetes: Para usar un paquete en R debemos hacer dos cosas, instalar el paquete (solo se hace una vez, por el momento) install.packages() y cargarlo  library(), esto ultimo cada vez que se use en una sesi√≥n\n\n\nAcontinuaci√≥n se muestra como hacerlo digitando c√≥digo:\n\n# El nombre del paquete a instalar, siempre entre comillas\ninstall.packages('nombre_paquete')\n# Suponiendo que se ha instalado, lo cargamos y no deberia generar error\nlibrary(nombre_paquete)\n\n\nConsejo profesional (No lo soy, pero igual): Por m√°s peque√±o que sea en lo que estes trabajando, siempre siempre crea un proyecto y luego crea internamente tus documentos para trabajar sobre estos.\n\n\n\nR Como C√°lculadora (algo original :V)\n\n\nComo en todo lenguaje de programaci√≥n, es usual empezar a interactuar con este en forma de calculadora, y lo haremos con R. A continuaci√≥n se listan las operaciones m√°s basicas (su s√≠mbolo, descripci√≥n y ejemplo junto con su salida), las cuales bastaran para nuestro fin.\n\n\n\n\n\nS√≠mbolo\n\n\nDescripci√≥n\n\n\nEjemplo\n\n\nSalida\n\n\n\n\n+\n\n\nOperador binario para sumar\n\n\n5 + 17\n\n\n 22\n\n\n\n\n-\n\n\nOperador binario para restar\n\n\n10 - 3\n\n\n7\n\n\n\n\n*\n\n\nOperador binario para multiplicar\n\n\n4 * 6\n\n\n 24\n\n\n\n\n/\n\n\nOperador binario para dividir\n\n\n20 / 5\n\n\n 4\n\n\n\n\n^\n\n\nOperador binario para potencia\n\n\n2^3\n\n\n 8\n\n\n\n\n%/%\n\n\nOperador binario para obtener el cociente en una divisi√≥n (n√∫mero entero)\n\n\n10%/%3 \n\n\n 3\n\n\n\n\n%%\n\n\nOperador binario para obtener el residuo en una divisi√≥n\n\n\n10 %% 3\n\n\n 1\n\n\n\n\nAhora vamos a R, ac√° se supone que las expresiones estan siendo ingresadas en consola, poe el momento. Importante para evaluar una expresi√≥n se ingrasa en la consola y damos enter (). As√≠ las cosas para la primera expresi√≥n a continuaci√≥n tenemos: ‚Äò5 + 17‚Äô + (enter)\n\n\n&gt; # Suma  \n&gt; 5 + 17\n[1] 22\n&gt; # Resta \n&gt; 10 - 3\n[1] 7\n&gt; # Multiplicaci√≥n \n&gt; 4 * 6\n[1] 24\n&gt; # Divisi√≥n usual \n&gt; 20 / 5\n[1] 4\n&gt; # Potenciaci√≥n \n&gt; 2^3\n[1] 8\n&gt; # Cociente de la divisi√≥n \n&gt; 10 %/% 3\n[1] 3\n&gt; # Residuo de la divisi√≥n  \n&gt; 10 %% 3\n[1] 1\n\n\nNota: R usa un punto (\\(\\cdot\\)), como separador decimal. Es importante tener esto en cuenta para evitar confusiones y errores innecesarios. Veamoslo:\n\n\n&gt; 2,25 + 2.45\nError: inesperado ',' en \"2,\"\n\n\nPrecedencia de operaciones y usos de parentesis\n\n\nTabla y notas sobre presedencia de operaciones‚Ä¶\n\n\nFunciones matem√°ticas ususales\n\n\nRevisaremos como se llaman y se operan algunas funciones matem√°ticas presentes en R por defecto.\n\n\nArgumentos de funciones\n\n\nArgumentos de funciones, seno, logaritmosss\n\n\nNotaci√≥n cientifica en R y funciones de redondeo: round(), trunc(), floor(), ceiling(). \n\n\nSobre notaci√≥n cientifica\n\nQue es notaci√≥n cientifica‚Ä¶\n\nDependiendo el contexto de\n\nTabla de funciones‚Ä¶ Sobre el nonbre se variables Remover variables de memoria\n\n\nFunciones y variables en R: Definici√≥n y usos. \n\n\n\nVariables\n\n\nLas variables como su nombre lo dice son simplemente variables, en R estas corresponderan a nombres de objetos (n√∫meros, vectores, matrices, funciones, listas, tablas, arrays‚Ä¶) que guardan alg√∫n valor, estas iran variando de acuerdo a las asignaciones que se le hagan sobre la marcha. Esto ser√° muy util a la hora de hacer alg√∫n script para solucionar una tarea o problema.\n\n\nEn otras palabras, una variable es el nombre que le damos un objeto que guarda un valor de un dato y con el cual haremos referencia a este para operar dentro del entorno\n\n\nVeamos las diferentes formas de definir variables en R:\n\n\nvar &lt;- valor\nvalor -&gt; var\nvar = valor\n\n\nNota: el operador de asignaci√≥n por defecto que utilizaremos sera  &lt;- , i.e.,  Var &lt;- valor \n\n\nDefinici√≥n de funciones:\n\n\nnombre_funcion &lt;- function(var1,var2,...,varn){definici√≥n y estructura}\n\n\nSobre los nombres de funciones y variables:\n\nLos nombres tanto de variables como de funciones deben empezar por una letra o un punto (no se admiten letras o caracteres), ademas los s√≠mbolos/car√°cteres permitidos para comformar estos ser√°n:\n\n\nLetras: may√∫sculas, min√∫sculas, acentos (se recomienda no utilizar).\n\n\nDigitos:0,1,2,. . .,9\n\n\nCaracteres: . y _\n\n\n\nRemoviendo/eliminado objetos en memoria: funciones y variables:\n\n\nPara borrar un objeto particilar presente en memoria, usamos el comando rm()\n\n\nEjemplo de funci√≥n: La ra√≠z n-√©sima de un n√∫mero real\n\n\nraiz_n_esima &lt;- function(x,y){if(x &gt;0){x^(1/y)}\n                              else if(x==0){print(\"Es uno\")}\n                              else{print(\"Su numero es menor a cero\")}}\n\nPara una definici√≥n de la ra√≠z \\(n-\\text{√©sima}\\) de un n√∫mero real positivo \\(\\mathbb{R}^{+}\\), como una funci√≥n del conjunto de los n√∫meros reales positivo \\(\\mathbb{R}^{+}\\), en los complejos \\(\\mathbb{C}^{}\\), es decir \\(f:\\mathbb{R}^{+} \\rightarrow \\mathbb{C}\\)\nAs√≠, para un n√∫mero real \\(x \\in \\mathbb{R}^{+}\\) y un exponente entero positivo \\(n \\in \\mathbb{N}^{+}\\):\n\\[\nf(x) =\n\\begin{cases}\n\\text{El √∫nico n√∫mero complejo } z \\text{ tal que } z^n = x & \\text{si } x \\geq 0 \\\\\n\\text{No est√° definido} & \\text{si } x &lt; 0 \\\\\n\\end{cases}\n\\]\n\nSi \\(x\\) es negativo: En el conjunto de los n√∫meros complejos, la ra√≠z n-√©sima de \\(x\\) puede ser definida como un conjunto de \\(n\\) n√∫meros complejos distintos \\(z_k\\) para \\(k = 0, 1, 2, ..., n-1\\), donde \\(z_{k} = r_{k} \\cdot e^{i\\theta_{k}}\\), con \\(r_{k} = \\sqrt[n]{|x|}\\) y \\(\\theta_{k} = \\frac{\\arg(x) + 2\\pi k}{n}\\), para \\(k = 0, 1, 2,\\ldots, n-1\\), siendo \\(\\arg(x)\\) el argumento principal de \\(x\\).\n\n\\[\nf(x) =\n\\begin{cases}\n\\{ z_0, z_1, z_2, ..., z_{n-1} \\} & \\text{si } x &lt; 0 \\\\\n\\end{cases}\n\\]\nEsta definici√≥n se aplica a los n√∫meros reales negativos.\nLa funci√≥n ra√≠z \\(n-√©sima\\) de un n√∫mero real a los n√∫meros complejos se define de la siguiente manera:\nSea \\(f: \\mathbb{R} \\rightarrow \\mathbb{C}\\) una funci√≥n que asigna a cada n√∫mero real su ra√≠z n-√©sima en el conjunto de los n√∫meros complejos:\n\\[\nf(x) =\n\\begin{cases}\n\\sqrt[n]{x} & \\text{si } x \\geq 0 \\\\\n\\sqrt[n]{|x|} \\cdot e^{i\\pi} & \\text{si } x &lt; 0 \\\\\n\\end{cases}\n\\]\nDonde \\(e^{i\\pi}\\) es la unidad imaginaria \\(i\\) multiplicada por \\(\\pi\\), que representa un √°ngulo de \\(\\pi\\) radianes en la forma polar. Esta expresi√≥n se obtiene al considerar que la ra√≠z n-√©sima de un n√∫mero negativo en los n√∫meros complejos se puede escribir como el m√≥dulo de ese n√∫mero multiplicado por \\(e^{i\\pi}\\), lo que representa una rotaci√≥n de \\(\\pi\\) radianes en el plano complejo.\nEsta funci√≥n mapea los n√∫meros reales no negativos en los n√∫meros complejos de manera directa, mientras que para los n√∫meros reales negativos, devuelve un n√∫mero complejo cuyo m√≥dulo es la ra√≠z n-√©sima del valor absoluto de \\(x\\) y cuyo argumento (√°ngulo) es \\(\\pi\\).\n\n\n\nEstructura de datos\n\n\n\nLas estructuras de datos son objetos que contienen datos almacenados y organizados de una manera particular. Una estructuras tienen diferentes caracter√≠sticas, como su dimensi√≥n y si son homogeneas o hereterogeneas respecto al tipo de datos que contienen almacenados.\n\n\nLa siguiente imagen contiene las estructuras de datos m√°s comunes en R, junto con su representacion intuitiva de su configuraci√≥n interna.\n\n\n\n\nEstructuras de datos en R\n\n\n\nParrrafo de texro 2\n\nLa siguiente tabla muestra las principales estructuras de datos que maneja R.\n\nEscalares:\n\nchat\n\nVectores:\n\nchat\n\nMatrices:\n\nchat\n\nParrrafo de texro 3\n\n\nTrabajano con un  dataframe \n\n\nUtilizaremos el conjunto de datos ToothGrowth, este dataframe viene almacenado por defecto en R. Siempre que se este trabajando con datos es importante conocer el contexto en el que los datos fueron registrados y sus fines, o al menos que tipo de datos tenemos.\n\n\nDescripci√≥n:  El dataframe contine la respuesta es la longitud de los odontoblastos (c√©lulas responsables del crecimiento de los dientes) en 60 cobayas/cuyes. Cada animal recibi√≥ uno de los tres niveles de dosis de vitamina C  (0,5, 1 y 2 mg/d√≠a) mediante uno de dos m√©todos de administraci√≥n: jugo de naranja o √°cido asc√≥rbico (una forma de vitamina C codificada como VC). El tama√±o del conjunto de datos es de 60 observaciones sobre 3 variables.\n\n[,1] len num√©rico Longitud del diente [,2] supp factor Tipo de suplemento (VC o DO). [,3] dose num√©rico Dosis en miligramos/d√≠a\n\nPara conocer el contenido y estructura de una variable almacenada en R, existen algunas funcion definidas por defencto. Las mas usuales son:  str(), class(), head().\n\n\nhead(ToothGrowth)\n\n   len supp dose\n1  4.2   VC  0.5\n2 11.5   VC  0.5\n3  7.3   VC  0.5\n4  5.8   VC  0.5\n5  6.4   VC  0.5\n6 10.0   VC  0.5\n\nrequire(graphics)\ncoplot(len ~ dose | supp, data = ToothGrowth, panel = panel.smooth,\n       xlab = \"Datos de crecimiento de diente : longitud vs dosis, dado el tipo de suplemento VC/OJ\")\n\n\n\n\n\n\n\n\n\nUn modelo cl√°sico de estad√≠stica: regresi√≥n lineal\n\n-buscar ejemplo con chat‚Ä¶\n\n\nCargando datos: diferentes fuente y formatos\n\n\nchat\nClaro, vamos a profundizar en la funci√≥n walk del paquete purrr en R.\n\n\nIntroducci√≥n a purrr::walk\nEl paquete purrr es parte del conjunto de paquetes tidyverse y se utiliza para realizar operaciones funcionales de manera eficiente y elegante. Proporciona funciones para trabajar con listas y vectores de una manera m√°s intuitiva que las funciones base de R.\n\n\nFunci√≥n walk\nLa funci√≥n walk en purrr es una funci√≥n de orden superior utilizada para aplicar una funci√≥n a cada elemento de una lista o vector de manera que se ejecuten efectos secundarios. Es similar a lapply o sapply en el sentido de que aplica una funci√≥n a cada elemento de una lista, pero se diferencia en que walk no devuelve nada (o m√°s precisamente, devuelve la lista de entrada invisiblemente). Es √∫til cuando necesitas aplicar una funci√≥n que realiza una acci√≥n, como imprimir o escribir en un archivo, y no necesitas los resultados.\n\n\nSintaxis\nLa sintaxis b√°sica de walk es:\nwalk(.x, .f, ...)\nDonde:\n\n.x es la lista o vector sobre el cual se va a iterar.\n.f es la funci√≥n que se aplicar√° a cada elemento de .x.\n... son argumentos adicionales que se pasan a .f.\n\n\n\nEjemplo con walk\nVeamos un ejemplo simple para entender c√≥mo funciona walk:\nlibrary(purrr)\n\n# Lista de objetos sobre los cuales se va a iterar (nombres, en nuestro ejemplo)\nnombres &lt;- c(\"Lizeth\", \"Daniel\", \"Carlos\")\n\n# Funci√≥n b√°sica para imprimir un saludo\nsaludar &lt;- function(nombres) {\n  cat(\"Hola\",nombres,\"!\\n\")\n}\n\n# Usando 'walk' para aplicar la funci√≥n 'saludar' a cada nombre en la lista\nwalk(nombres,saludar)\nAs√≠, walk aplica la funci√≥n saludar a cada elemento de la lista nombres y ejecuta el efecto secundario de imprimir un saludo para cada nombre.\n\n\nEjemplo de uso de walk (verificaci√≥n de paquetes)\nFrecuentemente olvidamos si tenemos o no algunos paquetes instalados, y seri√° de utilidad tener una manera rapidad de comprobar y hacer la instalaci√≥n. Luego utilizaremos walk para iterar sobre una lista de paquetes y verificar si cada uno est√° instalado, o no lo est√°. Esta nos permitir√° iterar sobre la lista de paquetes de interes y aplicar una funci√≥n que verifica e instala los paquetes listados sin preocuparnos por los valores de retorno, enfoc√°ndonos solo en los efectos secundarios (la instalaci√≥n de paquetes). Para el ejemplo listaremos paquetes de uso com√∫n en an√°lisis de datos, modelado predictivo y procesamiento de texto.\npackages &lt;- c( \n              \"broom\", \"forcats\", \"hcandersenr\", \"janitor\", \"LDAvis\", \"lubridate\", \n              \"magrittr\", \"naivebayes\", \"polite\", \"ranger\", \"rtweet\", \"rvest\", \"sotu\", \n              \"spacyr\", \"stm\", \"stmBrowser\", \"stmCorrViz\", \"textdata\", \"textrecipes\", \n              \"tidymodels\", \"tidytext\", \"topicmodels\", \"tune\", \"wordcloud\", \"workflows\", \n              \"yardstick\"\n              )\n\npurrr::walk(\n            packages, \n            ~{if (!.x %in% installed.packages()[, 1]) install.packages(.x)}\n            )\n\n\nA tener en cuenta en lo anterior:\n\nLista de paquetes: Se define una lista packages con los nombres de los paquetes que deseamos tener disponibles.\nFunci√≥n an√≥nima en walk:\n\npurrr::walk(packages, ~{ ... }): walk itera sobre cada elemento en packages.\n~{ ... }: La tilde (~) se usa para definir una funci√≥n an√≥nima (lambda) en purrr. Es una forma corta de definir una funci√≥n en l√≠nea.\n.x es el argumento impl√≠cito que representa el elemento actual de packages durante cada iteraci√≥n.\nif (!.x %in% installed.packages()[, 1]) install.packages(.x): Para cada paquete .x, verifica si est√° instalado (.x %in% installed.packages()[, 1]). Si no lo est√°, lo instala (install.packages(.x)).",
    "crumbs": [
      "RStudio B√°sico"
    ]
  },
  {
    "objectID": "R_Tutorial_01.html#consejo-profesional-no-lo-soy-pero-igual-por-m√°s-peque√±o-que-sea-en-lo-que-estes-trabajando-siempre-siempre-crea-un-proyecto-y-luego-crea-intenamente-tus-documentos",
    "href": "R_Tutorial_01.html#consejo-profesional-no-lo-soy-pero-igual-por-m√°s-peque√±o-que-sea-en-lo-que-estes-trabajando-siempre-siempre-crea-un-proyecto-y-luego-crea-intenamente-tus-documentos",
    "title": "Back to Basics R",
    "section": "Consejo profesional (No lo soy, pero igual): Por m√°s peque√±o que sea en lo que estes trabajando, siempre siempre crea un proyecto y luego crea intenamente tus documentos ",
    "text": "Consejo profesional (No lo soy, pero igual): Por m√°s peque√±o que sea en lo que estes trabajando, siempre siempre crea un proyecto y luego crea intenamente tus documentos"
  },
  {
    "objectID": "Trabajo.html",
    "href": "Trabajo.html",
    "title": "1. Refina tu Curr√≠culum:",
    "section": "",
    "text": "En busca de Chamnba!!\n\n\nEstad√≠stico | Cient√≠fico de datos | Analista de datos | Arquitecto de datos | Aprendizaje autom√°tico | Machine Learning | Forecasting | Artificial Intelligence | Programaci√≥n Estad√≠stica\nEstad√≠stico con conocimientos especializados y destrezas en Data Science, Machine Learning, Artificial Intelligence, y modelamiento financiero y actuarial. Poseo experiencia en la creaci√≥n, manejo, an√°lisis y mantenimiento de bases de datos de gran volumen, tanto SQL como NoSQL, as√≠ como en el manejo de estructuras de datos basadas en entornos relacionales y no relacionales. Adem√°s, tengo experiencia en la creaci√≥n de modelos para el an√°lisis de series de tiempo con el uso de nuevas t√©cnicas de aprendizaje de m√°quina supervisado y no supervisado, tambi√©n me he encargado del ajuste de TFT en distintos proyectos de predicci√≥n para indicadores econ√≥micos. Adicionalmente, puedo buscar alternativas bajo enfoques bayesianos, y no param√©tricos en pro del correcto modelamiento de cualquier tipo de datos. Incluso ofrezco apoyo en la investigaci√≥n, utilizando dise√±os experimentales adecuados para cualquier √°rea de investigaci√≥n. Todo esto lo aplico utilizando lenguajes de alto nivel como Python, R, Java y C++, junto con herramientas ofim√°ticas del paquete de Office en conjunto con Visual Basic, Power Bi, Markdown, LaTeX, las herramientas de Appscript, y librar√≠as especializadas en la visualizaci√≥n de datos (Seaborn, Matplotlib, Ggplot) para crear dashboards e informes web sobresalientes que sean comprensibles y accesibles para cualquier nivel de las partes interesadas.\nAdem√°s, tengo la capacidad y habilidad para trabajar en equipo, liderar y ejecutar proyectos en diferentes campos del conocimiento, siempre con un enfoque objetivo propio de un estad√≠stico. Sin descuidar el trato humano con mis semejantes, promuevo espacios de trabajo amenos basados en el respeto, la comunicaci√≥n y la empat√≠a. Estoy siempre dispuesto a dar y recibir cr√≠ticas constructivas para promover un ambiente laboral eficiente.\nSAnti: Estad√≠stico, especialista en machine learning y aspirante a matem√°tico, con experiencia en Business Intelligence, estrategia, consultor√≠a, retail, anal√≠tica y finanzas. Enfocado en ofrecer modelos impulsados por el costo-beneficio. Enfoque recursivo y autodidacta para el desarrollo de proyectos, lo que permite una resoluci√≥n efectiva y √°gil de problemas. Altamente adaptable, orientado a resultados y con habilidades para trabajar bajo presi√≥n. Excelentes habilidades de comunicaci√≥n y liderazgo. Python, SQL, R, Power BI, Knime.\n\nDestaca tus habilidades clave y logros acad√©micos.\nIncluye proyectos relevantes y experiencias pr√°cticas.\nAseg√∫rate de que est√© bien estructurado y libre de errores.\nObjetivo Profesional: Apasionado estudiante de Estad√≠stica con s√≥lidos conocimientos en an√°lisis de datos y modelado estad√≠stico. Busco aplicar mi experiencia acad√©mica y habilidades t√©cnicas en un entorno laboral din√°mico. Mi objetivo es contribuir al crecimiento empresarial mediante la aplicaci√≥n de metodolog√≠as estad√≠sticas avanzadas para la toma de decisiones informadas. Con un enfoque orientado a resultados, estoy ansioso de enfrentar desaf√≠os anal√≠ticos y colaborar en proyectos que impulsen la innovaci√≥n, la eficiencia y la generaci√≥n de valor.\n\nComunicar de manera clara y efectiva conceptos estad√≠sticos a audiencias no t√©cnicas en pro de la alfabetizaci√≥n y cultura de datos, respaldada por habilidades de presentaci√≥n y elaboraci√≥n de informes. Por tanto, mi papel en equipos multidisciplinarios, es brindar conversaciones razonadas y basadas en evidencias cuantificablesmi capacidad para el √©xito de los proyectos. Poseo habilidades en la recopilaci√≥n, limpieza de datos, y aplicaci√≥n de t√©cnicas estad√≠sticas para abordar proyectos anal√≠ticos con un enfoque integral. Familiaridad en lenguajes: R, Python, SQL, SAS y herramientas: Power BI, Excel, Apache Spark, KNIME.\n\n2. Crea un Perfil de LinkedIn:\n\nUtiliza una foto profesional y completa todos los detalles.\nConecta con profesores, compa√±eros de clase y profesionales de la industria.\nComparte publicaciones o art√≠culos relevantes sobre estad√≠stica.\n\n\n\n3. Desarrolla una Carta de Presentaci√≥n:\n\nPersonaliza cada carta seg√∫n el trabajo al que est√°s aplicando.\nDestaca c√≥mo tus habilidades y experiencia se alinean con los requisitos del trabajo.\n\n\n\n4. Desarrolla una Presencia en Redes Sociales:\n\nSigue empresas y profesionales del campo en Twitter, por ejemplo.\nParticipa en conversaciones relevantes y comparte tu conocimiento.\n\n\n\n5. Construye un Portafolio:\n\nIncluye proyectos estad√≠sticos, informes o an√°lisis que hayas realizado.\nMuestra c√≥mo aplicaste tus habilidades en situaciones pr√°cticas.\n\n\n\n6. Investiga Empresas:\n\nIdentifica empresas que est√©n buscando profesionales en estad√≠stica.\nInvestiga su cultura, proyectos y valores para adaptar tu enfoque.\n\n\n\n7. Prep√°rate para Entrevistas:\n\nPractica respuestas a preguntas comunes de entrevistas.\nDesarrolla historias sobre situaciones en las que hayas aplicado con √©xito tus habilidades estad√≠sticas.\n\n\n\n8. Networking:\n\nAsiste a eventos de la industria, conferencias y ferias de empleo.\nConecta con profesionales a trav√©s de LinkedIn y solicita reuniones informativas.\n\n\n\n9. Aplica a Trabajos y Programas de Pasant√≠as:\n\nPersonaliza cada aplicaci√≥n seg√∫n los requisitos espec√≠ficos del trabajo.\nConsidera programas de pasant√≠as como una entrada al mercado laboral.\n\n\n\n10. Mantente Actualizado:\n\nSigue aprendiendo y adquiriendo nuevas habilidades relacionadas con la estad√≠stica.\nMantente al tanto de las tendencias en la industria.\n\n\n\n11. Ceremonia de Grados:\n\nAseg√∫rate de participar en la ceremonia de grados y obtener tu diploma oficial.\n\nRecuerda que la perseverancia y la paciencia son clave. ¬°Buena suerte en tu b√∫squeda de trabajo! Si necesitas ayuda con alguna parte espec√≠fica de este proceso, no dudes en preguntar.\nHabilidades:\nHabilidades T√©cnicas: - An√°lisis de Datos: Experiencia en recopilaci√≥n, limpieza y an√°lisis de conjuntos de datos complejos. - Modelado Estad√≠stico: Competente en la aplicaci√≥n de t√©cnicas estad√≠sticas avanzadas para realizar pron√≥sticos y tomar decisiones fundamentadas. - Programaci√≥n: Familiaridad con lenguajes como R, Python y SQL para manipulaci√≥n y an√°lisis de datos. - Herramientas Estad√≠sticas: Uso experto de software estad√≠stico como SPSS, SAS y/o STATA.\nHabilidades de Software: - Dominio de Microsoft Excel para an√°lisis y presentaci√≥n de datos. - Experiencia en el uso de herramientas de visualizaci√≥n de datos como Tableau.\nHabilidades de Comunicaci√≥n: - Capacidad para explicar conceptos estad√≠sticos de manera clara y efectiva a audiencias no t√©cnicas. - Excelentes habilidades de presentaci√≥n y elaboraci√≥n de informes.\nHabilidades Anal√≠ticas: - Resoluci√≥n de Problemas: Aptitud para abordar problemas complejos y proponer soluciones efectivas. - Pensamiento Cr√≠tico: Capacidad para evaluar datos de manera cr√≠tica y formular conclusiones fundamentadas.\nHabilidades Blandas: - Trabajo en Equipo: Experiencia en proyectos colaborativos, con habilidades para trabajar eficientemente en equipos multidisciplinarios. - Gesti√≥n del Tiempo: Habilidad para priorizar tareas y cumplir con plazos ajustados. - Adaptabilidad: Capacidad para ajustarse a cambios y aprender r√°pidamente nuevas herramientas y t√©cnicas.\nComunicar de manera clara y efectiva conceptos estad√≠sticos a audiencias no t√©cnicas en pro de la alfabetizaci√≥n y cultura de datos, respaldada por habilidades de presentaci√≥n y elaboraci√≥n de informes. Por tanto, mi papel en equipos multidisciplinarios, es brindar conversaciones razonadas y basadas en evidencias cuantificablesmi capacidad para el √©xito de los proyectos. Poseo habilidades en la recopilaci√≥n, limpieza de datos, y aplicaci√≥n de t√©cnicas estad√≠sticas para abordar proyectos anal√≠ticos con un enfoque integral. Familiaridad en lenguajes: R, Python, SQL, SAS y herramientas: Power BI, Excel, Apache Spark, KNIME.\nComunicar de manera clara y efectiva conceptos estad√≠sticos a audiencias no t√©cnicas es una de mis capacidades, contribuyendo as√≠ a la alfabetizaci√≥n y cultura de datos. Esta habilidad se respalda con destrezas en presentaci√≥n y elaboraci√≥n de informes. En el contexto de equipos multidisciplinarios, mi papel consiste en ofrecer conversaciones razonadas y basadas en evidencias cuantificables, demostrando as√≠ mi capacidad para contribuir al √©xito de los proyectos.\nDestaci mi interes con interacruar con o\nAdaptabilidad y disposici√≥n para aprender r√°pidamente nuevas herramientas y t√©cnicas en busca de excelencia en el an√°lisis estad√≠stico.\nTu perfil profesional en LinkedIn est√° bien estructurado y contiene informaci√≥n relevante. Sin embargo, aqu√≠ tienes algunas sugerencias para mejorarlo:\nPerfil Profesional:"
  },
  {
    "objectID": "Trabajo_Grado.html",
    "href": "Trabajo_Grado.html",
    "title": "Vladimir Sanchez Tenjo",
    "section": "",
    "text": "El prop√≥sito de este libro es ofrecer una introducci√≥n rigurosa y exhaustiva a la t√©cnica de Incrustaci√≥n de Cadenas de Markov Finitas (ICMF) para estudiar las distribuciones de Rachas y Patrones desde un punto de vista unificado e intuitivo, alejado de las l√≠neas tradicionales de la combinatoria. A lo largo de las dos √∫ltimas d√©cadas, se han obtenido mediante este enfoque un n√∫mero considerable de nuevos resultados relacionados con las distribuciones de rachas y patrones.\n\n\nEl tema central de la Incrustaci√≥n de Cadenas de Markov Finitas (ICMF), como su nombre indica, es incrustar adecuadamente las variables aleatorias de inter√©s en el marco de una cadena de Markov finita, y las representaciones resultantes de las distribuciones subyacentes son compactas y muy susceptibles de un estudio m√°s profundo de las propiedades asociadas. En este libro, el concepto de ICMF se desarrolla sistem√°ticamente y se ilustra su utilidad mediante aplicaciones pr√°cticas a diversos campos, como la fiabilidad de los sistemas de ingenier√≠a, la comprobaci√≥n de hip√≥tesis, el control de calidad y la medici√≥n de la continuidad en el sector sanitario.\n\n\nEste libro est√° restringido a espacios muestrales discretos, una restricci√≥n que sirve para que este trabajo sea accesible a una audiencia m√°s amplia al simplificar los resultados te√≥ricos y sus aplicaciones. Las rachas y patrones considerados aqu√≠ se definen en gran medida en sucesiones de ensayos Markov-Dependientes de dos o m√∫ltiples estados, con aplicaciones pr√°cticas en mente; los definidos sobre permutaciones aleatorias de n√∫meros enteros, como los n√∫meros de Eulerian y Simon Newcomb, tambi√©n se tratan utilizando un procedimiento de inserci√≥n adicional. El contenido de este libro est√° orientado principalmente a los investigadores que utilizan la teor√≠a de la distribuci√≥n de rachas y patrones en diversos √°mbitos aplicados de la estad√≠stica, la probabilidad y la combinatoria, pero tambi√©n podr√≠a servir de base de un curso de temas especiales de un semestre de duraci√≥n en cuarto curso de licenciatura o a nivel de primer a√±o de posgrado.\n\n\n\nDeseamos agradecer la ayuda de Y. M. Chang y B. C. Johnson en la correcci√≥n de los primeros borradores del libro, as√≠ como el aliento de nuestros colegas de la Universidad de Manitoba y la Universidad de Toronto.\n\n\nTambi√©n estamos en deuda con nuestras familias por su inagotable apoyo. Por √∫ltimo, queremos agradecer a la Sra. E. H. Chionh, de World Scientific Publishing Co.¬†por su paciencia y apoyo administrativo.\n\n\n\n\nLa ocurrencia de rachas y patrones en una sucesi√≥n de resultados de ensayos discretos o permutaciones aleatorias es un concepto importante en diversas √°reas de la ciencia, como la ingenier√≠a de confiabilidad, el control de calidad, la psicolog√≠a, la sociolog√≠a, la comparaci√≥n de secuencias de ADN y la comprobaci√≥n de hip√≥tesis. Resultados de las distribuciones de probabilidad de rachas y patrones elementales se obtuvieron espor√°dicamente en la literatura hasta aproximadamente la d√©cada de 1940, cuando se publicaron una serie de estudios pioneros sobre rachas y patrones m√°s complejos: por ejemplo, Wishart e Hirshfeld (1936), Cochran (1938), Mood (1940), Wald y Wolfowitz (1940), Mosteller (1941) y Wolfowitz (1943). La mayor√≠a de estos estudios se centraron en hallar la distribuci√≥n condicional de las rachas de √©xito dado el n√∫mero total de √©xitos en una sucesi√≥n de ensayos de dos estados. Un libro reciente reciente de Balakrishnan y Koutras (2002), ofrece una buena revisi√≥n exhaustiva de los avances hist√≥ricos y actuales en la teor√≠a de la distribuci√≥n de rachas y las estad√≠sticas de escaneo.\nTradicionalmente, las distribuciones de rachas y patrones se estudiaban mediante an√°lisis combinatorio. Por ejemplo, Mood (1940) escribi√≥: ‚ÄúEl problema de la distribuci√≥n es, por supuesto, combinatorio, y todo el desarrollo depende de algunas identidades del an√°lisis combinatorio‚Äù. Sin embargo, encontrar las identidades combinatorias apropiadas para derivar las distribuciones de probabilidad puede ser dif√≠cil, si no imposible, para rachas y patrones complejos, y quiz√° sea √©sta la raz√≥n por la que las distribuciones exactas de muchos estad√≠sticos comunes definidos en rachas y patrones siguen siendo desconocidas. Adem√°s las identidades requeridas a menudo difieren incluso para rachas y patrones similares, y por lo tanto, incluso en el caso m√°s sencillo de ensayos independientes e id√©nticamente distribuidas (i.i.d.) de dos estados (los llamados ‚Äúensayos de Bernoulli‚Äù), cada nuevo problema de distribuci√≥n generalmente tiene que estudiarse caso por caso utilizando el enfoque combinatorio. Por ejemplo, s√≥lo hace relativamente poco tiempo Philippou y Makri (1986) e Hirano (1986), de forma independiente y mediante an√°lisis combinatorio, obtuvieron la distribuci√≥n exacta de la estad√≠stica de racha tradicional \\(\\small{N_{n,k}}\\), del n√∫mero de rachas de \\(k\\) √©xitos consecutivos no-solapados en una secuencia de \\(n\\) ensayos Bernoulli:\n\n\n\\[\\begin{equation}\n\\mathbb{P}(N_{n,k}=x)=\\sum_{m=0}^{k-1}\\sum_{x_1+x_2+\\cdots+\\\\\nkx_k=n-m-km}\\binom{x_1+x_2+\\cdots+x_k+x}{x_1,x_2,\\cdots,x_k,x}p^n\\Big(\\frac{q}{p}\\Big)^{x_1+x_2+\\cdots+x_k}\n\\end{equation}\\]\n\npara \\(x=0,1,\\ldots,[n/k]\\), con probabilidades de √©xito y fracaso denotadas por \\(p\\) y \\(q=1-p\\), respectivamente. Otro m√©todo para determinar una distribuci√≥n de probabilidad exacta consiste en derivar la funci√≥n generadora \\(\\small{\\varphi(s)}\\) para la variable aleatoria entera no negativa \\(\\small{X_n(\\Lambda)}\\) asociada con el patr√≥n \\(\\small{\\Lambda}\\) (por ejemplo, \\(\\small{X_n(\\Lambda)}\\) podr√≠a ser el n√∫mero de apariciones del patr√≥n \\(\\small{\\Lambda}\\) en \\(n\\) ensayos) y, a continuaci√≥n, diferenciar \\(\\small{\\varphi(s)}\\) \\(x\\) veces para obtener la funci√≥n de distribuci√≥n de probabilidad (fdp) dada por \\(\\small{\\mathbb{P}(X_n(\\Lambda) = x)}\\) este enfoque fue introducido por Feller (1968) utilizando la teor√≠a de los sucesos recurrentes. Por ejemplo, para la funci√≥n generadora del tiempo de espera \\(\\small{W(\\Lambda)}\\), el n√∫mero de ensayos Bernoulli hasta la primera aparici√≥n del patr√≥n \\(\\small{\\Lambda}\\) consistente en \\(k\\) √©xitos consecutivos, fue dada por Feller como:\n\n\n\\[\\begin{equation}\n\\varphi_{W}(s)=\\frac{p^ks^k(1-ps)}{1-s+qp^ks^{k+1}}\n\\end{equation}\\]\n\nPara rachas y patrones m√°s complejos, las funciones generadoras pueden ser dif√≠ciles de diferenciar un gran n√∫mero de veces y es posible que sea necesario emplear t√©cnicas de aproximaci√≥n. Feller utiliz√≥ el m√©todo de expansi√≥n de fracciones parciales, que puede requerir m√©todos num√©ricos eficientes para calcular ra√≠ces de polinomios. A traves del libro estudiaremos problemas de distribuci√≥n de rachas y patrones desde un punto de vista, en nuestra opini√≥n, m√°s unificado e intuitivo, alejado de las l√≠neas de la combinatoria tradicional. El enfoque adoptado consiste en incrustar adecuadamente la variable aleatoria \\(\\small{X_n(\\Lambda)}\\) en una cadena de Markov finita \\(\\small{\\{Y_t\\}}\\), de modo que la probabilidad de \\(\\small{X_n(\\Lambda)}=x\\) pueda expresarse en t√©rminos de la probabilidad de que el estado de la cadena de Markov al momento \\(\\small{n}\\), \\(\\small{Y_n}\\), se encuentre en un subconjunto \\(\\small{C_x}\\) del espacio de estados, es decir:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\{X_n(\\Lambda)=x\\}=\\mathbb{P}(Y_n \\in C_x)\n\\end{equation}\\]\n\ndonde la probabilidad del lado derecho se puede calcular f√°cilmente mediante las matrices de probabilidad de transici√≥n de la cadena de Markov. Esta representaci√≥n de la distribuci√≥n subyacente de \\(\\small{X_n(\\Lambda)}\\) es compacta, f√°cil de calcular y bastante susceptible de an√°lisis posteriores. El m√©todo depende en gran medida de la capacidad de construir una cadena de Markov adecuada asociada con la variable aleatoria \\(\\small{X_n(\\Lambda)}\\), pero una vez construida la cadena, la linealidad de la cadena de Markov reduce la complejidad computacional a menudo asociada con t√©cnicas combinatorias y de funciones generadoras para calcular los fdp‚Äôs exactas de rachas y patrones.\nLos primeros resultados de la teor√≠a de la distribuci√≥n de rachas y patrones se derivaron casi exclusivamente bajo el supuesto de ensayos Bernoulli o ensayos i.i.d. multiestados. Una gran ventaja de la t√©cnica de incrustaci√≥n de cadenas finitas de Markov es que se puede aplicar no s√≥lo a casos de ensayos i.i.d. , tambi√©n para ensayos multiestado Markov-dependientes, eso si, con poco esfuerzo adicional. Independientemente de los procedimientos de conteo especificados para patrones superpuestos (conteo superpuesto versus no superpuesto); tambi√©n se puede extender a varios tipos de rachas y patrones en permutaciones aleatorias. Recientemente, este m√©todo ha sido adoptado por varios investigadores para estudiar diversas distribuciones de rachas y patrones: por ejemplo, Antzoulakos (1999, 2001), Boutsikas y Koutras (2000a,b), Doi y Yamamoto (1998), Fu (1985, 1986, 1996), Pu y Koutras (1994), Fu y Lou (2000a,b), Han y Aki (2000a,b), Johnson (2002), Koutras (1996a,b, 1997a,b, 2003), Koutras y Alexandrou (1995), Lou (1996, 2000, 2001) y Nishimura y Sibuya (1997). Tocaremos algunos de estos trabajos recientes, pero nuestras formulaciones correspondientes pueden diferir ligeramente para tratar todos los problemas utilizando un enfoque de incrustaci√≥n com√∫n.\nEste libro no es una revisi√≥n de la teor√≠a de rachas y patrones, ni pretende ser utilizado principalmente como un libro de texto de curso; est√° dirigido principalmente a investigadores en estad√≠stica aplicada y probabilidad que est√©n interesados en utilizar la t√©cnica de incrustaci√≥n de cadenas finitas de Markov para estudiar las distribuciones de rachas y patrones que surgen en aplicaciones espec√≠ficas. El contenido del libro se basa en gran medida en desarrollos recientes en esta √°rea, pero se presenta de una manera que no requiere conocimiento de conceptos avanzados en matem√°ticas o probabilidad; Se supone que se tiene experiencia en teor√≠a de la probabilidad, al nivel de, por ejemplo, el libro de Feller (1968) ‚ÄúUna introducci√≥n a la teor√≠a de la probabilidad y sus aplicaciones, Volumen I‚Äù. El libro est√° organizado como sigue. En el Cap√≠tulo 2, presentamos las ideas y t√©cnicas b√°sicas de incrustaci√≥n de cadenas finitas de Markov. Este cap√≠tulo sienta las bases para calcular los fdp‚Äôs de rachas y patrones, incluidas las distribuciones de tiempo de espera. El Cap√≠tulo 3 examina las distribuciones de rachas y patrones asociados con los ensayos de dos estados, y en el Cap√≠tulo 4, se trata la extensi√≥n a los ensayos de m√∫ltiples estados a trav√©s del principio de avance y retroceso. El Cap√≠tulo 5 estudia principalmente las distribuciones de tiempo de espera de patrones simples y compuestos, as√≠ como sus funciones generadoras y aproximaciones de grandes desviaciones. En el Cap√≠tulo 6, la t√©cnica de incrustaci√≥n de cadenas finitas de Markov se extiende al estudio de distribuciones de patrones en permutaciones aleatorias de n√∫meros enteros, centr√°ndose en detalle en los n√∫meros de Euler y Simon Newcomb. El Cap√≠tulo 7 cubre varias aplicaciones de la teor√≠a de la distribuci√≥n de rachas y patrones en las √°reas de confiabilidad de sistemas de ingenier√≠a, pruebas de hip√≥tesis, medici√≥n de continuidad en atenci√≥n m√©dica y control de calidad.\n\n\n\n\n\nSea \\(\\small{\\Omega=\\{1,2,\\ldots,m\\}}\\quad(m&lt;\\infty)\\) un espacio de estados finito, y \\(\\small{\\mathcal{Y_t}=\\{Y_0,Y_1,\\ldots,Y_t,\\ldots\\}}\\) una familia de variables aleatorias definidas sobre \\(\\small{\\Omega}\\).(proceso estoc√°stico).\nDefinici√≥n 2.1 Decimos que la familia/colecci√≥n de variables aleatorias \\(\\small{\\{\\mathcal{Y_t}\\}}\\) es cadena de Markov si, para toda sucesi√≥n \\(\\small{\\{Y_0=i_0,Y_1=i_1,\\ldots,Y_{t-1}=i_{t-1},Y_t=i_t\\}},\\) con \\(\\small{t\\in \\{1,2,\\cdots\\}}\\), se tiene que:\n\n\n\\[\\begin{equation}\n\\mathbb{P}(Y_t=i_t \\mid Y_{t-1}=i_{t-1},\\ldots,Y_0=i_0)=\\mathbb{P}(Y_t=i_t \\mid Y_{t-1}=i_{t-1})\n\\end{equation}\\]\n\nEn otras palabras, la sucesi√≥n de variables aleatorias es una cadena de Markov si la probabilidad de que el sistema entre en el estado \\(\\small{i_t}\\) en el momento \\(\\small{t}\\) depende s√≥lo del estado inmediatamente anterior \\(\\small{i_{t-i}}\\) en el momento \\(\\small{t-1}\\). O m√°s sucintamente, visto desde el estado en el momento \\(\\small{t- 1}\\), el futuro es independiente del pasado. Las probabilidades condicionales.\n\n\n\\[\\begin{equation}\n\\mathbb{P}(Y_t=j \\mid Y_{t-1}=i)\\equiv p_{ij}\n\\end{equation}\\]\n\n\\(\\small{i,j \\in \\Omega}\\), se denominan probabilidades de transici√≥n de un paso para el sistema en el momento \\(t\\). Las probabilidades de transici√≥n \\(\\small{p_{ij}(t), 1 \\leq i,j \\leq m}\\), pueden representarse como una matriz \\(m\\times m\\)\n\n\n\\[\\begin{equation}\n\\boldsymbol{M_t}=(p_{ij(t)})=\\begin{pmatrix}\np_{11}(t) & p_{12}(t) & \\cdots & p_{1m}(t)\\\\\np_{21}(t) & p_{22}(t) & \\cdots & p_{2m}(t)\\\\\n\\vdots & \\ddots & \\ddots & \\cdots\\\\\np_{m1}(t) &p_{m2}(t) & \\cdots & p_{mm}(t)\\\\\n\\end{pmatrix}_{m\\times m}\n\\end{equation}\\]\n\nLas matrices \\(\\small{\\boldsymbol{M_t},\\,\\, t=1,2,\\ldots,}\\) son llamadas matrices de probabilidades de transici√≥n de un paso o simplemente matrices de transici√≥n de un paso.\nProposici√≥n. La matriz de probabilidades de transici√≥n \\(\\small{\\boldsymbol{M_t}=(p_{ij}(t))}\\) cumplen las siguientes propiedades, para cada tiempo \\(\\small{t}\\):\n\n\\(\\small{(p_{ij(t)}) \\geq 0}\\) para todo \\(\\small{t}\\).\n\\(\\small{\\displaystyle\\sum_{j}p_{ij}=1}\\), es decir, en cada momento del tiempo \\(\\small{t}\\), el proceso cambia de estado (puede ser permanecer en el mismo estado) con probabibilidad \\(\\small{1}\\).\n\nDefinici√≥n 2.2: Una cadena de Markov \\(\\small{\\{Y_0,Y_1,\\dots\\}}\\), es homogenea si las probabilidades de transici√≥n son constantes en el tiempo, i.e \\(\\small{\\mathbb{P}(Y_t=j \\mid Y_{t-1}=i)}=p_{ij}\\) para todo par \\(\\small{(i,j)\\in \\Omega \\times \\Omega=\\Omega^2}\\) y todo \\(\\small{t=1,2,\\ldots}\\)\nEsta definici√≥n equivale a decir que las matrices de probabilidad de transici√≥n de una cadena de Markov homog√©nea pueden representarse mediante la √∫nica matriz:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M=M_t}=(p_{ij}(t)), \\quad \\text{para todo } t=1,2,\\ldots\n\\end{equation}\\]\n\nen donde las probabilidades de transici√≥n \\(\\small{p_{ij}}\\) son independientes del √≠ndice del tiempo \\(\\small{t}\\).\nEl conjunto de probabilidades en el momento \\(\\small{0}\\), denotada como \\(\\small{\\mathbb{P}(Y_0 = i)}\\) para \\(i = 1,\\ldots,m\\) se conoce como la distribuci√≥n inicial de la cadena de Markov. Dada una distribuci√≥n de probablidad inicial y las probabilidades de transici√≥n de una cadena de Markov, la distribuci√≥n conjunta de la cadena se puede calcular de la siguiente manera:\n\n\n\\[\\begin{equation}\n\\begin{split}\n\\mathbb{P}(Y_n=i_n,\\ldots,Y_1=i_1,Y_0=i_0) = &  \\mathbb{P}(Y_n=i_n \\mid Y_{n-1}=i_{n-1})\\cdots \\\\\n& \\cdots \\mathbb{P}(Y_1=i_1 \\mid Y_0=i_0)\\mathbb{P}(Y_{0}=i_{0}).\n\\end{split}\n\\end{equation}\\]\n\nLas cadenas de Markov se han utilizado en el modelado de una gran cantidad de aplicaciones. Aqu√≠ damos dos ejemplos simples que se ven a menudo en la teor√≠a de probabilidad aplicada:\nEjemplo 2.1 (El problema de la ruina del jugador). Considere un jugador que gana y pierde un d√≥lar con probabilidades \\(p\\) y \\(q = 1-p\\), respectivamente. Supongamos que el jugador tiene un capital inicial de \\(\\small{a}\\) d√≥lares. El jugador deja de jugar cuando se queda sin capital (‚Äúarruinado‚Äù) o cuando alcanza una fortuna de \\(\\small{a + b}\\) d√≥lares (con ganancia neta \\(\\small{b &gt; 0}\\)).\nLa sucesi√≥n del monto de capital del jugador, \\(\\small{\\{Y_t: t = 0,1,2, \\ldots\\}}\\), forma una cadena de Markov homog√©nea con espacio de estados \\(\\small{\\Omega= \\{0,1, 2, \\ldots, a-1,a,a + 1,\\ldots, a + b}\\}\\) y las siguientes probabilidades de transici√≥n:\n\n\n\\[\\begin{equation}\np_{ij}=\\begin{cases}\np\\quad \\text{si } j=i+1\\\\\nq\\quad \\text{si } j=i-1\n\\end{cases}\n\\end{equation}\\]\n\npara \\(\\small{i=1,2,\\ldots,a+b-1,\\, p_{00}=p_{a+b,a+b}=1}\\) y cero en cualquier otro caso. Los estados \\(\\small{0}\\) y \\(\\small{a+b}\\) se denominan absorbentes, ya que, una vez alcanzados nunca se sale de estos. La Cadena de Markov tine la matriz de problabilidades de transici√≥n:\n\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\\begin{array}{cc} &\n\\begin{array}{cccccccc}\n\\end{array}\n\\\\\n\\begin{array}{ccc}\n0 \\\\\n1 \\\\\n\\vdots\\\\\n\\cdot \\\\\na-1 \\\\\na\\\\\na+1\\\\\n\\vdots\\\\\na+b\n\\end{array}\n&\n\\left(\n\\begin{array}{cccccccc}\n1 & 0 & 0 & 0 &  &  &   &   \\\\\nq & 0 & p & 0 &  &  &   &  \\\\\n& \\ddots & \\ddots & \\ddots &   &   &\\boldsymbol{0}   &  \\\\\n&  &  \\ddots & \\ddots & \\ddots &   &   &   \\\\\n&  &   &  q & 0& p &  &   \\\\\n& \\boldsymbol{0} &  &   &   \\ddots & \\ddots & \\ddots & \\\\\n&  &  &  &  & q & 0 & p \\\\\n&  &  &  &  & 0 & 0 & 1 \\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nen donde \\({\\mathbf{0}}\\) representa un matriz de ceros y la cadena tiene distribuci√≥n de probabilidad inicial \\(\\small{\\mathbb{P}(Y_0=a)=1}\\).\nEjemplo 2.2 (Modelo de Urnas). Considere una sucesi√≥n de ensayos independientes, cada uno de los cuales consiste en insertar una bola al azar en una de \\(\\small{k}\\) urnas. Decimos que el sistema \\(\\small{\\{Y_t : t = 0,1,\\ldots\\}}\\) est√° en estado \\(\\small{i}\\), si exactamente \\(\\small{i}\\) urnas est√°n ocupadas. Este sistema forma una cadena de Markov en el espacio de estados \\(\\small{\\Omega = \\{0,1,\\ldots, k\\}}\\) con probabilidades de transici√≥n\n\n\n\\[\\begin{equation}\np_{ij}=\\begin{cases}\n\\frac{i}{k}  \\quad\\quad  \\text{si } j=i\\\\\n\\frac{k-i}{k}\\quad \\text{ si } j=i+1\\\\\n0 \\quad \\quad \\text{en otro caso}\n\\end{cases}\n\\end{equation}\\]\n\npara \\(\\small{i=0,1,\\ldots,k}\\) y distribuci√≥n de probabilidad inicial \\(\\small{\\mathbb{P}(Y_0=0)=1}\\). La matriz de probabilidades de transici√≥n esta dada por: \n\n\\[\\begin{equation}\n\\boldsymbol{M}=\\begin{array}{cc} &\n\\begin{array}{ccccccc}\n\\end{array}\n\\\\\n\\begin{array}{ccc}\n0 \\\\\n1 \\\\\n\\\\\n\\vdots\\\\\ni\\\\\n\\vdots\\\\\nk-1\\\\\nk\n\\end{array}\n&\n\\left(\n\\begin{array}{ccccccc}\n0 & 1 & 0 &   &  &  &     \\\\\n0 & \\frac{1}{k} & \\frac{k-1}{k}  & 0 &  & \\boldsymbol{0} &      \\\\\n&  & \\ddots & \\ddots &   &   &      \\\\\n&  &        & \\frac{i}{k} & \\frac{k-i}{k} &   &       \\\\\n&   &   &  & \\ddots& \\ddots &    \\\\\n&   & \\boldsymbol{0} &   &   & \\frac{k-1}{k} & \\frac{1}{k}  \\\\\n&   &  &   &   & 0 & 1\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nSe pueden encontrar m√°s ejemplos de este tipo en Feller (1968) y Ross (2000). Por supuesto, tambi√©n habr√° muchos m√°s ejemplos de cadenas de Markov en secciones posteriores de este libro.\n\n\n\nPara una cadena de Markov no homog√©nea \\(\\small{\\{Y_t\\}}\\), las probabilidades de transici√≥n de \\(\\small{n}\\) pasos \\(\\small{\\mathbb{P}(Y_t= j \\mid Y_{t-n} = i) = p_{ij}^{(n)}(t)}\\) se pueden obtener a partir de las probabilidades de transici√≥n de un paso por una identidad importante conocida como Ecuaci√≥n de Chapman-Kolmogorov. Si \\(\\small{n = 2}\\), tenemos, para \\(\\small{t \\geq 2}\\),\n\n\n\\[\\begin{equation}\np_{ij}^{(2)}(t) = \\sum_{k\\in \\Omega}\\mathbb{P}(Y_{t-1}=k \\mid  Y_{t-2}=i)\\mathbb{P}(Y_{t}=j \\mid  Y_{t-1}=k)=\\sum_{k\\in \\Omega} p_{ik}(t-1)^{}p_{kj}^{}(t)\n\\end{equation}\\]\n\nque corresponde a sumar todos los posibles \\(\\small{k}\\) estados intermedios en la transici√≥n del estado \\(\\small{i}\\) al estado \\(\\small{j}\\).\nSi \\(\\small{\\{Y_t\\}}\\) es una cadena de Markov homog√©nea, entonces la ecuaci√≥n anterior (2.4) genera las probabilidades de transici√≥n de dos pasos \\(\\small{(n = 2)}\\)\n\n\n\\[\\begin{equation}\np_{ij}^{(2)} = \\sum_{ k \\in \\Omega}\\mathbb{P}(Y_{t-1}=k  \\mid  Y_{t-2}=i)\\mathbb{P}(Y_{t}=j \\mid  Y_{t-1}=k)=\\sum_{k\\in \\Omega} p_{ik}p_{kj}\n\\end{equation}\\]\n\nlas cuales son independientes de \\(\\small{t}\\). Por lo tanto, de la ecuaci√≥n (2.5), la matriz de probabilidades de transici√≥n de dos pasos \\(\\small{\\boldsymbol{M}^{(2)} = (p_{ij}^{(2)})}\\) satisface la identidad \\(\\small{\\boldsymbol{M}^{(2)}= \\boldsymbol{M}^2}\\). De manera analoga, para las probabilidades de transici√≥n de \\(\\small{n}\\) pasos de una cadena de Markov homog√©nea, la identidad de Chapman-Kolmogorov:\n\n\n\\[\\begin{equation}\np_{ij}^{(n)} = \\sum_{k \\in \\Omega} p_{ik}^{(s)}p_{kj}^{(n-s)}\n\\end{equation}\\]\n\nse mantiene para cada paso intermedio \\(\\small{s = 1,\\ldots, n -1}\\). Se deduce de las ecuaciones. (2.5) y arterior-(2.6) que\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}^{(n)}= \\boldsymbol{M}^{(s)}\\boldsymbol{M}^{(n-s)}=\\boldsymbol{M}^{n}\n\\end{equation}\\]\n\nPara una cadena de Markov homog√©nea \\(\\small{\\{Y_t\\}}\\), y cualquier subconjunto \\(\\small{{C}}\\) del espacio de estados \\(\\small{\\Omega}\\), se deduce de la Ec.(2.7) que la probabilidad condicional del sistema \\(\\small{Y_n}\\) resida en \\(\\small{{C}}\\) en el √≠ndice de tiempo \\(\\small{n}\\), dada la distribuci√≥n de probabilidad inicial \\(\\small{\\boldsymbol{\\mathbf{\\xi}}_0 = \\big(\\mathbb{P}(Y_0 = 1), \\cdots,P(Y_0 = m)\\big)}\\) es:\n\n\n\\[\\begin{equation}\n\\mathbb{P}(Y_n \\in {C} \\mid \\boldsymbol{\\mathbf{\\xi}}_0)=\\boldsymbol{\\mathbf{\\xi}}_0 \\boldsymbol{M}^{n}\\boldsymbol{\\mathbf{U}'}({C})\n\\end{equation}\\]\n\nen donde \\(\\small{\\boldsymbol{\\mathbf{U}'}({C})}\\) es la traspuesta de \\(\\small{\\boldsymbol{\\mathbf{U}}({C})}\\), con \\(\\small{\\boldsymbol{\\mathbf{U}}( {C})=\\displaystyle\\sum_{i \\in C}e_i}\\) y \\(\\small{\\boldsymbol{e}_i=(0,\\ldots,1,\\ldots,0)_{1\\times m}}\\) es un vector can√≥nico con un \\(\\small{1}\\) correspondiente al \\(i\\)-√©simo estado y cero en los otros. De manera m√°s general, si \\(\\small{\\{Y_t\\}}\\) es una cadena de Markov no homog√©nea, se puede demostrar (ver, Feller 1968) que la probabilidad condicional de \\(\\small{Y_n \\in {C} }\\) dado \\(\\small{\\boldsymbol{\\xi}_0}\\) se puede expresar simplemente como\n\n\n\\[\\begin{equation}\n\\mathbb{P}(Y_n \\in  {C} \\mid \\boldsymbol{\\mathbf{\\xi}}_0)=\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\prod_{t=1}^{n}\\boldsymbol{M_t}\\Big)\\boldsymbol{\\mathbf{U}'}({C})\n\\end{equation}\\]\n\nLas ecuaciones (2.8) y (2.9) son dos herramientas indispensables para evaluar las probabilidades de diversos eventos asociados con cadenas de Markov homog√©neas y no homog√©neas, respectivamente.\n\n\n\nCon el fin de ampliar las posibles aplicaciones, es √∫til considerar una extensi√≥n simple de la metodolog√≠a anterior a cadenas de Markov definidas en espacios de estados de diferentes tama√±os. Sea \\(\\small\\{Y_t\\}\\) una sucesi√≥n de variables aleatorias definidas en una familia de espacios de estados \\(\\small{\\{\\Omega_t\\}}\\), respectivamente. La sucesi√≥n \\(\\small{\\{Y_t\\}}\\) se denomina cadena de Markov con estructura de √°rbol si \\(\\small{\\{Y_t\\}}\\) es una cadena de Markov con matrices de transici√≥n\n\n\n\\[\\begin{equation}\n\\boldsymbol{M_t}=(p_{ij}(t)), \\quad \\text{para todo } t=1,2,\\ldots,\n\\end{equation}\\]\n\nen donde, para cada \\(\\small{i \\in {\\Omega}_{t-1}}\\) y \\(\\small{j \\in {\\Omega}_{t}}\\)\n\n\n\\[\\begin{equation}\np_{ij}(t)=\\mathbb{P}(Y_t=j\\mid Y_{t-1}=i).\n\\end{equation}\\]\n\nObs√©rvese que los espacios de estados de la colecci√≥n \\(\\small{\\{\\Omega_t\\}}\\) pueden tener tama√±os diferentes, las matrices de transici√≥n \\(\\small{\\boldsymbol{M_t}}\\) pueden ser rectangulares en lugar de cuadradas; es decir, \\(\\small{\\boldsymbol{M_t},\\, t = 1, 2, \\ldots,}\\) son matrices de orden \\(\\small{\\text{card}(\\Omega_{t-1}) \\times \\text{card}(\\Omega_{t})}\\), donde \\(\\small{\\text{card}(\\Omega)}\\) representa el n√∫mero cardinal del espacio de estados \\(\\small{\\Omega}\\). La sucesi√≥n de matrices de probabilidad de transici√≥n \\(\\small{\\{\\boldsymbol{M_t}}\\}\\) sigue determinando la cadena de Markov \\(\\small\\{{Y_t}\\}\\) estructurada en √°rbol, y la ecuaci√≥n de Chapman-Kolmogorov sigue siendo aplicable.\nPara cualquier subconjunto \\(\\small{ {C}\\subseteq \\Omega_n}\\), la probabilidad condicional de \\(\\small{Y_n\\in {C}}\\) dada la distribuci√≥n de probabilidad inicial \\(\\small{\\boldsymbol{\\xi}_0}\\), puede calcularse v√≠a:\n\n\n\\[\\begin{equation}\n\\mathbb{P}(Y_n \\in {C} \\mid \\boldsymbol{\\mathbf{\\xi}}_0)=\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\prod_{t=1}^{n}\\boldsymbol{M_t}\\Big)\\boldsymbol{\\mathbf{U}'}_{n}({C})\n\\end{equation}\\]\n\nsiendo \\(\\small{\\boldsymbol{\\mathbf{U}}_{n}({C})=\\displaystyle\\sum_{i \\in C}\\boldsymbol{e}_i}\\) y \\(\\small{\\boldsymbol{e}_i=(0,\\ldots,1,\\ldots,0)_{1\\times card(\\Omega_n)}}\\) es un vector unitario de tama√±o \\(\\small{1\\times card(\\Omega_n)}\\) con un \\(\\small{1}\\) asociado al \\(i\\)-√©simo estado. Si todo los espacios de estados son iguales \\(\\small{(\\Omega_1=\\cdots=\\Omega_n)}\\),entonces la Eq. (2.10) se reduce a Eq. (2.9).\n\n\n\nTradicionalmente, dentro de una sucesi√≥n de ensayos Bernoulli (i.i.d. √©xito-fracaso), una racha denota una sucesi√≥n de √©xitos o fracasos consecutivos. Por ejemplo una racha de √©xitos de tama√±o 4 implica el patr√≥n \\(\\small{SSSS}\\). Varias de las estad√≠sticas de rachas que se utilizan a menudo en estad√≠stica y probabilidad aplicada para una sucesi√≥n de \\(n\\) ensayos Bernoulli son:\n(i) \\(\\small{N_{n,k}}\\) el n√∫mero rachas de \\(\\small{k}\\) √©xitos consecutivos no solapados, en el sentido del conteo de Feller (1968);\n(ii) \\(\\small{M_{n,k}}\\) el n√∫mero de rachas de \\(\\small{k}\\) √©xitos consecutivos solapados;\n(iii) \\(\\small{E_{n,k}}\\) el n√∫mero de rachas de √©xitos de tama√±o exactamente igual a \\(\\small{k}\\), en el sentido del conteo de Mood (1940);\n(iv) \\(\\small{G_{n,k}}\\) el n√∫mero de rachas de √©xitos de tama√±o mayor o igual que \\(\\small{k}\\) ;\n(v) \\(\\small{L_{n}(S)}\\) el tama√±o de la racha de √©xitos m√°s larga.\nQuiz√°s la forma m√°s sencilla de comprender las definiciones dadas de estas estad√≠sticas de rachas y el procedimiento de conteo de solapado/no solapado, sea mediante el siguiente ejemplo. Supongamos que hay \\(\\small{n = 10}\\) ensayos de Bernoulli, con realizaci√≥n \\(\\small{SSFSSSSFFF}\\). Entonces \\(\\small{L_{10}(S) = 4}\\), y para \\(\\small{k = 2}\\), tenemos \\(\\small{N_{10,2} = 3, M_{10,2} = 4, E_{10,2} = 1}\\) y \\(\\small{G_{10,2} = 2}\\)\nDe las definiciones de estas estad√≠sticas de rachas, se deduce por inspecci√≥n que las siguientes relaciones siempre son verdaderas:\n\n\n\\[\\begin{equation}\nE_{n,k}\\leq G_{n,k} \\leq N_{n,k} \\leq M_{n,k}\\\\\nE_{n,k} = G_{n,k} - G_{n,k+1}\\\\\nL_n(S)&lt;k\\quad\\text{si y solo si }N_{n,k}=0\n\\end{equation}\\]\n\nPara ampliar las definiciones de rachas, consideremos una sucesi√≥n de \\(\\small{n}\\) ensayos multiestados \\(\\small{\\{{X}\\}_{t=1}^{n}}\\), cada una de las cuales tiene \\(\\small{m \\geq 2}\\) estados o s√≠mbolos como posibles resultados. Estos s√≠mbolos se denotan por \\(\\small{b_1,b_2,\\ldots,b_m}\\) y ocurren con probabilidades \\(\\small{p_1,p_2,\\ldots,p_m}\\), respectivamente. A continuaci√≥n, definimos tres tipos de patrones generales: un patr√≥n simple, un patr√≥n compuesto y un patr√≥n en serie.\nDefinici√≥n 2.3 Decimos que \\(\\small{\\Lambda}\\) es un patron simple, si esta conformado por una determinada serie de \\(\\small{k}\\) s√≠mbolos, i.e, \\(\\small{\\Lambda=b_{i_1}b_{i_2}\\cdots b_{i_k}}\\) con \\(\\small{i_j\\in \\{1,2,\\ldots,m\\}}\\), para todo \\(\\small{j=1,\\dots,k}\\). La longitud del patr√≥n es fija y los s√≠mbolos en el patr√≥n puede repetirse.\nLas rachas de √©xito y fracaso de tama√±o \\(\\small{k}\\) son por tanto patrones simples seg√∫n esta definici√≥n, y de hecho cualquier sucesi√≥n de √©xitos y fracasos de longitud fija, digamos \\(\\small{\\Lambda =SSFSF}\\), puede considerarse un patr√≥n simple dentro de una sucesi√≥n de de \\(\\small{n}\\) ensayos de dos estados \\(\\small{(m = 2)}\\).\nAhora, sean \\(\\small{\\Lambda_1}\\) y \\(\\small{\\Lambda_2}\\) dos patrones simples de longitudes/tama√±os \\(\\small{k_1}\\) y \\(\\small{k_2}\\) , respectivamente. Decimos que \\(\\small{\\Lambda_1}\\) y \\(\\small{\\Lambda_2}\\) son distintos si ni \\(\\small{\\Lambda_1}\\) incluye a \\(\\small{\\Lambda_2}\\) ni \\(\\small{\\Lambda_2}\\) incluye a \\(\\small{\\Lambda_1}\\). Definimos \\(\\small{\\Lambda_1 \\cup\\Lambda_2}\\) como la ocurrencia de uno de los dos patr√≥n \\(\\small{\\Lambda_1}\\) o \\(\\small{\\Lambda_2}\\) , y definimos \\(\\small{\\Lambda_1 \\ast\\Lambda_2}\\) como la ocurrencia de patr√≥n \\(\\small{\\Lambda_1}\\) seguido del patr√≥n \\(\\small{\\Lambda_1}\\) (quiz√°s con una separaci√≥n entre ellos).\nDefinici√≥n 2.4 Decimos que \\(\\small{\\Lambda}\\) es un patr√≥n compuesto si es la uni√≥n de \\(\\small{1 &lt; l &lt;\\infty}\\) patrones simples distintos solapados/no solapados, es decir, \\(\\small{\\Lambda=\\displaystyle\\bigcup_{i=1}^{l}\\Lambda_i}\\).\nDefinici√≥n 2.5 Decimos \\(\\small{\\Lambda}\\) es un patr√≥n en serie si \\(\\small{\\Lambda}\\) est√° compuesto por una sucesi√≥n ordenada de \\(\\small{1 &lt; l &lt;\\infty}\\) patrones simples distintos no superpuestos \\(\\small{\\Lambda_i}\\), es decir, \\(\\small{\\Lambda=\\Lambda_1 \\ast\\Lambda_2\\ast\\cdots\\Lambda_l}\\)\nA lo largo de este libro, la variable aleatoria \\(\\small{X_n(\\Lambda)}\\) representa el n√∫mero de ocurrencias del patr√≥n \\(\\small{\\Lambda}\\) en una sucesi√≥n de \\(\\small{n}\\) ensayos multiestado, utilizando el recuento con solapamiento o sin solapamiento. Para aclarar las tres definiciones de patrones y los dos m√©todos de recuento para los ensayos multiestado, presentamos el siguiente ejemplo.\nEjemplo 2.3 Sea \\(\\small{\\{X_t\\}_{t=1}^{16}}\\) una sucesi√≥n de diecis√©is ensayos de un proceso de cuatro estados, en donde los resultados posibles para cada ensayo son \\(\\small{A, G, C}\\) y \\(\\small{T}\\). Sea \\(\\small{\\Lambda_1=AGAG}\\) y \\(\\small{\\Lambda_2=AGT}\\) dos patrones simples distintos, \\(\\small{\\Lambda=\\Lambda_1 \\cup\\Lambda_2}\\) un patr√≥n compuesto y \\(\\small{\\Lambda^{\\ast}=\\Lambda_1 \\ast\\Lambda_2}\\) un patron en serie. Supongamos que la realizaci√≥n de esta sucesi√≥n de diecis√©is ensayos es \\(\\small{TAGAGAGTCAGAGTCC}\\), entonces:\n(i) \\(\\small{X_{16}(\\Lambda_1)}\\) es \\(\\small{3}\\) con conteo solapado y es \\(\\small{2}\\) con conteo no solapado,\n(ii) \\(\\small{X_{16}(\\Lambda)}\\) es \\(\\small{5}\\) con conteo solapado y es \\(\\small{3}\\) con conteo no solapado,\n(iii) \\(\\small{X_{16}(\\Lambda^{\\ast})}\\) es igual a \\(\\small{1}\\).\n(iv) \\(\\small{X_{16}(\\Lambda_2)}\\) es \\(\\small{2}\\).\nLas definiciones anteriores de rachas y patrones en una sucesi√≥n de ensayos de m√∫ltiples estados tambi√©n se pueden extender a permutaciones aleatorias \\(\\small{\\{\\pi : \\pi=(\\pi (1),\\ldots,\\pi(n)) \\}}\\) de \\(\\small{n}\\) enteros \\(\\small{\\{1, 2, \\ldots, n\\}}\\). Por ejemplo, el n√∫mero Euleriano \\(\\small{E(\\pi, n)}\\), el n√∫mero de aumentos en una permutaci√≥n aleatoria \\(\\small{\\pi}\\) (ver Carlitz 1964, Tanny 1973 y Worpitzky 1883), podr√≠a verse como una variable aleatoria \\(\\small{X_n(\\Lambda)}\\) con el patr√≥n \\(\\small{\\Lambda}\\) siendo un aumento. Matem√°ticamente, el n√∫mero de Euler se puede definir como\n\n\n\\[\\begin{equation}\nE(\\pi,n)=X_n(\\Lambda)=\\displaystyle \\sum_{i=0}^{n-1}I(\\pi,i),\n\\end{equation}\\]\n\nen donde \n\n\\[\\begin{equation}\nI(\\pi,i)=\\begin{cases}\n1 \\quad \\text{si }\\pi(i)&lt;\\pi(i+1) \\\\\n0 \\quad \\text{en otro caso }\n\\end{cases}\n\\end{equation}\\]\n\n\\[I(\\pi,i)=\\begin{cases}\n1 \\quad \\text{si }\\pi(i)&lt;\\pi(i+1) \\\\\n0 \\quad \\text{en otro caso,}\n\\end{cases}\\]\npara \\(\\small{i=1,\\ldots,n-1}\\), con \\(\\small{I(\\pi,i)=1}\\) por convenci√≥n (la brecha inicial que precede a la primera permutaci√≥n siempre se considera un aumento). Por ejemplo, el n√∫mero de aumentos \\(\\small{E(\\pi, 9)}\\) en la permutaci√≥n aleatoria \\(\\small{\\pi = (321459768)}\\) de 9 n√∫meros enteros son 5.\nEn vista de las definiciones y ejemplos anteriores, uno deber√≠a esperar que la distribuci√≥n exacta de la variable aleatoria \\(\\small{X_n(\\Lambda)}\\) dependa en gran medida de tres factores importantes:\n(a) la estructura del patr√≥n \\(\\small{\\Lambda}\\) ,\n (b) la estructura de la sucesi√≥n \\(\\small{\\{{X}\\}_{t=1}^{n}}\\) de \\(n\\) ensayos (o permutaciones aleatorias),\n (c) el procedimiento de conteo (conteo superpuesto o no superpuesto).\nDebido a estos factores, la determinaci√≥n anal√≠tica de distribuciones exactas mediante enfoques tradicionales como la combinatoria puede ser bastante desafiante y generalmente compleja, involucrando identidades especiales y un √°lgebra extensa. En consecuencia, las distribuciones exactas de muchas estad√≠sticas utilizadas en aplicaciones pr√°cticas nunca se han estudiado utilizando tales m√©todos, especialmente cuando los ensayos subyacentes no son i.i.d. (por ejemplo, Markov-dependientes).\nEn la siguiente subsecci√≥n, describimos una t√©cnica que permite obtener una representaci√≥n matricial compacta para la distribuci√≥n exacta de una manera relativamente simple y universal al incorporar la variable aleatoria \\(\\small{X_n(\\Lambda)}\\) en una cadena de Markov finita; la expresi√≥n resultante tambi√©n es muy adecuada para un an√°lisis m√°s detallado de propiedades estad√≠sticas, para el desarrollo de aproximaciones de grandes desviaciones y para una implementaci√≥n num√©rica eficiente para el c√°lculo de probabilidades exactas.\n\n\n\nLa t√©cnica de Incrustaci√≥n de Cadenas de Markov Finitas (ICMF) para encontrar la distribuci√≥n de la variable aleatoria \\(\\small{X_n(\\Lambda)}\\) tiene sus or√≠genes en una serie de art√≠culos de Fu (1985, 1986), Fu y Hu (1987), Chao y Fu (1989, 1991), y Fu y Lou (1991). El t√©rmino ‚ÄúCadena de Markov Finita Incrustable‚Äù para describir una variable aleatoria fue introducido formalmente por Fu y Koutras (1994).\nSea \\(\\small{\\Gamma_n=\\{0,1\\ldots,n\\}}\\) un conjunto de indices, y \\(\\small{\\Omega=\\{a_1,a_2,\\ldots,a_m\\}}\\) un espacio de estados finito.\nDefinicion 2.6 La variable aleatoria no negativa de valores enteros \\(\\small{X_n(\\Lambda)}\\), es una cadena de Markov finita incrustable si:\n(a). Existe una cadena de Markov finita \\(\\small{\\{Y_t:t\\in \\Gamma\\}}\\) definida sobre un espacio de estados \\(\\small{\\Omega}\\) finito, con vector de probabilidades inicial \\(\\small{\\boldsymbol{\\xi}_0}\\).\n(b). Existe una partici√≥n finita \\(\\small{\\{C_x:x=0,1,\\ldots,l_n\\}}\\) sobre el espacio de estado \\(\\small{\\Omega}\\).\n(c). Para todo \\(\\small{x=0,1,\\ldots,l_m}\\) tenemos: \\[\\small{\\mathbb{P}\\{X_n(\\Lambda)=x\\}=\\mathbb{P}\\{Y_n\\in C_x \\mid \\boldsymbol{\\xi}_0\\}.}\\] Sea \\(\\small{\\{\\boldsymbol{M}_t\\}_{t=1}^{n}}\\) una sucesi√≥n de matrices de probabilidades de transici√≥n de orden \\(\\small{m\\times m}\\) de una cadena finita de Markov \\(\\small{\\{Y_t\\}}\\) definida sobre un espacio de estados \\(\\small{\\Omega}\\) con distribuci√≥n de probablidad inicial \\(\\small{\\boldsymbol{\\xi}_0=\\big(\\mathbb{P}\\{Y_0=a_1\\},\\mathbb{P}\\{Y_0=a_2\\},\\ldots,\\mathbb{P}\\{Y_0=a_m\\}\\big)}\\)\nTeorema 2.1 Si \\(\\small{X_n(\\Lambda)}\\) es una cadena finita de Markov incrustable, entoces\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\{ X_n(\\Lambda)=x\\}=\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\prod_{t=1}^{n}\\boldsymbol{M}_t\\Big)\\boldsymbol{\\mathbf{U}'}({C_x})\n\\end{equation}\\]\n\nsiendo \\(\\small{\\boldsymbol{\\mathbf{U}}({C_x})=\\displaystyle\\sum_{r: a_r\\in C_x}\\boldsymbol{e}_r}\\) y \\(\\small{\\boldsymbol{e}_r=(0,\\ldots,1,\\ldots,0)_{1\\times m}}\\) es un vector unitario de tama√±o \\(\\small{1\\times m}\\) con un \\(\\small{1}\\) asociado al estado \\(\\small{a_r}\\) e \\(\\small{\\boldsymbol{\\mathbf{\\xi}}_0}\\) vector de probabilidades iniciales, y \\(\\small{\\boldsymbol{M}_t\\,,\\,\\,t=1,\\dots,n}\\) son las matrices de probabilidades de transici√≥n de la cadena de Markov incrustada.\nPrueba: Dado que \\(\\small{X_n(\\Lambda)}\\) es una cadena de Markov finita incrustable, se deduce de Definici√≥n 2.6(a) de que existe una cadena de Markov finita \\(\\small{\\{Y_t : t\\in \\Gamma_n \\}}\\) con probabilidades iniciales \\(\\small{\\boldsymbol{\\mathbf{\\xi}}_0}\\). Luego por la ecuaci√≥n de Chapman-Kolmogorov descrita en Secci√≥n 2.2, para cada \\(\\small{a_r\\in \\Omega}\\), tenemos\n\n\n\\[\\begin{equation}\n\\mathbb{P}(Y_n =a_r \\mid \\boldsymbol{\\mathbf{\\xi}}_0)=\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\prod_{t=1}^{n}\\boldsymbol{M}_t\\Big)\\boldsymbol{e_r'}\n\\end{equation}\\]\n\nAdem√°s, de las Definiciones 2.6(b) y (c) se deduce que, para cada \\(\\small{x =0,1\\ldots,l_n}\\),\n\n\n\\[\\begin{equation}\n\\begin{split}\n\\mathbb{P}\\{ X_n(\\Lambda)=x\\} & =  \\mathbb{P}(Y_n \\in C_x \\mid \\boldsymbol{\\mathbf{\\xi}}_0) \\\\\n& = \\sum_{a_r\\in C_x}\\mathbb{P}\\{Y_n=a_r\\mid \\boldsymbol{\\mathbf{\\xi}_0}\\}\\\\\n& = \\sum_{a_r\\in C_x} \\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\prod_{t=1}^{n}\\boldsymbol{M}_t\\Big)\\boldsymbol{e_r'}\\\\\n& = \\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\prod_{t=1}^{n}\\boldsymbol{M}_t\\Big)\\boldsymbol{\\mathbf{U}'}( {C_x})\\quad \\quad \\quad \\quad \\quad \\Box\n\\end{split}\n\\end{equation} \\Box\\]\n\nEl \\(\\small{k-}√©simo\\) momento \\(\\small{\\mathbb{E}\\{X_n^k(\\Lambda)\\},\\,\\,k=1,2,\\ldots,}\\) puede expresarse como:\n\n\n\\[\\begin{equation}\n\\mathbb{E}\\{X_n^k(\\Lambda)\\}=\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\prod_{t=1}^{n}\\boldsymbol{M}_t\\Big)\\boldsymbol{{V}_k'}\n\\end{equation}\\]\n\nen donde\n\n\n\\[\\begin{equation}\n\\boldsymbol{{V}_k'}=\\sum_{x=0}^{l_n}x^{k}\\boldsymbol{U}(\\mathbf{C_x})\n\\end{equation}\\]\n\nDe manera √°naloga la funci√≥n generadora de probabilidad de la variable aleatoria \\(\\small{X_n(\\Lambda)}\\) puede escribirse como:\n\n\n\\[\\begin{equation}\n\\psi(s)= \\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\prod_{t=1}^{n}\\boldsymbol{M}_t\\Big)\\boldsymbol{W'}(s)\n\\end{equation}\\]\n\nen donde \n\n\\[\\begin{equation}\n\\boldsymbol{W}(s)=\\sum_{x=0}^{l_n}s^{x}\\boldsymbol{U}(\\mathbf{C_x})\n\\end{equation}\\]\n\nLos funciones generadoras de probabilidad y de momentos se discutir√°n dentro del contexto de aplicaciones espec√≠ficas en secciones posteriores.\nEjemplo 2.4 (N√∫mero de parejas de resultados sucesivos id√©nticos). Sea \\(\\small{\\{X_t:t = 0,1,\\ldots, n\\}}\\) una sucesi√≥n de \\(\\small{n}\\) ensayos Markov-dependientes homog√©neos con \\(\\small{m}\\) estados y matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{A}_{m\\times m} = \\big(P_{ij}\\big)}\\) y una distribuci√≥n de probabilidad inicial \\(\\small{\\boldsymbol{\\xi}_0=\\big(\\mathbb{P}\\{X_0=1\\},\\mathbb{P}\\{X_0=2\\},\\ldots,\\mathbb{P}\\{X_0=m\\}\\big)=(1/m,1/m,\\ldots,1/m)}\\). Definiendo una sucesi√≥n de funciones indicadoras\n\n\n\\[\\begin{equation}\nI_i=\\begin{cases}\n1 \\quad \\text{si }X_t=X_{t-1}\\\\\n0 \\quad \\text{en otro caso}\n\\end{cases}\n\\end{equation}\\]\n\npara todo \\(\\small{t=1,\\ldots,n}\\)\nEn este ejemplo, nos interesa el n√∫mero de veces que un resultado particular (uno de \\(\\small{m}\\) resultados posibles) en un ensayo determinado se repite en el ensayo inmediatamente siguiente. En t√©rminos matem√°ticos, definimos el patr√≥n \\(\\small{\\Lambda}\\) para denotar dicho resultado repetido, un patr√≥n que est√° presente en el √≠ndice de tiempo \\(\\small{1 \\leq t \\leq n}\\) si \\(\\small{X_{t-1} = X_t}\\) o, de manera equivalente en t√©rminos de la funci√≥n indicadora anterior, si \\(\\small{I_t = 1}\\). La estad√≠stica de rachas:\n\n\n\\[\\begin{equation}\nX_n(\\Lambda)= \\sum_{t=1}^{n}I_t\n\\end{equation}\\]\n\ncorresponde al n√∫mero de veces que ocurri√≥ el patr√≥n \\(\\small{\\Lambda}\\) en la sucesi√≥n \\(\\small{\\{X\\}_{t=0}^{n}}\\) de \\(\\small{n}\\) ensayos Markov-dependientes con \\(\\small{m}\\) estados. En el sector sanitario, por ejemplo, la estad√≠stica \\(\\small{X_n(\\Lambda)/n}\\) se conoce como \\(SECON\\) y forma la medida principal de continuidad secuencial en una serie de \\(\\small{n}\\) visitas de pacientes a \\(\\small{m}\\) posibles proveedores de atenci√≥n sanitaria ( Steinwachs 1979).\nUna dificultad aqu√≠ es que las variables aleatorias \\(\\small{\\{I_t\\}}\\) no son independientes y no conforman una cadena de Markov, incluso si la sucesi√≥n \\(\\small{\\{X\\}_{t=0}^{n}}\\) se extrajera de ensayos i.i.d. de \\(\\small{m}\\) estados. De hecho, se puede demostrar que las variables aleatorias \\(\\small{\\{I_t\\}}\\) son dependientes y est√°n correlacionadas positivamente probando que \\(\\small{Cov(I_i, I_j) &gt; 0}\\) para todo \\(\\small{i}\\) y \\(\\small{j}\\), con \\(\\small{Cov(I_i, I_j) \\rightarrow 0}\\) cuando \\(\\small{\\mid i-j \\mid\\rightarrow 0}\\). Sin embargo, como se indica a continuaci√≥n, la distribuci√≥n exacta a√∫n se puede obtener f√°cilmente utilizando la t√©cnica de incrustaci√≥n de cadenas de Markov finitas.\nPrimero, descomponemos la matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{A}}\\) en dos matrices \\(\\small{\\boldsymbol{G}}\\) y \\(\\small{\\boldsymbol{D}}\\), donde la matriz \\(\\small{\\boldsymbol{D}}\\) contiene s√≥lo los elementos diagonales de \\(\\small{\\boldsymbol{A}}\\); es decir:\n\n\n\\[\\begin{equation}\n\\boldsymbol{A}_{m\\times m}=\\boldsymbol{G}_{m\\times m}+\\boldsymbol{D}_{m\\times m}\n\\end{equation}\\]\n\nen donde: \n\n\\[\\begin{equation}\n\\boldsymbol{G}_{m\\times m}=\n\\begin{pmatrix}\n0 & p_{ij} & \\cdots \\\\\n  & \\ddots &        \\\\\n\\cdots & p_{ij} & 0\n\\end{pmatrix}\n\\quad \\text{y} \\quad\n\n\\boldsymbol{D}_{m\\times m}=\n\\begin{pmatrix}\np_{11} &  & \\boldsymbol{0} \\\\\n  & \\ddots &        \\\\\n\\boldsymbol{0} &   & p_{mm}\n\\end{pmatrix}\n\\end{equation}\\]\n\nSea \\(\\small{\\Omega=\\{(u,v): u = 0,\\ldots,n, \\text{ y }v = 1,2,\\ldots, m\\}}\\) el espacio de estados que contiene un total de \\(\\small{(n+1)m}\\) estados. Dado \\(\\small{n}\\), se define una cadena de Markov homog√©nea y finita \\(\\small{\\{Y_t: t\\in \\Gamma\\}}\\) en el espacio de estados \\(\\small{\\Omega}\\) como\n\n\n\\[\\begin{equation}\nY_t=\\begin{cases}\n\\Big(\\displaystyle\\sum_{i=1}^{t}I_i, X_t \\Big) \\quad \\text{si } 1 \\leq t \\leq n\\\\\n\\big(0,X_0\\big) \\quad t=0\n\\end{cases}\n\\end{equation}\\]\n\ncon matriz de probabilidades de transici√≥n:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\\begin{pmatrix}\n\\boldsymbol{G} & \\boldsymbol{D} & \\boldsymbol{O} & \\cdots & \\boldsymbol{O}\\\\\n\\boldsymbol{O} & \\boldsymbol{G} & \\boldsymbol{D} & \\cdots & \\boldsymbol{O} \\\\\n\\vdots & \\ddots & \\ddots & \\ddots & \\vdots \\\\\n\\boldsymbol{O} & \\cdots & \\cdots & \\boldsymbol{G}& \\boldsymbol{D}\\\\\n\\boldsymbol{O} & \\boldsymbol{O} & \\cdots & \\boldsymbol{O}& \\boldsymbol{I}\\\\\n\\end{pmatrix}\n\\end{equation}\\]\n\ndonde \\(\\small{\\boldsymbol{M}}\\) es una matriz \\(\\small{(n + 1)m \\times (n + 1)m}\\), \\(\\small{\\boldsymbol{O}}\\) representa la matriz cero \\(\\small{m\\times m}\\) e \\(\\small{\\boldsymbol{I}}\\) es la matriz identidad \\(\\small{m\\times m}\\). Los estados en \\(\\small{\\boldsymbol{M}}\\) est√°n ordenados en orden lexicogr√°fico (diccionario). Por √∫ltimo, defininiendo la partici√≥n \\(\\small{\\{C_x: x=0,1,2,\\ldots,n\\}}\\) en el espacio de estados \\(\\small{\\boldsymbol{\\Omega}}\\) como\n\n\n\\[\\begin{equation}\nC_x=\\{(x,v): v=1,2,\\ldots,m\\}\n\\end{equation}\\]\n\nDadas las definiciones anteriores para la cadena de Markov \\(\\small\\{Y_t\\}\\), la variable aleatoria \\(\\small{X_n(\\Lambda)}\\) es, seg√∫n la Definici√≥n 2.6, una cadena de Markov finita incrustable y su distribuci√≥n exacta se desprende del Teorema 2.1: para \\(\\small{0 \\leq x \\leq n}\\),\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\{X_n(\\Lambda)=x\\}=\\boldsymbol{\\xi_0}\\begin{pmatrix}\n\\boldsymbol{G} & \\boldsymbol{D} & \\boldsymbol{O} & \\cdots & \\boldsymbol{O}\\\\\n\\boldsymbol{O} & \\boldsymbol{G} & \\boldsymbol{D} & \\cdots & \\boldsymbol{O} \\\\\n\\vdots & \\ddots & \\ddots & \\ddots & \\vdots \\\\\n\\boldsymbol{O} & \\cdots & \\cdots & \\boldsymbol{G}& \\boldsymbol{D}\\\\\n\\boldsymbol{O} & \\boldsymbol{O} & \\cdots & \\boldsymbol{O}& \\boldsymbol{I}\\\\\n\\end{pmatrix}^{n}\\boldsymbol{U'}(C_x)\n\\end{equation}\\]\n\ndonde \\(\\small{\\boldsymbol{\\xi_0}(\\pi_0,0,\\ldots,0)_{(n+1)\\times m}}\\) es la distribuci√≥n inicial del vector de estado \\(\\small{Y_0}\\), y \\(\\small{\\boldsymbol{U'}(C_x): (0,\\ldots, 0, \\underbrace{1, 1, ..., 1}_{C_x}, 0,\\ldots,0)}\\) es un vector de fila \\(\\small{1 \\times(n+1)m}\\) con \\(\\small{1}\\) en las coordenadas asociadas con los estados en \\(\\small{C_x}\\) y cero en otros posiciones. En el Cap√≠tulo 7 se dar√°n m√°s detalles y un ejemplo num√©rico de este problema.\nKoutras y Alexandrou (1995) introdujeron la noci√≥n de variables incrustables en cadenas finitas de Markov de tipo binomial (MVBS), y muchas estad√≠sticas comunes para rachas y patrones caen en esta categor√≠a especial. Sea la partici√≥n \\(\\small{ \\{C_x\\}=\\{[(x, v): v=1,...,r], \\text{ para } x = 0, 1,\\ldots, l_n\\}}\\), la partici√≥n del espacio de estados \\(\\small{\\Omega}\\).\nDefinici√≥n 2.7 Una variable aleatoria \\(\\small{X_n(\\Lambda)}\\) es una cadena de Markov finita incrustable de tipo binomial si:\n(i) \\(\\small{X_n(\\Lambda)}\\) es una cadena de Markov finita incrustable como en la Definici√≥n 2.6.\n(ii) \\(\\small{\\mathbb{P}\\{Y_t=(y,j) \\mid Y_{t-1} =(x,i)\\} \\equiv 0}\\) para todo \\(\\small{y\\neq x}\\) o \\(\\small{x + 1}\\).\nPara cualquier \\(\\small{MVB}\\), introduzca dos matrices de probabilidad de transici√≥n \\(\\small{r\\times r}\\):\n\n\n\\[\\begin{equation}\n\\boldsymbol{A_t}(x) = \\big(a_{ij}(t)\\big) = \\Big(\\mathbb{P}\\{Y_t = (x,j)\\mid Y_{t‚àí1} = (x, i)\\}\\Big)\n\\end{equation}\\]\n\ny \n\n\\[\\begin{equation}\n\\boldsymbol{B_t}(x) = \\big(b_{ij}(t)\\big) = \\Big(\\mathbb{P}\\{Y_t = (x+1,j)\\mid Y_{t‚àí1} = (x, i)\\}\\Big)\n\\end{equation}\\]\n\nPor tanto las matrices de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M_t}}\\) de la cadena de Markov incrustada tienen la siguiente forma: \n\n\\[\\begin{equation}\n\\boldsymbol{M}=\\begin{pmatrix}\n\n\\boldsymbol{A}_t(0) & \\boldsymbol{B}_t(0) & \\boldsymbol{O} & \\cdots &\\cdots  & \\boldsymbol{O} \\\\\n\n\\boldsymbol{O} &\\boldsymbol{A}_t(1) & \\boldsymbol{B}_t(1)  & \\boldsymbol{O} & \\cdots  & \\boldsymbol{O}\\\\\n\n\\vdots & \\boldsymbol{O} & \\ddots & \\ddots & \\ddots & \\vdots \\\\\n\\vdots & \\ddots & \\boldsymbol{O}& \\ddots & \\ddots & \\boldsymbol{O} \\\\\n\\vdots & \\cdots & \\cdots & \\boldsymbol{O}& \\boldsymbol{A}_t(l_n-1) & \\boldsymbol{B}_t(l_n-1) \\\\\n\\boldsymbol{O} & \\boldsymbol{O} & \\cdots &  \\boldsymbol{O}& \\boldsymbol{O} &  \\boldsymbol{A}_t(l_n) \\\\\n\\end{pmatrix}\n\\end{equation}\\]\n\npara \\(\\small{t = 1,\\ldots,n}\\), en donde los estados est√°n ordenados en orden lexicogr√°fico (diccionario). Hay muchas estad√≠sticas para rachas y patrones con matrices de transici√≥n que tienen esta forma, como, por ejemplo, las estad√≠sticas de rachas \\(\\small{N_{n,k},\\, M_{n,k}\\, \\text{y}\\, G_{n,k}}\\) introducidas en la Secci√≥n 2.4 (y estudiadas m√°s a fondo en el Cap√≠tulo 3).\nPara \\(\\small{MVB¬¥s}\\), se puede derivar una ecuaci√≥n recursiva eficiente para la distribuci√≥n de \\(\\small{X_n(\\Lambda)}\\), que aprovecha parcialmente la estructura de bandas de las matrices de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M}_t}\\). Sea el vector fila \\(\\small{\\boldsymbol{\\alpha}_t(x)=\\big(\\mathbb{P}\\{Y_t=(x,1)\\},\\ldots, \\mathbb{P}\\{Y_t=(x,1)\\}\\big)}\\) , para \\(\\small{t= 1,\\ldots, n}\\), de modo que la probabilidad de \\(\\small{X_n(\\Lambda)=x}\\) se puede representar como\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\{X_n(\\Lambda)=x \\mid \\boldsymbol{\\xi}_0\\}=\n\\boldsymbol{\\alpha}_n(x)\\boldsymbol{1}', \\, \\text{para toda}\\,\\,\nx=0,1,\\dots,l_n\n\\end{equation}\\]\n\ndonde \\(\\small{\\boldsymbol{1}'=(1,\\ldots,1)'}\\). Descomponga \\(\\small{\\boldsymbol{M}_t}\\) como \\(\\small{\\boldsymbol{M}_t=\\boldsymbol{K}_t+\\boldsymbol{H}_t}\\), donde \\(\\small{\\boldsymbol{K}_t}\\) es una matriz diagonal con componentes \\(\\small{\\boldsymbol{A}_t(x)}\\), para \\(\\small{x = 0,1,\\ldots,l_n}\\), y \\(\\small{\\boldsymbol{H}_t}\\) es una matriz diagonal superior con componentes \\(\\small{\\boldsymbol{B}_t(x)}\\), para \\(\\small{x = 0,1,\\ldots,l_{n-1}}\\). A partir de la multiplicaci√≥n hacia atr√°s, \\(\\small{\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\displaystyle\\prod_{j=1}^{t}\\boldsymbol{M}_j\\Big)=\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\displaystyle\\prod_{j=1}^{t-1}\\boldsymbol{M}_j\\Big)\\boldsymbol{M}_t=\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\displaystyle\\prod_{j=1}^{t-1}\\boldsymbol{M}_j\\Big)\\big(\\boldsymbol{K}_t+\\boldsymbol{H}_t\\big)}\\), puede demostrarse que se cumplen las siguientes ecuaciones recursivas:\n\n\n\\[\\begin{align*}\n\\boldsymbol{\\alpha_t}(0)&=\\boldsymbol{\\alpha_{t-1}}(0)\\boldsymbol{A_t}(0) \\\\\n\\boldsymbol{\\alpha_t}(X)&=\n\\boldsymbol{\\alpha_{t-1}}(x-1)\\boldsymbol{B_{t-1}}(t-1)+\\boldsymbol{\\alpha_{t-1}}(x)\\boldsymbol{A_t}(x),\\, x=1,\\ldots,l_n.\n\\end{align*}\\]\n\nLa ecuaci√≥n (2.17) proporciona un algoritmo eficiente para calcular las probabilidades \\(\\small{ \\mathbb{P}\\{X_n(\\Lambda)=x \\mid\\boldsymbol{\\xi}_0\\}=\\boldsymbol{\\alpha}_n(x)\\boldsymbol{1}', \\, \\text{para toda }\\, x=0,1,\\dots,l_n}\\), y esto es especialmente importante cuando la dimensi√≥n de las matrices de transici√≥n \\(\\small{\\boldsymbol{M_t}}\\) es grande y el esfuerzo computacional para calcular ingenuamente \\(\\small{\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\displaystyle\\prod_{t=1}^{n}\\boldsymbol{M}_t\\Big)\\boldsymbol{U'}(C_x)}\\) se vuelve prohibitivo. A partir de la multiplicaci√≥n hacia atr√°s, la t√©cnica de incrustaci√≥n de cadenas finitas de Markov a menudo proporciona una ecuaci√≥n recursiva en una forma similar a la ecuaci√≥n (2.17), una forma que, en general, no puede obtenerse tan f√°cilmente mediante los m√©todos combinatorios o de renovaci√≥n tradicionales.\n\n\n\nEn esta secci√≥n se derivan algunas expresiones √∫tiles para la probabilidad de entrar en un estado absorbente. Para mayor claridad de la exposici√≥n, nos centraremos en las cadenas de Markov homog√©neas, pero las ideas pueden generalizarse f√°cilmente a casos no homog√©neos.\nUn estado \\(\\small{\\alpha \\in \\Omega}\\) se llama estado absorbente si, una vez que el sistema entra en el estado \\(\\small{\\alpha}\\), nunca sale; es decir, \\(\\small{p_{\\alpha\\alpha}\\equiv 1}\\) (y \\(\\small{p_{\\alpha\\beta}\\equiv 0}\\) para cualquier \\(\\small{\\alpha\\neq\\beta}\\)). Sea \\(\\small{A=\\{\\alpha_1,\\ldots,\\alpha_k\\}}\\) el conjunto de todos los estados absorbentes de una cadena de Markov homog√©nea \\(\\small{\\{Y_t\\}}\\) con una matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M}}\\). Bajo una disposici√≥n apropiada del espacio de estados, la matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M}}\\) siempre se puede escribir de la siguiente forma:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\\left(\\begin{array}{c|c}\n\\boldsymbol{N}_{(m-k)\\times (m-k)} & \\boldsymbol{C}_{(m-k)\\times (m-k)}\\\\\n\\hline  \n\\boldsymbol{O}_{k\\times (m-k)} & \\boldsymbol{1}_{k \\times k}\n\\end{array}\\right)\n\\end{equation}\\]\n\ndonde \\(\\small{m}\\) y \\(\\small{k}\\) \\(\\small{(m&gt;k)}\\) son los n√∫meros de estados en \\(\\small{\\Omega}\\) y \\(\\small{A}\\), respectivamente. La matriz \\(\\small{\\boldsymbol{N}}\\) definida por la ecuaci√≥n. (2.18) se conoce como la submatriz de probabilidad de transici√≥n esencial de la cadena de Markov. Desempe√±a un papel importante en el estudio de las distribuciones exactas de variables aleatorias incrustables en cadenas de Markov, especialmente para las distribuciones asociadas de tiempos de espera.\nSea \\(\\small{\\boldsymbol{\\xi_{0}}=\\big(\\boldsymbol{\\xi}:\\boldsymbol{0}\\big)_{1\\times m}}\\) la distribuci√≥n inicial, donde \\(\\small{\\boldsymbol{\\xi}=(\\xi_1,\\ldots,\\xi_{m-k}), \\, \\boldsymbol{0}=(0,\\ldots,0)_{1\\times k}}\\) y \\(\\small{\\displaystyle{\\sum_{i=1}^{m-k}\\xi_i=1}}\\) y sea \\(\\small{\\big(\\boldsymbol{1:0}\\big)_{1\\times m}}\\) un vector fila, en donde \\(\\small{\\boldsymbol{1}=(1,\\ldots,1)_{1\\times (m-k)}}\\) La raz√≥n por la que suponemos que la distribuci√≥n inicial tiene la forma \\(\\small{\\big(\\boldsymbol{\\xi_0}:\\boldsymbol{0}\\big)}\\) es estrictamente por razones pr√°cticas, ya que la mayor√≠a de los sistemas siempre comienzan en un estado no absorbente.\nTeorema 2.2 Dada una matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M}}\\) de una cadena de Markov homog√©nea \\(\\small{\\{Y_t\\}}\\) en la forma de la ecuaci√≥n (2.18), la probabilidad para el √≠ndice de tiempo \\(\\small{n}\\) cuando el sistema ingresa por primera vez al conjunto de estados absorbentes puede ser obtenida como:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(Y_n\\in A,Y_{n-1}\\notin A,\\ldots,  Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)=\\boldsymbol{\\xi N}^{n-1}\\boldsymbol{(I-N)1'}\n\\end{equation}\\]\n\nDemostraci√≥n: Dado que \\(\\small{\\boldsymbol{M}}\\) tiene la forma de la Equaci√≥n 2.18, se sigue que:\n\n\n\\[\\begin{equation}\n\\mathbf{M}^{n-1}=\\left(\\begin{array}{c|c}\n\\boldsymbol{N}^{n-1} & \\boldsymbol{K}_{n-1}\\\\\n\\hline  \n\\boldsymbol{O} & \\boldsymbol{I}\n\\end{array}\\right)\n\\end{equation}\\]\n\nen donde \\(\\small{\\boldsymbol{K}_{n-1}=\\big( \\boldsymbol{I}+\\boldsymbol{N}+\\cdots+\\boldsymbol{N}^{n-2}\\big)\\boldsymbol{C}}\\). Adem√°s, como todos los estados en \\(\\small{\\boldsymbol{A}}\\) son estados absorbentes, de la ecuaci√≥n de Chapman-Kolmogorov se deduce que:\n\n\n\\[\\begin{align*}\n\\mathbb{P}\\big(Y_{n-1}\\notin A,\\cdots,  Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big) & =\\mathbb{P}\\big(Y_{n-1}\\in \\Omega-A\\mid \\boldsymbol{\\xi_0}\\big)\\\\\n& =\\big(\\boldsymbol{\\xi_0}:\\boldsymbol{0}\\big) \\boldsymbol{ M}^{n-1}\\big(\\boldsymbol{1}:\\boldsymbol{0}\\big)'.\n\\end{align*}\\]\n\nLuego la ecuaci√≥n (2.19) puede entonces deducirse utilizando las ecuaciones (2.20) y (2.21) a traves de:\n\n\n\\[\\begin{align*}\n& \\quad \\, \\, \\mathbb{P}\\big(Y_n\\in A,Y_{n-1}\\notin A,\\ldots,  Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)\\\\\n& =\\mathbb{P}\\big(Y_{n-1}\\notin A,\\ldots,  Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)-\\mathbb{P}\\big(Y_n\\notin A,Y_{n-1}\\notin A,\\ldots,  Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)\\\\\n& = \\big(\\boldsymbol{\\xi_0}:\\boldsymbol{0}\\big) \\boldsymbol{ M}^{n-1}\\big(\\boldsymbol{I-M}\\big)\\big(\\boldsymbol{1}:\\boldsymbol{0}\\big)' \\\\\n& =\\boldsymbol{\\xi N}^{n-1}\\boldsymbol{(I-N)1'}.\\hspace{8cm} \\Box\n\\end{align*}\\]\n\nEn vista de las Ecs. (2.20) y (2.21), los siguientes teoremas son inmediatos.\nTeorema 2.3 Para todo estado \\(\\small{i\\in \\Omega-A}\\)\n\n\n\\[\\begin{align*}\n\\mathbb{P}\\big(Y_{n-1}=i,Y_{n-2}\\notin A,\\ldots,  Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)= \\boldsymbol{\\xi N}^{n-1}\\boldsymbol{e_i'}.\n\\end{align*}\\]\n\nPrueba. Utilizando los mismos argumentos que en la demostraci√≥n del Teorema 2.2 y reemplazando \\(\\small{\\boldsymbol{1'}}\\) por \\(\\small{\\boldsymbol{e_i'}}\\), la Ec. (2.22) se sigue directamente de las ecuaciones (2.20) y (2.21). \\(\\hspace{1cm} \\Box\\)\nTeorema 2.4 Para cualquier estado absorbente \\(\\small{j \\in A}\\), la probabilidad del sistema para llegar por primera vez al estado absorbente \\(\\small{j}\\) en el \\(\\small{n}-\\)√©simo ensayo es:\n\n\n\\[\\begin{align*}\n\\mathbb{P}\\big(Y_{n}=j,Y_{n-1}\\notin A,\\ldots,  Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)= \\boldsymbol{\\xi N}^{n-1}{C_j'}.\n\\end{align*}\\]\n\nen donde, \\(\\small{C_j'}\\) es la \\(\\small{j}-\\)√©sima columna de la matriz \\(\\small{\\boldsymbol{C}}\\).\nPrueba: Para cualquier \\(\\small{j \\in A}\\), de la definici√≥n de la cadena de Markov y del Teorema 2.3 se deduce que:\n\n\n\\[\\begin{align*}\n& \\quad \\, \\mathbb{P}\\big(Y_{n-1}=j,Y_{n-1}\\notin A,\\ldots,  Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)\\\\\n& = \\sum_{i\\in \\Omega-A}\\mathbb{P}\\big(Y_{n-1}=i,Y_{n-2}\\notin A,\\ldots,  Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)\\times \\mathbb{P}\\big( Y_n=j\\mid Y_{n-1}=i \\big)\\\\\n&= \\sum_{i\\in \\Omega-A}\\boldsymbol{\\xi N}^{n-1}{e_i'}p_{ij}\\\\\n&= \\boldsymbol{\\xi N}^{n-1}\\sum_{i\\in \\Omega-A}{e_i'}p_{ij}\\\\\n&= \\boldsymbol{\\xi N}^{n-1}{C_j'}\\hspace{8cm}\n\\end{align*}\\]\n\nPara ilustrar los teoremas 2.2 a 2.4 y sus relaciones, proporcionamos el siguiente ejemplo sencillo.\nEjemplo 2.5 Sea \\(\\small{\\{Y_t\\}}\\) una cadena de Markov homog√©nea definida en el espacio de estados \\(\\small{\\{1, 2, 3, 4\\}}\\) con distribuci√≥n inicial \\(\\small{\\boldsymbol{\\xi_0}=\\big(\\xi : 0 \\big)=(1,0:0,0)}\\) y matriz de probabilidad de transici√≥n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\\begin{array}{cccc}&\n\\begin{array}{cccc}\n\\end{array}\n\\\\\n\\begin{array}{ccc}\n1 \\\\\n2 \\\\\n3\\\\\n4\\\\\n\\end{array}\n&\n\\left(\n\\begin{array}{cc|cc}\n1/2 & 1/4 & 1/4  &  0 \\\\\n1/3 & 1/3 & 0 &  1/3 \\\\\n\\hline\n0& 0  &  1 & 0 \\\\\n0&  0 & 0 &  1\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nen donde \\(\\small{A=\\{3,4\\}}\\) es el conjunto de estados absorbentes. Para \\(\\small{n = 3}\\) (tercer ensayo), las probabilidades de entrada del sistema en los estados absorbentes \\(\\small{3}\\) y \\(\\small{4}\\) son, respectivamente:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(Y_{3}=3,Y_{2}\\notin A,Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)=(0,1)\n\\left(\\begin{array}{cc}\n1/2 & 1/4\\\\\n1/3 & 1/3\\\\\n\\end{array} \\right)^{2}\n\\left(\\begin{array}{c}\n1/4\\\\\n0\\\\\n\\end{array} \\right)=\\frac{1}{12}\n\\end{equation}\\]\n\ny \n\n\\[\\begin{equation}\n\\mathbb{P}\\big(Y_{3}=4,Y_{2}\\notin A,Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)=(0,1)\n\\left(\\begin{array}{cc}\n1/2 & 1/4\\\\\n1/3 & 1/3\\\\\n\\end{array} \\right)^{2}\n\\left(\\begin{array}{c}\n0\\\\\n1/3\\\\\n\\end{array} \\right)=\\frac{5}{72}.\n\\end{equation}\\]\n\nAdem√°s, por el Teorema 2.2, la probabilidad de que el sistema entre por primera vez en el subconjunto \\(\\small{A=\\{3,4\\}}\\) en el tercer ensayo es\n\n\n\\[\\begin{align*}\n& \\quad \\,\\, \\mathbb{P}\\{Y_3\\in A,Y_{2}\\notin A,Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\}\\\\\n&=\\boldsymbol{\\xi N}^{3-1}\\boldsymbol{(I-N)1'}\\\\\n&=(0,1)\n\\left(\\begin{array}{cc}\n1/2 & 1/4\\\\\n1/3 & 1/3\\\\\n\\end{array} \\right)^{2}\n\\left[\n\\left(\\begin{array}{cc}\n1 & 0\\\\\n0 & 1\\\\\n\\end{array} \\right)-\n\\left(\\begin{array}{cc}\n1/2 & 1/4\\\\\n1/3 & 1/3\\\\\n\\end{array} \\right)\n\\right]\n\\left(\\begin{array}{c}\n1\\\\\n1\\\\\n\\end{array} \\right)\\\\\n& =\\frac{11}{72}\n\\end{align*}\\]\n\nComo verificaci√≥n de los resultados anteriores, observemos que:\n\n\n\\[\\begin{align*}\n\\mathbb{P}\\big(Y_3\\in A,Y_{2}\\notin A,Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)& =\n\\mathbb{P}\\big(Y_3= 3,Y_{2}\\notin A,Y_1\\notin A \\mid \\boldsymbol{\\xi_0} \\big)\\\\\n&+ \\mathbb{P}\\big(Y_3= 4,Y_{2}\\notin A,Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\\\\n&= \\frac{11}{72} \\hspace{5cm}\\Diamond\n\\end{align*}\\]\n\nDe forma m√°s general, puesto que para cada \\(\\small{i\\in \\Omega-A}\\)\n\n\\[\\begin{align*}\n\\sum_{j\\in A}p_{ij}= 1- \\sum_{j \\in \\Omega- A}p_{il}\n\\end{align*}\\]\n\nluego se deduce que \\(\\small{\\displaystyle\\sum_{j\\in A}C_j'=\\boldsymbol{(I-N)1'}}\\), y por tanto\n\n\n\\[\\begin{align*}\n\\sum_{j\\in A}\\boldsymbol{\\xi N}^{n-1}C_j'=\\boldsymbol{\\xi N}^{n-1}\\boldsymbol{(I-N)1'}\n\\end{align*}\\]\n\n\n\n\nUtilizando las ideas de la secci√≥n 2.6, podemos encontrar la probabilidad de que se produzca la primera entrada para cualquier subconjunto \\(\\small{B\\subset \\Omega}\\). Dado el subconjunto \\(\\small{B}\\), la matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M}}\\) de una cadena de Markov \\(\\small{\\{Y_t\\}}\\) homog√©nea siempre puede disponerse de la siguiente forma:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\n\\begin{array}{cc}\n{\\Omega-B} \\\\B \\end{array}\n\\left(\\begin{array}{c|c}\n\\boldsymbol{N} & \\boldsymbol{B}\\\\\n\\hline\n\\boldsymbol{J} &  \\boldsymbol{Q}\n\\end{array}\n\\right)\n\\end{equation}\\]\n\nTeorema 2.5 Sea \\(\\small{\\{Y_t\\}}\\) una cadena de Markov homog√©nea con matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M}}\\), en la forma de la ecuaci√≥n (2.25), y con distribuci√≥n inicial \\(\\small{\\boldsymbol{\\xi=(1:0)}}\\). Entonces, para un subconjunto \\(\\small{B}\\) de tama√±o \\(\\small{k}\\) contenido en el espacio de estados \\(\\small{\\Omega}\\) de tama√±o \\(\\small{m}\\), se cumplen las siguientes relaciones:\n(i) Para todo \\(\\small{j \\in B}\\)\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(Y_n =j,Y_{n-1}\\notin B,\\cdots,Y_1\\notin B \\mid \\boldsymbol{\\xi_0}\\big)=\\boldsymbol{\\xi N}^{n-1}\\boldsymbol{B_j'},\n\\end{equation}\\]\n\nen donde \\(\\small{B_j'}\\) es la \\(\\small{j}-\\)√©sima columna de la matriz \\(\\small{\\boldsymbol{B}_{(m-k)\\times k}}\\) y\n(ii)\n\n\n\\[\\begin{align*}\n& \\quad \\,\\, \\mathbb{P}\\big(Y_n \\in B,Y_{n-1}\\notin B,\\cdots,Y_1\\notin B \\mid \\boldsymbol{\\xi_0}\\big)\\\\\n&=\\boldsymbol{\\xi N}^{n-1}\\boldsymbol{(I-N)1'}\\\\\n&=\\sum_{j\\in B}\\boldsymbol{\\xi N}^{n-1}{B'}_j,\n\\end{align*}\\]\n\nPrueba. Defina una nueva cadena de Markov \\(\\small{\\{Z_t\\}}\\) en el espacio de estados \\(\\small{\\Omega}\\), donde \\(\\small{\\{Z_t\\}}\\) es igual a \\(\\small{\\{Y_t\\}}\\)para todos los estados \\(\\small{i \\in \\Omega-B}\\) y donde todos los estados \\(\\small{j \\in B}\\) se toman como estados absorbentes. Entonces la matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M^{\\star}}}\\) para la cadena de Markov \\(\\small{\\{Z_t\\}}\\) tiene la forma\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}^{\\star}=\\big(p_{ij}^{\\ast}\\big)=\n\\left(\\begin{array}{c|c}\n\\boldsymbol{N} & \\boldsymbol{B}   \\\\\n\\hline\n\\boldsymbol{O} &  \\boldsymbol{I}\n\\end{array}\n\\right).\n\\end{equation}\\]\n\nDado que, para cada \\(\\small{n}\\) \n\n\\[\\begin{equation}\n\\mathbb{P}\\big(Y_n =j,Y_{n-1} \\notin B,\\cdots, Y_1\\notin B,Y_1\\notin B \\mid \\boldsymbol{\\xi_0}\\big)=\\mathbb{P}\\big(Z_n =j,Z_{n-1} \\notin B,\\cdots, Y_1\\notin B,Z_1\\notin B \\mid \\boldsymbol{\\xi_0}\\big),\n\\end{equation}\\]\n\nEl resultado (i) se desprende del teorema 2.4. De manera similar, el resultado (ii) se sigue inmediatamente a partir de (i) y el hecho de que \\(\\small{\\boldsymbol{(I-N)1'}=\\displaystyle\\sum_{j\\in B}{B'}_j}\\). \\(\\hspace{1cm}\\Box\\)\nLa prueba anterior est√° guiada por el hecho de que todos los estados en \\(\\small{B}\\) son estados absorbentes con respecto a la nueva cadena de Markov \\(\\small{\\{Z_t\\}}\\) y, por lo tanto, por ejemplo, para cada \\(\\small{i \\in \\Omega-B}\\), la probabilidad \\(\\small{\\mathbb{P}(Z_{n-1}=i)}\\) se puede dividir en dos partes de la siguiente manera:\n\n\n\\[\\begin{align*}\n\\mathbb{P}\\big(Z_{n-1} = i \\mid \\boldsymbol{\\xi_0}\\big) & =\n\\mathbb{P}\\big(Z_{n-1} =i, Z_{n-2} \\notin B,\\cdots, Z_1\\notin B \\mid \\boldsymbol{\\xi_0}\\big)\\\\\n& + \\mathbb{P}\\big(Z_{n-1} =i \\text{ y por lo menos uno de } Z_{n-2},\\cdots ,Z_1 \\text{ esta dentro de } B \\mid \\boldsymbol{\\xi_0}\\big)\n\\end{align*}\\]\n\nen donde la segunda parte es siempre cero (ya que \\(\\small{i \\in \\Omega-B}\\) y \\(\\small{p_{ij}^{\\ast}\\equiv 0}\\) para todos \\(\\small{j \\in B}\\)). Tenga en cuenta que, en el teorema 2.5, asumimos la distribuci√≥n inicial \\(\\small{(\\boldsymbol{\\xi:0})}\\)), lo que equivale a decir \\(\\small{\\mathbb{P}\\big(Y_0\\in B\\big)\\equiv 1}\\). En consecuencia, la probabilidad \\(\\small{\\mathbb{P}\\big(Y_n \\in B,Y_{n-1}\\notin B,\\cdots,Y_1 \\notin B \\mid \\boldsymbol{\\xi_0}\\big)}\\) se conoce como probabilidad de primera entrada.\nEjemplo 2.6 Sea \\(\\small{\\{Y_t\\}}\\) una cadena de Markov homog√©nea definida en el espacio de estados \\(\\small{\\Omega=\\{1,2,3,4,5\\}}\\) con matriz de probabilidad de transici√≥n\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\n\\begin{array}{ccccc}&\n\\begin{array}{ccccc}\n\\end{array}\n\\\\\n\\begin{array}{ccccc}\n1 \\\\\n2 \\\\\n3\\\\\n4\\\\\n5\n\\end{array}\n&\n\\left(\n\\begin{array}{ccccc}\n1/2 & 1/4 & 1/4  & 0 &  0 \\\\\n1/4 & 1/2  & 0  &  1/4 & 0 \\\\\n1/4 & 1/4  &  0 & 0 & 1/2 \\\\\n0&  0 & 0 &  1 &0 \\\\\n0&  0 & 0 &  0 & 1 \\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nSupongamos que \\(\\small{B = \\{3, 4\\}}\\), entonces la matriz de probabilidad de transici√≥n de \\(\\small{B = \\{Y_t\\}}\\) se puede reorganizar como:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\n\\begin{array}{ccccc}&\n\\begin{array}{ccccc}\n\\end{array}\n\\\\\n\\begin{array}{ccccc}\n1 \\\\\n2 \\\\\n3\\\\\n4\\\\\n5\n\\end{array}\n&\n\\left(\n\\begin{array}{ccc|cc}\n1/2 & 1/4 & 0  & 1/4 &  0 \\\\\n1/4 & 1/2  & 0  &  0 & 1/4 \\\\\n0 & 0 &  1 & 0 & 0 \\\\\n\\hline\n1/4 &  1/4 & 1/2 &  0 & 0 \\\\\n0&  0 & 0 &  0 & 1 \\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nDada una distribuci√≥n inicial de \\(\\small{Y_0}\\), digamos \\(\\small{\\mathbb{P}(Y_0=1)=1}\\), la probabilidad de primera entrada para \\(\\small{Y_n=3}\\), es\n\n\n\\[\\begin{align*}\n& \\quad \\,\\mathbb{P}\\big(Y_n =3,Y_{n-1} \\notin B,\\cdots,Y_1\\notin B \\mid Y_0 = 1\\big)\n\\\\\n& =(0,0,1)\n\\left(\\begin{array}{ccc}\n1/2 & 1/4 & 0\\\\\n1/4 & 1/2 & 0\\\\\n0 & 0 & 1\n\\end{array} \\right)^{n-1}\n\\left(\\begin{array}{c}\n1/4\\\\\n0\\\\\n0\n\\end{array} \\right)\\\\\n\\end{align*}\\]\n\nPara \\(\\small{n = 3}\\), obtenemos que \\(\\small{\\mathbb{P}\\big(Y_n =3,Y_{3} \\notin B,Y_1\\notin B \\mid Y_0 = 1\\big)=5/64}\\). Tenga en cuenta que dado que el estado ‚Äú\\(\\small{5}\\)‚Äù es un estado absorbente, los c√°lculos se pueden reducir a√∫n m√°s a:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(Y_n =3,Y_{n-1} \\notin B,\\cdots,Y_1\\notin B \\mid Y_0 = 1\\big)=(1,0)\n\\left(\\begin{array}{ccc}\n1/2 & 1/4 \\\\\n1/4 & 1/2\n\\end{array} \\right)^{n-1}\n\\left(\\begin{array}{c}\n1/4\\\\\n0\n\\end{array} \\right) \\hspace{5cm}\\Diamond\n  \\end{equation}\\]\n\nSea \\(\\small{A}\\) el conjunto que contenga todos los estados absorbentes de \\(\\small{\\{Y_t\\}}\\) y sea \\(\\small{B^{\\ast}= A \\cup B}\\). La matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M^{*}}}\\) , correspondiente a la cadena de Markov asociada \\(\\small{\\{Z_t\\}}\\) en la que todos los estados en \\(\\small{B^{\\ast}}\\) se toman como estados absorbentes, puede entonces reordenarse como:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M^{\\ast}}=\n\\begin{array}{cc}\n{\\Omega-B^{\\ast}} \\\\B^{\\ast} \\end{array}\n\\left(\\begin{array}{c|c}\n\\boldsymbol{N^{\\ast}} & \\boldsymbol{B^{\\ast}}\\\\\n\\hline\n\\boldsymbol{J} &  \\boldsymbol{Q}\n\\end{array}\n\\right)\n\\end{equation}\\]\n\nen donde \\(\\small{\\boldsymbol{N^{*}}}\\) es la submatriz esencial de \\(\\small{\\boldsymbol{M^{*}}}\\), y \\(\\small{\\boldsymbol{B^{*}}}\\) es la matriz formada a partir de \\(\\small{\\boldsymbol{M^{*}}}\\) mediante la eliminaci√≥n de todas las columnas asociadas con los estados en \\(\\small{\\Omega-B^{*}}\\) y de todas las filas asociadas con los estados en \\(\\small{B^{*}}\\). Entonces se cumple el siguiente corolario.\nColorario: Para todo \\(\\small{j\\in B}\\)\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(Y_n =j,Y_{n-1} \\notin B,\\cdots,Y_1\\notin B \\mid (\\boldsymbol{\\xi}:\\boldsymbol{0}) \\big)= \\boldsymbol{\\xi^{\\ast}}(\\boldsymbol{N^{\\ast}})^{n-1}B_{j}^{*'},\n\\end{equation}\\]\n\nsiendo \\(\\small{B_{j}^{*'}}\\) la \\(j-\\)√©sima columna de la matriz \\(\\small{\\boldsymbol{B^{\\ast}}}\\)\nLa prueba del corolario anterior es sencilla y se deja en manos del lector. Tenga en cuenta que el tama√±o de la matriz \\(\\small{\\boldsymbol{N^{\\ast}}}\\) es menor o igual que el tama√±o de \\(\\small{\\boldsymbol{N}}\\).\n\n\n\n\n\n\nAunque las rachas y patrones en una sucesi√≥n de ensayos de Bernoulli son casos especiales de los ensayos multiestados, merecen un cap√≠tulo aparte debido a su larga historia, la gran cantidad de resultados asociados y su amplia aplicaci√≥n a numerosos campos. El enfoque de este cap√≠tulo ser√° derivar las distribuciones para las estad√≠sticas de rachas m√°s comunes y √∫tiles en ensayos de Bernoulli mediante la t√©cnica de incrustaci√≥n de cadenas finitas de Markov, y tambi√©n en extender estos resultados a secuencias de ensayos de dos estados dependientes de Markov. Tambi√©n se presentan t√©cnicas para obtener ecuaciones recursivas y funciones generadoras de probabilidad de estad√≠sticas de rachas a trav√©s del enfoque de incrustaci√≥n de cadenas finitas de Markov. Estas herramientas pueden ser muy √∫tiles para estudiar ciertas caracter√≠sticas de las distribuciones de rachas, como la media, la varianza y los momentos superiores.\nEn este cap√≠tulo se tratan las siguientes estad√≠sticas de rachas, definidas tradicionalmente en una secuencia de \\(\\small{n}\\) ensayos de Bernoulli:\n(i) \\(\\small{N_{n,k}}\\) el n√∫mero de \\(\\small{k}\\) √©xitos consecutivos no superpuestos;\n(ii) \\(\\small{G_{n,k}}\\) el n√∫mero de rachas exitosas de tama√±o mayor o igual a \\(\\small{k}\\).\n(iii) \\(\\small{M_{n,k}}\\) el n√∫mero de \\(\\small{k}\\) √©xitos consecutivos solapados.\n(iv) \\(\\small{E_{n,k}}\\) el n√∫mero de rachas de exctamente \\(\\small{k}\\) √©xitos.\n(v) \\(\\small{L_{n,k}}\\) el tama√±o de la racha de exitos m√°s larga;\n(vi) \\(\\small{S_{n,k}}\\) el n√∫mero total de √©xitos en rachas exitosas de longitud mayor o igual a \\(\\small{k}\\) .\nTambi√©n se trata la distribuci√≥n del tiempo de espera de una racha de √©xitos y se incluyen algunos resultados num√©ricos para las distribuciones de las estad√≠sticas de las rachas anteriores.\n\n\n\nEl n√∫mero de rachas de \\(\\small{k}\\) √©xitos consecutivos no superpuestos, \\(\\small{N_{n,k}}\\), en una secuencia de \\(\\small{n}\\) ensayos de Bernoulli es probablemente la estad√≠stica de ejecuciones m√°s importante, no s√≥lo por su amplia aplicaci√≥n a diversas √°reas sino tambi√©n por su conexi√≥n con otras estad√≠sticas de rachas; En teor√≠a de la distribuci√≥n, la distribuci√≥n de \\(\\small{N_{n,k}}\\) se conoce como distribuci√≥n binomial de orden \\(\\small{k}\\). Philippou y Makri (1986) e Hirano (1986) dieron de forma independiente una f√≥rmula para la distribuci√≥n exacta de \\(\\small{N_{n,k}}\\) en una secuencia de \\(\\small{n}\\) ensayos de Bernoulli como:\n\n\n\\[\\begin{equation}\n\\mathbb{P}(N_{n,k}=x)=\\sum_{m=0}^{k-1}\\sum_{x_1+x_2+\\cdots+\\\\\nkx_k=n-m-km}\\binom{x_1+x_2+\\cdots+x_k+x}{x_1,x_2,\\cdots,x_k,x}p^n\\Big(\\frac{q}{p}\\Big)^{x_1+x_2+\\cdots+x_k},\n\\end{equation}\\]\n\nen donde, \\(\\small{x=0,1,\\ldots,[n/k]}\\,\\) (\\(\\small{[n/k]}\\) la parte entera de \\(\\small{n/k}\\)) y con probabilidades de √©xito \\(\\small{p}\\) y fracaso \\(\\small{p=1-p}\\). Godbole (1990) dio una f√≥rmula alternativa para la funci√≥n de probabilidad de \\(\\small{N_{n,k}}\\) con \\(\\small{k&gt;1}\\):\n\n\n\\[\\begin{align*}\n\\mathbb{P}(N_{n,k}=x) &=\\sum_{[(n-kx)/k]\\leq y \\leq n-kx} \\binom{y+x}{x}q^yp^{n-y}\\\\\n& \\times \\sum_{0 \\leq j \\leq  [(n-kx-y)/k]}(-1)^j \\binom{y+1}{j} \\binom{n-kx-jk}{y},\n\\end{align*}\\]\n\npara \\(\\small{x=0,1,\\ldots,[n/k]}\\,\\). La f√≥rmula (3.2) tiene la ventaja sobre la (3.1) de que es m√°s f√°cil de evaluar por computadora para \\(\\small{n}\\,\\) grande. Hirano y Aki (1987, 1993) estudiaron algunas propiedades de esta distribuci√≥n y ampliaron los resultados al caso de ensayos de Markov dependientes de dos estados.\nPara comenzar nuestro estudio de \\(\\small{N_{n,k}}\\) utilizando el m√©todo de incrustaci√≥n de cadenas finitas de Markov, consideremos el espacio de estados\n\n\n\\[\\begin{equation}\n\\Omega =\\{(x,i):x=0,1,\\cdots,l_n\\, \\text{y}\\, 0,1,\\cdots,k-1\\},\n\\end{equation}\\]\n\nen donde, \\(\\small{l_n=[n/k]}\\,\\) es el n√∫mero m√°ximo de rachas exitosas no superpuestas de longitud \\(\\small{k}\\) que pueden ocurrir en \\(\\small{n}\\) ensayos. Ahora definamos la Cadena de Markov finita homogenea \\(\\small{\\{Y_t:t=0,1,\\ldots,n\\}}\\,\\) sobre \\(\\small{\\Omega}\\,\\) como sigue:\n\n\n\\[\\begin{equation}\nY_t=(N_{t,k},E_{t}),\\quad \\text{para }1\\leq t \\leq n,\n\\end{equation}\\]\n\ndonde \\(\\small{N_{n,k}}\\) es el n√∫mero de \\(\\small{k}\\) √©xitos consecutivos no superpuestos que ocurrieron durante los primeros \\(\\small{t}\\) ensayos \\(\\small{X_1,X_2,\\ldots,X_n}\\). El ‚Äúbloque final‚Äù \\(\\small{E_t}\\) es igual a \\(\\small{m}\\) m√≥dulo \\(\\small{k}\\), donde \\(\\small{m}\\) representa el n√∫mero de √©xitos finales (posiblemente cero) que existen en la sucesi√≥n despu√©s de las primeros \\(\\small{t}\\) ensayos:\n\n\n\\[\\begin{equation}\nFFSSF\\underbrace{SS\\cdots S}_{m}.\n\\end{equation}\\]\n\nObservemos que \\(\\small{E_t=0}\\) si \\(\\small{m}\\) es un m√∫ltiplo positivo de \\(\\small{k}\\) o si el \\(\\small{t-}\\)√©simo resultado es \\(\\small{F}\\). Esta variable de bloque final realiza un seguimiento del n√∫mero de √©xitos en una posible racha parcial asociada con en el \\(\\small{t-}\\)√©simo ensayo. Por ejemplo, dados \\(\\small{n=10}\\) ensayos de Bernoulli con resultados \\(\\small{\\{FSFFSSSFSS\\}}\\) y una duraci√≥n de ejecuci√≥n exitosa elegida de \\(\\small{k=2}\\), la realizaci√≥n de la cadena de Markov incorporada \\(\\small{\\{Y_t: t = 1,2,\\ldots, 10\\}}\\) con respecto a estos diez resultados es: \\(\\small{\\{Y_1=(0,0), Y_2 = (0, 1), Y_3=(0,0), Y_4=(0,0),Y_5= (0,1),Y_6 = (1,0), Y_7=(1, 1), Y_8=(1,0),Y_9=(1,1), Y_{10}=(2,0)\\}}\\). Tenga en cuenta que para una secuencia dada de resultados \\(\\small{\\{FS\\cdots SF\\}}\\), la realizaci√≥n de \\(\\small{\\{Y_t\\}}\\) es siempre √∫nica.\nDefinir los subconjuntos\n\n\n\\[\\begin{equation}\nC_x =\\{(x,i): i=0,1,\\cdots,k-1\\},\\quad 0\\leq x \\leq l_n\n\\end{equation}\\]\n\nLa colecci√≥n de subconjuntos \\(\\small{\\{C_x:x = 0,1,\\ldots,l_n\\}}\\) forma una partici√≥n del espacio de estados \\(\\small{\\Omega}\\). Dado que \\(\\small{\\{X_t\\}}\\) es, por el momento, una sucesi√≥n de ensayos Bernoulli, de las definiciones anteriores se deduce que \\(\\small{Y_t}\\) tiene una matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M_t} = (p_{(x,i)(y,j)})}\\) para todo \\(\\small{t=1,2,\\ldots,n}\\), con las probabilidades de transici√≥n \\(\\small{(p_{(x,i)(y,j)})}\\) dadas por la siguiente ecuaci√≥n: para \\(\\small{1 \\leq t \\leq n}\\) y \\(\\small{0 \\leq x \\leq l_n}\\) \n\n\\[\\begin{align*}\np_{(x,i)(y,j)} & = \\mathbb{P}\\big(Y_t=(y,j)\\mid Y_{t-1}=(x,i)\\big)\\\\\n& =\\begin{cases}\nq \\quad \\text{si }y=x\\,\\text{y }j=0,\\,\\text{para }i=0,1,\\ldots, k-1\n\\\\\np \\quad \\text{si }y=x\\,\\text{y }j=i+1,\\,\\text{para }i=0,1,\\ldots, k-2\n\\\\\np \\quad \\text{si }y=x+1\\,\\text{y }j=0,\\,\\text{para }i=k-1\\,\\text{y },x=0,1,\\ldots, l_{n}-1\n\\\\\n1 \\quad \\text{si }y=x=l_{n}\\,\\text{y }j=i=k-1\n\\\\\n0 \\quad \\text{en otro caso}\n\\end{cases}\n\\end{align*}\\]\n\nA modo de ilustraci√≥n, la matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M_t}}\\) de la cadena de Markov incrustada \\(\\small{{Y_t}}\\) asociada con la variable aleatoria \\(\\small{N_{5,2}}\\) viene dada por\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\n\\begin{array}{cccccc}&\n\\begin{array}{cccccc}\n\\end{array}\n\\\\\n\\begin{array}{cccccc}\n(0,0)\\\\\n(0,1)\\\\\n(1,0)\\\\\n(1,1)\\\\\n(2,0)\\\\\n(2,1)\n\\end{array}\n&\n\\left(\n\\begin{array}{cc|cc|cc}\nq&p&0&0&0&0\\\\\nq&0&p&0&0&0\\\\\n\\hline\n0&0&q&p&0&0\\\\\n0&0&q&0&p&0\\\\\n\\hline\n0&0&0&0&q&p\\\\\n0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}_{6\\times6}\n\\end{equation}\\]\n\npara \\(\\small{1\\leq t \\leq 5.}\\)\nPara el caso donde \\(\\small{\\{X_t\\}}\\) es una sucesi√≥n de ensayos de dos estados independientes pero no id√©nticamente distribuidos con probabilidades \\(\\small{\\mathbb{P}(X_t=S)=p_t}\\) y \\(\\small{\\mathbb{P}(X_t=F)=q_t}\\) , para \\(\\small{t=1,2,\\ldots,n}\\), las matrices de transici√≥n \\(\\small{\\boldsymbol{M_t}}\\) para la cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) permanece sin cambios excepto que la probabilidad \\(\\small{p}\\) se reemplaza por \\(\\small{p_t}\\) y \\(\\small{q}\\) se reemplaza por \\(\\small{q_t}\\). En general, para ensayos de dos estados independientes pero no id√©nticamente distribuidos, las matrices de probabilidad de transici√≥n se pueden escribir como\n\n\n\\[\\begin{equation}\n\\boldsymbol{M_t}(N_{n,k})=\n\\left(\\begin{array}{cccc}\n\\boldsymbol{A_t}&\\boldsymbol{B_t}&&&\\boldsymbol{0}\\\\\n&&\\ddots&\\ddots&\\\\\n\\boldsymbol{0}&&&\\boldsymbol{A_t}&\\boldsymbol{B_t}\\\\\n&&&&\\boldsymbol{A_{t}^{\\ast}}\\\\\n\\end{array}\\right)_{d\\times d},\n\\end{equation}\\]\n\npara \\(\\small{t=1,2,\\dots,n}\\), en donde:\n\n\n\\[\\begin{equation}\n\\boldsymbol{A_t}=\n\\left(\\begin{array}{ccccc}\nq_t&p_t&0&\\cdots&0\\\\\nq_t&0&p_t&\\cdots&0\\\\\n\\vdots& &\\ddots&\\ddots&\\\\\n\\vdots& & &\\ddots&p_t\\\\\nq_t&0&0&\\cdots&0\\\\\n\\end{array}\\right)_{k\\times k},\n\\end{equation}\\]\n\n\\(\\small{\\boldsymbol{B_t}}\\) es una matriz \\(\\small{k\\times k}\\) que tiene \\(\\small{p_t}\\) en la entrada \\(\\small{(k,1)}\\) y cero en el resto, \\(\\small{\\boldsymbol{A_t}^{\\ast}}\\) es igual que \\(\\small{\\boldsymbol{A_t}}\\) excepto que su √∫ltima fila se reemplaza con \\(\\small{(0,0,...,0,1)}\\), y la dimensi√≥n de \\(\\small{\\boldsymbol{M_t}(N_{n,k})}\\) viene dado por \\(\\small{d = k(l_n+1)}\\). Por tanto, en virtud del teorema 2.1, podemos afirmar que\n\n\n\\[\\begin{equation}\n\\small{\\mathbb{P}\\big( N_{n,k}=x\\big)=\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\prod_{t=1}^{n}\\boldsymbol{M}_t(N_{n,k})\\Big)\\boldsymbol{\\mathbf{U}'}(\\mathbf{C_x})},\\,\\,  x=1,2,\\ldots,l_n,\n\\end{equation}\\]\n\nen donde, \\(\\small{\\boldsymbol{\\mathbf{\\xi}}_0=(1,0,\\ldots,0)_{1\\times d}}\\) y \\(\\small{\\boldsymbol{\\mathbf{U}'}({C_x})}\\) es la transpuesta del vector \\(\\small{\\boldsymbol{\\mathbf{U}'}({C_x})=(0,\\ldots,0, 1,\\ldots, 1, 0,\\ldots,0)}\\) con unos en las ubicaciones asociadas con los estados en \\(\\small{C_x}\\). La ecuaci√≥n (3.8) representa la distribuci√≥n exacta de \\(\\small{N_{n,k}}\\) para ensayos independientes de dos estados distribuidos tanto de forma id√©ntica como no id√©ntica. En vista de la matriz de probabilidad de transici√≥n en la ecuaci√≥n (3.7), \\(\\small{N_{n,k}}\\) es una cadena finita de Markov incrustable de tipo binomial en el sentido de la Definici√≥n 2.7 (Koutras y Alexandrou 1995).\nSi \\(\\small{\\{X_t\\}}\\) es una Cadena de Markov no homogenea com matriz de probabilidades de transici√≥n:\n\n\n\\[\\begin{equation}\n\\left(\\begin{array}{cc}\np_{FF}(t)&p_{SS}(t)\\\\\np_{FF}(t)&p_{SS}(t)\n\\end{array}\\right),\n\\end{equation}\\]\n\nentonces, es necesaria una modificaci√≥n menor en el procedimiento de incrustaci√≥n para obtener la distribuci√≥n de \\(\\small{N_{n,k}}\\). Dado que el resultado de \\(\\small{X_{t+1}}\\), y por tanto tambi√©n de \\(\\small{Y_{t+1}}\\), ahora depende de \\(\\small{X_t}\\), cada estado de la cadena de Markov \\(\\small{Y_t}\\) debe implicar un cierto resultado de \\(\\small{X_t}\\). Este ya es el caso en nuestra definici√≥n anterior de \\(\\small{Y_t}\\), salvo para los estados con un bloque final de \\(\\small{E_t=0}\\), que puede surgir para cualquier resultado de \\(\\small{X_t}\\). Para resolver esta ambig√ºedad, definimos un estado de bloque final adicional, \\(\\small{E_t=\\gamma}\\), para corresponder al caso donde la serie de √©xitos finales es un m√∫ltiplo distinto de cero de \\(\\small{k}\\) √©xitos, y reservamos el estado \\(\\small{E_t=0}\\) para el caso donde el resultado \\(\\small{t-}\\)√©simo es un fracaso. La cadena de Markov incrustada se define entonces de la siguiente manera:\n\n\n\\[\\begin{equation}\nY_t =\n\\begin{cases}\n(x,\\gamma) & \\begin{array}{l} \\text{Si existen } x \\text{ rachas de } k \\text{ aciertos} \\\\\n\\text{consecutivos en los primeros } t \\\\\n\\text{ensayos con } m &gt; 0 \\text{ aciertos finales}\\\\\n\\text{tales que } m \\equiv k \\pmod{k} \\end{array} \\\\\n\\\\\n(x,0) & \\begin{array}{l}\\text{Si existen } x \\text{ rachas de } k \\text{ aciertos}\\\\\n\\text{consecutivos en los primeros } t\\text{ ensayos} \\\\ \\text{con } m = 0 \\text{ aciertos finales} \\text{ (}X_t=F\\text{)} \\end{array}\n\\end{cases}\n\\end{equation}\\]\n\ny \\(\\small{Y_t=(x,i)}\\), para \\(\\small{i=1,2,\\ldots,k-1}\\) se define como se indica en la ecuaci√≥n (3.3). La diferencia entre los estados \\(\\small{(x,\\gamma)}\\) y \\(\\small{ (x,0)}\\) se puede ver en el siguiente ejemplo: para una racha exitosa de longitud \\(\\small{k=2}\\), \\(\\small{Y_8=(SFFFSSSS) = (2,\\gamma)}\\) y \\(\\small{Y_8=(SFSSFSSF)= (2,0)}\\). Tenga en cuenta que el bloque final \\(\\small{E_t}\\) ahora contiene no solo la informaci√≥n requerida sobre los subpatrones sino que tambi√©n implica el resultado de \\(\\small{X_t}\\), lo que permite la asignaci√≥n de probabilidades de transici√≥n para la Cadena de Markov incustada.\nLas matrices de probabilidad de transici√≥n correspondientes a estas definiciones pueden deducirse f√°cilmente. La cadena de Markov incrustada asociada con la variable aleatoria \\(\\small{N_{5,2}}\\) como se considera en la Ecuaci√≥n (3.6) para ensayos de Bernoulli, tiene las siguientes matrices de transici√≥n \\(\\small{\\boldsymbol{M_t^{\\ast}}}\\) bajo ensayos dependientes de Markov no homog√©neos: para \\(\\small{t=1,2,\\ldots,n}\\)\n\n\n\\[\\begin{equation}\n\\boldsymbol{M_t^*}(N_{5,2})=\n\\begin{array}{cc}\n\\begin{array}{c}\n(0,0)\\\\\n(0,1)\\\\\n(1,c)\\\\\n(1,0)\\\\\n(1,1)\\\\\n(2,c)\\\\\n(2,1)\\\\\n(2,1)\n\\end{array}&\n\\left(\n\\begin{array}{cc|ccc|ccc}\np_{FF}(t)&p_{FS}(t)&0&0&0&0&0&0\\\\\np_{FS}(t)&0&p_{SS}(t)&0&0&0&0&0\\\\\n\\hline\n0&0&0&p_{SF}(t)&p_{SS}(t)&0&0&0\\\\\n0&0&0&p_{FF}(t)&p_{FS}(t)&0&0&0\\\\\n0&0&0&p_{SF}(t)&0&p_{SS}(t)&0&0\\\\\n\\hline\n0&0&0&0&0&&p_{SF}(t)&p_{SS}(t)\\\\\n0&0&0&0&0&0&p_{FF}(t)&p_{FS}(t)\\\\\n0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nNote que la estructura de ‚Äúfranja/banda‚Äù de \\(\\small{\\boldsymbol{M_t^{\\ast}}(N_{5,2})}\\) es similar con \\(\\small{\\boldsymbol{M_t}(N_{5,2})}\\) de la ecuaci√≥n (3.6) para ensayos de Bernoulli. Como es sencillo derivar la forma general de \\(\\small{\\boldsymbol{M_t^{\\ast}}(N_{n,k})}\\) an√°loga a la ecuaci√≥n (3.7), esto lo dejamos al lector interesado.\nCuando la secuencia \\(\\small{\\{X_t\\}}\\) es i.i.d., la distribuci√≥n inicial \\(\\small{\\boldsymbol{\\xi}_0}\\) puede definirse como \\(\\small{\\mathbb{P}\\big(Y_0=(0,0)\\big)=1}\\), y luego para \\(\\small{k&gt;1}\\), las probabilidades de transici√≥n \\(\\small{\\mathbb{P}\\big(Y_1=(0,1)\\mid Y_0=(0,0)\\big)=p}\\) y \\(\\small{\\mathbb{P}\\big(Y_1=(0,0)\\mid Y_0=(0,0)\\big)=q=(1-p)}\\). Sin embargo, cuando \\(\\small{\\{X_t\\}}\\) es una sucesi√≥n de variables aleatorias Markov-Dependientes , se debe tener cuidado al asumir \\(\\small{\\mathbb{P}\\big(Y_0=(0,0)\\big)=1}\\), lo que implicar√≠a que las probabilidades de transici√≥n entre \\(\\small{Y_0}\\) e \\(\\small{Y_1}\\) est√°n dadas por \\(\\small{\\mathbb{P}\\big(Y_1=(0,1)\\mid Y_0=(0,0)\\big)=p_{FS}(1)}\\) y \\(\\small{\\mathbb{P}\\big(Y_1=(0,0)\\mid Y_0=(0,0)\\big)=p_{FF}=1}\\), independiente de \\(\\small{p_{SF}}\\) y \\(\\small{p_{FF}}\\). Para evitar este tipo de sesgo, es √∫til crear un estado ficticio \\(\\small{\\emptyset}\\) como estado inicial para \\(\\small{Y_0}\\). Luego definimos \\(\\small{\\mathbb{P}\\big(Y_0=\\emptyset\\big)=1}\\), y las probabilidades de transici√≥n \\(\\small{\\mathbb{P}\\big(Y_1=(0,1)\\mid Y_0=\\emptyset\\big)=p_{s}}\\), y \\(\\small{\\mathbb{P}\\big(Y_1=(0,0)\\mid Y_0=\\emptyset\\big)=p_{f}}\\). Por tanto, para \\(\\small{N_{5,2}}\\) la correspondiente cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) se define en el espacio de estados expandido \\(\\small{\\Omega=\\{\\emptyset,(0,0),(0,1),(1,0),\\ldots\\}}\\) con matrices de probabilidad de transici√≥n:\n\n\n\\[\\begin{equation}\n\\begin{array}{cc} &\n\\begin{array}{cccccc}(0,0)&(0,1)&(1,c)&(1,0)&(1,1)&\\cdots\n\\end{array}\\\\\n\\begin{array}{cccccccc}\n\\end{array}\n&\n\\left(\n\\begin{array}{c|ccccc}\n0 &  p_{f}  & p_{s} &  0  &   0 & \\cdots \\\\\n\\hline\n\\, 0&&&&&\\\\\n0&&&\\boldsymbol{M_t}^{\\ast}(N_{5,2})&&\\\\\n0&&&&&\\\\\n\\end{array}\n\\right)\\end{array}\n\\end{equation}\\]\n\nTenga en cuenta que el procedimiento de incrustaci√≥n de cadenas finitas de Markov utilizado para obtener la distribuci√≥n exacta de \\(\\small{N_{n,k}}\\) sigue siendo el mismo, excepto por diferencias menores en las matrices de probabilidad de transici√≥n, independientemente de si la secuencia de ensayos \\(\\small{\\{X_t\\}}\\) es i.i.d., independiente pero no id√©ntica distribuida o si es Markov-Dependiente.\n\n\n\nPara una sucesi√≥n de ensayos de dos estados, la variable aleatoria \\(\\small{G_{n,k}}\\) se define como el n√∫mero de rachas exitosas de longitud mayor o igual a \\(\\small{G_{n,k}}\\). Consideremos una cadena de Markov finita \\(\\small{\\{Y_t:t=0,1,2,\\ldots,n\\}}\\) definida en el espacio de estados:\n\n\n\\[\\begin{equation}\n\\Omega =\\{(x,i):x=0,1,\\cdots,l_n\\,\\, \\text{y}\\,\\, i= \\gamma,0,1,\\cdots,k-1\\}-{\\{(0,\\gamma)\\}},\n\\end{equation}\\]\n\nen donde, \\(\\small{l_n=[(n+1)/(k+1)]}\\). Para una sucesi√≥n de resultados de los primeros \\(\\small{t}\\) ensayos con \\(\\small{m}\\) √©xitos finales, digamos \\(\\small{FS \\cdots F \\underbrace{SS \\cdots}_{m}S}\\), definimos la cadena de Markov:\n\n\n\\[\\begin{equation}\nY_t=(G_{n,k},E_t) \\quad 1\\leq t\\leq n,\n\\end{equation}\\]\n\ndonde \\(\\small{G_{n,k}}\\), es el n√∫mero de rachas exitosas de longitud mayor o igual a \\(\\small{k}\\) en la sucesi√≥n \\(\\small{\\{X_t\\}}\\), y \\(\\small{E_t}\\) es la variable del bloque final con \\(\\small{E_t=m}\\) si \\(\\small{m=0,1,2,\\ldots,k-1}\\), y \\(\\small{E_t=\\gamma}\\) si \\(\\small{m\\geq k}\\). Para ilustrar esta definici√≥n, considere una longitud de racha m√≠nima de \\(\\small{k=2}\\) y los siguientes doce resultados, de un ensayo de dos estados: \\(\\small{FSFFSSFSSSFS}\\), para los cuales \\(\\small{G_{12,2}=2}\\). Se deduce de la Ec.(3.9) que la realizaci√≥n de la Cadena de Markov \\(\\small{\\{Y_t:t=0,1,2,\\ldots,14\\}}\\) es : \\(\\small{\\{Y_1=(0,0),Y_2=(0,1),Y_3=(0,0),Y_4=(0,0),Y_5=(0,1),Y_6=(1,\\gamma),Y_7=(1,0),Y_8=(1,1),Y_9=(2,\\gamma),Y_{10}=(2,\\gamma),Y_{11}=(2,0),Y_{12}=(2,0)\\}}\\). Note que el bloque final \\(\\small{E_t=\\gamma}\\) puede ocurrir s√≥lo cuando hay al menos \\(\\small{k}\\) √©xitos finales, en cuyo caso \\(\\small{G_{n,k}\\geq k}\\) por esta raz√≥n, el estado \\(\\small{(0,\\gamma)}\\) fue excluido en la definici√≥n anterior del espacio de estados \\(\\small{\\Omega}\\).\nDe la definici√≥n de la cadena de Markov incrustada dada por la Ecu. (3.9), las probabilidades de transici√≥n de un paso en \\(\\small{\\boldsymbol{M_t}(G_{n,k})}\\) para ensayos independientes pero no identicamente distribuidos se especifican mediante la siguiente ecuaci√≥n: para \\(\\small{t=1,2,\\ldots,n}\\)\n\n\n\\[\\begin{equation}\np_{(x,i)(y,i)}(t) =\n\\begin{cases}\nq_t & \\begin{array}{l} \\text{Si}\\,\\, y=x \\,\\, \\text{y}\\,\\, j=0 \\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n \\,\\text{y}\\, i=\\gamma,0,1,\\ldots,k-1  \\end{array} \\\\\np_t & \\begin{array}{l} \\text{Si}\\,\\, y=x \\,\\, \\text{y}\\,\\, j=i=\\gamma\\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n  \\end{array}\n\\\\\np_t & \\begin{array}{l} \\text{Si}\\,\\, y=x \\,\\, \\text{y}\\,\\, j=i+1\\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n \\,\\text{y}\\, i=\\gamma,0,1,\\ldots,k-2  \\end{array}\n\\\\\np_t & \\begin{array}{l} \\text{Si}\\,\\, y=x+1,\\,i=k-1 \\,\\, \\text{y}\\, j=\\gamma \\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n-1  \\end{array}\n\\\\\n1 & \\begin{array}{l} \\text{Si}\\,\\, y=x=l_n,\\,j=x=k-1\\end{array} \\\\\n0 & \\begin{array}{l} \\text{Otro caso} \\end{array}\n\\end{cases}\\\\\n\\end{equation}\\]\n\nEn el caso especial de \\(\\small{n=5}\\) y \\(\\small{k=2}\\) la matriz de probabilidades de transici√≥n \\(\\small{\\boldsymbol{M_t}(G_{n,k})}\\) esta dada por:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M_t}(G_{5,2})=\n\\begin{array}{cc}&\n\\begin{array}{cccccc}\n\\end{array}\n\\\\\n\\begin{array}{cccccc}\n(0,0)\\\\\n(0,1)\\\\\n(1,\\gamma)\\\\\n(1,0)\\\\\n(1,1)\\\\\n(2,\\gamma)\\\\\n(2,0)\\\\\n(2,1)\n\\end{array}\n&\n\\left(\n\\begin{array}{cc|c|cc|c|cc}\nq_t&p_t&0&0&0&0&0&0\\\\\nq_t&0&p_t&0&0&0&0&0\\\\\n\\hline\n0&0&p_t&q_t&0&0&0\\\\\n\\hline\n0&0&0&q_t&p_t&0&0&0\\\\\n0&0&0&q_t&0&p_t&0&0\\\\\n\\hline\n0&0&0&0&0&p_t&q_t&0\\\\\n\\hline\n0&0&0&0&0&0&q_t&p_t\\\\\n0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\npara \\(\\small{t=1,2,\\ldots,5}\\). En general \\(\\small{\\boldsymbol{M_t}(G_{n,k})}\\) es una matriz bidiagonal de bloques de la forma: \n\n\\[\\begin{equation}\n\\left(\n\\begin{array}{ccccccc}\n\\boldsymbol{A_t}&p_t\\boldsymbol{e_k'}&&&&&\\boldsymbol{O}\\\\\n&p_t&q_t\\boldsymbol{e_1}&&\\boldsymbol{O}&&\\\\\n&&\\boldsymbol{A_t}&p_t\\boldsymbol{e_k'}&&&\\\\\n&&&\\ddots&\\ddots&&\\\\\n&&&&\\ddots&\\ddots&\\\\\n&&\\boldsymbol{O}&&&p_t&q_t\\boldsymbol{e_1}\\\\\n\\boldsymbol{O}&&&&&&\\boldsymbol{A_t^{\\ast}}\\\\\n\\end{array}\n\\right)\n\\end{equation}\\]\n\nen donde \\(\\small{\\boldsymbol{e_1}=(1,0,\\ldots,0)}\\) y \\(\\small{\\boldsymbol{e_1}=(0,\\ldots,0,1)}\\) son vectores fila unitarios \\(\\small{1\\times k}\\), y \\(\\small{\\boldsymbol{A_t}}\\) es dada por:\n\n\n\\[\\begin{equation}\n\\boldsymbol{A_t} =\\left(\n\\begin{array}{ccccc}\nq_t & p_t & 0  & \\ldots &  0 \\\\\n\\vdots & \\ddots & \\ddots  &    &   \\\\\n\\vdots &  &  \\ddots& \\ddots &   \\\\\n\\vdots&  &   &  \\ddots &p_t \\\\\nq_t&  0 & 0 &  \\cdots & 1 \\\\\n\\end{array}\n\\right)\n\\end{equation}\\]\n\nLa matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{A_t}}\\), en el contexto de la demograf√≠a, a menudo se denomina matriz de Leslie o, m√°s generalmente, matriz de tipo renovaci√≥n (v√©ase Seneta, 1981). La dimensi√≥n de \\(\\small{\\boldsymbol{A_t}(G_{n,k})}\\) es igual a \\(\\small{(l_n+1)(k+1)-1}\\). La matriz \\(\\small{\\boldsymbol{A_t^{\\ast}}}\\) en la Ec. (3.11) es igual que \\(\\small{\\boldsymbol{A_t}}\\) excepto por la √∫ltima fila, que se reemplaza por \\(\\small{(0,\\ldots,0,1)}\\)\nSi definimos la partici√≥n \\(\\small{\\{C_x:i=0,1,2,\\ldots,l_n\\}}\\) sobre \\(\\small{\\Omega}\\)\n\n\n\\[\\begin{align*}\nC_0&=\\{(0,i):i=0,1,\\ldots,k-1\\} \\\\\nC_x&=\\{(0,i):i=\\gamma,0,1,\\ldots,k-1\\},\\,\\text{para}\\, x=1,2,\\ldots,l_n\n\\end{align*}\\]\n\ny en consecuencia \\(\\small{\\mathbb{P}\\big(G_{n,k}=x\\big)=\\mathbb{P}\\big(Y_n \\in C_x \\big)}\\) para todo \\(\\small{x=0,1,2,\\ldots,l_n}\\). La funci√≥n de distribuci√≥n, los momentos y la funci√≥n generadora de probabilidad ahora se pueden calcular f√°cilmente mediante las ecuaciones (2.11), (2.12) y (2.13), respectivamente.\nPara el caso de ensayos i.i.d., todas las probabilidades de transici√≥n ser√≠an constantes y se podr√≠a llevar a cabo una extensi√≥n a los ensayos de Markov-Dependientes como se describe para el estad√≠stico \\(\\small{N_{n,k}}\\) en la secci√≥n anterior; En el resto de este cap√≠tulo sobre ensayos en dos Estados, nos centraremos principalmente en el caso de ensayos independientes pero no id√©nticamente distribuidos.\n\n\n\nLa variable aleatoria \\(\\small{M_{n,k}}\\) se define como el n√∫mero \\(\\small{k}\\) de √©xitos consecutivos superpuestos en una sucesi√≥n de \\(\\small{n}\\) ensayos independientes de dos estados. La cadena de Markov incrustada \\(\\small{\\{Y_t:t=0,1,2,\\ldots,n\\}}\\) asociada a \\(\\small{M_{n,k}}\\) puede definirse como\n\n\n\\[\\begin{align*}\nY_t=(M_{t,k},E_t),\\quad t=1,2,\\ldots,n\n\\end{align*}\\]\n\nsobre el espacio de estados\n\n\n\\[\\begin{align*}\n\\Omega &=\\{(x,i):x=0,1,\\cdots,l_n-1\\,\\, \\text{e}\\,\\, i=\\gamma, 0,1,\\cdots,k-1\\} \\\\\n& \\cup \\{(l_n,\\gamma)\\}-\\{(0,\\gamma)\\},\n\\end{align*}\\]\n\ndonde \\(\\small{l_n=n-k+1,\\, M_{n,k}}\\) es el n√∫mero de \\(\\small{k}\\) √©xitos consecutivos superpuestos en las primeros \\(\\small{t}\\) ensayos, y \\(\\small{E_t}\\) es la variable del bloque final que lleva la cuenta del n√∫mero \\(\\small{m}\\) de √©xitos finales:\n\n\n\\[\\begin{equation}\nE_t=\\begin{cases}\n\\gamma & \\text{si}\\, m\\geq k\\\\\nm & \\text{si}\\, m=0,1,\\ldots,k-1.\n\\end{cases}\n\\end{equation}\\]\n\nCon conteo superpuesto, es f√°cil verificar que las probabilidades para las matrices de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M_t}=p_{(x,i)(y,j)}(t)}\\) se pueden obtener a partir de la siguiente ecuaci√≥n:\n\n\n\\[\\begin{equation}\np_{(x,i)(y,j)}(t) =\n\\begin{cases}\nq_t & \\begin{array}{l} \\text{Si}\\,\\, y=x \\,\\, \\text{y}\\,\\, j=0 \\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n \\,\\,\\text{e}\\, i=\\gamma,0,1,\\ldots,k-1 \\end{array} \\\\\np_t & \\begin{array}{l} \\text{Si}\\,\\, y=x \\,\\, \\text{y}\\,\\, j=i+1\\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n \\,\\, \\text{e}\\,\\,i=0,1,\\ldots,k-2 \\end{array}\n\\\\\np_t & \\begin{array}{l} \\text{Si}\\,\\, y=x+1 \\,\\, \\text{y}\\,\\, j=\\gamma\\,\\,\\text{e}\\,\\,i=k-1,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n-1 \\end{array}\n\\\\\np_t & \\begin{array}{l} \\text{Si}\\, y=x+1,\\,j=i=\\gamma\\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n-1  \\end{array}\n\\\\\n1 & \\begin{array}{l} \\text{Si} \\,\\, y=x=l_n,\\,\\text{y}\\ j=i=\\gamma\\end{array} \\\\\n0 & \\begin{array}{l} \\text{Otro caso} \\end{array}\n\\end{cases}\\\\\n\\end{equation}\\]\n\nLa partici√≥n correspondiente del espacio de estados \\(\\small{\\Omega}\\) se puede especificar de la siguiente manera:\n\n\n\\[\\begin{align*}\nC_0 &=\\{(x,i):i=0,1,\\cdots,k-1\\}\\\\\nC_x &=\\{(x,i):i=\\gamma,0,1,\\cdots,k-1\\},\\, x=1,\\cdots,l_n,\\\\\nC_{l_n} &= \\{(l_n,\\gamma)\\}\n\\end{align*}\\]\n\nComo ejemplo considerese, \\(\\small{n=4}\\) y \\(\\small{k=2}\\), luego las matrices de probabilidades de transici√≥n \\(\\small{\\boldsymbol{M_t}(M_{4,2})}\\) para \\(\\small{t=1,2,3,4}\\) son:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M_t}(M_{4,2})=\n\\begin{array}{cc}&\n\\begin{array}{cccccc}\n\\end{array}\n\\\\\n\\begin{array}{cccccc}\n(0,0)\\\\\n(0,1)\\\\\n(1,\\gamma)\\\\\n(1,0)\\\\\n(1,1)\\\\\n(2,\\gamma)\\\\\n(2,0)\\\\\n(2,1)\\\\\n(3,\\gamma)\n\\end{array}\n&\n\\left(\n\\begin{array}{cc|c|cc|c|cc|c}\nq_t&p_t&0&0&0&0&0&0&0\\\\\nq_t&0&p_t&0&0&0&0&0&0\\\\\n\\hline\n0&0&0&q_t&0&p_t&0&0&0\\\\\n\\hline\n0&0&0&q_t&p_t&0&0&0&0\\\\\n0&0&0&q_t&0&p_t&0&0&0\\\\\n\\hline\n0&0&0&0&0&0&q_t&0&p_t\\\\\n\\hline\n0&0&0&0&0&0&q_t&p_t&0\\\\\n0&0&0&0&0&0&q_t&0&p_t\\\\\n\\hline\n0&0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nEn general para \\(\\small{n}\\) y \\(\\small{k}\\) arbitrareos, las matrices de probabilidad de transici√≥n contin√∫an teniendo una forma de bandas similar a \\(\\small{\\boldsymbol{M_t}(M_{4,2})}\\) en la ecuaci√≥n (3.15), y son de dimensi√≥n \\(\\small{l_n(k+1)}\\). La distribuci√≥n y los momentos de la variable aleatoria \\(\\small{M_{n,k}}\\) se pueden calcular nuevamente mediante las ecuaciones (2.11) y (2.12), respectivamente.\n\n\n\nLa Cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) asociada con la variable aleatoria, \\(\\small{E_{n,k}}\\), del n√∫mero de rachas exitosas de tama√±o exactamente \\(\\small{k}\\) en \\(\\small{n}\\) ensayos independientes de dos estados, se define por:\n\n\n\\[\\begin{equation}\nY_t=(E_{t,k},E_t)\n\\end{equation}\\]\n\nsobre el espacio de estados:\n\n\n\\[\\begin{equation}\n\\Omega =\\{(x,i):x=0,1,\\cdots,l_n\\,\\, \\text{e}\\,\\, i=\\beta,\\gamma,0,1,\\cdots,k-1\\}-\\{(0,\\gamma)\\},\n\\end{equation}\\]\n\nen donde, \\(\\small{l_n=[(n+1)/(k+1)]}\\), \\(\\small{E_{t,k}}\\) es el n√∫mero de rachas √©xitosas de longitud igual a \\(\\small{k}\\) en los primeros \\(\\small{t}\\) ensayos, y el bloque final \\(\\small{E_{t}}\\) se define en funci√≥n del n√∫mero de √©xitos finales \\(\\small{m}\\), en los primeros \\(\\small{t}\\) ensayos de la siguiente manera:\n\n\n\\[\\begin{equation}\nE_t=\\begin{cases}\nm & \\text{Si}\\,\\, m=0,1,\\ldots,k-1\\\\\n\\gamma & \\text{Si}\\,\\, m = k\\\\\n\\beta & \\text{Si}\\,\\, m&gt;k\n\\end{cases}\n\\end{equation}\\]\n\nLos dos estados del bloque final \\(\\small{\\beta}\\) e \\(\\small{\\gamma}\\) tienes la siguiente interpretaci√≥n:\n(i) Estado de espera \\(\\small{(x,\\gamma),\\,\\,x=1,2,\\dots,l_n}\\):\n\\(\\small{ Y_t=(x,\\gamma)}\\) significa que \\(\\small{m=k}\\) y que \\(\\small{x-}\\)√©sima racha exitosa de tama√±o \\(\\small{k}\\) ha ocurrido en el \\(\\small{t-}\\)√©simo ensayo, y\n(ii) Estado de desbordamiento \\(\\small{(x,\\beta),\\,\\,x=1,2,\\dots,l_n}\\):\n\\(\\small{ Y_t=(x,\\beta)}\\) significa que \\(\\small{m&gt;k}\\) y que exactamente \\(\\small{x}\\) rachas exitosas de tama√±o \\(\\small{k}\\) han aparecido antes de los √∫ltimos \\(\\small{m+1}\\) resultados \\(\\small{(F\\underbrace{S\\cdots S}_{m})}\\).\nCon estos bloques finales en mente, podemos construir f√°cilmente la partici√≥n para el espacio de estados \\(\\small{\\Omega:\\, C_0=\\{(0,i):i=\\beta,0,1,\\ldots, k-1\\} }\\) y \\(\\small{C_x=\\{(x,i):i=\\gamma,\\beta,0,1,\\ldots, k-1\\} }\\), para \\(\\small{x=1,\\ldots,l_n}\\).\nLas probabilidades para las matrices de transici√≥n \\(\\small{\\boldsymbol{M_t}(E_{t,k})}\\) de la cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\), se especifican mediante la siguiente ecuaci√≥n:\n\n\n\\[\\begin{equation}\np_{(x,i)(y,j)}(t) =\n\\begin{cases}\nq_t & \\begin{array}{l} \\text{Si}\\,\\, y=x \\,\\, \\text{y}\\,\\, j=0 \\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n \\,\\,\\text{e}\\,\\, i=\\gamma,\\beta,0,1,\\ldots,k-1 \\end{array} \\\\\np_t & \\begin{array}{l} \\text{Si}\\,\\, y=x \\,\\, \\text{y}\\,\\, j=i+1\\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n \\,\\, \\text{e}\\,\\,i=0,1,\\ldots,k-2 \\end{array}\n\\\\\np_t & \\begin{array}{l} \\text{Si}\\,\\, y=x+1 \\,\\, \\text{y}\\,\\, j=\\gamma\\,\\,\\text{e}\\,\\,i=k-1,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n-1 \\end{array}\n\\\\\np_t & \\begin{array}{l} \\text{Si}\\,\\, y=x-1,\\,\\,j=\\beta\\,\\, \\,\\,\\text{e}\\,\\, i=\\gamma\\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n  \\end{array}\n\\\\\np_t & \\begin{array}{l} \\text{Si}\\,\\, y=x,\\,\\,\\text{e}\\,\\, j=i=\\beta\\,, \\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n  \\end{array}\n\\\\\n1 & \\begin{array}{l} \\text{Si} \\,\\, y=x=l_n\\,\\,\\text{y}\\,\\, j=i=k-1\\end{array} \\\\\n0 & \\begin{array}{l} \\text{Otro caso}. \\end{array}\n\\end{cases}\\\\\n\\end{equation}\\]\n\nA modo de ilustraci√≥n, consideremos el caso \\(\\small{n=5}\\) y \\(\\small{k=2}\\), para lo cual tenemos las matrices de probabilidad de transici√≥n:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M_t}(E_{5,2})=\n\\begin{array}{cc}&\n\\begin{array}{c}\n(0,\\beta)\\\\\n(0,0)\\\\\n(0,1)\\\\\n(1,\\gamma)\\\\\n(1,\\beta)\\\\\n(1,0)\\\\\n(1,1)\\\\\n(2,\\gamma)\\\\\n(2,\\beta)\\\\\n(2,0)\\\\\n(2,1)\n\\end{array}\n&\n\\left(\n\\begin{array}{c|cc|cc|cc|cc|cc}\nq_t&p_t&0&0&0&0&0&0&0&0&0\\\\\n\\hline\n0&q_t&p_t&0&0&0&0&0&0&0&0\\\\\n0&q_t&0&p_t&0&0&0&0&0&0&0\\\\\n\\hline\np_t&0&0&0&0&q_t&0&0&0&0&0\\\\\n0&0&0&0&p_t&q_t&0&0&0&0&0\\\\\n\\hline\n0&0&0&0&0&q_t&p_t&0&0&0&0\\\\\n0&0&0&0&0&q_t&0&p_t&0&0&0\\\\\n\\hline\n0&0&0&0&p_t&0&0&0&0&q_t&0\\\\\n0&0&0&0&0&0&0&0&p_t&q_t&0\\\\\n\\hline\n0&0&0&0&0&0&0&0&0&q_t&p_t\\\\\n0&0&0&0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nEn general, las matrices de probabilidad de transici√≥n de la cadena de Markov \\(\\small{\\{Y_t\\}}\\) asociadas con \\(\\small{E_{n,k}}\\) tienen la forma dada por la ecuaci√≥n (3.19) con dimensi√≥n \\(\\small{(l_n + 1)(k+1)+l_n}\\).\n\n\n\nSea \\(\\small{L_n(S)}\\), la duraci√≥n de la racha exitosa m√°s larga en una sucesi√≥n de ensayos de dos estados. Para el caso de \\(\\small{n}\\) lanzamientos independientes de una moneda justa, sea \\(\\small{A_n(k)}\\) el n√∫mero de secuencias de longitud \\(\\small{n}\\) en las que la racha m√°s larga de √©xitos (cara) es menor o igual a \\(\\small{k}\\). Dado que todas las sucesiones son igualmente probables con probabilidad \\(\\small{(1/2)^n}\\), la distribuci√≥n del racha m√°s largo es:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(L_n(S)\\leq k\\big)=2^{-n}A_n(k)\n\\end{equation}\\]\n\ndonde \\(\\small{A_n(k)}\\) satisface la ecuaci√≥n recursiva (Schilling 1990)\n\n\n\\[\\begin{equation}\nA_n(k)=\\begin{cases}\n\\displaystyle\\sum_{j=0}^{k}A_{n-1-j}(k) & \\text{si}\\, n &gt; k\\\\\n2^{n} & \\text{si}\\,\\, n \\leq k\\\\\n1 & \\text{si}\\,\\, k = 0\\\\\n\\end{cases}\n\\end{equation}\\]\n\nPara monedas sesgadas \\(\\small{(p\\neq1/2)}\\), el an√°lisis combinatorio es:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(L_n(S)\\leq k\\big)=\\displaystyle\\sum_{x=0}^{k}C_{n}^{(x)}(k)p^{x}q^{n-x},\n\\end{equation}\\]\n\npara \\(\\small{1 \\leq k \\leq n}\\), y \\(\\small{\\mathbb{P}\\big(L_n(S)=0 \\big)=q^{-n}}\\), donde \\(\\small{C_n^{(x)}(k)}\\) es el n√∫mero de secuencias de longitud \\(\\small{n}\\) en las que ocurren exactamente \\(\\small{x}\\) √©xitos, pero en las que no m√°s de \\(\\small{k}\\) de estos √©xitos ocurren consecutivamente. \\(\\small{C_n^{(x)}(k)}\\) se puede obtener a trav√©s de la ecuaci√≥n recursiva:\n\n\n\\[\\begin{equation}\nC_n^{(x)}(k)=\\begin{cases}\n\\displaystyle\\sum_{j=0}^{k}C_{n-1-j}^{x-j}(k) & \\text{si}\\,\\,  k&lt;x&lt;n\\\\\n\\binom{n}{x} & \\text{si}\\,\\,  x \\leq k \\leq n\\\\\n\\, 0 & \\text{si}\\,\\,k&lt;x= n\\\\\n\\end{cases}\n\\end{equation}\\]\n\nDe manera m√°s general, supongamos que las probabilidades de √©xito y fracaso podr√≠an ser diferentes en cada ensayo, iguales a \\(\\small{p_t}\\) y \\(\\small{q_t}\\), respectivamente, para \\(\\small{t=1,2,\\ldots,n}\\). El siguiente teorema deriva la distribuci√≥n de \\(\\small{L_n(S)}\\):\nTeorema 3.1 Para \\(\\small{0\\leq k\\leq n}\\),\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(L_n(S)\\leq k\\big)=\\boldsymbol{\\mathbf{\\xi}} \\Big(\\prod_{t=1}^{n}\\boldsymbol{N}_t\\Big)\\boldsymbol{\\mathbf{1}'}_{1 \\times(k+1)}\n\\end{equation}\\]\n\nen donde \\(\\small{\\boldsymbol{\\mathbf{\\xi}}=(1,0,\\ldots,0)}\\) es un vector fila unitario de tama√±o \\(\\small{1\\times (k+1)}\\) y \\(\\small{\\boldsymbol{N_t}}\\) es como se indica a continuaci√≥n, la submatriz esencial \\(\\small{(k+1)\\times (k+1)}\\) de la matriz de probabilidades de transici√≥n:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M_t}=\n\\begin{array}{cc}&\n\\begin{array}{c}\n0\\\\\n1\\\\\n\\vdots\\\\\n\\vdots\\\\\nk\\\\\n\\alpha\n\\end{array}\n&\\left(\n\\begin{array}{ccccc|c}\nq_t&p_t&0&\\cdots&0&0\\\\\nq_t&0&p_t&\\cdots&0&0\\\\\n\\vdots&&\\ddots&\\ddots&&\\vdots\\\\\n\\vdots&&\\ddots&\\ddots&\\ddots&\\vdots\\\\\nq_t&0&\\cdots&\\cdots&0&p_t\\\\\n\\hline\n0&0&\\cdots&\\cdots&0&1\\\\\n\\end{array}\n\\right)_{(k+2) \\times (k+2)}\n\\end{array}=\\left(\\begin{array}{c|c}\n\\boldsymbol{N_t} &  {C_t}\\\\\n\\hline\n\\boldsymbol{0}&  {1}\\\\\n\\end{array}\n\\right)\n\\end{equation}\\]\n\nDemostraci√≥n: La racha exitosa m√°s larga en una sucesi√≥n de ensayos de dos estados est√° relacionada con las estad√≠sticas de ejecuci√≥n \\(\\small{N_{n,k}}\\), \\(\\small{G_{n,k}}\\) y \\(\\small{M_{n,k}}\\) de la siguiente manera sencilla:\n\n\n\\[\\begin{equation}\nL_n(S)\\leq k \\,\\, \\text{si y solo si}\\,\\, N_{n,k+1} = G_{n,k+1}=M_{n,k+1}=0\n\\end{equation}\\]\n\nPor tanto, \\(\\small{\\mathbb{P}\\big(L_n(S)\\leq k\\big)=\\mathbb{P}\\big(N_{n,k+1}=0\\big)}\\), y podemos completar la demostraci√≥n considerando la Ecuaci√≥n (3.8) para \\(\\small{\\mathbb{P}\\big(N_{n,k+1}=x\\big)}\\) con \\(\\small{x=0}\\). Cambiando los estados \\(\\small{(0,0),(0,1),\\ldots,(0,k)}\\) en esta aplicaci√≥n de la Ecuaci√≥n (3.8) a los estados \\(\\small{0,1,2,\\ldots,k}\\) respectivamente, y combinando todos los dem√°s estados en el estado absorbente \\(\\small{\\alpha}\\), obtenemos:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(L_n(S)\\leq k\\big)=\\mathbb{P}\\big(N_{n,k+1}=0\\big)=\\boldsymbol{\\mathbf{\\xi}_0} \\Big(\\prod_{t=1}^{n}\\boldsymbol{M}_t\\Big)(1,\\ldots,1,0)'\n\\end{equation}\\]\n\nen donde \\(\\small{\\boldsymbol{\\xi_0}=(1,0\\ldots,0)_{1\\times(k+2)}=(\\boldsymbol{\\xi}:0)}\\). Con la notaci√≥n \\(\\small{(1,\\ldots,1,0)_{1\\times(k+2)}=(\\boldsymbol{1}:0)}\\) y haciendo uso del hecho que las matrices de transici√≥n de probabilidad tienen la forma:\n\n\n\\[\\begin{equation}\n\\prod_{t=1}^{n}\\boldsymbol{M_t}=\n\\left(\n\\begin{array}{c|c}\n\\displaystyle\\prod_{t=1}^{n}\\boldsymbol{N_t}& C_t(n)\\\\\n\\hline\n\\boldsymbol{0}&1\n\\end{array}\n\\right)\n\\end{equation}\\]\n\nluego, el teorema se sigue inmediatamente. \\(\\hspace{3cm}\\Box\\)\nColorario Dados \\(\\small{1 \\leq k \\leq n}\\) se satisface la siguiente ecuaci√≥n recursiva:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(L_n(S)\\leq k\\big)=q_n\\cdot\\mathbb{P}\\big(L_{n-1}(S)\\leq k\\big)+\\displaystyle\\sum_{i=1}^{k}q_{n-i} \\prod_{j=n-i+1}^{n}p_{j}\\cdot\\mathbb{P}\\big(L_{n-i-1}(S)\\leq k\\big)\n\\end{equation}\\]\n\ncon \\(\\small{\\mathbb{P}\\big(L_n(S)=0\\big)=\\displaystyle\\prod_{j=1}^{n}q_j}\\) y \\(\\small{\\mathbb{P}\\big(L_n(S)\\leq n\\big)\\equiv1}\\) para \\(\\small{k=m}.\\)\nDemostraci√≥n De la estructuradada dada por la Ec.(3.25) para las matrices de probabilidades de transici√≥n \\(\\small{\\boldsymbol{M_t}}\\), se sigue que:\n\n\n\\[\\begin{align*}\n\\text{(i)}\\,\\, \\boldsymbol{M_te_0'} &=q_t(1,\\ldots,1,0)'_{1\\times(k+2)}\\,\\, \\text{y} \\\\\n\\text{(ii)}\\,\\,\\boldsymbol{M_te_i'} &=p_t\\boldsymbol{e_{i-1}'},\\,\\,\\text{para}\\,\\, i=1,2,\\ldots,k,\n\\end{align*}\\]\n\nen donde \\(\\small{\\boldsymbol{e_i}=(0,\\ldots,0,1,0,\\ldots,0)}\\) es un vector fila unitario con un uno en la coordenada asociada al estado \\(\\small{i}\\), para \\(\\small{i=0,1,2,\\ldots,k}\\).\nDado que \\(\\small{\\displaystyle\\sum_{i=0}^{k}\\boldsymbol{e_i'}}\\), nuestro resultado es una consecuencia directa de (i),(ii) y multiplicaciones hacia atr√°s de la ecuaci√≥n (3.24).\nTomando \\(\\small{p_t=q_t=1/2}\\) para todo \\(\\small{t=1,2,\\ldots,n}\\) y multiplicando \\(\\small{\\mathbb{P}\\big(L_n(S)\\leq k\\big)=1}\\) por \\(\\small{2^n}\\), la ecuaci√≥n (3.26) produce la ecuaci√≥n recursiva (3.21) para \\(\\small{A_n(k)}\\). El teorema 3.1 tambi√©n se puede extender para la rachas de falla m√°s larga \\(\\small{L_n(F)}\\) y a la estad√≠stica de racha m√°s larga \\(\\small{L_n = \\max\\{L_n(S), L_n(F)\\}}\\). Para el caso i.i.d. y para \\(\\small{n}\\) grande, hay varios resultados sobresalientes sobre la duraci√≥n de la racha exitosa m√°s larga. R√©nyi (1970), Cs√∂rg√∂ (1979), Erd√∂s y R√©nyi (1970) y Erd√∂s y R√©v√©sz (1975) muestran que, cuando \\(\\small{n \\rightarrow \\infty}\\)\n\n\n\\[\\begin{equation}\n\\frac{L_n(S)}{\\log_{1/p}(n)} \\xrightarrow{a.s} 1\n\\end{equation}\\]\n\nA este resultado se le suele denominar la nueva ley de los grandes n√∫meros.\nEn el Cap√≠tulo 5, desarrollaremos una aproximaci√≥n de grande desviaci√≥n para la probabilidad de \\(\\small{L_n(S)}\\) bajo ensayos i.i.d. (y Markov-Dependientes homog√©neos):\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(L_n(S)\\leq  k\\big)\\sim \\exp\\{-n\\beta\\}\n\\end{equation}\\]\n\nen donde \\(\\small{\\beta=-\\log(\\lambda_{[1]})}\\) y \\(\\small{\\lambda_{[1]}}\\) es el valor propio m√°s grande de la submatriz de probabilidad de transici√≥n esencial \\(\\small{\\boldsymbol{N_t}}\\) (con \\(\\small{p_t}\\) y \\(\\small{q_t}\\) constantes) dada por la ecuaci√≥n (3.25).\n\n\n\nSea \\(\\small{\\Lambda=S\\cdots S}\\) el patr√≥n simple de \\(\\small{k}\\) √©xitos consecutivos y defina la variable aleatoria \\(\\small{W(\\Lambda)}\\) como el tiempo de espera para que ocurra el patr√≥n \\(\\small{\\Lambda}\\), es decir \n\n\\[\\begin{equation}\nW(\\Lambda)=\\inf\\{n:X_{n-k+1}=X_{n-k+2}=\\cdots=X_{n}=S\\}.\n\\end{equation}\\]\n\nPor ejemplo, dado \\(\\small{k=3}\\), \\(\\small{W(\\Lambda)=6}\\) significa que el patr√≥n \\(\\small{SSS}\\) ocurre por primera vez despu√©s de seis intentos, como en \\(\\small{SFFSSS}\\). La distribuci√≥n de \\(\\small{W(\\Lambda)}\\) para los ensayos de Bernoulli a menudo se denomina distribuci√≥n geom√©trica de orden \\(\\small{k}\\) (ver Aki 1985 e Hirano 1986).\nTeorema 3.2 Dado un patr√≥n de longitud \\(\\small{k\\geq 1}\\) y una sucesi√≥n de ensayos Bernoulli \\(\\small{\\{X_t\\}}\\), la distribuci√≥n de \\(\\small{W(\\Lambda)}\\) esta dada por:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(W(\\Lambda)=n\\big)=\\boldsymbol{\\xi} \\boldsymbol{N_t}^{n-1}(\\Lambda)\\big(\\boldsymbol{I-N}(\\Lambda)\\big)\\boldsymbol{1'}\n\\end{equation}\\]\n\nen donde \\(\\small{\\boldsymbol{\\xi}=(1,0,\\ldots,0)}\\) es un vector fila \\(\\small{1\\times k}\\) y \\(\\small{\\boldsymbol{N}(\\Lambda)}\\) es la submatriz de probabilidades de transici√≥n esencial:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}(\\Lambda)=\n\\begin{array}{cc}&\n\\begin{array}{c}\n0\\\\\n1\\\\\n\\vdots\\\\\n\\vdots\\\\\nk-1\\\\\n\\alpha\n\\end{array}\n&\\left(\n\\begin{array}{ccccc|c}\np&q&0&\\cdots&0&0\\\\\nq&0&p&\\cdots&0&0\\\\\n\\vdots& &\\ddots&\\ddots&&\\vdots\\\\\n\\vdots&&\\ddots&\\ddots&\\ddots&\\vdots\\\\\nq&0&\\cdots&\\cdots&0&p\\\\\n\\hline\n0&0&\\cdots&\\cdots&0&1\\\\\n\\end{array}\n\\right)_{(k+1)\\times(k+1)}\n\\end{array}=\n\\left(\n\\begin{array}{c|c}\n\\boldsymbol{N}(\\Lambda)&C\\\\\n\\hline\n\\boldsymbol{0} & 1\n\\end{array}\\right)\n\\end{equation}\\]\n\nSe deduce adem√°s que la funci√≥n generadora de probabilidad de \\(\\small{W(\\Lambda)}\\) est√° dada por:\n\n\n\\[\\begin{equation}\n\\varphi_{W}(s)=\\frac{p^ks^k(1-ps)}{1-s+qp^ks^{k+1}}\n\\end{equation}\\]\n\nPrueba. Dados \\(\\small{\\Lambda}\\),\\(\\small{}\\) y \\(\\small{k \\leq n}\\), de la definici√≥n de \\(\\small{W(\\Lambda)}\\) y \\(\\small{N_{n,k}}\\), se deduce que estas dos variables aleatorias tienen la siguiente relaci√≥n:\n\n\n\\[\\begin{equation}\nW(\\Lambda) \\leq n \\quad \\text{si y solo si}\\quad N_{n,k}\\geq 1 \\,\\,\\text{para todo }\\, n \\geq k.\n\\end{equation}\\]\n\nPor tanto \\(\\small{\\mathbb{P}\\big(W(\\Lambda)\\leq n\\big)=\\mathbb{P}\\big(N_{n,k}\\geq 1\\big)}\\) y\n\n\n\\[\\begin{align*}\n\\mathbb{P}\\big(W(\\Lambda)\\leq n\\big) &= \\mathbb{P}\\big(N_{n,k}\\geq 1\\big)-\\mathbb{P}\\big(N_{n-1,k}\\geq 1\\big), \\\\\n&=  \\mathbb{P}\\big(N_{n-1,k}= 0\\big)-\\mathbb{P}\\big(N_{n,k}= 0\\big).\n\\end{align*}\\]\n\nPuesto que s√≥lo necesitamos el resultado general de \\(\\small{\\mathbb{P}\\big(N_{n,k}= 0\\big)}\\) para completar la prueba, podemos, como en la secci√≥n anterior sobre la racha exitosa m√°s larga, reemplazar los estados \\(\\small{(0,0),\\cdots,(0,k-1)}\\) definidos en la Secci√≥n 3.2 por los estados \\(\\small{0,1,2,\\ldots,k-1}\\) y combinar todos los dem√°s estados en un estado absorbente \\(\\small{\\alpha}\\). Bajo este espacio de estados reducido, la matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M_t}(N_{n,k})}\\) se simplifica a \\(\\small{\\boldsymbol{M}(\\Lambda)}\\). La ecuaci√≥n (3.27) del teorema 3.2 es entonces una consecuencia inmediata de las ecuaciones (3.8), (3.30) y Teorema 3.1.\nNote que, para \\(\\small{0\\leq i\\leq k-1,}\\)\n\n\n\\[\\begin{equation}\n\\boldsymbol{e_iN}(\\Lambda)=q\\boldsymbol{e_0}+p\\boldsymbol{e_{i+1}}.\n\\end{equation}\\]\n\nDado \\(\\small{\\boldsymbol{\\xi=e}_0}\\), y usando del resultado de multiplicaci√≥n hacia adelante obtenemos la siguiente ecuaci√≥n recursiva:\n\n\n\\[\\begin{align*}\n\\mathbb{P}\\big(W(\\Lambda)= n\\big) &= \\boldsymbol{\\xi N}^{n-1}(\\Lambda)\\big(\\boldsymbol{I-N}(\\Lambda)\\big)\\boldsymbol{1'} \\\\\n&= \\sum_{i=1}^{k}qp^{i-1}\\mathbb{P}\\big(W(\\Lambda)=n-i\\big).\n\\end{align*}\\]\n\nLa anterior ecuaci√≥n recursivay la condici√≥n de frontera \\(\\small{\\mathbb{P}\\big(W(\\Lambda)=k\\big)=p^{k}}\\) conducen a la siguiente ecuaci√≥n recursiva para la funci√≥n generadora de probabilidad \\(\\small{\\varphi_{W}(s)}\\):\n\n\n\\[\\begin{equation}\n\\varphi_{W}(s)= s^kp^k+\\sum_{i=1}^{k}qp^{i-1}s^{i}\\varphi_{W}(s)\n\\end{equation}\\]\n\nSumando las series de potencias finitas se obtiene el resultado expl√≠cito para \\(\\small{\\varphi_{W}(s)}\\) dado en la Ec. (3.29), resultado que fue derivado por primera vez por Feller (1968) utilizando la teor√≠a de la renovaciones.\\(\\hspace{3cm}\\Box\\)\nSi definimos las matrices:\n\n\n\\[\\begin{equation}\n\\boldsymbol{A}=\\left(\n\\begin{array}{ccccc}\nq&p&0&\\cdots&0\\\\\nq&0&p& &0\\\\\n\\vdots& &\\ddots&\\ddots& \\\\\nq& & &0&p\\\\\nq&0&\\cdots&&0\\\\\n\\end{array}\n\\right)_{k\\times k},\\,\n\\boldsymbol{B}=\\left(\n\\begin{array}{ccccc}\n0&0&0&\\cdots&0\\\\\n0&0&0& &\\\\\n\\vdots& &\\ddots&\\ddots& \\\\\n0& & &0&0\\\\\np&0&\\cdots&&0\\\\\n\\end{array}\n\\right)_{k\\times k}\n\\end{equation}\\]\n\n\n\n\\[\\begin{equation}\n\\boldsymbol{A}^{\\ast}=(1)_{1\\times 1}\\,\\, \\text{y}\\,\\, \\boldsymbol{B}^{\\ast}=(0\\,\\,0\\,\\,\\cdots \\, 0\\,\\,p)'_{k\\times 1}\n\\end{equation}\\]\n\ny sea \\(\\small{W(m,\\Lambda)}\\) el tiempo de espera para la \\(\\small{m-}\\)√©sima racha de \\(\\small{k}\\) √©xitos consecutivos (sin solapamiento). De forma similar al desarrollo anterior para \\(\\small{W(\\Lambda)}\\), la distribuci√≥n de la variable aleatoria \\(\\small{W(m,\\Lambda)}\\) puede ser obtenida usando la Ecuaci√≥n (3.27) al remplazar la matriz de probabilidades de transici√≥n \\(\\small{W(\\Lambda)}\\), por:\n\n\n\\[\\begin{equation}\n\\boldsymbol{W}(m,\\Lambda)=\\left(\n\\begin{array}{ccccc}\n\\boldsymbol{A}&\\boldsymbol{A}& &\\boldsymbol{O}&\\\\\n&\\ddots & \\ddots& &\\\\\n& &\\boldsymbol{A}&\\boldsymbol{B}& \\\\\n&\\boldsymbol{O} &&\\boldsymbol{A}&\\boldsymbol{B^{\\ast}}\\\\\n& & &&\\boldsymbol{A^{\\ast}}\\\\\n\\end{array}\n\\right)_{(mk+1)\\times (mk+1)}\n\\end{equation}\\]\n\nObs√©rvese que la matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M}(\\Lambda)}\\) de la Ec. (3.28) es el caso especial de \\(\\small{\\boldsymbol{M}(m,\\Lambda)}\\) con \\(\\small{m=1}\\). Puesto que \\(\\small{W(m,\\Lambda)=\\displaystyle\\sum_{i=1}^{m}W_i(\\Lambda)}\\), donde \\(\\small{W_i(\\Lambda)}\\) representa el tiempo de espera desde la \\(\\small{(i-1)-}\\)√©sima ocurrencia hasta la \\(\\small{(i)-}\\)√©sima ocurrencia del patr√≥n \\(\\small{\\Lambda}\\), y puesto que las variables aleatorias \\(\\small{W(\\Lambda)}\\) son i.i.d., se deduce de la Ec. (3.29) que la funci√≥n generadora de probabilidad de \\(\\small{W(m,\\Lambda)}\\) es:\n\n\n\\[\\begin{equation}\n\\varphi_{W(m,\\Lambda)}^{m}(s)=\\varphi_{W}^{m}(s)=\\Bigg(\\frac{p^ks^k(1-ps)}{1-s+qp^ks^{k+1}}\\Bigg)^{m}.\n\\end{equation}\\]\n\nLa funci√≥n generadora de probabilidad \\(\\small{\\varphi_{W}(s)}\\) siempre existe para todo \\(\\small{|s| \\leq 1}\\)\nEsto se desprende de su definici√≥n y del hecho de que:\n\n\n\\[\\begin{equation}\n|\\varphi_{W}(s)|\\leq\\sum_{n=1}^{\\infty}|s^{n}|\\cdot\\mathbb{P}(W=n)\\leq\\sum_{n=1}^{\\infty}\\mathbb{P}(W=n)=1.\n\\end{equation}\\]\n\nSin embargo, la funci√≥n generadora de probabilidad \\(\\small{\\varphi_{W}(s)}\\) puede existir m√°s all√° de la regi√≥n \\(\\small{|s| \\leq 1}\\). La regi√≥n exacta var√≠a de un problema a otro. Volveremos a discutir la mayor regi√≥n de existencia de \\(\\small{\\varphi_{W}(s)}\\) en la secci√≥n 5.7.\nLa distribuci√≥n de \\(\\small{W(m,\\Lambda)}\\) tambi√©n puede obtenerse mediante la ecuaci√≥n\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(W(m,\\Lambda)=n\\big)=\\frac{1}{n!}\\frac{d^{n}}{ds^{n}}\\varphi_{W(m,\\Lambda)}(s)\\Bigr|_{s=0}.\n\\end{equation}\\]\n\nenfoque que puede obtenerse m√°s f√°cilmente utilizando software de manipulaci√≥n simb√≥lica (por ejemplo, MAPLE o MATLAB). En el cap√≠tulo 5 se ofrece un tratamiento m√°s detallado de las distribuciones de tiempo de espera para patrones simples y compuestos en ensayos i.i.d. y Markov-Dependientes multiestado.\n\n\n\nAntes de estudiar estad√≠sticas de rachas m√°s complejas, en esta secci√≥n proporcionamos algunos resultados num√©ricos para las estad√≠sticas de rachas y los tiempos de espera descritos en las secciones anteriores con el fin de ilustrar los resultados te√≥ricos. Dada la matriz (o matrices) de probabilidad de transici√≥n de la cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) , en general s√≥lo necesitamos dos tipos de f√≥rmulas, en las formas de las Ecs. (3.8) y (3.27), para evaluar las distribuciones de \\(\\small{X_n(\\Lambda)}\\) y \\(\\small{W(\\Lambda)}\\), respectivamente. Las f√≥rmulas son sencillas y eficientes desde el punto de vista computacional, adecuadas incluso para \\(\\small{n}\\) muy grandes. Los resultados num√©ricos que aqu√≠ se presentan tambi√©n pueden servir para comprobar los propios c√°lculos de programaci√≥n. En todos los ejemplos considerados, el tiempo de c√°lculo para obtener cada distribuci√≥n es m√≠nimo, una fracci√≥n de segundo en un PC actual.\nEn la Tabla 3.1 se presentan las distribuciones exactas y las medias de las variables aleatorias \\(\\small{E_{15,2},\\, G_{15,2},\\,N_{15,2},\\, M_{15,2}}\\) y \\(\\small{L_{15}(S)}\\) bajo el supuesto de que \\(\\small{\\{X_t\\}}\\)es una secuencia de ensayos independientes de dos estados con probabilidades \\(\\small{p_t=1/(t+1)}\\) para \\(\\small{t=1,2,\\ldots,15}\\).\nLa Tabla 3.2 muestra las distribuciones del tiempo de espera de la primera racha con √©xito de longitud \\(\\small{k}\\), para varios valores de \\(\\small{k}\\) y probabilidades de estado \\(\\small{p_t}\\). En los cap√≠tulos 5 y 7 se ofrecen m√°s resultados num√©ricos sobre las distribuciones del tiempo de espera.\n\n\n\nSea \\(\\small{S_{n,k}}\\) el n√∫mero total de √©xitos en rachas de √©xitos de longitud mayor o igual que \\(\\small{}\\), para \\(\\small{k=1,2,\\ldots,n}\\). Puede escribirse como\n\n\n\\[\\begin{equation}\nS_{n,k}=\\sum_{i=k}^{n}iR_n(i),\n\\end{equation}\\]\n\nen donde \\(\\small{R_n(i)}\\), para \\(\\small{i=k,\\ldots,n}\\) es el n√∫mero de rachas √©xitosas de longitud exactamente igual a \\(\\small{i}\\) en una sucesi√≥n \\(\\small{\\{X_t\\}}\\). Para \\(\\small{k=1}\\), la Ec. (3.33) es equivalente al n√∫mero total de √©xitos en la sucesi√≥n \\(\\small{\\{X_t\\}}\\), es decir:\n\n\n\\[\\begin{equation}\nS_{n,1}=\\sum_{i=k}^{n}I_{X_i},\n\\end{equation}\\]\n\nen donde \\(\\small{I_{X_i}=1}\\) cuando el \\(\\small{i-}\\)√©simo ensayo es √©xito y cero en otro caso. Si \\(\\small{\\{X_t\\}}\\) es una sucesi√≥n de ensayos Bernoulli, entonces \\(\\small{S_{n,1}}\\) tiene distribuciones binomial exacta y normal en el l√≠mite, respectivamente. De manera m√°s general, para el caso \\(\\small{\\{X_t\\}}\\) es una sucesi√≥n de variables aleatorias Markov-Dependientes, la estad√≠stica \\(\\small{S_{n,k}}\\) tambi√©n tiene una distrubuci√≥n l√≠mite normal, como determino Nagaev (1957) para \\(\\small{k=1}\\) y Fu, Lou, Bai y Li (2002) para \\(\\small{k \\geq 2}\\). En esta secci√≥n, s√≥lo estudiamos la distribuci√≥n exacta de \\(\\small{S_{n,k}}\\) con \\(\\small{k \\geq 2}\\).\nSea \\(\\small{L_j}\\), para \\(\\small{j \\geq 2}\\), la longitud de la racha de √©xitos situada entre el \\(\\small{(j-1)-}\\)√©simo y el \\(\\small{j-}\\) √©simo fallo en la sucesi√≥n \\(\\small{\\{X_t\\}}\\), con \\(\\small{L_1=0}\\) si el primer ensayo es un fallo y \\(\\small{L_1=l}\\) si los primeros \\(\\small{l}\\) ensayos son √©xitos y el \\(\\small{(j+1)-}\\)√©simo ensayo es un fallo. Para un √≠ndice de tiempo \\(\\small{t}\\) dado, sea \\(\\small{m_t}\\) el n√∫mero de fracasos en la subsecuencia \\(\\small{X_1, X_2,\\ldots, X_t}\\) y sea \\(\\small{L_t^{\\star}}\\) el n√∫mero de √©xitos que se producen despu√©s del \\(\\small{m_t-}\\)√©simo fracaso en esta subsecuencia. N√≥tese que \\(\\small{0 \\leq L_{t}^{\\star} \\leq t}\\) y \\(\\small{0\\leq L_t^{\\star} \\leq L_{m_t+1}}\\). Por otra parte, \\(\\small{S_{t,k}}\\), tal como se define en la Ec. (3.33), tambi√©n se puede escribir como:\n\n\n\\[\\begin{equation}\nS_{t,k}=\\sum_{j=1}^{m_t}L_{j}(k)+L_t^{\\star}(t),\n\\end{equation}\\]\n\ncon \n\n\\[\\begin{equation}\nL_{j}(k)=L_j\\cdot I_{\\{L_j\\geq k\\}}\\quad \\text{y}\\quad L_{j}^{\\star}(k)=L_j^{\\star}\\cdot I_{\\{L_j^{\\star} \\geq k\\}}.\n\\end{equation}\\]\n\nAc√° \\(\\small{I_{\\{L_j \\geq k\\}}}\\), es la funci√≥n indicadora del evento \\(\\small{\\{L_j \\geq k\\}}\\), es decir, es igual a uno cuando (\\(\\small{I_{\\{L_j^{\\star} \\geq k\\}}}\\), se define de manera an√°loga) Para capturar la informaci√≥n relevante en la subsucesi√≥n \\(\\small{\\{X_1,X_2,\\cdots, X_t\\}}\\) definimos una nueva sucesi√≥n de variables aleatorias en la forma del vector de dos componentes\n\n\n\\[\\begin{equation}\nY_t=\\big( S_{t,k},E_{t}(t)\\big),\\,\\, t=1,2,\\ldots,n,\n\\end{equation}\\]\n\nen donde \\(\\small{S_{t,k}}\\) indica el n√∫mero total de √©xitos en rachas exitosas de longitud mayor o igual a \\(\\small{k}\\) en los primeros \\(\\small{t}\\) ensayos, y \\(\\small{E_{t}(k)}\\) es la variable aleatoria de bloque final dada por:\n\n\n\\[\\begin{equation}\nE_{t}(k)= L_{t}^{\\star}\\big(1-I_{\\{L_j^{\\star}\\geq k\\}}\\big)+k^{+}\\cdot I_{\\{L_j^{\\star} \\geq k\\}}.\n\\end{equation}\\]\n\nEn esta expresi√≥n, el s√≠mbolo \\(\\small{k^{+}}\\) representa el estado donde \\(\\small{L_t}\\) es mayor o igual que \\(\\small{k}\\).\nEl bloque final \\(\\small{E_t(k)}\\) representa la longitud de la racha de √©xitos contando hacia atr√°s desde el \\(\\small{t-}\\)√©simo ensayo, con \\(\\small{E_t(k)=0}\\) si el \\(\\small{t-}\\)√©simo ensayo es un fracaso y \\(\\small{E_t(k)=k^{+}}\\) si la longitud es mayor o igual a \\(\\small{k}\\). M√°s espec√≠ficamente, considere que desde el 1 \\(\\small{ m_t-}\\)√©simo (o m√°s reciente) fracaso \\(\\small{F}\\) hasta el final de la subsucesi√≥n \\(\\small{\\{X_1,X_2,\\cdots, X_t\\}}\\) s√≥lo podemos tener los siguientes resultados posibles: \\(\\small{\\{F,FS,\\cdots,FS\\cdots S,\\,\\text{or}\\, S\\cdots S\\, \\text{si } m_t = 0\\}}\\); la variable aleatoria \\(\\small{E_t(k)}\\) es igual al n√∫mero de √©xitos en estos resultados si el n√∫mero es menor que \\(\\small{k}\\), y \\(\\small{E_t(k)=k^{+}}\\) si es igual o mayor que \\(\\small{k}\\). Este bloque final de los primeros \\(\\small{t}\\) ensayos proporciona informaci√≥n esencial sobre las probabilidades de transici√≥n de \\(\\small{Y_t}\\) a \\(\\small{Y_{t+1}}\\).\nDefinimos el espacio de estados\n\n\n\\[\\begin{equation}\n\\Omega =\\{(u,v):u=0,k,\\cdots,n-1,n\\,\\, \\text{y}\\,\\, v=0,1,\\cdots,k-1,k^{+}\\},\n\\end{equation}\\]\n\ncon tama√±o \\(\\small{d=\\text{card}(\\Omega)=(n-k+2)(k+1)}\\), y consideraremos aqu√≠ el caso en que la sucesi√≥n \\(\\small{\\{X_t\\}}\\) es una cadena de Markov homog√©nea con probabilidades de transici√≥n \\(\\small{p_{FF},p_{Fs},p_{SF}}\\) y \\(\\small{p_{SS}}\\). En nuestro procedimiento de recuento, la sucesi√≥n de vectores aleatorios \\(\\small{Y_t=\\big( S_{t,k},E_{t}(t)\\big),\\,\\, t=1,2,\\ldots,n,}\\) definida en \\(\\small{\\Omega}\\) obedece las siguientes reglas:\n(i) Dado \\(\\small{Y_{t-1}=(x,0)}\\), entonces \\(\\small{Y_{t}=(x,0)}\\) con probabilidad \\(\\small{p_{FF}}\\) si el resultado del \\(\\small{t-}\\)√©simo ensayo es \\(\\small{F}\\), e \\(\\small{Y_{t}=(x,1)}\\) con probabilidad \\(\\small{p_{FS}}\\) si el resultado del \\(\\small{t-}\\)√©simo ensayo es \\(\\small{S}\\).\n(ii) Dado \\(\\small{Y_{t-1}=(x,y)}\\) para \\(\\small{1\\leq y \\leq k-2}\\) entonces \\(\\small{Y_{t}=(x,0)}\\) con probabilidad \\(\\small{p_{SF}}\\) si el resultado del \\(\\small{t-}\\)√©simo ensayo es \\(\\small{F}\\), e \\(\\small{Y_{t}=(x,y+1)}\\) con probabilidad \\(\\small{p_{SS}}\\) si el resultado del \\(\\small{t-}\\)√©simo ensayo es \\(\\small{S}\\).\n(iii) Dado \\(\\small{Y_{t-1}=(x,k-1)}\\), entonces \\(\\small{Y_{t}=(x,0)}\\), con probabilidad \\(\\small{p_{SF}}\\) si el resultado del \\(\\small{t-}\\)√©simo ensayo es \\(\\small{F}\\), e \\(\\small{Y_{t-1}=(x+k,k^{+})}\\), con probabilidad \\(\\small{p_{SS}}\\) si el resultado del \\(\\small{t-}\\)√©simo ensayo es \\(\\small{S}\\).\n(iv) Dado \\(\\small{Y_{t-1}=(x,k^{+})}\\), entonces \\(\\small{Y_{t}=(x,0)}\\) con probabilidad \\(\\small{p_{SF}}\\) si el resultado del \\(\\small{t-}\\)√©simo ensayo es \\(\\small{F}\\), e \\(\\small{Y_{t}=(x+1,k^{+})}\\) con probabilidad \\(\\small{p_{SS}}\\) si el resultado del \\(\\small{t-}\\)√©simo prueba es \\(\\small{S}\\).\nA la vista de nuestra construcci√≥n, la sucesi√≥n \\(\\small{\\{Y_t = \\big( S_{t,k}, E_t(k) \\big) : t = 1, 2,..., n\\}}\\) forma una cadena de Markov homog√©nea con matriz de probabilidad de transici√≥n:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\\big( p_{(x,y)\\times(u,v)}\\big)_{d\\times d}\n\\end{equation}\\]\n\ndonde las probabilidades de transici√≥n \\(\\small{p_{(x,y)\\times(u,v)}}\\), bajo orden lexicogr√°fico de los estados \\(\\small{(\\cdot,\\cdot)}\\), se pueden especificar expl√≠citamente de la siguiente manera. Dado \\(\\small{(x,y)\\in \\Omega}\\),\n\n\n\\[\\begin{equation}\np_{(x,y)(u,v)}(t) =\n\\begin{cases}\np_{FF} & \\begin{array}{l} \\text{Si}\\,\\, y=v=0 \\,\\, \\text{y}\\,\\, u=x, \\end{array} \\\\\np_{FS} & \\begin{array}{l} \\text{Si}\\,\\, y=0,\\,v=1 \\,\\, \\text{y}\\,\\, u=x, \\end{array}\n\\\\\np_{SF} & \\begin{array}{l} \\text{Si}\\,\\, y\\neq 0,\\,v=0\\,\\, \\text{y}\\,\\, u=x, \\end{array}\n\\\\\np_{SS} & \\begin{array}{l} \\text{Si}\\,\\, 1 \\leq y \\leq k-2,\\,\\,v=y+1\\,\\, \\,\\,\\text{e}\\,\\, u=x,\\\\\n\\text{o si}\\,\\, y=k-1,\\,\\, v=k^{+}\\,\\,\\text{e}\\,\\, u=x+k,\\\\\n\\text{o si}\\,\\, y=k^{+},\\,\\, v=k^{+}\\,\\,\\text{e}\\,\\, u=x+1\\\\\n\\end{array}\n\\\\\n1 & \\begin{array}{l} \\text{Si} \\,\\, y=v\\,\\,\\text{y}\\,\\, u=x=n\\end{array} \\\\\n0 & \\begin{array}{l} \\text{Otro caso}. \\end{array}\n\\end{cases}\n\\end{equation}\\]\n\nPor lo tanto, la variable aleatoria \\(\\small{S_{n,k}}\\) es una Cadena de Markov incrustable y las probabilidades exactas se pueden obtener de:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(S_{n,k}= x\\big) = \\boldsymbol{\\xi_0 M}^{n-1}\\boldsymbol{U}(C_x),\\,\\, x=0,k,\\ldots,n\n\\end{equation}\\]\n\ndonde el vector fila \\(\\small{\\boldsymbol{\\xi_0}=(q_0,p_0,0,\\ldots,0)_{1 \\times d}}\\) es la distribuci√≥n inicial de \\(\\small{Y_1}\\), la partici√≥n \\(\\small{\\{C_x\\}}\\) se define como:\n\n\n\\[\\begin{equation}\nC_x =\\{(x,y):y=0,1,\\cdots,k-1,k^{+}\\},\\,\\,x=0,k,\\cdots,n,\n\\end{equation}\\]\n\ny \\(\\small{\\boldsymbol{U}'(C_x)}\\) es la transposici√≥n del vector fila \\(\\small{\\boldsymbol{U}(C_x)=(0,\\ldots,0,1,\\ldots,1,0,\\ldots,0)}\\) con unos en las coordenadas correspondientes a los estados de \\(\\small{C_x}\\).\nPara comprender mejor los efectos de los distintos par√°metros, en la Figura 3.1 se muestran gr√°ficamente las distribuciones de \\(\\small{S_{n,k}}\\) para algunos casos representativos con \\(\\small{n=15,30,60}\\), en los que se supone la distribuci√≥n inicial \\(\\small{\\boldsymbol{\\xi_0}=(1,0,\\ldots,0)}\\). Cuando \\(\\small{p_{SS}}\\) es peque√±o (por ejemplo, \\(\\small{p_{SS}=0.2}\\)), los efectos de los par√°metros sobre la distribuci√≥n son menos pronunciados, por lo que en la Figura 3.1 s√≥lo se presentan casos con valores grandes de \\(\\small{p_{SS}\\,(=0.8)}\\). A efectos de comparaci√≥n, tambi√©n se incluyen las esperanzas.\nPara \\(\\small{n}\\) fijo, el efecto de \\(\\small{k}\\) y \\(\\small{p_{FS}}\\) puede resumirse como sigue. Para \\(\\small{k}\\) peque√±o \\(\\small{(k=2)}\\) , la distribuci√≥n de \\(\\small{S_{n,k}}\\) se suaviza y adquiere forma de campana a medida que aumenta \\(\\small{n}\\) (de la Figura 3.1(a) a (d) a (g)), y esta tendencia se amplifica con valores mayores de \\(\\small{p_{FS}}\\). A medida que \\(\\small{k}\\) aumenta, las distribuciones se alejan de la forma normal y se vuelven muy sesgadas hacia la derecha (por ejemplo, de la Figura 3.1(d) a (e) a (f)). La distribuci√≥n de \\(\\small{S_{n,k}}\\) s√≥lo puede aproximarse a una distribuci√≥n normal cuando \\(\\small{k}\\) es mucho menor que \\(\\small{n}\\), y las aproximaciones normales deben utilizarse con precauci√≥n. En Fu, Lou, Bai y Li (2002) se ofrecen m√°s detalles sobre la distribuci√≥n l√≠mite de \\(\\small{S_{n,k}}\\).\n\n\n\n\n\n\nEn el cap√≠tulo 3, analizamos las ideas clave de la t√©cnica de Incrustaci√≥n de Cadenas de Markov Finitas (ICMF) para obtener las distribuciones exactas del n√∫mero de rachas y patrones con √©xitos en una sucesi√≥n de ensayos de dos estados. El objetivo principal de este cap√≠tulo es ampliar la t√©cnica de ICMF para estudiar el n√∫mero de rachas y patrones en una secuencia de ensayos multiestado. Podr√≠a parecer que, en principio, la ampliaci√≥n deber√≠a ser sencilla y requerir s√≥lo peque√±as modificaciones. Sin embargo, no es as√≠, especialmente cuando el patr√≥n es complejo y la sucesi√≥n \\(\\small{\\{X_t\\}}\\) est√° formada por ensayos multiestado Markov-Dependientes. Las principales dificultades se deben a la complejidad de construir una cadena de Markov finita adecuada asociada a la variable aleatoria \\(\\small{X_n(\\Lambda)}\\), especialmente en el proceso de obtenci√≥n de las probabilidades de transici√≥n. Para superar estas dificultades, introducimos el principio de avance y retroceso. En este cap√≠tulo nos centraremos en la utilizaci√≥n del principio de avance y retroceso para obtener las distribuciones de patrones simples y compuestos. De hecho, el principio de avance y retroceso desempe√±a un papel indispensable en la construcci√≥n de la Cadena de Markov Incrustada para casi todas las aplicaciones cubiertas por este libro.\n\n\n\nComencemos con el caso simple de que \\(\\small{\\{X_t\\}_{t=1}^{n}}\\) es una secuencia de i.i.d. ensayos miltiestados. Cada ensayo tiene \\(\\small{m\\,\\, (m\\geq 2)}\\) resultados posibles (estados o s√≠mbolos), etiquetados como \\(\\small{\\mathscr{S} =\\{b_1,\\ldots, b_m\\}}\\) y que ocurren con probabilidades \\(\\small{p_1,p_2,\\ldots,p_m,}\\) respectivamente. Denotamos \\(\\small{X_n(\\Lambda)}\\) al n√∫mero de patrones simples \\(\\small{\\Lambda}\\) no-superpuestos en la sucesi√≥n \\(\\small{\\{X_t\\}}\\). Primero, nos gustar√≠a presentar el principio de avance y retroceso para la t√©cnica de incrustaci√≥n de cadenas de Markov finitas, un principio que guiar√° la construcci√≥n de una cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) y la determinaci√≥n de sus matrices de probabilidad de transici√≥n. Para facilitar la discusi√≥n, el principio de avance y retroceso se introduce mediante el siguiente ejemplo.\nEjemplo 4.1 Consideremos el patr√≥n simple \\(\\small{\\Lambda=\\{b_{1}b_{1}b_{2}\\}}\\) en una sucesi√≥n de ensayos de tres estados (\\(\\small{\\mathscr{S} =\\{b_1,b_{2}, b_{3}\\}}\\)).\n(i) Descompongamos el patr√≥n \\(\\small{\\Lambda=b_{1}b_{1}b_{2}}\\) en un conjunto de subpatrones secuenciales \\(\\small{\\mathscr{S}(\\Lambda) =\\{b_1,b_{1}b_{1}, b_{1}b_{1}b_{2}\\}}\\). Definiendo\n\n\n\\[\\begin{equation}\n\\mathscr{E}=\\mathscr{S}\\, \\cup \\,\\mathscr{S}(\\Lambda)=\\{b_{1},b_{2},b_{3},b_{1}b_{1}, b_{1}b_{1}b_{2}\\}\n\\end{equation}\\]\n\ncomo un conjunto de bloques finales inducidos por el patr√≥n \\(\\small{ b_{1}b_{1}b_{2}}\\) con respecto a sucesi√≥n de ensayos \\(\\small{\\{X_t\\}}\\)\n(ii) Sea \\(\\small{{\\omega} =(x_{1},\\ldots, x_n)}\\) una realizaci√≥n de una sucesi√≥n de \\(\\small{n}\\) ensayos de tres estados. Definiendo el espacio de estados:\n\n\n\\[\\begin{equation}\n\\Omega =\\{(u,v):u=0,1,\\cdots,[n\n/3],\\,\\, v\\in \\mathscr{E}\\}\\,\\cup \\,\\{\\emptyset\\}\\, -\\,\\{(0,b_{1}b_{1}b_{2})\\}\n\\end{equation}\\]\n\ny una cadena de Markov\n\n\n\\[\\begin{equation}\n\\big\\{Y_t=\\big(X_n(\\Lambda), E_t\\big),\\,t=0,1,2,\\ldots,n\\big\\}\n\\end{equation}\\]\n\noperando sobre \\(\\small{\\omega}\\) como\n\n\n\\[\\begin{equation}\nY_t(\\omega)=(u,v),\\,\\, \\text{para}\\,\\, t=1,\\ldots,n\n\\end{equation}\\]\n\nen donde: \n\n\\[\\begin{align*}\nu &=\\begin{cases}\n\\begin{array}{l}\nX_n(\\Lambda)(\\omega)=\\,\\text{el n√∫mero total de patrones no-solapados}\\,\\Lambda\\,\\\\\n\\text{en los primeros}\\,\\, t\\,\\, \\text{ensayos contando hacia delante desde} \\\\\n\\text{el primer ensayo hasta el}\\,\\, t-√©simo\\,\\, \\text{ensayo, y}\n\\end{array}\n\\end{cases}\\\\\n\\\\\nv &=\\begin{cases}\n\\begin{array}{l}\nE_t(w) =\\,\\text{el bloque final m√°s largo en}\\ \\mathscr{S},\\\\\n\\text{contando hacia atr√°s desde}\\, X_t.\n\\end{array}\n\\end{cases}\n\\end{align*}\\]\n\nLas definiciones de \\(\\small{u}\\) y \\(\\small{v}\\) para la sucesi√≥n de los primeros \\(\\small{t}\\) ensayos se ilustran gr√°ficamente en la figura 4.1. Para que la cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) y el concepto de bloque final m√°s largo sean m√°s transparentes, consideremos la siguiente realizaci√≥n, \\(\\small{\\omega=(b_{3}b_{1}b_{2}b_{1}b_{1}b_{2}b_{1})}\\), de una sucesi√≥n de siete ensayos de tres estados. Aplicando el principio de avance y retroceso, la correspondiente del la cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) sobre \\(\\small{\\omega}\\) viene dada por \\(\\small{\\{Y_{1}(\\omega)=(0,b_{3}), Y_{2}(\\omega)=(0, b_{1}), Y_{3}(\\omega) = (0, b_{2}), Y_{4}(\\omega)= (0, b_{1}), Y_{5}(\\omega)=(0, b_{1}b_{1}), Y_{6}(\\omega) = (1, b_{1}b_{1}b_{2})\\,\\text{y}\\, Y_{7}(\\omega)=(1, b_{1})\\}}\\). Tenga en cuenta que para cada \\(\\small{\\omega}\\) dada, la realizaci√≥n de la cadena de Markov incrustada \\(\\small{Y_t(\\omega) = (u, v)}\\) est√° determinada √∫nicamente por lo anterior procedimientos (i) y (ii) bajo conteo sin superposici√≥n. En palabras sencillas, el el bloque final \\(\\small{v}\\) representa el estado de formaci√≥n del siguiente patr√≥n \\(\\small{\\Lambda}\\) para el subsecuencia \\(\\small{\\{{x_1,., ,x_t} \\}}\\) que contiene \\(\\small{u}\\) patrones completos.\n(iii) La cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) es homog√©nea y su matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M_t}= \\big(p_{(x,z),(u,v)}\\big)}\\) puede determinarse del siguiente modo. Por ejemplo, dado \\(\\small{Y_5(\\omega)=(0,b_{1}b_{1})}\\), como \\(\\small{X_{6}}\\) s√≥lo puede ser uno de los tres resultados posibles \\(\\small{b_{1}, b_{2}}\\) y \\(\\small{b_{3}}\\), el procedimiento de recuento hacia delante y hacia atr√°s da como resultado\n\n\n\\[\\begin{align*}\nY_{5}(\\omega) & \\rightarrow \\quad \\quad Y_{6}(\\omega)\n\\\\\n(0,b_{1}b_{1}) &\\rightarrow  \\begin{cases}\n\\begin{array}{cl}\n(0,b_{1}b_{1}) & \\text{si}\\,\\, X_6= b_{1}\\,\\,(\\text{con probabilidad}\\, p_{1})\\\\\n(1,b_{1}b_{1}b_{2}) & \\text{si}\\,\\, X_6= b_{2}\\,\\,(\\text{con probabilidad}\\, p_{2})\\\\\n(0,b_{3}) & \\text{si}\\,\\, X_6= b_{3}\\,\\,(\\text{con probabilidad}\\, p_{3}),\n\\end{array}\n\\end{cases}\n\\end{align*}\\]\n\ne \\(\\small{Y_5(\\omega)}\\) pasa a cualquier otro estado con probabilidad cero. De esta forma se obtienen todas las probabilidades de transici√≥n \\(\\small{\\mathbb{P}\\big(Y_t=(u,v)\\mid Y_{t-1}=(x,z)\\big)}\\). El estado ficticio \\(\\small{\\emptyset}\\) se a√±adir√° como estado inicial con \\(\\small{\\mathbb{P}\\big(Y_{0}=\\emptyset\\big)=1}\\) y con probabilidades de transici√≥n \\(\\small{\\mathbb{P}\\big(Y_{1}=b_{i}\\mid Y_0=\\emptyset\\big)=p_{i}}\\) para \\(\\small{i=1,2,3}\\). Obs√©rvese que el estado \\(\\small{(0,\\Lambda=b_{1}b_{1}b_{2})}\\) se elimin√≥ del espacio de estados, ya que siempre que el bloque final \\(\\small{v}\\) sea igual a \\(\\small{\\Lambda}\\) debe haber al menos una ocurrencia de el patr√≥n en la secuencia (es decir, \\(\\small{u\\geq1}\\) si \\(\\small{v=\\Lambda}\\)).\n(iv) Dado \\(\\small{n}\\), tenemos la siguiente partici√≥n en el espacio de estados \\(\\small{\\Omega}\\):\n\n\n\\[\\begin{align*}\n\\big\\{C_{\\emptyset} &=[\\emptyset], C_{0}=[(0,b_{1}),(0,b_{2}),(0,b_{3}),(0,b_{1}b_{1})], \\\\\n& \\,\\,\\text{y}\\,\\,C_{x}=[(x,v),v\\in \\mathscr{E}],\\, x=1,\\ldots,[n/3] \\big\\}.\n\\end{align*}\\]\n\nPara \\(\\small{n=5}\\) y la probabilidad inicial \\(\\small{\\mathbb{P}\\big(Y_0=\\emptyset \\big)\\equiv 1}\\), se deduce de los procedimientos (i) a (iv) anteriores que la cadena de Markov incrustada \\(\\small{\\{Y_t\\}_{t=0}^{5}}\\) est√° definida en el espacio de estados \\(\\small{\\Omega=\\{\\emptyset, (0, b_{1}), (0, b_{2}), (0, b_{3}), (0, b_{1}b_{1}), (1, b_{1}b_{1}b_{2}), (1, b_{1}), (1, b_{2}), (1, b_{3}), (1, b_{1}b_{1})\\}}\\) con matriz de probabilidad de transici√≥n\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\n\\begin{array}{cc}&\n\\begin{array}{c}\n\\emptyset\\\\\n(0,b_{1})\\\\\n(0,b_{2})\\\\\n(0,b_{3})\\\\\n(0,b_{1}b_{1})\\\\\n(1,b_{1}b_{1}b_{2})\\\\\n(1,b_{1})\\\\\n(1,b_{2})\\\\\n(1,b_{3})\\\\\n(1,b_{1}b_{1})\n\\end{array}\n&\n\\left(\n\\begin{array}{c|cccc|ccccc}\n0&p_{1}&p_{2}&p_{3}&0&0&0&0&0&0\\\\\n\\hline\n0&0&p_{2}&p_{3}&0&0&0&0&0&0\\\\\n0&p_{1}&p_{2}&p_{3}&0&0&0&0&0&0\\\\\n0&p_{1}&p_{2}&p_{3}&0&0&0&0&0&0\\\\\n0&0&0&p_{3}&p_{1}&p_{2}&0&0&0\\\\\n\\hline\n0&0&0&0&0&0&p_{1}&p_{2}&p_{3}&0\\\\\n0&0&0&0&0&0&0&p_{2}&p_{3}&p_{1}\\\\\n0&0&0&0&0&0&p_{1}&p_{2}&p_{3}&0\\\\\n0&0&0&0&0&0&p_{1}&p_{2}&p_{3}&0\\\\\n0&0&0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nLas probabilidades \\(\\small{\\mathbb{P}\\big(X_n(\\Lambda)=5\\big)=\\boldsymbol{\\xi_0M}^5\\boldsymbol{U'}(C_x),\\, x=0,1,}\\), pueden computarse facilmente.\nPara demostrar la aplicabilidad del principio de avance y retroceso a los patrones compuestos, consideremos el siguiente ejemplo.\nEjemplo 4.2 Dado \\(\\small{n=4}\\) y un patr√≥n compuesto \\(\\small{\\Lambda= \\Lambda_{1} \\cup \\Lambda_{2}}\\), que consiste en la uni√≥n de dos patrones simples distintos \\(\\small{ \\Lambda_{1}=b_{1}b_{2}}\\) y \\(\\small{ \\Lambda_{1}=b_{3}b_{1}}\\), estamos interesados en encontrar la distribuci√≥n de la variable aleatoria \\(\\small{X_4(\\Lambda)}\\), el n√∫mero de ocurrencias de \\(\\small{\\Lambda_{1}}\\) o \\(\\small{\\Lambda_{2}}\\) en una secuencia de cuatro ensayos i.i.d. de tres estados. Procediendo como en el ejemplo anterior, se obtiene la cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) definida en el espacio de estados\n\n\n\\[\\begin{align*}\n\\Omega &=\\big\\{\\emptyset,(0,b_{1}),(0,b_{2}),(0,b_{3}),(1,b_{1}b_{2}), (1,b_{3}b_{1}), \\\\\n& \\quad \\quad (1,b_{1}),(1,b_{2}),(1,b_{3}),(2,b_{1}b_{2}),(2,b_{3}b_{1})\\big\\}.\n\\end{align*}\\]\n\ncon matriz de probabilidades de transici√≥n:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\n\\begin{array}{cc}&\n\\begin{array}{c}\n\\emptyset\\\\\n(0,b_{1})\\\\\n(0,b_{2})\\\\\n(0,b_{3})\\\\\n(1,b_{1}b_{2})\\\\\n(1,b_{3}b_{1})\\\\\n(1,b_{1})\\\\\n(1,b_{2})\\\\\n(1,b_{3})\\\\\n(2,b_{1}b_{2})\\\\\n(2,b_{3}b_{1})\n\\end{array}\n&\n\\left(\n\\begin{array}{c|ccc|ccccc|cc}\n0&p_{1}&p_{2}&p_{3}&0&0&0&0&0&0&0\\\\\n\\hline\n0&p_{1}&0&p_{3}&p_{2}&0&0&0&0&0&0\\\\\n0&p_{1}&p_{2}&p_{3}&0&0&0&0&0&0&0\\\\\n0&0&p_{2}&p_{3}&0&p_{1}&0&0&0&0&0\\\\\n\\hline\n0&0&0&0&p_{1}&0&0&p_{2}&p_{3}&0&0\\\\\n0&0&0&0&0&0&p_{1}&p_{2}&p_{3}&0&0\\\\\n0&0&0&0&0&0&p_{1}&0&p_{3}&p_{2}&0\\\\\n0&0&0&0&0&0&p_{1}&p_{2}&p_{3}&0&0\\\\\n0&0&0&0&0&0&0&p_{2}&p_{3}&0&p_{1}\\\\\n\\hline\n0&0&0&0&0&0&0&0&0&1&0\\\\\n0&0&0&0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nLas probabilidades \\(\\small{\\mathbb{P}\\big(X_n(\\Lambda)=4\\big)=\\boldsymbol{\\xi_0M}^4\\boldsymbol{U'}(C_x),\\, x=0,1,2}\\), pueden computarse facilmente.\nEl m√©todo tambi√©n puede extenderse, con modificaciones simples, a la caso donde \\(\\small{\\{X_t\\}}\\) es una sucesi√≥n de ensayos multiestado Markov-Dependientes.\nEjemplo 4.3 Volvamos al Ejemplo 4.1, pero consideremos aqu√≠ que \\(\\small{\\{X_t\\}}\\) es una secuencia de ensayos de tres estados Markov-Dependientes con matriz de probabilidad de transici√≥n:\n\n\n\\[\\begin{equation}\n\\boldsymbol{A}=\\left(\n\\begin{array}{ccc}\np_{11}&p_{12}&p_{13}\\\\\np_{21}&p_{22}&p_{23}\\\\\np_{31}&p_{32}&p_{33}\\\\\n\\end{array}\n\\right)\n\\end{equation}\\]\n\nNuestro objetivo es determinar la distribuci√≥n del patr√≥n \\(\\small{\\Lambda=b_{1}b_{1}b_{2}}\\) en una secuencia de cinco ensayos. De forma an√°loga al Ejemplo 4.1, las probabilidades de transici√≥n de la cadena de Markov incrustada pueden obtenerse para cada estado mediante el siguiente argumento. Dado \\(\\small{Y_3 = (0, b_{1}b_{1})}\\), por ejemplo, tenemos:\n\n\n\\[\\begin{align*}\nY_3 & \\rightarrow \\quad \\quad \\, Y_{4}\\\\\n(0,b_{1}b_{1}) &\\rightarrow  \\begin{cases}\n\\begin{array}{cl}\n(0,b_{1}b_{1}) & \\text{si}\\,\\, X_{4}= b_{1}\\,\\,(\\text{con probabilidad}\\, p_{11})\\\\\n(1,b_{1}b_{1}b_{2}) & \\text{si}\\,\\, X_{4}= b_{2}\\,\\,(\\text{con probabilidad}\\, p_{12})\\\\\n(0,b_{3}) & \\text{si}\\,\\, X_{4}= b_{3}\\,\\,(\\text{con probabilidad}\\, p_{13}).\n\\end{array}\n\\end{cases}\n\\end{align*}\\]\n\nLas ecuaciones (4.4) y (4.9) son equivalentes, salvo que las probabilidades \\(\\small{p_{1}}\\),\\(\\small{p_{2}}\\) y \\(\\small{p_{3}}\\) se sustituyen por \\(\\small{p_{11}}\\),\\(\\small{p_{12}}\\) y \\(\\small{p_{13}}\\) respectivamente. Por lo tanto, la cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) se define aqu√≠ en el mismo espacio de estados \\(\\small{\\Omega}\\) y con matriz de probabilidad de transici√≥n:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\n\\begin{array}{cc}&\n\\begin{array}{c}\n\\emptyset\\\\\n(0,b_{1})\\\\\n(0,b_{2})\\\\\n(0,b_{3})\\\\\n(0,b_{1}b_{1})\\\\\n(1,b_{1}b_{1}b_{2})\\\\\n(1,b_{1})\\\\\n(1,b_{2})\\\\\n(1,b_{3})\\\\\n(1,b_{1}b_{1})\n\\end{array}\n&\n\\left(\n\\begin{array}{c|cccc|ccccc}\n0&p_{1}&p_{2}&p_{3}&0&0&0&0&0&0\\\\\n\\hline\n0&0&p_{12}&p_{13}&p_{11}&0&0&0&0&0\\\\\n0&p_{21}&p_{22}&p_{23}&0&0&0&0&0&0\\\\\n0&p_{31}&p_{32}&p_{33}&0&0&0&0&0&0\\\\\n0&0&0&p_{13}&p_{11}&p_{12}&0&0&0\\\\\n\\hline\n0&0&0&0&0&0&p_{21}&p_{22}&p_{23}&0\\\\\n0&0&0&0&0&0&0&p_{12}&p_{13}&p_{11}\\\\\n0&0&0&0&0&0&p_{21}&p_{22}&p_{23}&0\\\\\n0&0&0&0&0&0&p_{31}&p_{32}&p_{33}&0\\\\\n0&0&0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\ndonde las probabilidades de transici√≥n \\(\\small{\\mathbb{P}\\big(Y_{t}(u,v)=Y_{t-1}(x,z)\\big)}\\) se obtienen como se ilustra en la Ec. (4.9). Obs√©rvese que la matriz de probabilidades de transici√≥n de la Ec. (4.10) tiene exactamente la misma forma que la matriz de la Ec. (4.6) para el caso i.i.d..\nEn vista de las transiciones de estado esbozadas por las Ecs. (4.4) y (4.9), que conducen a las matrices de probabilidad de transici√≥n de los Ejemplos 4.1 a 4.3, dadas en las Ecs. (4.6), (4.8) y (4.10) respectivamente, definimos la siguiente notaci√≥n: dado \\(\\small{Y_{t-1} = (x, z) \\in \\Omega}\\) y \\(\\small{X_t = j\\in \\mathscr{S}}\\), \n\n\\[\\begin{equation}\n(u,v)\\equiv &lt;(x,z),j&gt;_{\\Omega}\n\\end{equation}\\]\n\ndonde el estado \\(\\small{(u,v)\\in \\Omega}\\) es el resultado del recuento hacia delante y hacia atr√°s (no solapado) cuando se incluye un resultado adicional \\(\\small{X_t=j}\\). Para cada \\(\\small{(x, z)\\in \\Omega}\\), definimos tambi√©n \\(\\small{L(z)\\in \\mathscr{S}}\\) como el √∫ltimo elemento del bloque final \\(\\small{z}\\). Entonces, para el caso general, las probabilidades de transici√≥n de la cadena de Markov incrustada \\(\\small{Y_t}\\) se especifican mediante la siguiente ecuaci√≥n:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(Y_t=(u,v)\\mid Y_{t-1}=(x,z)\\big) =\\begin{cases}\np_{ij} & \\quad\n\\begin{array}{l}\n\\text{si}\\,\\, X_{t}=j\\in\\mathscr{S},\\, L(z)=i\\\\\n\\text{y}\\,\\,(u,v)= &lt;(x,z),j&gt;_{\\Omega}\n\\end{array}\\\\\nm & \\quad \\text{en otro caso}\n\\end{cases}\n\\end{equation}\\]\n\ndonde \\(\\small{p_{ij}}\\) son las probabilidades de transici√≥n de la cadena de Markov \\(\\small{\\{X_t\\}}\\). Si \\(\\small{\\{X_t\\}}\\) es una secuencia de ensayos multiestado i.i.d., la Ec.(4.12) se convierte en\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(Y_t=(u,v)\\mid Y_{t-1}=(x,z)\\big) =\\begin{cases}\np_{j} & \\quad\n\\begin{array}{l}\n\\text{si}\\,\\, X_{t}=j\\in\\mathscr{S},\\\\\n\\text{y}\\,\\,(u,v)= &lt;(x,z),j&gt;_{\\Omega}\n\\end{array}\\\\\n0 & \\quad \\text{en otro caso}\n\\end{cases}\n\\end{equation}\\]\n\nTeorema 4.1 Suponiendo que \\(\\small{\\{X_t\\}}\\) es una cadena de Markov homog√©nea con matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{A} = \\big(p_{ij}\\big)_{m\\times m}}\\), y \\(\\small{\\Lambda=\\displaystyle{\\bigcup_{i=1}^{l}\\Lambda_{i}}}\\) es un patr√≥n compuesto generado por \\(\\small{l}\\) patrones simples distintos \\(\\small{\\Lambda_{i}}\\) que tienen la misma longitud \\(\\small{k}\\), entonces la cadena de Markov incrustada \\(\\small{\\big\\{Y_t=\\big(X_{t}(\\Lambda),E_{t} \\big),\\,t=1,2,\\,\\ldots,n\\big\\}}\\) correspondiente a la variable aleatoria \\(\\small{X_{n}(\\Lambda)}\\)\n(i) se define sobre el espacio de estados:\n\n\n\\[\\begin{align*}\\Omega &=\\{\\emptyset\\}\\, \\cup\\,\\{(x,z):x=0,1,\\cdots,[n\n/k],\\,\\, z\\in \\mathscr{E}\\}\\\\\n&\\quad- \\{(0,\\Lambda_{i}):i=1,\\cdots,l\\}\n-\\,\\{([n/k],z):k[n/k]+z(k)&gt;n\\},\\end{align*}\\]\n\nen donde \\(\\small{\\mathscr{E} =\\mathscr{S}\\,\\cup\\Bigg(\\displaystyle\\bigcup_{i=1}{\\mathscr{S}(\\Lambda_{i})\\Bigg)}}\\) y \\(\\small{z(k)\\equiv [\\text{longitud de}\\,z] \\pmod k}\\)\n(ii) tiene la matriz de probabilidades de transici√≥n: \n\n\\[\\begin{equation}\n\\boldsymbol{M}=\\big(p_{(x,z)(u,v)}\\big)_{d\\times d}\n\\end{equation}\\]\n\nen donde las probabilidades de transici√≥n estan dadas por: \n\n\\[\\begin{equation}\np_{(x,z)(u,v)}=\\begin{cases}\np_{j} & \\,\\text{si}\\, (x,z)=\\emptyset,\\,u=0,\\,v=j,\\, \\text{para todo}\\, j \\in \\mathscr{S}\\\\ \\\\\np_{ij} &\n\\begin{array}{l}\n\\text{si}\\,(u,v)=&lt;(x,z),j&gt;_{\\Omega},\\, x\\leq [n/k],\\, j\\in \\mathscr{S},\\\\\nL(z)=i,\\,\\text{y}\\,\\, kx+z(k)&lt;n\n\\end{array} \\\\ \\\\\n1 &\n\\begin{array}{l}\n\\text{si}\\,(u,v)= (x,z) ,\\, x= [n/k]\\\\\n\\,\\text{y}\\,\\, k[n/k]+z(k)=n\n\\end{array} \\\\\\\\\nm & \\text{en otro caso.}\n\\end{cases}\n\\end{equation}\\]\n\ncon \\(\\small{d=\\text{card}(\\Omega)}\\), el tama√±o del espacio de estados \\(\\small{\\Omega}\\), igual a:\n\n\n\\[\\begin{align*}d =1 & +([n/k]+1)\\times \\text{card}\\big(\\mathscr{E}\\big)-l\\\\\n& -\\text{card}\\Big(\\big\\{([n/k],z):\\,z \\in \\mathscr{E}, \\,k[n/k]+z(k)&gt;n\\big\\}\\big),\\end{align*}\\]\n\ny (iii) se obtiene la distribuci√≥n:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big( X_n(\\Lambda)=x\\big)=\\boldsymbol{\\mathbf{\\xi}}_0\\boldsymbol{M}^{n}\\boldsymbol{\\mathbf{U}'}( {C_x}),\\,\\,  x=1,2,\\ldots,[n/k],\n\\end{equation}\\]\n\nen donde \\(\\small{\\boldsymbol{\\xi}_0}\\) es la distribuci√≥n inicial especificada por \\(\\small{\\mathbb{P}\\big(Y_{0}=\\emptyset\\big)\\equiv 1}\\) y \n\n\\[\\begin{align*}\nC_{\\emptyset} &=[\\emptyset],\\, C_{0}=[(0,z):z\\in\\mathscr{S}]-[(0,\\Lambda_{i}):i=1,2,\\ldots,l], \\\\\nC_{x} &=  [(x,z):z\\in \\mathscr{E}],\\, 1\\leq x \\leq [n/k], \\, \\text{y}\\\\\nC_{[n/x]}&=[([n/k],z):z\\in \\mathscr{E},\\,k[n/k]+z(k)\\leq n]\n\\end{align*}\\]\n\nson las particiones del espacio de estados \\(\\small{\\Omega}\\).\nN√≥tese que el espacio de estados \\(\\small{\\Omega}\\) y su tama√±o \\(\\small{d}\\) son funciones de \\(\\small{n}\\), la estructura de los patrones \\(\\small{\\Lambda_{i},\\,i=1,\\ldots,l}\\) y la longitud del patr√≥n com√∫n \\(\\small{k}\\). El lector puede comprobar que los resultados de los Ejemplos 4.1 a 4.3 se deducen directamente del Teorema 4.1.\nDemostraci√≥n. Dado \\(\\small{n}\\), como la longitud de cada patr√≥n es \\(\\small{k}\\), el n√∫mero m√°ximo de patrones es \\(\\small{[n/k]}\\) (bajo conteo no solapado). El conjunto \\(\\small{\\mathscr{E} =\\mathscr{S}\\,\\cup\\Bigg(\\displaystyle\\bigcup_{i=1}{\\mathscr{S}(\\Lambda_{i})\\Bigg)}}\\) contiene todos los posibles bloques finales generados por \\(\\small{\\mathscr{S}}\\) y todos los patrones, y se deduce que para recuento hacia delante y hacia atr√°s sin solapamiento, el espacio de estados tiene la forma \\(\\small{\\big\\{(x,z): x=0,\\ldots,[n/k]},\\,z\\in\\mathscr{E}\\big\\}\\). Los estados \\(\\small{\\big\\{(0,\\Lambda_{i}): i=1,\\ldots,l}\\big\\}\\) se eliminan porque si el bloque final es \\(\\small{\\Lambda_{i}}\\), entonces debe haber al menos un patr√≥n \\(\\small{\\Lambda_{i}}\\), en la secuencia \\(\\small{(x\\geq 1)}\\), por lo que los estados \\(\\small{\\big\\{(0,\\Lambda_{i})\\big\\}}\\) son inalcanzables; por la misma raz√≥n, los estados \\(\\small{\\big\\{([n/k],z):k[k/z]+z(k)&gt;n\\big\\}}\\) tampoco pueden darse y pueden eliminarse. As√≠, el espacio de estados \\(\\small{\\Omega}\\) de la cadena de Markov incrustada tiene la forma dada por la Ec. (4.14), y su tama√±o \\(\\small{d}\\) viene determinado por la Ec.(4.17).\nDados \\(\\small{(x,z)\\in \\Omega,\\,0\\leq x \\leq [n/n]}\\), y \\(\\small{kx + z(k) &lt; n}\\), si \\(\\small{X_{t}=j\\in \\mathscr{S}}\\) y \\(\\small{(u, v) = &lt; (x, z), j &gt;_{\\Omega}}\\) , entonces, como se describe en las Ecs. (4.9) y (4.12), se deduce que\n\n\n\\[\\begin{align*}\np_{(x,z)(u,v)}=\\mathbb{P}\\big(Y_t=(u,v)\\mid Y_{t-1}=(x,z)\\big)=p_{ij},\n\\end{align*}\\]\n\ndonde \\(\\small{i=L(z)}\\). Si \\(\\small{Y_{t-1}=([n/k], z) }\\), y \\(\\small{[kn/k] + z(k) = n}\\) entonces \\(\\small{t-1\\equiv n}\\); por conveniencia, asignamos las probabilidades de transici√≥n para estos estados como \\(\\small{\\mathbb{P}\\big(Y_t=([n/k],z)\\mid Y_{t-1}=([n/k],z)\\big)\\equiv1}\\) . Esto completa la construcci√≥n de la Ec. (4.16) y la matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M}}\\) . Las particiones en el espacio de estados \\(\\small{\\Omega}\\) , dadas por la Ec. (4.19), son una consecuencia directa de la definici√≥n de la cadena de Markov incrustada introducida en la Ec. (4.3). Por lo tanto, la distribuci√≥n para el patr√≥n compuesto \\(\\small{\\Lambda}\\) en la Ec. (4.18) es una consecuencia inmediata del Teorema 2.1. Esto completa la demostraci√≥n. \\(\\hspace{1cm}\\Box\\)\nEl teorema 4.1 anterior tambi√©n es v√°lido para patrones simples, el caso especial cuando \\(\\small{l=1}\\) . Cuando las longitudes de los patrones \\(\\small{k_{i},\\, i=1,\\ldots,l}\\) no son todas iguales, el principio de avance y retroceso puede seguir utiliz√°ndose para hallar la distribuci√≥n del patr√≥n compuesto \\(\\small{\\Lambda}\\) . En principio, el procedimiento de recuento de avance y retroceso es aplicable a cualquier n√∫mero de patrones \\(\\small{l}\\) de tama√±os \\(\\small{k_{i}}\\) variables, pero no es sencillo escribir la forma general del espacio de estados y la matriz de probabilidad de transici√≥n de la cadena de Markov incrusrada. Trataremos este problema en el cap√≠tulo 5 utilizando la relaci√≥n de dualidad entre \\(\\small{X_{n}(\\Lambda)}\\) y el tiempo de espera \\(\\small{W(\\Lambda)}\\).\n\n\n\nConsideremos que la secuencia \\(\\small{\\{X_t\\}}\\) es una cadena de Markov homog√©nea definida sobre el espacio de estados \\(\\small{\\mathscr{S}=\\{a, b, c\\}}\\) con matriz de probabilidades de transici√≥n\n\n\n\\[\\begin{equation}\n\\boldsymbol{A}=\\big(p_{ij}\\big),\\, i,j=a,b,c\n\\end{equation}\\]\n\nSea \\(\\small{\\Lambda}\\) un patr√≥n simple de longitud \\(\\small{k}\\). La diferencia b√°sica entre el recuento por solapamiento y el recuento sin solapamiento es que cuando se forma el patr√≥n \\(\\small{\\Lambda}\\), una parte de A se contar√° para formar el siguiente patr√≥n \\(\\small{\\Lambda}\\) bajo el recuento por solapamiento, hasta los √∫ltimos \\(\\small{(k-1)}\\) ensayos.\nDefinici√≥n 4.1 Un bloque final \\(\\small{E^¬∞}\\) generado por el patr√≥n \\(\\small{\\Lambda}\\) es el bloque final m√°s largo \\(\\small{(E^{¬∞} \\neq \\Lambda)}\\) que, despu√©s de cada aparici√≥n de \\(\\small{\\Lambda}\\) bajo conteo superpuesto, se puede asignar como bloque final inicial para la siguiente aparici√≥n de \\(\\small{\\Lambda}\\). Escribimos \\(\\small{(E^{¬∞} \\cong \\Lambda}\\) , con respecto al conteo de superposici√≥n.\nPor ejemplo, bajo el conteo superpuesto:\n\nSi \\(\\small{\\Lambda=aca}\\), entonces \\(\\small{E^{¬∞}=a}\\),\nSi \\(\\small{\\Lambda=abcab}\\), entonces \\(\\small{E^{¬∞}=ab}\\), y\nSi \\(\\small{\\Lambda=\\underbrace{a\\cdots a}_{k}}\\), entonces \\(\\small{E^{¬∞}=\\underbrace{a\\ldots a}_{k-1}}\\).\n\nPara un patr√≥n como \\(\\small{\\Lambda=abc}\\), no existe un \\(\\small{E^{¬∞}}\\), en cuyo caso el conteo superpuesto y no superpuesto es el mismo. Tenga en cuenta que bajo el conteo superpuesto, dado que el primer patr√≥n requiere \\(\\small{k}\\) elementos y cada patr√≥n adicional requiere solo \\(\\small{k-\\text{Card}(E^{¬∞})}\\) elementos, el mayor n√∫mero posible de patrones \\(\\small{\\Lambda}\\) que pueden ocurrir en \\(\\small{n (n \\geq k)}\\) ensayos es\n\n\n\\[\\begin{equation*}\nl_{n}^{o}=1+\\bigg[\\frac{n-k}{k-\\text{Card}(E^{¬∞})}\\bigg].\n\\end{equation*} \\]\n\nPara ilustrar las diferencias menores que surgen de los dos tipos de conteo, se proporciona el siguiente ejemplo.\nEjemplo 4.4 Consideremos el n√∫mero de patrones \\(\\small{\\Lambda=aca}\\) que ocurren en \\(\\small{n=5}\\) ensayos i.i.d. de tres estados. Bajo el conteo no superpuesto, la matriz de transici√≥n de probabilidades \\(\\small{\\boldsymbol{M}}\\) asociada con la cadena de Markov incrustada\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\n\\begin{array}{cc}&\n\\begin{array}{c}\n(0,a)\\\\\n(0,b)\\\\\n(0,c)\\\\\n(0,ab)\\\\\n(1,\\Lambda)\\\\\n(1,a)\\\\\n(1,b)\\\\\n(1,c)\\\\\n(1,ac)\\\\\n\\end{array}\n&\n\\left(\n\\begin{array}{ccccccccc}\np_{a}&p_{b}&0&p_{c}&0&0&0&0&0\\\\\np_{a}&p_{b}&p_{c}&0&0&0&0&0&0\\\\\np_{a}&p_{b}&p_{c}&0&0&0&0&0&0\\\\\n0&p_{b}&p_{c}&0&p_{a}&0&0&0&0\\\\\n0&0&0&0&0&p_{a}&p_{b}&p_{c}&0\\\\\n0&0&0&0&0&p_{a}&p_{b}&0&p_{c}\\\\\n0&0&0&0&0&p_{a}&p_{b}&p_{c}&0\\\\\n0&0&0&0&0&p_{a}&p_{b}&p_{c}&0\\\\\n0&0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\ndonde \\(\\small{(1,\\Lambda)\\equiv (1,aca)}\\) . Bajo conteo de superpuesto, la matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M^{¬∞}}}\\) asociada con la cadena de Markov incrustada es\n\n\n\\[\\begin{equation}\n\\boldsymbol{M^{¬∞}}=\n\\begin{array}{cc}&\n\\begin{array}{c}\n(0,a)\\\\\n(0,b)\\\\\n(0,c)\\\\\n(0,ab)\\\\\n(1,\\Lambda)\\\\\n(1,a)\\\\\n(1,b)\\\\\n(1,c)\\\\\n(1,ac)\\\\\n(2,\\Lambda)\n\\end{array}\n&\n\\left(\n\\begin{array}{ccccc|cccc}\np_{a}&p_{b}&0&p_{c}&0&0&0&0&0&0\\\\\np_{a}&p_{b}&p_{c}&0&0&0&0&0&0&0\\\\\np_{a}&p_{b}&p_{c}&0&0&0&0&0&0&0\\\\\n0&p_{b}&p_{c}&0&p_{a}&0&0&0&0&0\\\\\n\\hline\n0&0&0&0&0&p_{a}&p_{b}&0&p_{c}&0\\\\\n\\hline\n0&0&0&0&0&p_{a}&p_{b}&0&p_{c}&0\\\\\n0&0&0&0&0&p_{a}&p_{b}&p_{c}&0&0\\\\\n0&0&0&0&0&p_{a}&p_{b}&p_{c}&0&0\\\\\n0&0&0&0&0&0&p_{b}&p_{c}&0&p_{a}\\\\\n0&0&0&0&0&0&0&0&1&0\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nLa principal diferencia entre las dos matrices surge despu√©s de que ha ocurrido el primer patr√≥n. Con probabilidad \\(\\small{p_{c}}\\) , el estado \\(\\small{(1,\\Lambda)}\\) pasa al estado \\(\\small{(1,c)}\\) bajo conteo no superpuesto, mientras que \\(\\small{(1,\\Lambda)}\\) pasa a \\(\\small{(1,ac)}\\) bajo conteo superpuesto, lo que tambi√©n implica el estado adicional \\(\\small{l_{n}^{¬∞}=(2,\\Lambda)}\\). \\(\\hspace{1cm}\\Diamond\\)\nSi \\(\\small{\\{X_t\\}}\\) es una cadena de Markov homog√©nea con probabilidades de transici√≥n dadas por la Ecuaci√≥n. (4.20), la matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M^{¬∞}}}\\) del anterior ejemplo (bajo conteo superpuesto) se convierte en:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M^{¬∞}}=\n\\begin{array}{cc}&\n\\begin{array}{c}\n\\emptyset\\\\\n(0,a)\\\\\n(0,b)\\\\\n(0,c)\\\\\n(0,ab)\\\\\n(1,\\Lambda)\\\\\n(1,a)\\\\\n(1,b)\\\\\n(1,c)\\\\\n(1,ac)\\\\\n(2,\\Lambda)\n\\end{array}\n&\n\\left(\n\\begin{array}{cccccc|ccccc}\n0&p_{a}&p_{b}&p_{c}&0&0&0&0&0&0&0\\\\\n0&p_{aa}&p_{ab}&0&p_{ac}&0&0&0&0&0&0\\\\\n0&p_{ba}&p_{bb}&p_{bc}&0&0&0&0&0&0&0\\\\\n0&p_{ca}&p_{cb}&p_{cc}&0&0&0&0&0&0&0\\\\\n0&0&p_{bb}&p_{bc}&0&p_{ab}&0&0&0&0&0\\\\\n\\hline\n0&0&0&0&0&0&p_{aa}&p_{ab}&0&p_{ac}&0\\\\\n\\hline\n0&0&0&0&0&0&p_{aa}&p_{ab}&0&p_{ac}&0\\\\\n0&0&0&0&0&0&p_{ba}&p_{bb}&p_{bc}&0&0\\\\\n0&0&0&0&0&0&p_{ca}&p_{cb}&p_{cc}&0&0\\\\\n0&0&0&0&0&0&0&p_{cb}&p_{cc}&0&p_{ca}\\\\\n0&0&0&0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\ndonde \\(\\small{p_{a},\\, p_{b}}\\), y \\(\\small{p_{c}}\\) son las probabilidades de transici√≥n dadas del estado \\(\\small{\\emptyset}\\) a los estados \\(\\small{(0, a), (0,b)}\\) y \\(\\small{(0, c)}\\), respectivamente. Nuevamente, la extensi√≥n de i.i.d. a los emnsayos Markov-Dependientes sigue siendo sencillo. El concepto considerado en el ejemplo anterior se puede extender al caso de superposici√≥n hasta los √∫ltimos \\(\\small{d}\\) ensayos \\(\\small{(1 \\leq d \\leq k ‚àí 1)}\\), como lo introdujeron Aki e Hirano (2000). Una ventaja significativa de la t√©cnica de incrustaci√≥n de cadenas finitas de Markov es que la extensi√≥n del conteo sin superposici√≥n al conteo superpuesto es directa y simple.\n\n\n\nLa distribuci√≥n del n√∫mero de patrones en serie \\(\\small{\\Lambda=\\Lambda_{1}\\ast\\Lambda_{2}}\\) se puede obtener casi de la misma manera que para un patr√≥n simple, con modificaciones menores en el estado despu√©s de que se haya producido el primer patr√≥n \\(\\small{\\Lambda_{1}}\\).\nEjemplo 4.5 Consideremos una secuencia de \\(\\small{n=5}\\) ensayos i.i.d. de tres estados extra√≠dos de \\(\\small{\\mathscr{S}=\\{a,b,c\\}}\\), y el patr√≥n de serie \\(\\small{\\Lambda}=ab\\ast cc\\) generado por los dos patrones simples \\(\\small{\\Lambda_{1}=ab}\\) y \\(\\small{\\Lambda_{2}=cc}\\). Definiendo el conjunto de bloques finales \\(\\small{\\mathscr{E}=\\{a,\\bar{a},ab\\ast,ab{\\ast}c,ab{\\ast}cc\\}}\\) y el espacio de estados\n\n\n\\[\\begin{equation}\n\\Omega=\\{\\emptyset,(0,a),(0,\\bar{a}),(0,ab{\\ast}),(0,ab{\\ast}c),(1,ab{\\ast}cc),(1,a),(1,\\bar{a})\\}\n\\end{equation}\\]\n\ndonde \\(\\small{\\bar{a}}\\) representa \\(\\small{b}\\) o \\(\\small{c}\\), y \\(\\small{ab{\\ast}}\\) representa \\(\\small{ab{\\ast}a}\\) o \\(\\small{ab{\\ast}b}\\). La correspondiente cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) tiene la matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M}}\\) dada por:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\n\\begin{array}{cc}&\n\\begin{array}{c}\n\\emptyset\\\\\n(0,a)\\\\\n(0,\\bar{a})\\\\\n(0,ab{\\ast})\\\\\n(0,ab{\\ast}c)\\\\\n(1,ab{\\ast}cc)\\\\\n(1,a)\\\\\n(1,\\bar{a})\\\\\n\\end{array}\n&\n\\left(\n\\begin{array}{cccccccc}\n0&p_{a}&p_{b}+p_{c}&0&0&0&0&0\\\\\n0&p_{a}&p_{c}&p_{b}&0&0&0&0\\\\\n0&p_{a}&p_{b}+p_{c}&0&0&0&0&0\\\\\n0&0&0&p_{a}+p_{b}&p_{c}&0&0&0\\\\\n0&0&0&p_{a}+p_{b}&0&p_{c}&0&0\\\\\n0&0&0&0&0&0&p_{a}&p_{b}+p_{c}\\\\\n0&0&0&0&0&0&1&0\\\\\n0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nPor lo tanto:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(X_{n}(\\Lambda)=x\\big)=\\boldsymbol{\\xi}_{0}\\boldsymbol{M}^{5}\\boldsymbol{U}(C_{x}),\\,x=0,1.\n\\end{equation}\\]\n\nObs√©rvese que si \\(\\small{\\{Y_t\\}}\\) est√° en el estado \\(\\small{(0, ab{\\ast})}\\) o \\(\\small{(0,ab{\\ast}c)}\\), significa que el patr√≥n \\(\\small{\\Lambda_{1}=ab}\\) ha ocurrido antes o en el \\(\\small{t-}\\)√©simo ensayo. Ahora bien, si la realizaci√≥n de \\(\\small{X_{t+1}}\\) es \\(\\small{a}\\) o \\(\\small{b}\\) , entonces \\(\\small{Y_{t+1}}\\) tiene que estar en el estado \\(\\small{(0, ab{\\ast})}\\), suceso que ocurre con probabilidad de transici√≥n \\(\\small{p_{a}+p_{b}}\\) , y si la realizaci√≥n de \\(\\small{X_{t+1}}\\) es \\(\\small{c}\\), entonces \\(\\small{Y_{t+1}}\\) avanza al estado \\(\\small{(0, ab{\\ast}c)}\\) o \\(\\small{(1, ab{\\ast}cc)}\\), respectivamente, sucesos que ocurren con probabilidad de transici√≥n \\(\\small{p_{c}}\\).\nEl ejemplo anterior pone de manifiesto las diferencias entre los patrones en series y los patrones simples en lo que respecta a sus matrices de probabilidad de transici√≥n de las cadenas de Markov incrustadas. Ampliando ligeramente el espacio de estados \\(\\small{\\Omega}\\), sustituyendo \\(\\small{(i,\\bar{a}),\\, i=0,1}\\), por \\(\\small{(i,b)}\\) y \\(\\small{(i, c)}\\), y sustituyendo \\(\\small{(0, ab{\\ast})}\\) por \\(\\small{(0, ab{\\ast}a)}\\) y \\(\\small{(0, ab{\\ast}b)}\\), el ejemplo anterior puede ampliarse f√°cilmente al caso de ensayos de tres estados Markov-Dependientes.\n\n\n\nHallar la distribuci√≥n conjunta de dos n√∫meros de rachas, digamos \\(\\small{X_n(\\Lambda_{1})}\\) y \\(\\small{X_n(\\Lambda_{2})}\\) , en una secuencia de ensayos de dos o varios estados \\(\\small{\\{X_t\\}}\\) utilizando la t√©cnica de incrustaci√≥n de cadenas de Markov finitas es similar a hallar la distribuci√≥n exacta de \\(\\small{X_n(\\Lambda)}\\) introducida en la Secci√≥n 4.2. En general, la cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) asociada a la distribuci√≥n conjunta de \\(\\small{X_n(\\Lambda_{1})}\\) y \\(\\small{X_n(\\Lambda_{2})}\\) tiene la forma\n\n\n\\[\\begin{equation}\nY_{t}=\\big(X_{t}(\\Lambda_{1}),X_{t}(\\Lambda_{2}),E_{t}\\big),\\,t=1,2,\\ldots,n.\n\\end{equation}\\]\n\nEl espacio de estados \\(\\small{\\Omega}\\) y el bloque final \\(\\small{E_{t}}\\) para \\(\\small{\\{Y_t\\}}\\) dependen en gran medida de la estructura de los patrones \\(\\small{\\Lambda_{1}}\\) y \\(\\small{\\Lambda_{2}}\\). Las matrices de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M}_{t}}\\) de la cadena de Markov inscrustada pueden construirse utilizando los mismos principios descritos en secciones anteriores. A continuaci√≥n, damos un ejemplo para demostrar el procedimiento para encontrar la distribuci√≥n conjunta.\nEjemplo 4.6 Sea \\(\\small{X_{n}}\\) el n√∫mero total de rachas de √©xito \\(\\small{X_{n}(S)}\\) y de fracaso \\(\\small{X_{n}(S)}\\) en una secuencia de \\(\\small{n}\\) ensayos de dos estados. Para cada \\(\\small{X_{n} = X_{n}(S) + X_{n}(F)}\\), y los n√∫meros de rachas \\(\\small{X_{n}(S)}\\) y \\(\\small{X_{n}(F)}\\) est√°n relacionados de la siguiente manera: si hay \\(\\small{x}\\) rachas de √©xito, entonces s√≥lo puede haber \\(\\small{x+1, x}\\), o \\(\\small{x-1}\\) rachas de fracaso. De ello se deduce que s√≥lo puede haber cuatro tipos de estados \\(\\small{Y_{t}=(X_{t}(S), X_{t}(F), E_{t})}\\), donde el bloque final \\(\\small{E_{t}}\\) es \\(\\small{S}\\) o \\(\\small{F}\\) : (i) \\(\\small{(x, x-1, S)}\\), (ii) \\(\\small{(x, x + 1, F)}\\), (iii) \\(\\small{(x, x, S)}\\) y (iv) \\(\\small{(x, x, F)}\\).\nConsideremos los resultados de diez ensayos de dos estados \\(\\small{w = (SSFFSFSSSF)}\\). La realizaci√≥n de la cadena de Markov imbricada \\(\\small{\\{Y_t\\}}\\) es \\(\\small{\\{Y_{1}=(1,0, S), Y_{2}=(1,0,S), Y_{3}=(1,1,F), Y_{4}=(1,1,F), Y_{5}=(2,1,S), Y_{6}= (2,2,F),Y_{7}=(3,2,S),Y_{8}=(3,2, S),Y_{9}=(3,2,S), Y_{10} = (3,3, F)\\}}\\). El espacio de estados \\(\\small{\\Omega}\\) tiene la forma \\(\\small{\\Omega=\\{(1,0,S), (0,1,F), (1,1,S), (1,1,F),\\ldots, (l_{n},l_{n}S), (l_{n}, l_{n},F)\\}}\\), donde \\(\\small{l_{n}=[(n+1)/2]}\\). Para el caso de ensayos de dos estados independientes pero no id√©nticamente distribuidos, la definici√≥n de \\(\\small{Y_{t}}\\) da como resultado las matrices de probabilidad de transici√≥n, para \\(\\small{t=2,3,\\ldots,n,}\\)\n\n\n\\[\\begin{equation}\n\\boldsymbol{M_{t}}=\n\\begin{array}{cc}&\n\\begin{array}{c}\n(1,0,S)\\\\\n(0,1,S)\\\\\n(1,1,S)\\\\\n(1,1,S)\\\\\n\\cdot\\\\\n\\cdot\\\\\n\\cdot\\\\\n(l_{n},l_{n}-1,S)\\\\\n(l_{n}-1,l_{n},F)\\\\\n(l_{n},l_{n},S)\\\\\n(l_{n},l_{n},F)\\\\\n\\end{array}\n&\n\\left(\n\\begin{array}{ccccccccccc}\np_{t}&0&0&q_{t}&&&&&&&\\\\\n&q_{t}&p_{t}&0&0&&&&&&\\\\\n&&p_{t}&0&0&q_{t}&&&&&\\\\\n&&&q_{t}&p_{t}&0&0&&&&\\\\\n&&&&\\ddots&\\ddots&\\ddots&\\ddots&&&\\\\\n&&&&&\\cdot&\\cdot&\\cdot&\\cdot&&\\\\\n&&&&&&\\ddots&\\ddots&\\ddots&\\ddots&\\\\\n&&&&&&&p_{t}&0&0&q_{t}\\\\\n&&&&&&&&q_{t}&p_{t}&0\\\\\n&&&&&&&&&1&0\\\\\n&&&&&&&&&&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nDado \\(\\small{\\boldsymbol{\\xi}_{1}=(p_{1},q_{1},0,\\ldots,0)}\\) , se deduce que la distribuci√≥n conjunta de \\(\\small{X_n(S)}\\) y \\(\\small{X_n(F)}\\) est√° dada por:\n\n\n\\[\\begin{equation}\n\\small{\\mathbb{P}\\big( X_{n}(S)=x,X_{n}(F)=y\\mid \\boldsymbol{\\xi}_{1}\\big)=\\boldsymbol{\\mathbf{\\xi}}_{1} \\Big(\\prod_{t=1}^{n}\\boldsymbol{M}_{t}\\Big)\\boldsymbol{\\mathbf{U}'}(\\mathbf{C}_{(x,y)})},\n\\end{equation}\\]\n\ndonde, si \\(\\small{y= x+1}\\), entonces \\(\\small{C_{(x,x+1)}=\\{{(x, x + 1, F)}\\}}\\), si \\(\\small{y=x-1}\\), entonces \\(\\small{C_{(x, x-1)}=\\{(x, x-1, S)\\}}\\), si \\(\\small{y=x}\\) entonces \\(\\small{C_{(x,x)}=\\{(x, x, S), (x, x, F)\\}}\\), y \\(\\small{C_{(x,y)}=\\{\\emptyset\\}}\\) en cualquier otro caso.\nUna vez m√°s, con algunas modificaciones sencillas de las matrices de probabilidades de transici√≥n, los resultados anteriores tambi√©n son v√°lidos tanto para ensayos de dos estados i.i.d., como Markov-Dependientes homog√©neos y no homog√©neos. Las distribuciones marginales de \\(\\small{X_{n}(S)}\\) y \\(\\small{X_{n}(F)}\\) pueden obtenerse proyectando la distribuci√≥n conjunta sobre las particiones generadas por las variables aleatorias \\(\\small{X_{n}(S)}\\) y \\(\\small{X_{n}(F)}\\), respectivamente. De forma m√°s general, la distribuci√≥n conjunta de \\(\\small{l&gt;2}\\) variables aleatorias \\(\\small{X_{n}(\\Lambda_{1}),X_{n}(\\Lambda_{2}),\\ldots,X_{n}(\\Lambda_{l})}\\) puede obtenerse del mismo modo con una cadena de Markov \\(\\small{(l+1)-}\\)dimensional \\(\\small{\\{Y_{t} = \\big(X_{t}(\\Lambda_{1}),\\cdots, X_{t}(\\Lambda_{l}), E_{t}\\big)\\}}\\).\nFin 05 de Nov\n\n\n\n\n\n\n\nAbramson, M. and Moser, W. O. J. (1967). Permutations without rising or falling w-sequences. Annals of Mathematical Statistics 38, 1245-1254.\nAki, S. (1985). Discrete distributions of order k on a binary sequence. Annals of the Institute of Statistical Mathematics 37, 205-224.\nAki, S. (1997). On sooner and later problems between success and failure runs.Advances in Combinatorial Methods and Applications to Probability and Statistics (ed.¬†N. Balakrishnan), Birkh√§user, Boston, 385-400.\nAki, S. (1999). Distributions of runs and consecutive systems on directed trees. Annals of the Institute of Statistical Mathematics 51, 1-15.\nAki, S., Balakrishnan, N. and Mohanty, S. G. (1996). Sooner and later waiting time problems for success and failure runs in higher order Markov dependent trials. Annals of the Institute of Statistical Mathematics 48, 773-787.\nAki, S. and Hirano, K. (1988). Some characteristics of the binomial distribution of order k and related distributions. Statistical Theory and Data Analysis II (ed.¬†K. Matusita), North-Holland, Amsterdam, 211-222.\nAki, S. and Hirano K. (1999). Sooner and later waiting time problems for runs in Markov dependent bivariate trials. Annals of the Institute of Statistical Mathematics 51, 17-29.\nAki, S. and Hirano K. (2000). Numbers of success-runs of specified length until certain stopping time rules and generalized binomial distributions of order k. Annals of the Institute of Statistical Mathematics 52, 767-777.\nAki, S., Kuboki, H. and Hirano, K. (1984). On discrete distributions of order k. Annals of the Institute of Statistical Mathematics 36, 431-440.\nAntzoulakos, D. L. (1999). On waiting time problems associated with runs in Markov dependent trials. Annals of the Institute of Statistical Mathematics 51, 323-330.\nAntzoulakos, D. L. (2001). Waiting times for patterns in a sequence of multistate trials. Journal of Applied Probability 38, 508-518.\nBalakrishnan, N. and Koutras, M. V. (2002). Runs and Scans with Applications, Wiley, New York\nBalasubramanian, K., Viveros, R. and Balakrishnan, N. (1993). Sooner and later waiting time problems for Markovian Bernoulli trials. Statistics and Prob- ability Letters 18, 153‚Äì161.}\nBarnard, G. A. (1959). Control charts and stochastic processes. Journal of the Royal Statistical Society, Series B 21, 239-271.\nBarton, D. E. and David, F. N. (1958). Non-randomness in a sequence of two alternatives: II. Runs test. Biometrika 45, 253-256.\nBateman, G. (1948). On the power function of the longest run as a test for randomness in a sequence of alternatives. Biometrika 35, 97-112.\nBoutsikas, M. V. and Koutras, M. V. (2000a). Generalized reliability bounds for coherent structures. Journal of Applied Probability 37, 778-794.\nBoutsikas, M. V. and Koutras, M. V. (2000b). Reliability approximation for Markov chain imbeddable systems. Methodology and Computing in Applied Probability 2, 393-411.\nBrook, D. and Evans, D. A. (1972). An approach to the probability distribution of cusum run length. Biometrika 59, 539-549.\nCai, J. (1994). Reliability of a large consecutive-k-out-of-r-from-n:F system with unequal component-reliability. IEEE Transactions on Reliability 43, 107‚Äì 111.\nCarlitz, L. (1964). Extended Bernoulli and Eulerian numbers. Duke Mathematical Journal 31, 667-689.\nChao, M. T. (1999). Applications of Markov chains in quality-related matters. Statistical Process Monitoring and Optimization (eds.¬†S. H. Park and G. G. Vining), Marcel Dekker, New York, 175-188.\nChao, M. T. and Fu, J. C. (1989). A limit theorem of certain repairable systems. Annals of the Institute of Statistical Mathematics 41, 809‚Äì818.\nChao, M. T. and Fu, J. C. (1991). The reliability of large series system under a Markovian structure. Advances in Applied Probability 23, 894-908.\nChao, M. T., Fu, J. C. and Koutras, M. V. (1995). Survey of reliability stud- ies of consecutive-k-out-of-n: F and related systems. IEEE Transactions on Reliability 44, 120-127.\nChao, M. T. and Lin, G. D. (1984). Economical design of large consecutive-k- out-of-n:F systems. IEEE Transactions on Reliability 33, 411-413.\nChen, J. and Glaz, J. (1997). Approximations and inequalities for the distribution of a scan statistic for 0-1 Bernoulli trials. Advances in the Theory and Practice of Statistics (eds.¬†N. L. Johnson and N. Balakrishnan), Wiley, New York, 285-298.\nChen, J. and Glaz, J. (1999). Approximations for the distribution and the moments of discrete scan statistics. Scan Statistics and Applications (eds.¬†J. Glaz and N. Balakrishnan), Birkh√§user, Boston, 27-66.\nCheung, L. K. W. (2002). Statistical Pattern Recognition in Genomic DNA Sequences. Ph.D.¬†Dissertation, Department of Statistics, University of Manitoba, Canada.\nChiang, D. T. and Niu, S. C. (1981). Reliability of consecutive-k-out-of-n:F sys- tems. IEEE Transactions on Reliability 30, 87-89.\nChrysaphinou, O. and Papastavridis, S. (1988). A limit theorem on the number of overlapping appearances of a pattern in a sequence of independent trials. Probability Theory and Related Fields 79, 129-143.\nCochran, W. G. (1938). An extension of Gold‚Äôs method for examining the apparent persistence of one type of weather. Quarterly Journal of the Royal Meteorological Society 64, 631-634.\nCs√∂rg√∂, S. (1979). Erd√∂s-R√©nyi laws. Annals of Statistics 7, 772-787. David, F. N. (1947). A power function for tests of randomness in a sequence of alternatives. Biometrika 34, 335-339.\nDavid, F. N. and Barton, D. E. (1962). Combinatorial Chance, Hafner, New York. Derman, G., Lieberman, G. J. and Ross, S. M. (1982). On the consecutive-k-out- of-n:F system. IEEE Transactions on Reliability 31, 57-63.\nDillon, J. F. and Roselle, D. P. (1969). Simon Newcomb‚Äôs problem. SIAM Journal on Applied Mathematics 17, 1086-1093.\nDoi, M. and Yamamoto, E. (1998). On the joint distribution of runs in a sequence of multi-state trials. Statistics and Probability Letters 39, 133-141.\nDwass, M. (1973). The number of increases in a random permutation. Journal of Combinatorial Theory, Series A 15, 192-199.\nEbneshahrashoob, M. and Sobel, M. (1990). Sooner and later problems for Bernoulli trials: frequency and run quotas. Statistics and Probability Letters 9, 5-11.\nErd√∂s, P. and R√©nyi, A. (1970). On a new law of large numbers. Journal d‚ÄôAnalyse Math√©matique 23, 103-111.\nErd√∂s, P. and R√©v√©sz, P. (1975). On the length of the longest head-run. Topics in Information Theory, Colloquia Mathematica Societatis J√°nos Bolyai, 16 (eds.¬†I. Csiszar and P. Elias; Keszthely, Hungary), North-Holland, Amster- dam, 219-228.\nEwan, W. D. and Kemp, K. W. (1960). Sampling inspection of continuous pro- cesses with no autocorrelation between successive results. Biometrika 47, 363-380.\nFeller, W. (1968). An Introduction to Probability Theory and Its Applications (Vol. I, 3rd ed.), Wiley, New York.\nFu, J. C. (1985). Reliability of consecutive-k-out-of-n:F system. IEEE Transac- tions on Reliability 34, 127-130.\nFu, J. C. (1986). Reliability of consecutive-k-out-of-n:F systems with (k-1) step Markov dependence. IEEE Transactions on Reliability 35, 602-606.\nFu, J. C. (1995). Exact and limiting distributions of the number of successions in a random permutation. Annals of the Institute of Statistical Mathematics 47, 435-446.\nFu, J. C. (1996). Distribution theory of runs and patterns associated with a sequence of multi-state trials. Statistica Sinica 6, 957-974.\nFu, J. C. (2001). Distribution of scan statistics for a sequence of bi-state trials Journal of Applied Probability 38, 1-9.\nFu, J. C. and Chang, Y. M. (2002). On probability generating functions for wait- ing time distributions of compound patterns in a sequence of multistate trials. Journal of Applied Probability 39, 70-80.\nFu, J. C. and Hu, B. (1987). On reliability of a large consecutive-k-out-of-n:F sys- tem with k-1 step Markov dependence. IEEE Transactions on Reliability 36, 75-77.\nFu, J. C. and Koutras, M. V. (1994). Distribution theory of runs: a Markov chain approach. Journal of the American Statistical Association 89, 1050-1058.\nFu, J. C. and Lou, W. Y. W. (1991). On reliabilities of certain large linearly connected engineering systems. Statistics and Probability Letters 12, 291-296.\nFu, J. C. and Lou, W. Y. W. (2000a). On the exact distribution of SECON and its application. Statistica Sinica 10, 999-1010.\nFu, J. C. and Lou, W. Y. W. (2000b). Joint distribution of rises and falls. Annals of the Institute of Statistical Mathematics 52, 415-425.\nFu, J. C., Lou, W. Y. W., Bai, Z. D. and Li, G. (2002). The exact and limiting distributions for the number of successes in success runs within a sequence of Markov-dependent two-state trials. Annals of the Institute of Statistical Mathematics 54, 719-730.\nFu, J. C., Lou, W. Y. W. and Chen, S. C. (1999). On the probability of pattern matching in nonaligned DNA sequences: a finite Markov chain imbedding approach. Scan Statistics and Applications (eds.¬†J. Glaz and N. Balakrish- nan), Birkh√§user, Boston, 287-302.\nFu, J. C., Lou, W. Y. W. and Wang, Y. J. (1999). On the exact distributions of Eulerian and Simon Newcomb numbers associated with random permuta- tions. Statistics and Probability Letters 42, 115‚Äì125.\nFu, J. C., Shmueli, G. and Chang, Y. M. (2002). A unified Markov chain approach for computing the run length distribution for control charts with simple or compound rules. Technical Report, Department of Statistics, University of Manitoba.\nFu, J. C., Spiring, F. A. and Xie, H. (2002). On the average run lengths of quality control schemes using a Markov chain approach. Statistics and Probability Letters 56, 369-380.\nGlaz, J. (1989). Approximations and bounds for the distribution of the scan statistic. Journal of the American Statistical Association 84, 560-566.\nGlaz, J. (1992). Approximations for tail probabilities and moments of the scan statistic. Computational Statistics and Data Analysis 14, 213-227.\nGlaz, J., Naus, J. I. and Wallenstein, S. (2001). Scan Statistics, Springer-Verlag, New York.\nGodbole, A. P. (1990). Specific formulae for some success run distributions. Statistics and Probability Letters 10, 119-124.\nGodbole, A. P. (1991). Poisson approximations for runs and patterns of rare events. Advances in Applied Probability 23, 851-865.\nGoncharov, V. L. (1944). On the field of combinatory analysis. Isvestija Akad. Nauk. SSSR. Ser. Math. 8, 3-48 (in Russian); English translation: Translations of the AMS Ser. Math. 19 (1962), 1-46.\nGoodman, L. A. (1958). Simplified runs tests and likelihood ratio tests for Markoff chains. Biometrika 45, 181-197.\nHan, Q. and Aki, S. (1998). Formulae and recursions for the joint distributions of success runs of several lengths in a two-state Markov chain. Statistics and Probability Letters 40, 203-214.\nHan, Q. and Aki, S. (2000a). Sooner and later waiting time problems based on a dependent sequence. Annals of the Institute of Statistical Mathematics 52, 407-414.\nHan, Q. and Aki, S. (2000b). Waiting time problems in a two-state Markov chain. Annals of the Institute of Statistical Mathematics 52, 778-789.\nHirano, K. (1986). Some properties of the distributions of order k. Fibonacci Numbers and Their Applications (eds.¬†A. N. Philippou, G. E. Bergum, and A. F. Horadam), Reidel, Dordrecht, 43-53.\nHirano, K. and Aki, S. (1987). Properties of the extended distributions of order k. Statistics and Probability Letters 6, 67-69.\nHirano, K. and Aki, S. (1993). One number of occurrences of success runs of specified length in a two-state Markov chain. Statistica Sinica 3, 313-320.\nHuntington, R. J. and Naus, J. I. (1975). A simpler expression for kth nearest neighbor coincidence probabilities. Annals of Probability 3, 894-896.\nHwang, F. K. (1982). Fast solutions for consecutive-k-out-of-n:F system. IEEE Transactions on Reliability 31, 447-448.\nHwang, F. K. (1986). Simplified reliabilities for consecutive-k-out-of-n systems.SIAM Journal on Algebraic and Discrete Methods 7, 258-264.\nJackson, D. M. and Reilly, J. W. (1976). Permutations with a prescribed number of p-runs. Ars Combinatoria 1, 297-305.\nJohnson, B. C. (2001). Distribution of increasing l-sequences in a random permutation. Methodology and Computing in Applied Probability 3, 35-49.\nJohnson, B. C. (2002). The distribution of increasing 2-sequences in random per- mutations of arbitrary multi-sets. Statistics and Probability Letters 59, 67-74.\nJohnson, B. C and Fu, J. C. (2000). The distribution of increasing l-sequences in random permutations: A Markov chain approach. Statistics and Probability Letters 49, 337-344.\nKaplansky, I. (1944). Symbolic solution of certain problems in permutations. Bul- letin of the American Mathematical Society 50, 906-914.\nKarlin, S. and McGregor, J. (1959). Coincident probabilities. Pacific Journal of Mathematics 9, 1141-1164.\nKontoleon, J. M. (1980). Reliability determination of a r-successive-out-of-n:F system. IEEE Transactions on Reliability 29, 437.\nKossow, A. and Preuss, W. (1989). Reliability of consecutive-k-out-of-n:F system with nonidentical component reliabilities. IEEE Transaction on Reliability 38, 229-233.\nKoutras, M. V. (1996a). On a Markov chain approach for the study of reliability structures. Journal of Applied Probability 33, 357-367.\nKoutras, M. V. (1996b). On a waiting time distribution in a sequence of Bernoulli trials. Annals of the Institute of Statistical Mathematics 48, 789-806.\nKoutras, M. V. (1997a). Waiting time distributions associated with runs of fixed length in two-state Markov chains. Annals of the Institute of Statistical Mathematics 49, 123-139.\nKoutras, M. V. (1997b). Waiting times and number of appearances of events in a sequence of discrete random variables. Advances in Combinatorial Meth- ods and Applications to Probability and Statistics (ed.¬†N. Balakrishnan), Birkh√§user, Boston, 363-384.\nKoutras, M. V. (2003). Applications of Markov chains to the distribution the- ory of runs and patterns. Handbook of Statistics 21: Stochastic Processes, Modeling and Simulation (eds.¬†D. N. Shanbhag and C. R. Rao), Elsevier, Amsterdam, in press.\nKoutras, M. V. and Alexandrou, V. (1995). Runs, scans and urn model distributions: a unified Markov chain approach. Annals of the Institute of Statistical Mathematics 47, 743-766.\nKoutras, M. V. and Alexandrou, V. (1997a). Non-parametric randomness tests based on success runs of fixed length. Statistics and Probability Letters 32, 393-404.\nKoutras, M. V. and Alexandrou, V. (1997b). Sooner waiting time problems in a sequence of trinary trials. Journal of Applied Probability 34, 593‚Äì609.\nKoutras, M. V. and Papastavridis, S. G. (1993). Application of the Stein-Chen method for bounds and limit theorems in the reliability of coherent struc- tures. Naval Research Logistics 40, 617-631.\nLing, K. D. (1992). A generalization of the sooner and later waiting time problems for Bernoulli trials: frequency quota. Statistics and Probability Letters 14, 401-405.\nLing, K. D and Low, T. Y. (1993). On the soonest and the latest waiting time distributions: succession quotas. Communications in Statistics Theory and Methods 22, 2207-2221.\nLou, W. Y. W. (1996). On runs and longest run tests: method of finite Markov chain imbedding. Journal of the American Statistical Association 91, 1595‚Äì 1601.\nLou, W. Y. W. (1997). An application of the method of finite Markov chain imbedding to runs tests. Statistics and Probability Letters 31, 155‚Äì161.\nLou, W. Y. W. (2000). The exact distribution of the continuity of care measure NOP. Statistics and Probability Letters 48, 361‚Äì368.\nLou, W. Y. W. (2001). The distribution of the usual provider continuity index under Markov dependence. Statistics and Probability Letters 54, 269‚Äì276.\nLou, W. Y. W. (2003). The exact distribution of the K-tuple statistic for sequence homology. Statistics and Probability Letters 1, 51-59.\nLucas, J. M. and Crosier, R. B. (1982). Fast initial response for CUSUM quality control schemes: Give your CUSUM a head start. Technometrics 24, 199-205.\nMacMahon, P. A. (1915). Combinatory Analysis, Cambridge University Press, London.\nMohanty, S. G. (1994). Success runs of length k in Markov dependent trials. Annals of the Institute of Statistical Mathematics 46, 777-796.\nMontgomery, D. C. (2001). Introduction to Statistical Quality Control (4th ed.). Wiley, New York.\nMood, A. M. (1940). The distribution theory of runs. Annals of Mathematical Statistics 11, 367‚Äì392.\nMosteller, F. (1941). Note on an application of runs to quality control charts. Annals of Mathematical Statistics 12, 228-232.\nMuselli, M. (2000). Useful inequalities for the longest run distribution. Statistics and Probability Letters 46, 239-249.\nNagaev, S. V. (1957). Some limit theorems for stationary Markov chains. Theory of Probability and its Applications 2, 378-406.\nNaus, J. I. (1965). The distribution of the size of the maximum cluster of points on a line. Journal of the American Statistical Association 60, 532-538.\nNaus, J. I. (1974). Probabilities for a generalized birthday problem. Journal of the American Statistical Association 69, 810-815\nNaus, J. I. (1982). Approximations for distributions of scan statistics. Journal of the American Statistical Association 77, 177-183.\nNishimura, K. and Sibuya, M. (1997). Extended Stirling family of discrete probability distributions. Communications in Statistics Theory and Methods 26, 1727-1744.\nPapastavridis, S. G. (1988). A Weibull limit for the reliability of a consecutive k-within-m-out-of-n system. Advances in Applied Probability 20, 690-692.\nPapastavridis, S. G. and Koutras, M. V. (1993). Bounds for reliability of consec- utive k-within-m-out-of-n:F systems. IEEE Transactions on Reliability 42, 156-160.\nPhilippou, A. N. (1986). Distributions and Fibonacci polynomials of order k, longest runs, and reliability of consecutive-k-out-of-n:F systems. Fibonacci Numbers and Their Applications (eds.¬†A. N. Philippou, G. E. Bergum and A. F. Horadam), Reidel, Dordrecht, 203-227.\nPhilippou, A. N., Georghiou, C. and Philippou, G. N. (1983). A generalized geometric distribution and some of its properties. Statistics and Probability Letters 1, 171‚Äì175.\nPhilippou, A. N. and Makri, F. S. (1986). Success runs and longest runs. Statistics and Probability Letters 4, 211‚Äì215.\nPyke, R. (1961). Markov renewal processes: definitions and preliminary proper- ties. Annals of Mathematical Statistics 32, 1231-1242.\nReilly, J. W. and Tanny, S. M. (1979). Counting successions in permutations. Studies in Applied Mathematics 61, 73-81.\nR√©nyi, A (1970). Probability Theory, American Elsevier Publishing Company Inc., New York.\nRiordan, J. (1958). An Introduction to Combinatorial Analysis, Wiley, New York.\nRoselle, D. P. (1968). Permutations by number of rises and successions. Proceed- ings of the American Mathematical Society 19, 8-16. Ross, S. M. (2000). Introduction to Probability Models (7th ed.), Academic Press, San Diego.\nRubin, G., McCulloch, C. E. and Shapiro, M. A. (1990). Multinomial runs tests to detect clustering in constrained free recall. Journal of the American Sta- tistical Association 85, 315-320.\nSaperstein, B. (1972). The generalized birthday problem. Journal of the American Statistical Association 67, 425-428.\nSchilling, M. F. (1990). The longest run of heads. The College Mathematics Jour- nal 21, 196-207.\nSeneta, E. (1981). Non-negative Matrices and Markov Chains (2nd ed.), Springer- Verlag, New York.\nSheng, K. N. and Naus, J. I. (1994). Pattern matching between two non-aligned random sequences. Bulletin of Mathematical Biology 56, 1143-1162.\nSteinwachs, D. M. (1979). Measuring provider continuity in ambulatory care. Medical Care 17, 551-565.\nSwed, F. S. and Eisenhart, C. (1943). Tables for testing randomness of grouping in a sequence of alternatives. Annals of Mathematical Statistics 14, 66-87.\nTanny, S. (1973). A probabilistic interpretation of Eulerian numbers. Duke Math- ematical Journal 40, 717-722.\nTanny, S. M. (1976). Permutations and successions. Journal of Combinatorial Theory, Series A 21, 196-202.\nVaggelatou, E. (2003). On the length of the longest run in a multi-state Markov chain. Statistics and Probability Letters 62, 211‚Äì221.\nUchida, M. and Aki, S. (1995). Sooner and later waiting time problems in a two- state Markov chain. Annals of the Institute of Statistical Mathematics 47, 415-433\nWald, A. and Wolfowitz, J. (1940). On a test whether two samples are from the same population. Annals of Mathematical Statistics 11, 147-162.\nWigle, D. T. (1982). Prevalence of selected chronic diseases in Canada, 1978-1979. Chronic Disease in Canada 3, 9.\nWishart, J. and Hirshfeld, H. O. (1936). A theorem concerning the distribution of joins between line segments. Journal of the London Mathematical Society 11, 227-235.\nWolfowitz, J. (1943). On the theory of runs with some applications to quality control. Annals of Mathematical Statistics 14, 280-288.\nWorpitzky, J. (1883). Studien √ºber die Bernoullischen und Eulerschen Zahlen. Journal f√ºr die reine und angewandte Mathematik 94, 203-232.",
    "crumbs": [
      "Trabajo Grado"
    ]
  },
  {
    "objectID": "Trabajo_Grado.html#teor√≠a-de-distribuci√≥n-de-rachas-y-patrones-y-sus-aplicaciones.-un-enfoque-de-incrustaci√≥n-de-cadenas-de-markov-finitas.",
    "href": "Trabajo_Grado.html#teor√≠a-de-distribuci√≥n-de-rachas-y-patrones-y-sus-aplicaciones.-un-enfoque-de-incrustaci√≥n-de-cadenas-de-markov-finitas.",
    "title": "Vladimir Sanchez Tenjo",
    "section": "",
    "text": "El prop√≥sito de este libro es ofrecer una introducci√≥n rigurosa y exhaustiva a la t√©cnica de Incrustaci√≥n de Cadenas de Markov Finitas (ICMF) para estudiar las distribuciones de Rachas y Patrones desde un punto de vista unificado e intuitivo, alejado de las l√≠neas tradicionales de la combinatoria. A lo largo de las dos √∫ltimas d√©cadas, se han obtenido mediante este enfoque un n√∫mero considerable de nuevos resultados relacionados con las distribuciones de rachas y patrones.\n\n\nEl tema central de la Incrustaci√≥n de Cadenas de Markov Finitas (ICMF), como su nombre indica, es incrustar adecuadamente las variables aleatorias de inter√©s en el marco de una cadena de Markov finita, y las representaciones resultantes de las distribuciones subyacentes son compactas y muy susceptibles de un estudio m√°s profundo de las propiedades asociadas. En este libro, el concepto de ICMF se desarrolla sistem√°ticamente y se ilustra su utilidad mediante aplicaciones pr√°cticas a diversos campos, como la fiabilidad de los sistemas de ingenier√≠a, la comprobaci√≥n de hip√≥tesis, el control de calidad y la medici√≥n de la continuidad en el sector sanitario.\n\n\nEste libro est√° restringido a espacios muestrales discretos, una restricci√≥n que sirve para que este trabajo sea accesible a una audiencia m√°s amplia al simplificar los resultados te√≥ricos y sus aplicaciones. Las rachas y patrones considerados aqu√≠ se definen en gran medida en sucesiones de ensayos Markov-Dependientes de dos o m√∫ltiples estados, con aplicaciones pr√°cticas en mente; los definidos sobre permutaciones aleatorias de n√∫meros enteros, como los n√∫meros de Eulerian y Simon Newcomb, tambi√©n se tratan utilizando un procedimiento de inserci√≥n adicional. El contenido de este libro est√° orientado principalmente a los investigadores que utilizan la teor√≠a de la distribuci√≥n de rachas y patrones en diversos √°mbitos aplicados de la estad√≠stica, la probabilidad y la combinatoria, pero tambi√©n podr√≠a servir de base de un curso de temas especiales de un semestre de duraci√≥n en cuarto curso de licenciatura o a nivel de primer a√±o de posgrado.\n\n\n\nDeseamos agradecer la ayuda de Y. M. Chang y B. C. Johnson en la correcci√≥n de los primeros borradores del libro, as√≠ como el aliento de nuestros colegas de la Universidad de Manitoba y la Universidad de Toronto.\n\n\nTambi√©n estamos en deuda con nuestras familias por su inagotable apoyo. Por √∫ltimo, queremos agradecer a la Sra. E. H. Chionh, de World Scientific Publishing Co.¬†por su paciencia y apoyo administrativo.\n\n\n\n\nLa ocurrencia de rachas y patrones en una sucesi√≥n de resultados de ensayos discretos o permutaciones aleatorias es un concepto importante en diversas √°reas de la ciencia, como la ingenier√≠a de confiabilidad, el control de calidad, la psicolog√≠a, la sociolog√≠a, la comparaci√≥n de secuencias de ADN y la comprobaci√≥n de hip√≥tesis. Resultados de las distribuciones de probabilidad de rachas y patrones elementales se obtuvieron espor√°dicamente en la literatura hasta aproximadamente la d√©cada de 1940, cuando se publicaron una serie de estudios pioneros sobre rachas y patrones m√°s complejos: por ejemplo, Wishart e Hirshfeld (1936), Cochran (1938), Mood (1940), Wald y Wolfowitz (1940), Mosteller (1941) y Wolfowitz (1943). La mayor√≠a de estos estudios se centraron en hallar la distribuci√≥n condicional de las rachas de √©xito dado el n√∫mero total de √©xitos en una sucesi√≥n de ensayos de dos estados. Un libro reciente reciente de Balakrishnan y Koutras (2002), ofrece una buena revisi√≥n exhaustiva de los avances hist√≥ricos y actuales en la teor√≠a de la distribuci√≥n de rachas y las estad√≠sticas de escaneo.\nTradicionalmente, las distribuciones de rachas y patrones se estudiaban mediante an√°lisis combinatorio. Por ejemplo, Mood (1940) escribi√≥: ‚ÄúEl problema de la distribuci√≥n es, por supuesto, combinatorio, y todo el desarrollo depende de algunas identidades del an√°lisis combinatorio‚Äù. Sin embargo, encontrar las identidades combinatorias apropiadas para derivar las distribuciones de probabilidad puede ser dif√≠cil, si no imposible, para rachas y patrones complejos, y quiz√° sea √©sta la raz√≥n por la que las distribuciones exactas de muchos estad√≠sticos comunes definidos en rachas y patrones siguen siendo desconocidas. Adem√°s las identidades requeridas a menudo difieren incluso para rachas y patrones similares, y por lo tanto, incluso en el caso m√°s sencillo de ensayos independientes e id√©nticamente distribuidas (i.i.d.) de dos estados (los llamados ‚Äúensayos de Bernoulli‚Äù), cada nuevo problema de distribuci√≥n generalmente tiene que estudiarse caso por caso utilizando el enfoque combinatorio. Por ejemplo, s√≥lo hace relativamente poco tiempo Philippou y Makri (1986) e Hirano (1986), de forma independiente y mediante an√°lisis combinatorio, obtuvieron la distribuci√≥n exacta de la estad√≠stica de racha tradicional \\(\\small{N_{n,k}}\\), del n√∫mero de rachas de \\(k\\) √©xitos consecutivos no-solapados en una secuencia de \\(n\\) ensayos Bernoulli:\n\n\n\\[\\begin{equation}\n\\mathbb{P}(N_{n,k}=x)=\\sum_{m=0}^{k-1}\\sum_{x_1+x_2+\\cdots+\\\\\nkx_k=n-m-km}\\binom{x_1+x_2+\\cdots+x_k+x}{x_1,x_2,\\cdots,x_k,x}p^n\\Big(\\frac{q}{p}\\Big)^{x_1+x_2+\\cdots+x_k}\n\\end{equation}\\]\n\npara \\(x=0,1,\\ldots,[n/k]\\), con probabilidades de √©xito y fracaso denotadas por \\(p\\) y \\(q=1-p\\), respectivamente. Otro m√©todo para determinar una distribuci√≥n de probabilidad exacta consiste en derivar la funci√≥n generadora \\(\\small{\\varphi(s)}\\) para la variable aleatoria entera no negativa \\(\\small{X_n(\\Lambda)}\\) asociada con el patr√≥n \\(\\small{\\Lambda}\\) (por ejemplo, \\(\\small{X_n(\\Lambda)}\\) podr√≠a ser el n√∫mero de apariciones del patr√≥n \\(\\small{\\Lambda}\\) en \\(n\\) ensayos) y, a continuaci√≥n, diferenciar \\(\\small{\\varphi(s)}\\) \\(x\\) veces para obtener la funci√≥n de distribuci√≥n de probabilidad (fdp) dada por \\(\\small{\\mathbb{P}(X_n(\\Lambda) = x)}\\) este enfoque fue introducido por Feller (1968) utilizando la teor√≠a de los sucesos recurrentes. Por ejemplo, para la funci√≥n generadora del tiempo de espera \\(\\small{W(\\Lambda)}\\), el n√∫mero de ensayos Bernoulli hasta la primera aparici√≥n del patr√≥n \\(\\small{\\Lambda}\\) consistente en \\(k\\) √©xitos consecutivos, fue dada por Feller como:\n\n\n\\[\\begin{equation}\n\\varphi_{W}(s)=\\frac{p^ks^k(1-ps)}{1-s+qp^ks^{k+1}}\n\\end{equation}\\]\n\nPara rachas y patrones m√°s complejos, las funciones generadoras pueden ser dif√≠ciles de diferenciar un gran n√∫mero de veces y es posible que sea necesario emplear t√©cnicas de aproximaci√≥n. Feller utiliz√≥ el m√©todo de expansi√≥n de fracciones parciales, que puede requerir m√©todos num√©ricos eficientes para calcular ra√≠ces de polinomios. A traves del libro estudiaremos problemas de distribuci√≥n de rachas y patrones desde un punto de vista, en nuestra opini√≥n, m√°s unificado e intuitivo, alejado de las l√≠neas de la combinatoria tradicional. El enfoque adoptado consiste en incrustar adecuadamente la variable aleatoria \\(\\small{X_n(\\Lambda)}\\) en una cadena de Markov finita \\(\\small{\\{Y_t\\}}\\), de modo que la probabilidad de \\(\\small{X_n(\\Lambda)}=x\\) pueda expresarse en t√©rminos de la probabilidad de que el estado de la cadena de Markov al momento \\(\\small{n}\\), \\(\\small{Y_n}\\), se encuentre en un subconjunto \\(\\small{C_x}\\) del espacio de estados, es decir:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\{X_n(\\Lambda)=x\\}=\\mathbb{P}(Y_n \\in C_x)\n\\end{equation}\\]\n\ndonde la probabilidad del lado derecho se puede calcular f√°cilmente mediante las matrices de probabilidad de transici√≥n de la cadena de Markov. Esta representaci√≥n de la distribuci√≥n subyacente de \\(\\small{X_n(\\Lambda)}\\) es compacta, f√°cil de calcular y bastante susceptible de an√°lisis posteriores. El m√©todo depende en gran medida de la capacidad de construir una cadena de Markov adecuada asociada con la variable aleatoria \\(\\small{X_n(\\Lambda)}\\), pero una vez construida la cadena, la linealidad de la cadena de Markov reduce la complejidad computacional a menudo asociada con t√©cnicas combinatorias y de funciones generadoras para calcular los fdp‚Äôs exactas de rachas y patrones.\nLos primeros resultados de la teor√≠a de la distribuci√≥n de rachas y patrones se derivaron casi exclusivamente bajo el supuesto de ensayos Bernoulli o ensayos i.i.d. multiestados. Una gran ventaja de la t√©cnica de incrustaci√≥n de cadenas finitas de Markov es que se puede aplicar no s√≥lo a casos de ensayos i.i.d. , tambi√©n para ensayos multiestado Markov-dependientes, eso si, con poco esfuerzo adicional. Independientemente de los procedimientos de conteo especificados para patrones superpuestos (conteo superpuesto versus no superpuesto); tambi√©n se puede extender a varios tipos de rachas y patrones en permutaciones aleatorias. Recientemente, este m√©todo ha sido adoptado por varios investigadores para estudiar diversas distribuciones de rachas y patrones: por ejemplo, Antzoulakos (1999, 2001), Boutsikas y Koutras (2000a,b), Doi y Yamamoto (1998), Fu (1985, 1986, 1996), Pu y Koutras (1994), Fu y Lou (2000a,b), Han y Aki (2000a,b), Johnson (2002), Koutras (1996a,b, 1997a,b, 2003), Koutras y Alexandrou (1995), Lou (1996, 2000, 2001) y Nishimura y Sibuya (1997). Tocaremos algunos de estos trabajos recientes, pero nuestras formulaciones correspondientes pueden diferir ligeramente para tratar todos los problemas utilizando un enfoque de incrustaci√≥n com√∫n.\nEste libro no es una revisi√≥n de la teor√≠a de rachas y patrones, ni pretende ser utilizado principalmente como un libro de texto de curso; est√° dirigido principalmente a investigadores en estad√≠stica aplicada y probabilidad que est√©n interesados en utilizar la t√©cnica de incrustaci√≥n de cadenas finitas de Markov para estudiar las distribuciones de rachas y patrones que surgen en aplicaciones espec√≠ficas. El contenido del libro se basa en gran medida en desarrollos recientes en esta √°rea, pero se presenta de una manera que no requiere conocimiento de conceptos avanzados en matem√°ticas o probabilidad; Se supone que se tiene experiencia en teor√≠a de la probabilidad, al nivel de, por ejemplo, el libro de Feller (1968) ‚ÄúUna introducci√≥n a la teor√≠a de la probabilidad y sus aplicaciones, Volumen I‚Äù. El libro est√° organizado como sigue. En el Cap√≠tulo 2, presentamos las ideas y t√©cnicas b√°sicas de incrustaci√≥n de cadenas finitas de Markov. Este cap√≠tulo sienta las bases para calcular los fdp‚Äôs de rachas y patrones, incluidas las distribuciones de tiempo de espera. El Cap√≠tulo 3 examina las distribuciones de rachas y patrones asociados con los ensayos de dos estados, y en el Cap√≠tulo 4, se trata la extensi√≥n a los ensayos de m√∫ltiples estados a trav√©s del principio de avance y retroceso. El Cap√≠tulo 5 estudia principalmente las distribuciones de tiempo de espera de patrones simples y compuestos, as√≠ como sus funciones generadoras y aproximaciones de grandes desviaciones. En el Cap√≠tulo 6, la t√©cnica de incrustaci√≥n de cadenas finitas de Markov se extiende al estudio de distribuciones de patrones en permutaciones aleatorias de n√∫meros enteros, centr√°ndose en detalle en los n√∫meros de Euler y Simon Newcomb. El Cap√≠tulo 7 cubre varias aplicaciones de la teor√≠a de la distribuci√≥n de rachas y patrones en las √°reas de confiabilidad de sistemas de ingenier√≠a, pruebas de hip√≥tesis, medici√≥n de continuidad en atenci√≥n m√©dica y control de calidad.\n\n\n\n\n\nSea \\(\\small{\\Omega=\\{1,2,\\ldots,m\\}}\\quad(m&lt;\\infty)\\) un espacio de estados finito, y \\(\\small{\\mathcal{Y_t}=\\{Y_0,Y_1,\\ldots,Y_t,\\ldots\\}}\\) una familia de variables aleatorias definidas sobre \\(\\small{\\Omega}\\).(proceso estoc√°stico).\nDefinici√≥n 2.1 Decimos que la familia/colecci√≥n de variables aleatorias \\(\\small{\\{\\mathcal{Y_t}\\}}\\) es cadena de Markov si, para toda sucesi√≥n \\(\\small{\\{Y_0=i_0,Y_1=i_1,\\ldots,Y_{t-1}=i_{t-1},Y_t=i_t\\}},\\) con \\(\\small{t\\in \\{1,2,\\cdots\\}}\\), se tiene que:\n\n\n\\[\\begin{equation}\n\\mathbb{P}(Y_t=i_t \\mid Y_{t-1}=i_{t-1},\\ldots,Y_0=i_0)=\\mathbb{P}(Y_t=i_t \\mid Y_{t-1}=i_{t-1})\n\\end{equation}\\]\n\nEn otras palabras, la sucesi√≥n de variables aleatorias es una cadena de Markov si la probabilidad de que el sistema entre en el estado \\(\\small{i_t}\\) en el momento \\(\\small{t}\\) depende s√≥lo del estado inmediatamente anterior \\(\\small{i_{t-i}}\\) en el momento \\(\\small{t-1}\\). O m√°s sucintamente, visto desde el estado en el momento \\(\\small{t- 1}\\), el futuro es independiente del pasado. Las probabilidades condicionales.\n\n\n\\[\\begin{equation}\n\\mathbb{P}(Y_t=j \\mid Y_{t-1}=i)\\equiv p_{ij}\n\\end{equation}\\]\n\n\\(\\small{i,j \\in \\Omega}\\), se denominan probabilidades de transici√≥n de un paso para el sistema en el momento \\(t\\). Las probabilidades de transici√≥n \\(\\small{p_{ij}(t), 1 \\leq i,j \\leq m}\\), pueden representarse como una matriz \\(m\\times m\\)\n\n\n\\[\\begin{equation}\n\\boldsymbol{M_t}=(p_{ij(t)})=\\begin{pmatrix}\np_{11}(t) & p_{12}(t) & \\cdots & p_{1m}(t)\\\\\np_{21}(t) & p_{22}(t) & \\cdots & p_{2m}(t)\\\\\n\\vdots & \\ddots & \\ddots & \\cdots\\\\\np_{m1}(t) &p_{m2}(t) & \\cdots & p_{mm}(t)\\\\\n\\end{pmatrix}_{m\\times m}\n\\end{equation}\\]\n\nLas matrices \\(\\small{\\boldsymbol{M_t},\\,\\, t=1,2,\\ldots,}\\) son llamadas matrices de probabilidades de transici√≥n de un paso o simplemente matrices de transici√≥n de un paso.\nProposici√≥n. La matriz de probabilidades de transici√≥n \\(\\small{\\boldsymbol{M_t}=(p_{ij}(t))}\\) cumplen las siguientes propiedades, para cada tiempo \\(\\small{t}\\):\n\n\\(\\small{(p_{ij(t)}) \\geq 0}\\) para todo \\(\\small{t}\\).\n\\(\\small{\\displaystyle\\sum_{j}p_{ij}=1}\\), es decir, en cada momento del tiempo \\(\\small{t}\\), el proceso cambia de estado (puede ser permanecer en el mismo estado) con probabibilidad \\(\\small{1}\\).\n\nDefinici√≥n 2.2: Una cadena de Markov \\(\\small{\\{Y_0,Y_1,\\dots\\}}\\), es homogenea si las probabilidades de transici√≥n son constantes en el tiempo, i.e \\(\\small{\\mathbb{P}(Y_t=j \\mid Y_{t-1}=i)}=p_{ij}\\) para todo par \\(\\small{(i,j)\\in \\Omega \\times \\Omega=\\Omega^2}\\) y todo \\(\\small{t=1,2,\\ldots}\\)\nEsta definici√≥n equivale a decir que las matrices de probabilidad de transici√≥n de una cadena de Markov homog√©nea pueden representarse mediante la √∫nica matriz:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M=M_t}=(p_{ij}(t)), \\quad \\text{para todo } t=1,2,\\ldots\n\\end{equation}\\]\n\nen donde las probabilidades de transici√≥n \\(\\small{p_{ij}}\\) son independientes del √≠ndice del tiempo \\(\\small{t}\\).\nEl conjunto de probabilidades en el momento \\(\\small{0}\\), denotada como \\(\\small{\\mathbb{P}(Y_0 = i)}\\) para \\(i = 1,\\ldots,m\\) se conoce como la distribuci√≥n inicial de la cadena de Markov. Dada una distribuci√≥n de probablidad inicial y las probabilidades de transici√≥n de una cadena de Markov, la distribuci√≥n conjunta de la cadena se puede calcular de la siguiente manera:\n\n\n\\[\\begin{equation}\n\\begin{split}\n\\mathbb{P}(Y_n=i_n,\\ldots,Y_1=i_1,Y_0=i_0) = &  \\mathbb{P}(Y_n=i_n \\mid Y_{n-1}=i_{n-1})\\cdots \\\\\n& \\cdots \\mathbb{P}(Y_1=i_1 \\mid Y_0=i_0)\\mathbb{P}(Y_{0}=i_{0}).\n\\end{split}\n\\end{equation}\\]\n\nLas cadenas de Markov se han utilizado en el modelado de una gran cantidad de aplicaciones. Aqu√≠ damos dos ejemplos simples que se ven a menudo en la teor√≠a de probabilidad aplicada:\nEjemplo 2.1 (El problema de la ruina del jugador). Considere un jugador que gana y pierde un d√≥lar con probabilidades \\(p\\) y \\(q = 1-p\\), respectivamente. Supongamos que el jugador tiene un capital inicial de \\(\\small{a}\\) d√≥lares. El jugador deja de jugar cuando se queda sin capital (‚Äúarruinado‚Äù) o cuando alcanza una fortuna de \\(\\small{a + b}\\) d√≥lares (con ganancia neta \\(\\small{b &gt; 0}\\)).\nLa sucesi√≥n del monto de capital del jugador, \\(\\small{\\{Y_t: t = 0,1,2, \\ldots\\}}\\), forma una cadena de Markov homog√©nea con espacio de estados \\(\\small{\\Omega= \\{0,1, 2, \\ldots, a-1,a,a + 1,\\ldots, a + b}\\}\\) y las siguientes probabilidades de transici√≥n:\n\n\n\\[\\begin{equation}\np_{ij}=\\begin{cases}\np\\quad \\text{si } j=i+1\\\\\nq\\quad \\text{si } j=i-1\n\\end{cases}\n\\end{equation}\\]\n\npara \\(\\small{i=1,2,\\ldots,a+b-1,\\, p_{00}=p_{a+b,a+b}=1}\\) y cero en cualquier otro caso. Los estados \\(\\small{0}\\) y \\(\\small{a+b}\\) se denominan absorbentes, ya que, una vez alcanzados nunca se sale de estos. La Cadena de Markov tine la matriz de problabilidades de transici√≥n:\n\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\\begin{array}{cc} &\n\\begin{array}{cccccccc}\n\\end{array}\n\\\\\n\\begin{array}{ccc}\n0 \\\\\n1 \\\\\n\\vdots\\\\\n\\cdot \\\\\na-1 \\\\\na\\\\\na+1\\\\\n\\vdots\\\\\na+b\n\\end{array}\n&\n\\left(\n\\begin{array}{cccccccc}\n1 & 0 & 0 & 0 &  &  &   &   \\\\\nq & 0 & p & 0 &  &  &   &  \\\\\n& \\ddots & \\ddots & \\ddots &   &   &\\boldsymbol{0}   &  \\\\\n&  &  \\ddots & \\ddots & \\ddots &   &   &   \\\\\n&  &   &  q & 0& p &  &   \\\\\n& \\boldsymbol{0} &  &   &   \\ddots & \\ddots & \\ddots & \\\\\n&  &  &  &  & q & 0 & p \\\\\n&  &  &  &  & 0 & 0 & 1 \\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nen donde \\({\\mathbf{0}}\\) representa un matriz de ceros y la cadena tiene distribuci√≥n de probabilidad inicial \\(\\small{\\mathbb{P}(Y_0=a)=1}\\).\nEjemplo 2.2 (Modelo de Urnas). Considere una sucesi√≥n de ensayos independientes, cada uno de los cuales consiste en insertar una bola al azar en una de \\(\\small{k}\\) urnas. Decimos que el sistema \\(\\small{\\{Y_t : t = 0,1,\\ldots\\}}\\) est√° en estado \\(\\small{i}\\), si exactamente \\(\\small{i}\\) urnas est√°n ocupadas. Este sistema forma una cadena de Markov en el espacio de estados \\(\\small{\\Omega = \\{0,1,\\ldots, k\\}}\\) con probabilidades de transici√≥n\n\n\n\\[\\begin{equation}\np_{ij}=\\begin{cases}\n\\frac{i}{k}  \\quad\\quad  \\text{si } j=i\\\\\n\\frac{k-i}{k}\\quad \\text{ si } j=i+1\\\\\n0 \\quad \\quad \\text{en otro caso}\n\\end{cases}\n\\end{equation}\\]\n\npara \\(\\small{i=0,1,\\ldots,k}\\) y distribuci√≥n de probabilidad inicial \\(\\small{\\mathbb{P}(Y_0=0)=1}\\). La matriz de probabilidades de transici√≥n esta dada por: \n\n\\[\\begin{equation}\n\\boldsymbol{M}=\\begin{array}{cc} &\n\\begin{array}{ccccccc}\n\\end{array}\n\\\\\n\\begin{array}{ccc}\n0 \\\\\n1 \\\\\n\\\\\n\\vdots\\\\\ni\\\\\n\\vdots\\\\\nk-1\\\\\nk\n\\end{array}\n&\n\\left(\n\\begin{array}{ccccccc}\n0 & 1 & 0 &   &  &  &     \\\\\n0 & \\frac{1}{k} & \\frac{k-1}{k}  & 0 &  & \\boldsymbol{0} &      \\\\\n&  & \\ddots & \\ddots &   &   &      \\\\\n&  &        & \\frac{i}{k} & \\frac{k-i}{k} &   &       \\\\\n&   &   &  & \\ddots& \\ddots &    \\\\\n&   & \\boldsymbol{0} &   &   & \\frac{k-1}{k} & \\frac{1}{k}  \\\\\n&   &  &   &   & 0 & 1\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nSe pueden encontrar m√°s ejemplos de este tipo en Feller (1968) y Ross (2000). Por supuesto, tambi√©n habr√° muchos m√°s ejemplos de cadenas de Markov en secciones posteriores de este libro.\n\n\n\nPara una cadena de Markov no homog√©nea \\(\\small{\\{Y_t\\}}\\), las probabilidades de transici√≥n de \\(\\small{n}\\) pasos \\(\\small{\\mathbb{P}(Y_t= j \\mid Y_{t-n} = i) = p_{ij}^{(n)}(t)}\\) se pueden obtener a partir de las probabilidades de transici√≥n de un paso por una identidad importante conocida como Ecuaci√≥n de Chapman-Kolmogorov. Si \\(\\small{n = 2}\\), tenemos, para \\(\\small{t \\geq 2}\\),\n\n\n\\[\\begin{equation}\np_{ij}^{(2)}(t) = \\sum_{k\\in \\Omega}\\mathbb{P}(Y_{t-1}=k \\mid  Y_{t-2}=i)\\mathbb{P}(Y_{t}=j \\mid  Y_{t-1}=k)=\\sum_{k\\in \\Omega} p_{ik}(t-1)^{}p_{kj}^{}(t)\n\\end{equation}\\]\n\nque corresponde a sumar todos los posibles \\(\\small{k}\\) estados intermedios en la transici√≥n del estado \\(\\small{i}\\) al estado \\(\\small{j}\\).\nSi \\(\\small{\\{Y_t\\}}\\) es una cadena de Markov homog√©nea, entonces la ecuaci√≥n anterior (2.4) genera las probabilidades de transici√≥n de dos pasos \\(\\small{(n = 2)}\\)\n\n\n\\[\\begin{equation}\np_{ij}^{(2)} = \\sum_{ k \\in \\Omega}\\mathbb{P}(Y_{t-1}=k  \\mid  Y_{t-2}=i)\\mathbb{P}(Y_{t}=j \\mid  Y_{t-1}=k)=\\sum_{k\\in \\Omega} p_{ik}p_{kj}\n\\end{equation}\\]\n\nlas cuales son independientes de \\(\\small{t}\\). Por lo tanto, de la ecuaci√≥n (2.5), la matriz de probabilidades de transici√≥n de dos pasos \\(\\small{\\boldsymbol{M}^{(2)} = (p_{ij}^{(2)})}\\) satisface la identidad \\(\\small{\\boldsymbol{M}^{(2)}= \\boldsymbol{M}^2}\\). De manera analoga, para las probabilidades de transici√≥n de \\(\\small{n}\\) pasos de una cadena de Markov homog√©nea, la identidad de Chapman-Kolmogorov:\n\n\n\\[\\begin{equation}\np_{ij}^{(n)} = \\sum_{k \\in \\Omega} p_{ik}^{(s)}p_{kj}^{(n-s)}\n\\end{equation}\\]\n\nse mantiene para cada paso intermedio \\(\\small{s = 1,\\ldots, n -1}\\). Se deduce de las ecuaciones. (2.5) y arterior-(2.6) que\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}^{(n)}= \\boldsymbol{M}^{(s)}\\boldsymbol{M}^{(n-s)}=\\boldsymbol{M}^{n}\n\\end{equation}\\]\n\nPara una cadena de Markov homog√©nea \\(\\small{\\{Y_t\\}}\\), y cualquier subconjunto \\(\\small{{C}}\\) del espacio de estados \\(\\small{\\Omega}\\), se deduce de la Ec.(2.7) que la probabilidad condicional del sistema \\(\\small{Y_n}\\) resida en \\(\\small{{C}}\\) en el √≠ndice de tiempo \\(\\small{n}\\), dada la distribuci√≥n de probabilidad inicial \\(\\small{\\boldsymbol{\\mathbf{\\xi}}_0 = \\big(\\mathbb{P}(Y_0 = 1), \\cdots,P(Y_0 = m)\\big)}\\) es:\n\n\n\\[\\begin{equation}\n\\mathbb{P}(Y_n \\in {C} \\mid \\boldsymbol{\\mathbf{\\xi}}_0)=\\boldsymbol{\\mathbf{\\xi}}_0 \\boldsymbol{M}^{n}\\boldsymbol{\\mathbf{U}'}({C})\n\\end{equation}\\]\n\nen donde \\(\\small{\\boldsymbol{\\mathbf{U}'}({C})}\\) es la traspuesta de \\(\\small{\\boldsymbol{\\mathbf{U}}({C})}\\), con \\(\\small{\\boldsymbol{\\mathbf{U}}( {C})=\\displaystyle\\sum_{i \\in C}e_i}\\) y \\(\\small{\\boldsymbol{e}_i=(0,\\ldots,1,\\ldots,0)_{1\\times m}}\\) es un vector can√≥nico con un \\(\\small{1}\\) correspondiente al \\(i\\)-√©simo estado y cero en los otros. De manera m√°s general, si \\(\\small{\\{Y_t\\}}\\) es una cadena de Markov no homog√©nea, se puede demostrar (ver, Feller 1968) que la probabilidad condicional de \\(\\small{Y_n \\in {C} }\\) dado \\(\\small{\\boldsymbol{\\xi}_0}\\) se puede expresar simplemente como\n\n\n\\[\\begin{equation}\n\\mathbb{P}(Y_n \\in  {C} \\mid \\boldsymbol{\\mathbf{\\xi}}_0)=\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\prod_{t=1}^{n}\\boldsymbol{M_t}\\Big)\\boldsymbol{\\mathbf{U}'}({C})\n\\end{equation}\\]\n\nLas ecuaciones (2.8) y (2.9) son dos herramientas indispensables para evaluar las probabilidades de diversos eventos asociados con cadenas de Markov homog√©neas y no homog√©neas, respectivamente.\n\n\n\nCon el fin de ampliar las posibles aplicaciones, es √∫til considerar una extensi√≥n simple de la metodolog√≠a anterior a cadenas de Markov definidas en espacios de estados de diferentes tama√±os. Sea \\(\\small\\{Y_t\\}\\) una sucesi√≥n de variables aleatorias definidas en una familia de espacios de estados \\(\\small{\\{\\Omega_t\\}}\\), respectivamente. La sucesi√≥n \\(\\small{\\{Y_t\\}}\\) se denomina cadena de Markov con estructura de √°rbol si \\(\\small{\\{Y_t\\}}\\) es una cadena de Markov con matrices de transici√≥n\n\n\n\\[\\begin{equation}\n\\boldsymbol{M_t}=(p_{ij}(t)), \\quad \\text{para todo } t=1,2,\\ldots,\n\\end{equation}\\]\n\nen donde, para cada \\(\\small{i \\in {\\Omega}_{t-1}}\\) y \\(\\small{j \\in {\\Omega}_{t}}\\)\n\n\n\\[\\begin{equation}\np_{ij}(t)=\\mathbb{P}(Y_t=j\\mid Y_{t-1}=i).\n\\end{equation}\\]\n\nObs√©rvese que los espacios de estados de la colecci√≥n \\(\\small{\\{\\Omega_t\\}}\\) pueden tener tama√±os diferentes, las matrices de transici√≥n \\(\\small{\\boldsymbol{M_t}}\\) pueden ser rectangulares en lugar de cuadradas; es decir, \\(\\small{\\boldsymbol{M_t},\\, t = 1, 2, \\ldots,}\\) son matrices de orden \\(\\small{\\text{card}(\\Omega_{t-1}) \\times \\text{card}(\\Omega_{t})}\\), donde \\(\\small{\\text{card}(\\Omega)}\\) representa el n√∫mero cardinal del espacio de estados \\(\\small{\\Omega}\\). La sucesi√≥n de matrices de probabilidad de transici√≥n \\(\\small{\\{\\boldsymbol{M_t}}\\}\\) sigue determinando la cadena de Markov \\(\\small\\{{Y_t}\\}\\) estructurada en √°rbol, y la ecuaci√≥n de Chapman-Kolmogorov sigue siendo aplicable.\nPara cualquier subconjunto \\(\\small{ {C}\\subseteq \\Omega_n}\\), la probabilidad condicional de \\(\\small{Y_n\\in {C}}\\) dada la distribuci√≥n de probabilidad inicial \\(\\small{\\boldsymbol{\\xi}_0}\\), puede calcularse v√≠a:\n\n\n\\[\\begin{equation}\n\\mathbb{P}(Y_n \\in {C} \\mid \\boldsymbol{\\mathbf{\\xi}}_0)=\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\prod_{t=1}^{n}\\boldsymbol{M_t}\\Big)\\boldsymbol{\\mathbf{U}'}_{n}({C})\n\\end{equation}\\]\n\nsiendo \\(\\small{\\boldsymbol{\\mathbf{U}}_{n}({C})=\\displaystyle\\sum_{i \\in C}\\boldsymbol{e}_i}\\) y \\(\\small{\\boldsymbol{e}_i=(0,\\ldots,1,\\ldots,0)_{1\\times card(\\Omega_n)}}\\) es un vector unitario de tama√±o \\(\\small{1\\times card(\\Omega_n)}\\) con un \\(\\small{1}\\) asociado al \\(i\\)-√©simo estado. Si todo los espacios de estados son iguales \\(\\small{(\\Omega_1=\\cdots=\\Omega_n)}\\),entonces la Eq. (2.10) se reduce a Eq. (2.9).\n\n\n\nTradicionalmente, dentro de una sucesi√≥n de ensayos Bernoulli (i.i.d. √©xito-fracaso), una racha denota una sucesi√≥n de √©xitos o fracasos consecutivos. Por ejemplo una racha de √©xitos de tama√±o 4 implica el patr√≥n \\(\\small{SSSS}\\). Varias de las estad√≠sticas de rachas que se utilizan a menudo en estad√≠stica y probabilidad aplicada para una sucesi√≥n de \\(n\\) ensayos Bernoulli son:\n(i) \\(\\small{N_{n,k}}\\) el n√∫mero rachas de \\(\\small{k}\\) √©xitos consecutivos no solapados, en el sentido del conteo de Feller (1968);\n(ii) \\(\\small{M_{n,k}}\\) el n√∫mero de rachas de \\(\\small{k}\\) √©xitos consecutivos solapados;\n(iii) \\(\\small{E_{n,k}}\\) el n√∫mero de rachas de √©xitos de tama√±o exactamente igual a \\(\\small{k}\\), en el sentido del conteo de Mood (1940);\n(iv) \\(\\small{G_{n,k}}\\) el n√∫mero de rachas de √©xitos de tama√±o mayor o igual que \\(\\small{k}\\) ;\n(v) \\(\\small{L_{n}(S)}\\) el tama√±o de la racha de √©xitos m√°s larga.\nQuiz√°s la forma m√°s sencilla de comprender las definiciones dadas de estas estad√≠sticas de rachas y el procedimiento de conteo de solapado/no solapado, sea mediante el siguiente ejemplo. Supongamos que hay \\(\\small{n = 10}\\) ensayos de Bernoulli, con realizaci√≥n \\(\\small{SSFSSSSFFF}\\). Entonces \\(\\small{L_{10}(S) = 4}\\), y para \\(\\small{k = 2}\\), tenemos \\(\\small{N_{10,2} = 3, M_{10,2} = 4, E_{10,2} = 1}\\) y \\(\\small{G_{10,2} = 2}\\)\nDe las definiciones de estas estad√≠sticas de rachas, se deduce por inspecci√≥n que las siguientes relaciones siempre son verdaderas:\n\n\n\\[\\begin{equation}\nE_{n,k}\\leq G_{n,k} \\leq N_{n,k} \\leq M_{n,k}\\\\\nE_{n,k} = G_{n,k} - G_{n,k+1}\\\\\nL_n(S)&lt;k\\quad\\text{si y solo si }N_{n,k}=0\n\\end{equation}\\]\n\nPara ampliar las definiciones de rachas, consideremos una sucesi√≥n de \\(\\small{n}\\) ensayos multiestados \\(\\small{\\{{X}\\}_{t=1}^{n}}\\), cada una de las cuales tiene \\(\\small{m \\geq 2}\\) estados o s√≠mbolos como posibles resultados. Estos s√≠mbolos se denotan por \\(\\small{b_1,b_2,\\ldots,b_m}\\) y ocurren con probabilidades \\(\\small{p_1,p_2,\\ldots,p_m}\\), respectivamente. A continuaci√≥n, definimos tres tipos de patrones generales: un patr√≥n simple, un patr√≥n compuesto y un patr√≥n en serie.\nDefinici√≥n 2.3 Decimos que \\(\\small{\\Lambda}\\) es un patron simple, si esta conformado por una determinada serie de \\(\\small{k}\\) s√≠mbolos, i.e, \\(\\small{\\Lambda=b_{i_1}b_{i_2}\\cdots b_{i_k}}\\) con \\(\\small{i_j\\in \\{1,2,\\ldots,m\\}}\\), para todo \\(\\small{j=1,\\dots,k}\\). La longitud del patr√≥n es fija y los s√≠mbolos en el patr√≥n puede repetirse.\nLas rachas de √©xito y fracaso de tama√±o \\(\\small{k}\\) son por tanto patrones simples seg√∫n esta definici√≥n, y de hecho cualquier sucesi√≥n de √©xitos y fracasos de longitud fija, digamos \\(\\small{\\Lambda =SSFSF}\\), puede considerarse un patr√≥n simple dentro de una sucesi√≥n de de \\(\\small{n}\\) ensayos de dos estados \\(\\small{(m = 2)}\\).\nAhora, sean \\(\\small{\\Lambda_1}\\) y \\(\\small{\\Lambda_2}\\) dos patrones simples de longitudes/tama√±os \\(\\small{k_1}\\) y \\(\\small{k_2}\\) , respectivamente. Decimos que \\(\\small{\\Lambda_1}\\) y \\(\\small{\\Lambda_2}\\) son distintos si ni \\(\\small{\\Lambda_1}\\) incluye a \\(\\small{\\Lambda_2}\\) ni \\(\\small{\\Lambda_2}\\) incluye a \\(\\small{\\Lambda_1}\\). Definimos \\(\\small{\\Lambda_1 \\cup\\Lambda_2}\\) como la ocurrencia de uno de los dos patr√≥n \\(\\small{\\Lambda_1}\\) o \\(\\small{\\Lambda_2}\\) , y definimos \\(\\small{\\Lambda_1 \\ast\\Lambda_2}\\) como la ocurrencia de patr√≥n \\(\\small{\\Lambda_1}\\) seguido del patr√≥n \\(\\small{\\Lambda_1}\\) (quiz√°s con una separaci√≥n entre ellos).\nDefinici√≥n 2.4 Decimos que \\(\\small{\\Lambda}\\) es un patr√≥n compuesto si es la uni√≥n de \\(\\small{1 &lt; l &lt;\\infty}\\) patrones simples distintos solapados/no solapados, es decir, \\(\\small{\\Lambda=\\displaystyle\\bigcup_{i=1}^{l}\\Lambda_i}\\).\nDefinici√≥n 2.5 Decimos \\(\\small{\\Lambda}\\) es un patr√≥n en serie si \\(\\small{\\Lambda}\\) est√° compuesto por una sucesi√≥n ordenada de \\(\\small{1 &lt; l &lt;\\infty}\\) patrones simples distintos no superpuestos \\(\\small{\\Lambda_i}\\), es decir, \\(\\small{\\Lambda=\\Lambda_1 \\ast\\Lambda_2\\ast\\cdots\\Lambda_l}\\)\nA lo largo de este libro, la variable aleatoria \\(\\small{X_n(\\Lambda)}\\) representa el n√∫mero de ocurrencias del patr√≥n \\(\\small{\\Lambda}\\) en una sucesi√≥n de \\(\\small{n}\\) ensayos multiestado, utilizando el recuento con solapamiento o sin solapamiento. Para aclarar las tres definiciones de patrones y los dos m√©todos de recuento para los ensayos multiestado, presentamos el siguiente ejemplo.\nEjemplo 2.3 Sea \\(\\small{\\{X_t\\}_{t=1}^{16}}\\) una sucesi√≥n de diecis√©is ensayos de un proceso de cuatro estados, en donde los resultados posibles para cada ensayo son \\(\\small{A, G, C}\\) y \\(\\small{T}\\). Sea \\(\\small{\\Lambda_1=AGAG}\\) y \\(\\small{\\Lambda_2=AGT}\\) dos patrones simples distintos, \\(\\small{\\Lambda=\\Lambda_1 \\cup\\Lambda_2}\\) un patr√≥n compuesto y \\(\\small{\\Lambda^{\\ast}=\\Lambda_1 \\ast\\Lambda_2}\\) un patron en serie. Supongamos que la realizaci√≥n de esta sucesi√≥n de diecis√©is ensayos es \\(\\small{TAGAGAGTCAGAGTCC}\\), entonces:\n(i) \\(\\small{X_{16}(\\Lambda_1)}\\) es \\(\\small{3}\\) con conteo solapado y es \\(\\small{2}\\) con conteo no solapado,\n(ii) \\(\\small{X_{16}(\\Lambda)}\\) es \\(\\small{5}\\) con conteo solapado y es \\(\\small{3}\\) con conteo no solapado,\n(iii) \\(\\small{X_{16}(\\Lambda^{\\ast})}\\) es igual a \\(\\small{1}\\).\n(iv) \\(\\small{X_{16}(\\Lambda_2)}\\) es \\(\\small{2}\\).\nLas definiciones anteriores de rachas y patrones en una sucesi√≥n de ensayos de m√∫ltiples estados tambi√©n se pueden extender a permutaciones aleatorias \\(\\small{\\{\\pi : \\pi=(\\pi (1),\\ldots,\\pi(n)) \\}}\\) de \\(\\small{n}\\) enteros \\(\\small{\\{1, 2, \\ldots, n\\}}\\). Por ejemplo, el n√∫mero Euleriano \\(\\small{E(\\pi, n)}\\), el n√∫mero de aumentos en una permutaci√≥n aleatoria \\(\\small{\\pi}\\) (ver Carlitz 1964, Tanny 1973 y Worpitzky 1883), podr√≠a verse como una variable aleatoria \\(\\small{X_n(\\Lambda)}\\) con el patr√≥n \\(\\small{\\Lambda}\\) siendo un aumento. Matem√°ticamente, el n√∫mero de Euler se puede definir como\n\n\n\\[\\begin{equation}\nE(\\pi,n)=X_n(\\Lambda)=\\displaystyle \\sum_{i=0}^{n-1}I(\\pi,i),\n\\end{equation}\\]\n\nen donde \n\n\\[\\begin{equation}\nI(\\pi,i)=\\begin{cases}\n1 \\quad \\text{si }\\pi(i)&lt;\\pi(i+1) \\\\\n0 \\quad \\text{en otro caso }\n\\end{cases}\n\\end{equation}\\]\n\n\\[I(\\pi,i)=\\begin{cases}\n1 \\quad \\text{si }\\pi(i)&lt;\\pi(i+1) \\\\\n0 \\quad \\text{en otro caso,}\n\\end{cases}\\]\npara \\(\\small{i=1,\\ldots,n-1}\\), con \\(\\small{I(\\pi,i)=1}\\) por convenci√≥n (la brecha inicial que precede a la primera permutaci√≥n siempre se considera un aumento). Por ejemplo, el n√∫mero de aumentos \\(\\small{E(\\pi, 9)}\\) en la permutaci√≥n aleatoria \\(\\small{\\pi = (321459768)}\\) de 9 n√∫meros enteros son 5.\nEn vista de las definiciones y ejemplos anteriores, uno deber√≠a esperar que la distribuci√≥n exacta de la variable aleatoria \\(\\small{X_n(\\Lambda)}\\) dependa en gran medida de tres factores importantes:\n(a) la estructura del patr√≥n \\(\\small{\\Lambda}\\) ,\n (b) la estructura de la sucesi√≥n \\(\\small{\\{{X}\\}_{t=1}^{n}}\\) de \\(n\\) ensayos (o permutaciones aleatorias),\n (c) el procedimiento de conteo (conteo superpuesto o no superpuesto).\nDebido a estos factores, la determinaci√≥n anal√≠tica de distribuciones exactas mediante enfoques tradicionales como la combinatoria puede ser bastante desafiante y generalmente compleja, involucrando identidades especiales y un √°lgebra extensa. En consecuencia, las distribuciones exactas de muchas estad√≠sticas utilizadas en aplicaciones pr√°cticas nunca se han estudiado utilizando tales m√©todos, especialmente cuando los ensayos subyacentes no son i.i.d. (por ejemplo, Markov-dependientes).\nEn la siguiente subsecci√≥n, describimos una t√©cnica que permite obtener una representaci√≥n matricial compacta para la distribuci√≥n exacta de una manera relativamente simple y universal al incorporar la variable aleatoria \\(\\small{X_n(\\Lambda)}\\) en una cadena de Markov finita; la expresi√≥n resultante tambi√©n es muy adecuada para un an√°lisis m√°s detallado de propiedades estad√≠sticas, para el desarrollo de aproximaciones de grandes desviaciones y para una implementaci√≥n num√©rica eficiente para el c√°lculo de probabilidades exactas.\n\n\n\nLa t√©cnica de Incrustaci√≥n de Cadenas de Markov Finitas (ICMF) para encontrar la distribuci√≥n de la variable aleatoria \\(\\small{X_n(\\Lambda)}\\) tiene sus or√≠genes en una serie de art√≠culos de Fu (1985, 1986), Fu y Hu (1987), Chao y Fu (1989, 1991), y Fu y Lou (1991). El t√©rmino ‚ÄúCadena de Markov Finita Incrustable‚Äù para describir una variable aleatoria fue introducido formalmente por Fu y Koutras (1994).\nSea \\(\\small{\\Gamma_n=\\{0,1\\ldots,n\\}}\\) un conjunto de indices, y \\(\\small{\\Omega=\\{a_1,a_2,\\ldots,a_m\\}}\\) un espacio de estados finito.\nDefinicion 2.6 La variable aleatoria no negativa de valores enteros \\(\\small{X_n(\\Lambda)}\\), es una cadena de Markov finita incrustable si:\n(a). Existe una cadena de Markov finita \\(\\small{\\{Y_t:t\\in \\Gamma\\}}\\) definida sobre un espacio de estados \\(\\small{\\Omega}\\) finito, con vector de probabilidades inicial \\(\\small{\\boldsymbol{\\xi}_0}\\).\n(b). Existe una partici√≥n finita \\(\\small{\\{C_x:x=0,1,\\ldots,l_n\\}}\\) sobre el espacio de estado \\(\\small{\\Omega}\\).\n(c). Para todo \\(\\small{x=0,1,\\ldots,l_m}\\) tenemos: \\[\\small{\\mathbb{P}\\{X_n(\\Lambda)=x\\}=\\mathbb{P}\\{Y_n\\in C_x \\mid \\boldsymbol{\\xi}_0\\}.}\\] Sea \\(\\small{\\{\\boldsymbol{M}_t\\}_{t=1}^{n}}\\) una sucesi√≥n de matrices de probabilidades de transici√≥n de orden \\(\\small{m\\times m}\\) de una cadena finita de Markov \\(\\small{\\{Y_t\\}}\\) definida sobre un espacio de estados \\(\\small{\\Omega}\\) con distribuci√≥n de probablidad inicial \\(\\small{\\boldsymbol{\\xi}_0=\\big(\\mathbb{P}\\{Y_0=a_1\\},\\mathbb{P}\\{Y_0=a_2\\},\\ldots,\\mathbb{P}\\{Y_0=a_m\\}\\big)}\\)\nTeorema 2.1 Si \\(\\small{X_n(\\Lambda)}\\) es una cadena finita de Markov incrustable, entoces\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\{ X_n(\\Lambda)=x\\}=\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\prod_{t=1}^{n}\\boldsymbol{M}_t\\Big)\\boldsymbol{\\mathbf{U}'}({C_x})\n\\end{equation}\\]\n\nsiendo \\(\\small{\\boldsymbol{\\mathbf{U}}({C_x})=\\displaystyle\\sum_{r: a_r\\in C_x}\\boldsymbol{e}_r}\\) y \\(\\small{\\boldsymbol{e}_r=(0,\\ldots,1,\\ldots,0)_{1\\times m}}\\) es un vector unitario de tama√±o \\(\\small{1\\times m}\\) con un \\(\\small{1}\\) asociado al estado \\(\\small{a_r}\\) e \\(\\small{\\boldsymbol{\\mathbf{\\xi}}_0}\\) vector de probabilidades iniciales, y \\(\\small{\\boldsymbol{M}_t\\,,\\,\\,t=1,\\dots,n}\\) son las matrices de probabilidades de transici√≥n de la cadena de Markov incrustada.\nPrueba: Dado que \\(\\small{X_n(\\Lambda)}\\) es una cadena de Markov finita incrustable, se deduce de Definici√≥n 2.6(a) de que existe una cadena de Markov finita \\(\\small{\\{Y_t : t\\in \\Gamma_n \\}}\\) con probabilidades iniciales \\(\\small{\\boldsymbol{\\mathbf{\\xi}}_0}\\). Luego por la ecuaci√≥n de Chapman-Kolmogorov descrita en Secci√≥n 2.2, para cada \\(\\small{a_r\\in \\Omega}\\), tenemos\n\n\n\\[\\begin{equation}\n\\mathbb{P}(Y_n =a_r \\mid \\boldsymbol{\\mathbf{\\xi}}_0)=\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\prod_{t=1}^{n}\\boldsymbol{M}_t\\Big)\\boldsymbol{e_r'}\n\\end{equation}\\]\n\nAdem√°s, de las Definiciones 2.6(b) y (c) se deduce que, para cada \\(\\small{x =0,1\\ldots,l_n}\\),\n\n\n\\[\\begin{equation}\n\\begin{split}\n\\mathbb{P}\\{ X_n(\\Lambda)=x\\} & =  \\mathbb{P}(Y_n \\in C_x \\mid \\boldsymbol{\\mathbf{\\xi}}_0) \\\\\n& = \\sum_{a_r\\in C_x}\\mathbb{P}\\{Y_n=a_r\\mid \\boldsymbol{\\mathbf{\\xi}_0}\\}\\\\\n& = \\sum_{a_r\\in C_x} \\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\prod_{t=1}^{n}\\boldsymbol{M}_t\\Big)\\boldsymbol{e_r'}\\\\\n& = \\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\prod_{t=1}^{n}\\boldsymbol{M}_t\\Big)\\boldsymbol{\\mathbf{U}'}( {C_x})\\quad \\quad \\quad \\quad \\quad \\Box\n\\end{split}\n\\end{equation} \\Box\\]\n\nEl \\(\\small{k-}√©simo\\) momento \\(\\small{\\mathbb{E}\\{X_n^k(\\Lambda)\\},\\,\\,k=1,2,\\ldots,}\\) puede expresarse como:\n\n\n\\[\\begin{equation}\n\\mathbb{E}\\{X_n^k(\\Lambda)\\}=\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\prod_{t=1}^{n}\\boldsymbol{M}_t\\Big)\\boldsymbol{{V}_k'}\n\\end{equation}\\]\n\nen donde\n\n\n\\[\\begin{equation}\n\\boldsymbol{{V}_k'}=\\sum_{x=0}^{l_n}x^{k}\\boldsymbol{U}(\\mathbf{C_x})\n\\end{equation}\\]\n\nDe manera √°naloga la funci√≥n generadora de probabilidad de la variable aleatoria \\(\\small{X_n(\\Lambda)}\\) puede escribirse como:\n\n\n\\[\\begin{equation}\n\\psi(s)= \\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\prod_{t=1}^{n}\\boldsymbol{M}_t\\Big)\\boldsymbol{W'}(s)\n\\end{equation}\\]\n\nen donde \n\n\\[\\begin{equation}\n\\boldsymbol{W}(s)=\\sum_{x=0}^{l_n}s^{x}\\boldsymbol{U}(\\mathbf{C_x})\n\\end{equation}\\]\n\nLos funciones generadoras de probabilidad y de momentos se discutir√°n dentro del contexto de aplicaciones espec√≠ficas en secciones posteriores.\nEjemplo 2.4 (N√∫mero de parejas de resultados sucesivos id√©nticos). Sea \\(\\small{\\{X_t:t = 0,1,\\ldots, n\\}}\\) una sucesi√≥n de \\(\\small{n}\\) ensayos Markov-dependientes homog√©neos con \\(\\small{m}\\) estados y matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{A}_{m\\times m} = \\big(P_{ij}\\big)}\\) y una distribuci√≥n de probabilidad inicial \\(\\small{\\boldsymbol{\\xi}_0=\\big(\\mathbb{P}\\{X_0=1\\},\\mathbb{P}\\{X_0=2\\},\\ldots,\\mathbb{P}\\{X_0=m\\}\\big)=(1/m,1/m,\\ldots,1/m)}\\). Definiendo una sucesi√≥n de funciones indicadoras\n\n\n\\[\\begin{equation}\nI_i=\\begin{cases}\n1 \\quad \\text{si }X_t=X_{t-1}\\\\\n0 \\quad \\text{en otro caso}\n\\end{cases}\n\\end{equation}\\]\n\npara todo \\(\\small{t=1,\\ldots,n}\\)\nEn este ejemplo, nos interesa el n√∫mero de veces que un resultado particular (uno de \\(\\small{m}\\) resultados posibles) en un ensayo determinado se repite en el ensayo inmediatamente siguiente. En t√©rminos matem√°ticos, definimos el patr√≥n \\(\\small{\\Lambda}\\) para denotar dicho resultado repetido, un patr√≥n que est√° presente en el √≠ndice de tiempo \\(\\small{1 \\leq t \\leq n}\\) si \\(\\small{X_{t-1} = X_t}\\) o, de manera equivalente en t√©rminos de la funci√≥n indicadora anterior, si \\(\\small{I_t = 1}\\). La estad√≠stica de rachas:\n\n\n\\[\\begin{equation}\nX_n(\\Lambda)= \\sum_{t=1}^{n}I_t\n\\end{equation}\\]\n\ncorresponde al n√∫mero de veces que ocurri√≥ el patr√≥n \\(\\small{\\Lambda}\\) en la sucesi√≥n \\(\\small{\\{X\\}_{t=0}^{n}}\\) de \\(\\small{n}\\) ensayos Markov-dependientes con \\(\\small{m}\\) estados. En el sector sanitario, por ejemplo, la estad√≠stica \\(\\small{X_n(\\Lambda)/n}\\) se conoce como \\(SECON\\) y forma la medida principal de continuidad secuencial en una serie de \\(\\small{n}\\) visitas de pacientes a \\(\\small{m}\\) posibles proveedores de atenci√≥n sanitaria ( Steinwachs 1979).\nUna dificultad aqu√≠ es que las variables aleatorias \\(\\small{\\{I_t\\}}\\) no son independientes y no conforman una cadena de Markov, incluso si la sucesi√≥n \\(\\small{\\{X\\}_{t=0}^{n}}\\) se extrajera de ensayos i.i.d. de \\(\\small{m}\\) estados. De hecho, se puede demostrar que las variables aleatorias \\(\\small{\\{I_t\\}}\\) son dependientes y est√°n correlacionadas positivamente probando que \\(\\small{Cov(I_i, I_j) &gt; 0}\\) para todo \\(\\small{i}\\) y \\(\\small{j}\\), con \\(\\small{Cov(I_i, I_j) \\rightarrow 0}\\) cuando \\(\\small{\\mid i-j \\mid\\rightarrow 0}\\). Sin embargo, como se indica a continuaci√≥n, la distribuci√≥n exacta a√∫n se puede obtener f√°cilmente utilizando la t√©cnica de incrustaci√≥n de cadenas de Markov finitas.\nPrimero, descomponemos la matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{A}}\\) en dos matrices \\(\\small{\\boldsymbol{G}}\\) y \\(\\small{\\boldsymbol{D}}\\), donde la matriz \\(\\small{\\boldsymbol{D}}\\) contiene s√≥lo los elementos diagonales de \\(\\small{\\boldsymbol{A}}\\); es decir:\n\n\n\\[\\begin{equation}\n\\boldsymbol{A}_{m\\times m}=\\boldsymbol{G}_{m\\times m}+\\boldsymbol{D}_{m\\times m}\n\\end{equation}\\]\n\nen donde: \n\n\\[\\begin{equation}\n\\boldsymbol{G}_{m\\times m}=\n\\begin{pmatrix}\n0 & p_{ij} & \\cdots \\\\\n  & \\ddots &        \\\\\n\\cdots & p_{ij} & 0\n\\end{pmatrix}\n\\quad \\text{y} \\quad\n\n\\boldsymbol{D}_{m\\times m}=\n\\begin{pmatrix}\np_{11} &  & \\boldsymbol{0} \\\\\n  & \\ddots &        \\\\\n\\boldsymbol{0} &   & p_{mm}\n\\end{pmatrix}\n\\end{equation}\\]\n\nSea \\(\\small{\\Omega=\\{(u,v): u = 0,\\ldots,n, \\text{ y }v = 1,2,\\ldots, m\\}}\\) el espacio de estados que contiene un total de \\(\\small{(n+1)m}\\) estados. Dado \\(\\small{n}\\), se define una cadena de Markov homog√©nea y finita \\(\\small{\\{Y_t: t\\in \\Gamma\\}}\\) en el espacio de estados \\(\\small{\\Omega}\\) como\n\n\n\\[\\begin{equation}\nY_t=\\begin{cases}\n\\Big(\\displaystyle\\sum_{i=1}^{t}I_i, X_t \\Big) \\quad \\text{si } 1 \\leq t \\leq n\\\\\n\\big(0,X_0\\big) \\quad t=0\n\\end{cases}\n\\end{equation}\\]\n\ncon matriz de probabilidades de transici√≥n:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\\begin{pmatrix}\n\\boldsymbol{G} & \\boldsymbol{D} & \\boldsymbol{O} & \\cdots & \\boldsymbol{O}\\\\\n\\boldsymbol{O} & \\boldsymbol{G} & \\boldsymbol{D} & \\cdots & \\boldsymbol{O} \\\\\n\\vdots & \\ddots & \\ddots & \\ddots & \\vdots \\\\\n\\boldsymbol{O} & \\cdots & \\cdots & \\boldsymbol{G}& \\boldsymbol{D}\\\\\n\\boldsymbol{O} & \\boldsymbol{O} & \\cdots & \\boldsymbol{O}& \\boldsymbol{I}\\\\\n\\end{pmatrix}\n\\end{equation}\\]\n\ndonde \\(\\small{\\boldsymbol{M}}\\) es una matriz \\(\\small{(n + 1)m \\times (n + 1)m}\\), \\(\\small{\\boldsymbol{O}}\\) representa la matriz cero \\(\\small{m\\times m}\\) e \\(\\small{\\boldsymbol{I}}\\) es la matriz identidad \\(\\small{m\\times m}\\). Los estados en \\(\\small{\\boldsymbol{M}}\\) est√°n ordenados en orden lexicogr√°fico (diccionario). Por √∫ltimo, defininiendo la partici√≥n \\(\\small{\\{C_x: x=0,1,2,\\ldots,n\\}}\\) en el espacio de estados \\(\\small{\\boldsymbol{\\Omega}}\\) como\n\n\n\\[\\begin{equation}\nC_x=\\{(x,v): v=1,2,\\ldots,m\\}\n\\end{equation}\\]\n\nDadas las definiciones anteriores para la cadena de Markov \\(\\small\\{Y_t\\}\\), la variable aleatoria \\(\\small{X_n(\\Lambda)}\\) es, seg√∫n la Definici√≥n 2.6, una cadena de Markov finita incrustable y su distribuci√≥n exacta se desprende del Teorema 2.1: para \\(\\small{0 \\leq x \\leq n}\\),\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\{X_n(\\Lambda)=x\\}=\\boldsymbol{\\xi_0}\\begin{pmatrix}\n\\boldsymbol{G} & \\boldsymbol{D} & \\boldsymbol{O} & \\cdots & \\boldsymbol{O}\\\\\n\\boldsymbol{O} & \\boldsymbol{G} & \\boldsymbol{D} & \\cdots & \\boldsymbol{O} \\\\\n\\vdots & \\ddots & \\ddots & \\ddots & \\vdots \\\\\n\\boldsymbol{O} & \\cdots & \\cdots & \\boldsymbol{G}& \\boldsymbol{D}\\\\\n\\boldsymbol{O} & \\boldsymbol{O} & \\cdots & \\boldsymbol{O}& \\boldsymbol{I}\\\\\n\\end{pmatrix}^{n}\\boldsymbol{U'}(C_x)\n\\end{equation}\\]\n\ndonde \\(\\small{\\boldsymbol{\\xi_0}(\\pi_0,0,\\ldots,0)_{(n+1)\\times m}}\\) es la distribuci√≥n inicial del vector de estado \\(\\small{Y_0}\\), y \\(\\small{\\boldsymbol{U'}(C_x): (0,\\ldots, 0, \\underbrace{1, 1, ..., 1}_{C_x}, 0,\\ldots,0)}\\) es un vector de fila \\(\\small{1 \\times(n+1)m}\\) con \\(\\small{1}\\) en las coordenadas asociadas con los estados en \\(\\small{C_x}\\) y cero en otros posiciones. En el Cap√≠tulo 7 se dar√°n m√°s detalles y un ejemplo num√©rico de este problema.\nKoutras y Alexandrou (1995) introdujeron la noci√≥n de variables incrustables en cadenas finitas de Markov de tipo binomial (MVBS), y muchas estad√≠sticas comunes para rachas y patrones caen en esta categor√≠a especial. Sea la partici√≥n \\(\\small{ \\{C_x\\}=\\{[(x, v): v=1,...,r], \\text{ para } x = 0, 1,\\ldots, l_n\\}}\\), la partici√≥n del espacio de estados \\(\\small{\\Omega}\\).\nDefinici√≥n 2.7 Una variable aleatoria \\(\\small{X_n(\\Lambda)}\\) es una cadena de Markov finita incrustable de tipo binomial si:\n(i) \\(\\small{X_n(\\Lambda)}\\) es una cadena de Markov finita incrustable como en la Definici√≥n 2.6.\n(ii) \\(\\small{\\mathbb{P}\\{Y_t=(y,j) \\mid Y_{t-1} =(x,i)\\} \\equiv 0}\\) para todo \\(\\small{y\\neq x}\\) o \\(\\small{x + 1}\\).\nPara cualquier \\(\\small{MVB}\\), introduzca dos matrices de probabilidad de transici√≥n \\(\\small{r\\times r}\\):\n\n\n\\[\\begin{equation}\n\\boldsymbol{A_t}(x) = \\big(a_{ij}(t)\\big) = \\Big(\\mathbb{P}\\{Y_t = (x,j)\\mid Y_{t‚àí1} = (x, i)\\}\\Big)\n\\end{equation}\\]\n\ny \n\n\\[\\begin{equation}\n\\boldsymbol{B_t}(x) = \\big(b_{ij}(t)\\big) = \\Big(\\mathbb{P}\\{Y_t = (x+1,j)\\mid Y_{t‚àí1} = (x, i)\\}\\Big)\n\\end{equation}\\]\n\nPor tanto las matrices de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M_t}}\\) de la cadena de Markov incrustada tienen la siguiente forma: \n\n\\[\\begin{equation}\n\\boldsymbol{M}=\\begin{pmatrix}\n\n\\boldsymbol{A}_t(0) & \\boldsymbol{B}_t(0) & \\boldsymbol{O} & \\cdots &\\cdots  & \\boldsymbol{O} \\\\\n\n\\boldsymbol{O} &\\boldsymbol{A}_t(1) & \\boldsymbol{B}_t(1)  & \\boldsymbol{O} & \\cdots  & \\boldsymbol{O}\\\\\n\n\\vdots & \\boldsymbol{O} & \\ddots & \\ddots & \\ddots & \\vdots \\\\\n\\vdots & \\ddots & \\boldsymbol{O}& \\ddots & \\ddots & \\boldsymbol{O} \\\\\n\\vdots & \\cdots & \\cdots & \\boldsymbol{O}& \\boldsymbol{A}_t(l_n-1) & \\boldsymbol{B}_t(l_n-1) \\\\\n\\boldsymbol{O} & \\boldsymbol{O} & \\cdots &  \\boldsymbol{O}& \\boldsymbol{O} &  \\boldsymbol{A}_t(l_n) \\\\\n\\end{pmatrix}\n\\end{equation}\\]\n\npara \\(\\small{t = 1,\\ldots,n}\\), en donde los estados est√°n ordenados en orden lexicogr√°fico (diccionario). Hay muchas estad√≠sticas para rachas y patrones con matrices de transici√≥n que tienen esta forma, como, por ejemplo, las estad√≠sticas de rachas \\(\\small{N_{n,k},\\, M_{n,k}\\, \\text{y}\\, G_{n,k}}\\) introducidas en la Secci√≥n 2.4 (y estudiadas m√°s a fondo en el Cap√≠tulo 3).\nPara \\(\\small{MVB¬¥s}\\), se puede derivar una ecuaci√≥n recursiva eficiente para la distribuci√≥n de \\(\\small{X_n(\\Lambda)}\\), que aprovecha parcialmente la estructura de bandas de las matrices de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M}_t}\\). Sea el vector fila \\(\\small{\\boldsymbol{\\alpha}_t(x)=\\big(\\mathbb{P}\\{Y_t=(x,1)\\},\\ldots, \\mathbb{P}\\{Y_t=(x,1)\\}\\big)}\\) , para \\(\\small{t= 1,\\ldots, n}\\), de modo que la probabilidad de \\(\\small{X_n(\\Lambda)=x}\\) se puede representar como\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\{X_n(\\Lambda)=x \\mid \\boldsymbol{\\xi}_0\\}=\n\\boldsymbol{\\alpha}_n(x)\\boldsymbol{1}', \\, \\text{para toda}\\,\\,\nx=0,1,\\dots,l_n\n\\end{equation}\\]\n\ndonde \\(\\small{\\boldsymbol{1}'=(1,\\ldots,1)'}\\). Descomponga \\(\\small{\\boldsymbol{M}_t}\\) como \\(\\small{\\boldsymbol{M}_t=\\boldsymbol{K}_t+\\boldsymbol{H}_t}\\), donde \\(\\small{\\boldsymbol{K}_t}\\) es una matriz diagonal con componentes \\(\\small{\\boldsymbol{A}_t(x)}\\), para \\(\\small{x = 0,1,\\ldots,l_n}\\), y \\(\\small{\\boldsymbol{H}_t}\\) es una matriz diagonal superior con componentes \\(\\small{\\boldsymbol{B}_t(x)}\\), para \\(\\small{x = 0,1,\\ldots,l_{n-1}}\\). A partir de la multiplicaci√≥n hacia atr√°s, \\(\\small{\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\displaystyle\\prod_{j=1}^{t}\\boldsymbol{M}_j\\Big)=\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\displaystyle\\prod_{j=1}^{t-1}\\boldsymbol{M}_j\\Big)\\boldsymbol{M}_t=\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\displaystyle\\prod_{j=1}^{t-1}\\boldsymbol{M}_j\\Big)\\big(\\boldsymbol{K}_t+\\boldsymbol{H}_t\\big)}\\), puede demostrarse que se cumplen las siguientes ecuaciones recursivas:\n\n\n\\[\\begin{align*}\n\\boldsymbol{\\alpha_t}(0)&=\\boldsymbol{\\alpha_{t-1}}(0)\\boldsymbol{A_t}(0) \\\\\n\\boldsymbol{\\alpha_t}(X)&=\n\\boldsymbol{\\alpha_{t-1}}(x-1)\\boldsymbol{B_{t-1}}(t-1)+\\boldsymbol{\\alpha_{t-1}}(x)\\boldsymbol{A_t}(x),\\, x=1,\\ldots,l_n.\n\\end{align*}\\]\n\nLa ecuaci√≥n (2.17) proporciona un algoritmo eficiente para calcular las probabilidades \\(\\small{ \\mathbb{P}\\{X_n(\\Lambda)=x \\mid\\boldsymbol{\\xi}_0\\}=\\boldsymbol{\\alpha}_n(x)\\boldsymbol{1}', \\, \\text{para toda }\\, x=0,1,\\dots,l_n}\\), y esto es especialmente importante cuando la dimensi√≥n de las matrices de transici√≥n \\(\\small{\\boldsymbol{M_t}}\\) es grande y el esfuerzo computacional para calcular ingenuamente \\(\\small{\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\displaystyle\\prod_{t=1}^{n}\\boldsymbol{M}_t\\Big)\\boldsymbol{U'}(C_x)}\\) se vuelve prohibitivo. A partir de la multiplicaci√≥n hacia atr√°s, la t√©cnica de incrustaci√≥n de cadenas finitas de Markov a menudo proporciona una ecuaci√≥n recursiva en una forma similar a la ecuaci√≥n (2.17), una forma que, en general, no puede obtenerse tan f√°cilmente mediante los m√©todos combinatorios o de renovaci√≥n tradicionales.\n\n\n\nEn esta secci√≥n se derivan algunas expresiones √∫tiles para la probabilidad de entrar en un estado absorbente. Para mayor claridad de la exposici√≥n, nos centraremos en las cadenas de Markov homog√©neas, pero las ideas pueden generalizarse f√°cilmente a casos no homog√©neos.\nUn estado \\(\\small{\\alpha \\in \\Omega}\\) se llama estado absorbente si, una vez que el sistema entra en el estado \\(\\small{\\alpha}\\), nunca sale; es decir, \\(\\small{p_{\\alpha\\alpha}\\equiv 1}\\) (y \\(\\small{p_{\\alpha\\beta}\\equiv 0}\\) para cualquier \\(\\small{\\alpha\\neq\\beta}\\)). Sea \\(\\small{A=\\{\\alpha_1,\\ldots,\\alpha_k\\}}\\) el conjunto de todos los estados absorbentes de una cadena de Markov homog√©nea \\(\\small{\\{Y_t\\}}\\) con una matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M}}\\). Bajo una disposici√≥n apropiada del espacio de estados, la matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M}}\\) siempre se puede escribir de la siguiente forma:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\\left(\\begin{array}{c|c}\n\\boldsymbol{N}_{(m-k)\\times (m-k)} & \\boldsymbol{C}_{(m-k)\\times (m-k)}\\\\\n\\hline  \n\\boldsymbol{O}_{k\\times (m-k)} & \\boldsymbol{1}_{k \\times k}\n\\end{array}\\right)\n\\end{equation}\\]\n\ndonde \\(\\small{m}\\) y \\(\\small{k}\\) \\(\\small{(m&gt;k)}\\) son los n√∫meros de estados en \\(\\small{\\Omega}\\) y \\(\\small{A}\\), respectivamente. La matriz \\(\\small{\\boldsymbol{N}}\\) definida por la ecuaci√≥n. (2.18) se conoce como la submatriz de probabilidad de transici√≥n esencial de la cadena de Markov. Desempe√±a un papel importante en el estudio de las distribuciones exactas de variables aleatorias incrustables en cadenas de Markov, especialmente para las distribuciones asociadas de tiempos de espera.\nSea \\(\\small{\\boldsymbol{\\xi_{0}}=\\big(\\boldsymbol{\\xi}:\\boldsymbol{0}\\big)_{1\\times m}}\\) la distribuci√≥n inicial, donde \\(\\small{\\boldsymbol{\\xi}=(\\xi_1,\\ldots,\\xi_{m-k}), \\, \\boldsymbol{0}=(0,\\ldots,0)_{1\\times k}}\\) y \\(\\small{\\displaystyle{\\sum_{i=1}^{m-k}\\xi_i=1}}\\) y sea \\(\\small{\\big(\\boldsymbol{1:0}\\big)_{1\\times m}}\\) un vector fila, en donde \\(\\small{\\boldsymbol{1}=(1,\\ldots,1)_{1\\times (m-k)}}\\) La raz√≥n por la que suponemos que la distribuci√≥n inicial tiene la forma \\(\\small{\\big(\\boldsymbol{\\xi_0}:\\boldsymbol{0}\\big)}\\) es estrictamente por razones pr√°cticas, ya que la mayor√≠a de los sistemas siempre comienzan en un estado no absorbente.\nTeorema 2.2 Dada una matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M}}\\) de una cadena de Markov homog√©nea \\(\\small{\\{Y_t\\}}\\) en la forma de la ecuaci√≥n (2.18), la probabilidad para el √≠ndice de tiempo \\(\\small{n}\\) cuando el sistema ingresa por primera vez al conjunto de estados absorbentes puede ser obtenida como:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(Y_n\\in A,Y_{n-1}\\notin A,\\ldots,  Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)=\\boldsymbol{\\xi N}^{n-1}\\boldsymbol{(I-N)1'}\n\\end{equation}\\]\n\nDemostraci√≥n: Dado que \\(\\small{\\boldsymbol{M}}\\) tiene la forma de la Equaci√≥n 2.18, se sigue que:\n\n\n\\[\\begin{equation}\n\\mathbf{M}^{n-1}=\\left(\\begin{array}{c|c}\n\\boldsymbol{N}^{n-1} & \\boldsymbol{K}_{n-1}\\\\\n\\hline  \n\\boldsymbol{O} & \\boldsymbol{I}\n\\end{array}\\right)\n\\end{equation}\\]\n\nen donde \\(\\small{\\boldsymbol{K}_{n-1}=\\big( \\boldsymbol{I}+\\boldsymbol{N}+\\cdots+\\boldsymbol{N}^{n-2}\\big)\\boldsymbol{C}}\\). Adem√°s, como todos los estados en \\(\\small{\\boldsymbol{A}}\\) son estados absorbentes, de la ecuaci√≥n de Chapman-Kolmogorov se deduce que:\n\n\n\\[\\begin{align*}\n\\mathbb{P}\\big(Y_{n-1}\\notin A,\\cdots,  Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big) & =\\mathbb{P}\\big(Y_{n-1}\\in \\Omega-A\\mid \\boldsymbol{\\xi_0}\\big)\\\\\n& =\\big(\\boldsymbol{\\xi_0}:\\boldsymbol{0}\\big) \\boldsymbol{ M}^{n-1}\\big(\\boldsymbol{1}:\\boldsymbol{0}\\big)'.\n\\end{align*}\\]\n\nLuego la ecuaci√≥n (2.19) puede entonces deducirse utilizando las ecuaciones (2.20) y (2.21) a traves de:\n\n\n\\[\\begin{align*}\n& \\quad \\, \\, \\mathbb{P}\\big(Y_n\\in A,Y_{n-1}\\notin A,\\ldots,  Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)\\\\\n& =\\mathbb{P}\\big(Y_{n-1}\\notin A,\\ldots,  Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)-\\mathbb{P}\\big(Y_n\\notin A,Y_{n-1}\\notin A,\\ldots,  Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)\\\\\n& = \\big(\\boldsymbol{\\xi_0}:\\boldsymbol{0}\\big) \\boldsymbol{ M}^{n-1}\\big(\\boldsymbol{I-M}\\big)\\big(\\boldsymbol{1}:\\boldsymbol{0}\\big)' \\\\\n& =\\boldsymbol{\\xi N}^{n-1}\\boldsymbol{(I-N)1'}.\\hspace{8cm} \\Box\n\\end{align*}\\]\n\nEn vista de las Ecs. (2.20) y (2.21), los siguientes teoremas son inmediatos.\nTeorema 2.3 Para todo estado \\(\\small{i\\in \\Omega-A}\\)\n\n\n\\[\\begin{align*}\n\\mathbb{P}\\big(Y_{n-1}=i,Y_{n-2}\\notin A,\\ldots,  Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)= \\boldsymbol{\\xi N}^{n-1}\\boldsymbol{e_i'}.\n\\end{align*}\\]\n\nPrueba. Utilizando los mismos argumentos que en la demostraci√≥n del Teorema 2.2 y reemplazando \\(\\small{\\boldsymbol{1'}}\\) por \\(\\small{\\boldsymbol{e_i'}}\\), la Ec. (2.22) se sigue directamente de las ecuaciones (2.20) y (2.21). \\(\\hspace{1cm} \\Box\\)\nTeorema 2.4 Para cualquier estado absorbente \\(\\small{j \\in A}\\), la probabilidad del sistema para llegar por primera vez al estado absorbente \\(\\small{j}\\) en el \\(\\small{n}-\\)√©simo ensayo es:\n\n\n\\[\\begin{align*}\n\\mathbb{P}\\big(Y_{n}=j,Y_{n-1}\\notin A,\\ldots,  Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)= \\boldsymbol{\\xi N}^{n-1}{C_j'}.\n\\end{align*}\\]\n\nen donde, \\(\\small{C_j'}\\) es la \\(\\small{j}-\\)√©sima columna de la matriz \\(\\small{\\boldsymbol{C}}\\).\nPrueba: Para cualquier \\(\\small{j \\in A}\\), de la definici√≥n de la cadena de Markov y del Teorema 2.3 se deduce que:\n\n\n\\[\\begin{align*}\n& \\quad \\, \\mathbb{P}\\big(Y_{n-1}=j,Y_{n-1}\\notin A,\\ldots,  Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)\\\\\n& = \\sum_{i\\in \\Omega-A}\\mathbb{P}\\big(Y_{n-1}=i,Y_{n-2}\\notin A,\\ldots,  Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)\\times \\mathbb{P}\\big( Y_n=j\\mid Y_{n-1}=i \\big)\\\\\n&= \\sum_{i\\in \\Omega-A}\\boldsymbol{\\xi N}^{n-1}{e_i'}p_{ij}\\\\\n&= \\boldsymbol{\\xi N}^{n-1}\\sum_{i\\in \\Omega-A}{e_i'}p_{ij}\\\\\n&= \\boldsymbol{\\xi N}^{n-1}{C_j'}\\hspace{8cm}\n\\end{align*}\\]\n\nPara ilustrar los teoremas 2.2 a 2.4 y sus relaciones, proporcionamos el siguiente ejemplo sencillo.\nEjemplo 2.5 Sea \\(\\small{\\{Y_t\\}}\\) una cadena de Markov homog√©nea definida en el espacio de estados \\(\\small{\\{1, 2, 3, 4\\}}\\) con distribuci√≥n inicial \\(\\small{\\boldsymbol{\\xi_0}=\\big(\\xi : 0 \\big)=(1,0:0,0)}\\) y matriz de probabilidad de transici√≥n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\\begin{array}{cccc}&\n\\begin{array}{cccc}\n\\end{array}\n\\\\\n\\begin{array}{ccc}\n1 \\\\\n2 \\\\\n3\\\\\n4\\\\\n\\end{array}\n&\n\\left(\n\\begin{array}{cc|cc}\n1/2 & 1/4 & 1/4  &  0 \\\\\n1/3 & 1/3 & 0 &  1/3 \\\\\n\\hline\n0& 0  &  1 & 0 \\\\\n0&  0 & 0 &  1\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nen donde \\(\\small{A=\\{3,4\\}}\\) es el conjunto de estados absorbentes. Para \\(\\small{n = 3}\\) (tercer ensayo), las probabilidades de entrada del sistema en los estados absorbentes \\(\\small{3}\\) y \\(\\small{4}\\) son, respectivamente:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(Y_{3}=3,Y_{2}\\notin A,Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)=(0,1)\n\\left(\\begin{array}{cc}\n1/2 & 1/4\\\\\n1/3 & 1/3\\\\\n\\end{array} \\right)^{2}\n\\left(\\begin{array}{c}\n1/4\\\\\n0\\\\\n\\end{array} \\right)=\\frac{1}{12}\n\\end{equation}\\]\n\ny \n\n\\[\\begin{equation}\n\\mathbb{P}\\big(Y_{3}=4,Y_{2}\\notin A,Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)=(0,1)\n\\left(\\begin{array}{cc}\n1/2 & 1/4\\\\\n1/3 & 1/3\\\\\n\\end{array} \\right)^{2}\n\\left(\\begin{array}{c}\n0\\\\\n1/3\\\\\n\\end{array} \\right)=\\frac{5}{72}.\n\\end{equation}\\]\n\nAdem√°s, por el Teorema 2.2, la probabilidad de que el sistema entre por primera vez en el subconjunto \\(\\small{A=\\{3,4\\}}\\) en el tercer ensayo es\n\n\n\\[\\begin{align*}\n& \\quad \\,\\, \\mathbb{P}\\{Y_3\\in A,Y_{2}\\notin A,Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\}\\\\\n&=\\boldsymbol{\\xi N}^{3-1}\\boldsymbol{(I-N)1'}\\\\\n&=(0,1)\n\\left(\\begin{array}{cc}\n1/2 & 1/4\\\\\n1/3 & 1/3\\\\\n\\end{array} \\right)^{2}\n\\left[\n\\left(\\begin{array}{cc}\n1 & 0\\\\\n0 & 1\\\\\n\\end{array} \\right)-\n\\left(\\begin{array}{cc}\n1/2 & 1/4\\\\\n1/3 & 1/3\\\\\n\\end{array} \\right)\n\\right]\n\\left(\\begin{array}{c}\n1\\\\\n1\\\\\n\\end{array} \\right)\\\\\n& =\\frac{11}{72}\n\\end{align*}\\]\n\nComo verificaci√≥n de los resultados anteriores, observemos que:\n\n\n\\[\\begin{align*}\n\\mathbb{P}\\big(Y_3\\in A,Y_{2}\\notin A,Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\big)& =\n\\mathbb{P}\\big(Y_3= 3,Y_{2}\\notin A,Y_1\\notin A \\mid \\boldsymbol{\\xi_0} \\big)\\\\\n&+ \\mathbb{P}\\big(Y_3= 4,Y_{2}\\notin A,Y_1\\notin A \\mid \\boldsymbol{\\xi_0}\\\\\n&= \\frac{11}{72} \\hspace{5cm}\\Diamond\n\\end{align*}\\]\n\nDe forma m√°s general, puesto que para cada \\(\\small{i\\in \\Omega-A}\\)\n\n\\[\\begin{align*}\n\\sum_{j\\in A}p_{ij}= 1- \\sum_{j \\in \\Omega- A}p_{il}\n\\end{align*}\\]\n\nluego se deduce que \\(\\small{\\displaystyle\\sum_{j\\in A}C_j'=\\boldsymbol{(I-N)1'}}\\), y por tanto\n\n\n\\[\\begin{align*}\n\\sum_{j\\in A}\\boldsymbol{\\xi N}^{n-1}C_j'=\\boldsymbol{\\xi N}^{n-1}\\boldsymbol{(I-N)1'}\n\\end{align*}\\]\n\n\n\n\nUtilizando las ideas de la secci√≥n 2.6, podemos encontrar la probabilidad de que se produzca la primera entrada para cualquier subconjunto \\(\\small{B\\subset \\Omega}\\). Dado el subconjunto \\(\\small{B}\\), la matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M}}\\) de una cadena de Markov \\(\\small{\\{Y_t\\}}\\) homog√©nea siempre puede disponerse de la siguiente forma:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\n\\begin{array}{cc}\n{\\Omega-B} \\\\B \\end{array}\n\\left(\\begin{array}{c|c}\n\\boldsymbol{N} & \\boldsymbol{B}\\\\\n\\hline\n\\boldsymbol{J} &  \\boldsymbol{Q}\n\\end{array}\n\\right)\n\\end{equation}\\]\n\nTeorema 2.5 Sea \\(\\small{\\{Y_t\\}}\\) una cadena de Markov homog√©nea con matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M}}\\), en la forma de la ecuaci√≥n (2.25), y con distribuci√≥n inicial \\(\\small{\\boldsymbol{\\xi=(1:0)}}\\). Entonces, para un subconjunto \\(\\small{B}\\) de tama√±o \\(\\small{k}\\) contenido en el espacio de estados \\(\\small{\\Omega}\\) de tama√±o \\(\\small{m}\\), se cumplen las siguientes relaciones:\n(i) Para todo \\(\\small{j \\in B}\\)\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(Y_n =j,Y_{n-1}\\notin B,\\cdots,Y_1\\notin B \\mid \\boldsymbol{\\xi_0}\\big)=\\boldsymbol{\\xi N}^{n-1}\\boldsymbol{B_j'},\n\\end{equation}\\]\n\nen donde \\(\\small{B_j'}\\) es la \\(\\small{j}-\\)√©sima columna de la matriz \\(\\small{\\boldsymbol{B}_{(m-k)\\times k}}\\) y\n(ii)\n\n\n\\[\\begin{align*}\n& \\quad \\,\\, \\mathbb{P}\\big(Y_n \\in B,Y_{n-1}\\notin B,\\cdots,Y_1\\notin B \\mid \\boldsymbol{\\xi_0}\\big)\\\\\n&=\\boldsymbol{\\xi N}^{n-1}\\boldsymbol{(I-N)1'}\\\\\n&=\\sum_{j\\in B}\\boldsymbol{\\xi N}^{n-1}{B'}_j,\n\\end{align*}\\]\n\nPrueba. Defina una nueva cadena de Markov \\(\\small{\\{Z_t\\}}\\) en el espacio de estados \\(\\small{\\Omega}\\), donde \\(\\small{\\{Z_t\\}}\\) es igual a \\(\\small{\\{Y_t\\}}\\)para todos los estados \\(\\small{i \\in \\Omega-B}\\) y donde todos los estados \\(\\small{j \\in B}\\) se toman como estados absorbentes. Entonces la matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M^{\\star}}}\\) para la cadena de Markov \\(\\small{\\{Z_t\\}}\\) tiene la forma\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}^{\\star}=\\big(p_{ij}^{\\ast}\\big)=\n\\left(\\begin{array}{c|c}\n\\boldsymbol{N} & \\boldsymbol{B}   \\\\\n\\hline\n\\boldsymbol{O} &  \\boldsymbol{I}\n\\end{array}\n\\right).\n\\end{equation}\\]\n\nDado que, para cada \\(\\small{n}\\) \n\n\\[\\begin{equation}\n\\mathbb{P}\\big(Y_n =j,Y_{n-1} \\notin B,\\cdots, Y_1\\notin B,Y_1\\notin B \\mid \\boldsymbol{\\xi_0}\\big)=\\mathbb{P}\\big(Z_n =j,Z_{n-1} \\notin B,\\cdots, Y_1\\notin B,Z_1\\notin B \\mid \\boldsymbol{\\xi_0}\\big),\n\\end{equation}\\]\n\nEl resultado (i) se desprende del teorema 2.4. De manera similar, el resultado (ii) se sigue inmediatamente a partir de (i) y el hecho de que \\(\\small{\\boldsymbol{(I-N)1'}=\\displaystyle\\sum_{j\\in B}{B'}_j}\\). \\(\\hspace{1cm}\\Box\\)\nLa prueba anterior est√° guiada por el hecho de que todos los estados en \\(\\small{B}\\) son estados absorbentes con respecto a la nueva cadena de Markov \\(\\small{\\{Z_t\\}}\\) y, por lo tanto, por ejemplo, para cada \\(\\small{i \\in \\Omega-B}\\), la probabilidad \\(\\small{\\mathbb{P}(Z_{n-1}=i)}\\) se puede dividir en dos partes de la siguiente manera:\n\n\n\\[\\begin{align*}\n\\mathbb{P}\\big(Z_{n-1} = i \\mid \\boldsymbol{\\xi_0}\\big) & =\n\\mathbb{P}\\big(Z_{n-1} =i, Z_{n-2} \\notin B,\\cdots, Z_1\\notin B \\mid \\boldsymbol{\\xi_0}\\big)\\\\\n& + \\mathbb{P}\\big(Z_{n-1} =i \\text{ y por lo menos uno de } Z_{n-2},\\cdots ,Z_1 \\text{ esta dentro de } B \\mid \\boldsymbol{\\xi_0}\\big)\n\\end{align*}\\]\n\nen donde la segunda parte es siempre cero (ya que \\(\\small{i \\in \\Omega-B}\\) y \\(\\small{p_{ij}^{\\ast}\\equiv 0}\\) para todos \\(\\small{j \\in B}\\)). Tenga en cuenta que, en el teorema 2.5, asumimos la distribuci√≥n inicial \\(\\small{(\\boldsymbol{\\xi:0})}\\)), lo que equivale a decir \\(\\small{\\mathbb{P}\\big(Y_0\\in B\\big)\\equiv 1}\\). En consecuencia, la probabilidad \\(\\small{\\mathbb{P}\\big(Y_n \\in B,Y_{n-1}\\notin B,\\cdots,Y_1 \\notin B \\mid \\boldsymbol{\\xi_0}\\big)}\\) se conoce como probabilidad de primera entrada.\nEjemplo 2.6 Sea \\(\\small{\\{Y_t\\}}\\) una cadena de Markov homog√©nea definida en el espacio de estados \\(\\small{\\Omega=\\{1,2,3,4,5\\}}\\) con matriz de probabilidad de transici√≥n\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\n\\begin{array}{ccccc}&\n\\begin{array}{ccccc}\n\\end{array}\n\\\\\n\\begin{array}{ccccc}\n1 \\\\\n2 \\\\\n3\\\\\n4\\\\\n5\n\\end{array}\n&\n\\left(\n\\begin{array}{ccccc}\n1/2 & 1/4 & 1/4  & 0 &  0 \\\\\n1/4 & 1/2  & 0  &  1/4 & 0 \\\\\n1/4 & 1/4  &  0 & 0 & 1/2 \\\\\n0&  0 & 0 &  1 &0 \\\\\n0&  0 & 0 &  0 & 1 \\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nSupongamos que \\(\\small{B = \\{3, 4\\}}\\), entonces la matriz de probabilidad de transici√≥n de \\(\\small{B = \\{Y_t\\}}\\) se puede reorganizar como:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\n\\begin{array}{ccccc}&\n\\begin{array}{ccccc}\n\\end{array}\n\\\\\n\\begin{array}{ccccc}\n1 \\\\\n2 \\\\\n3\\\\\n4\\\\\n5\n\\end{array}\n&\n\\left(\n\\begin{array}{ccc|cc}\n1/2 & 1/4 & 0  & 1/4 &  0 \\\\\n1/4 & 1/2  & 0  &  0 & 1/4 \\\\\n0 & 0 &  1 & 0 & 0 \\\\\n\\hline\n1/4 &  1/4 & 1/2 &  0 & 0 \\\\\n0&  0 & 0 &  0 & 1 \\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nDada una distribuci√≥n inicial de \\(\\small{Y_0}\\), digamos \\(\\small{\\mathbb{P}(Y_0=1)=1}\\), la probabilidad de primera entrada para \\(\\small{Y_n=3}\\), es\n\n\n\\[\\begin{align*}\n& \\quad \\,\\mathbb{P}\\big(Y_n =3,Y_{n-1} \\notin B,\\cdots,Y_1\\notin B \\mid Y_0 = 1\\big)\n\\\\\n& =(0,0,1)\n\\left(\\begin{array}{ccc}\n1/2 & 1/4 & 0\\\\\n1/4 & 1/2 & 0\\\\\n0 & 0 & 1\n\\end{array} \\right)^{n-1}\n\\left(\\begin{array}{c}\n1/4\\\\\n0\\\\\n0\n\\end{array} \\right)\\\\\n\\end{align*}\\]\n\nPara \\(\\small{n = 3}\\), obtenemos que \\(\\small{\\mathbb{P}\\big(Y_n =3,Y_{3} \\notin B,Y_1\\notin B \\mid Y_0 = 1\\big)=5/64}\\). Tenga en cuenta que dado que el estado ‚Äú\\(\\small{5}\\)‚Äù es un estado absorbente, los c√°lculos se pueden reducir a√∫n m√°s a:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(Y_n =3,Y_{n-1} \\notin B,\\cdots,Y_1\\notin B \\mid Y_0 = 1\\big)=(1,0)\n\\left(\\begin{array}{ccc}\n1/2 & 1/4 \\\\\n1/4 & 1/2\n\\end{array} \\right)^{n-1}\n\\left(\\begin{array}{c}\n1/4\\\\\n0\n\\end{array} \\right) \\hspace{5cm}\\Diamond\n  \\end{equation}\\]\n\nSea \\(\\small{A}\\) el conjunto que contenga todos los estados absorbentes de \\(\\small{\\{Y_t\\}}\\) y sea \\(\\small{B^{\\ast}= A \\cup B}\\). La matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M^{*}}}\\) , correspondiente a la cadena de Markov asociada \\(\\small{\\{Z_t\\}}\\) en la que todos los estados en \\(\\small{B^{\\ast}}\\) se toman como estados absorbentes, puede entonces reordenarse como:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M^{\\ast}}=\n\\begin{array}{cc}\n{\\Omega-B^{\\ast}} \\\\B^{\\ast} \\end{array}\n\\left(\\begin{array}{c|c}\n\\boldsymbol{N^{\\ast}} & \\boldsymbol{B^{\\ast}}\\\\\n\\hline\n\\boldsymbol{J} &  \\boldsymbol{Q}\n\\end{array}\n\\right)\n\\end{equation}\\]\n\nen donde \\(\\small{\\boldsymbol{N^{*}}}\\) es la submatriz esencial de \\(\\small{\\boldsymbol{M^{*}}}\\), y \\(\\small{\\boldsymbol{B^{*}}}\\) es la matriz formada a partir de \\(\\small{\\boldsymbol{M^{*}}}\\) mediante la eliminaci√≥n de todas las columnas asociadas con los estados en \\(\\small{\\Omega-B^{*}}\\) y de todas las filas asociadas con los estados en \\(\\small{B^{*}}\\). Entonces se cumple el siguiente corolario.\nColorario: Para todo \\(\\small{j\\in B}\\)\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(Y_n =j,Y_{n-1} \\notin B,\\cdots,Y_1\\notin B \\mid (\\boldsymbol{\\xi}:\\boldsymbol{0}) \\big)= \\boldsymbol{\\xi^{\\ast}}(\\boldsymbol{N^{\\ast}})^{n-1}B_{j}^{*'},\n\\end{equation}\\]\n\nsiendo \\(\\small{B_{j}^{*'}}\\) la \\(j-\\)√©sima columna de la matriz \\(\\small{\\boldsymbol{B^{\\ast}}}\\)\nLa prueba del corolario anterior es sencilla y se deja en manos del lector. Tenga en cuenta que el tama√±o de la matriz \\(\\small{\\boldsymbol{N^{\\ast}}}\\) es menor o igual que el tama√±o de \\(\\small{\\boldsymbol{N}}\\).\n\n\n\n\n\n\nAunque las rachas y patrones en una sucesi√≥n de ensayos de Bernoulli son casos especiales de los ensayos multiestados, merecen un cap√≠tulo aparte debido a su larga historia, la gran cantidad de resultados asociados y su amplia aplicaci√≥n a numerosos campos. El enfoque de este cap√≠tulo ser√° derivar las distribuciones para las estad√≠sticas de rachas m√°s comunes y √∫tiles en ensayos de Bernoulli mediante la t√©cnica de incrustaci√≥n de cadenas finitas de Markov, y tambi√©n en extender estos resultados a secuencias de ensayos de dos estados dependientes de Markov. Tambi√©n se presentan t√©cnicas para obtener ecuaciones recursivas y funciones generadoras de probabilidad de estad√≠sticas de rachas a trav√©s del enfoque de incrustaci√≥n de cadenas finitas de Markov. Estas herramientas pueden ser muy √∫tiles para estudiar ciertas caracter√≠sticas de las distribuciones de rachas, como la media, la varianza y los momentos superiores.\nEn este cap√≠tulo se tratan las siguientes estad√≠sticas de rachas, definidas tradicionalmente en una secuencia de \\(\\small{n}\\) ensayos de Bernoulli:\n(i) \\(\\small{N_{n,k}}\\) el n√∫mero de \\(\\small{k}\\) √©xitos consecutivos no superpuestos;\n(ii) \\(\\small{G_{n,k}}\\) el n√∫mero de rachas exitosas de tama√±o mayor o igual a \\(\\small{k}\\).\n(iii) \\(\\small{M_{n,k}}\\) el n√∫mero de \\(\\small{k}\\) √©xitos consecutivos solapados.\n(iv) \\(\\small{E_{n,k}}\\) el n√∫mero de rachas de exctamente \\(\\small{k}\\) √©xitos.\n(v) \\(\\small{L_{n,k}}\\) el tama√±o de la racha de exitos m√°s larga;\n(vi) \\(\\small{S_{n,k}}\\) el n√∫mero total de √©xitos en rachas exitosas de longitud mayor o igual a \\(\\small{k}\\) .\nTambi√©n se trata la distribuci√≥n del tiempo de espera de una racha de √©xitos y se incluyen algunos resultados num√©ricos para las distribuciones de las estad√≠sticas de las rachas anteriores.\n\n\n\nEl n√∫mero de rachas de \\(\\small{k}\\) √©xitos consecutivos no superpuestos, \\(\\small{N_{n,k}}\\), en una secuencia de \\(\\small{n}\\) ensayos de Bernoulli es probablemente la estad√≠stica de ejecuciones m√°s importante, no s√≥lo por su amplia aplicaci√≥n a diversas √°reas sino tambi√©n por su conexi√≥n con otras estad√≠sticas de rachas; En teor√≠a de la distribuci√≥n, la distribuci√≥n de \\(\\small{N_{n,k}}\\) se conoce como distribuci√≥n binomial de orden \\(\\small{k}\\). Philippou y Makri (1986) e Hirano (1986) dieron de forma independiente una f√≥rmula para la distribuci√≥n exacta de \\(\\small{N_{n,k}}\\) en una secuencia de \\(\\small{n}\\) ensayos de Bernoulli como:\n\n\n\\[\\begin{equation}\n\\mathbb{P}(N_{n,k}=x)=\\sum_{m=0}^{k-1}\\sum_{x_1+x_2+\\cdots+\\\\\nkx_k=n-m-km}\\binom{x_1+x_2+\\cdots+x_k+x}{x_1,x_2,\\cdots,x_k,x}p^n\\Big(\\frac{q}{p}\\Big)^{x_1+x_2+\\cdots+x_k},\n\\end{equation}\\]\n\nen donde, \\(\\small{x=0,1,\\ldots,[n/k]}\\,\\) (\\(\\small{[n/k]}\\) la parte entera de \\(\\small{n/k}\\)) y con probabilidades de √©xito \\(\\small{p}\\) y fracaso \\(\\small{p=1-p}\\). Godbole (1990) dio una f√≥rmula alternativa para la funci√≥n de probabilidad de \\(\\small{N_{n,k}}\\) con \\(\\small{k&gt;1}\\):\n\n\n\\[\\begin{align*}\n\\mathbb{P}(N_{n,k}=x) &=\\sum_{[(n-kx)/k]\\leq y \\leq n-kx} \\binom{y+x}{x}q^yp^{n-y}\\\\\n& \\times \\sum_{0 \\leq j \\leq  [(n-kx-y)/k]}(-1)^j \\binom{y+1}{j} \\binom{n-kx-jk}{y},\n\\end{align*}\\]\n\npara \\(\\small{x=0,1,\\ldots,[n/k]}\\,\\). La f√≥rmula (3.2) tiene la ventaja sobre la (3.1) de que es m√°s f√°cil de evaluar por computadora para \\(\\small{n}\\,\\) grande. Hirano y Aki (1987, 1993) estudiaron algunas propiedades de esta distribuci√≥n y ampliaron los resultados al caso de ensayos de Markov dependientes de dos estados.\nPara comenzar nuestro estudio de \\(\\small{N_{n,k}}\\) utilizando el m√©todo de incrustaci√≥n de cadenas finitas de Markov, consideremos el espacio de estados\n\n\n\\[\\begin{equation}\n\\Omega =\\{(x,i):x=0,1,\\cdots,l_n\\, \\text{y}\\, 0,1,\\cdots,k-1\\},\n\\end{equation}\\]\n\nen donde, \\(\\small{l_n=[n/k]}\\,\\) es el n√∫mero m√°ximo de rachas exitosas no superpuestas de longitud \\(\\small{k}\\) que pueden ocurrir en \\(\\small{n}\\) ensayos. Ahora definamos la Cadena de Markov finita homogenea \\(\\small{\\{Y_t:t=0,1,\\ldots,n\\}}\\,\\) sobre \\(\\small{\\Omega}\\,\\) como sigue:\n\n\n\\[\\begin{equation}\nY_t=(N_{t,k},E_{t}),\\quad \\text{para }1\\leq t \\leq n,\n\\end{equation}\\]\n\ndonde \\(\\small{N_{n,k}}\\) es el n√∫mero de \\(\\small{k}\\) √©xitos consecutivos no superpuestos que ocurrieron durante los primeros \\(\\small{t}\\) ensayos \\(\\small{X_1,X_2,\\ldots,X_n}\\). El ‚Äúbloque final‚Äù \\(\\small{E_t}\\) es igual a \\(\\small{m}\\) m√≥dulo \\(\\small{k}\\), donde \\(\\small{m}\\) representa el n√∫mero de √©xitos finales (posiblemente cero) que existen en la sucesi√≥n despu√©s de las primeros \\(\\small{t}\\) ensayos:\n\n\n\\[\\begin{equation}\nFFSSF\\underbrace{SS\\cdots S}_{m}.\n\\end{equation}\\]\n\nObservemos que \\(\\small{E_t=0}\\) si \\(\\small{m}\\) es un m√∫ltiplo positivo de \\(\\small{k}\\) o si el \\(\\small{t-}\\)√©simo resultado es \\(\\small{F}\\). Esta variable de bloque final realiza un seguimiento del n√∫mero de √©xitos en una posible racha parcial asociada con en el \\(\\small{t-}\\)√©simo ensayo. Por ejemplo, dados \\(\\small{n=10}\\) ensayos de Bernoulli con resultados \\(\\small{\\{FSFFSSSFSS\\}}\\) y una duraci√≥n de ejecuci√≥n exitosa elegida de \\(\\small{k=2}\\), la realizaci√≥n de la cadena de Markov incorporada \\(\\small{\\{Y_t: t = 1,2,\\ldots, 10\\}}\\) con respecto a estos diez resultados es: \\(\\small{\\{Y_1=(0,0), Y_2 = (0, 1), Y_3=(0,0), Y_4=(0,0),Y_5= (0,1),Y_6 = (1,0), Y_7=(1, 1), Y_8=(1,0),Y_9=(1,1), Y_{10}=(2,0)\\}}\\). Tenga en cuenta que para una secuencia dada de resultados \\(\\small{\\{FS\\cdots SF\\}}\\), la realizaci√≥n de \\(\\small{\\{Y_t\\}}\\) es siempre √∫nica.\nDefinir los subconjuntos\n\n\n\\[\\begin{equation}\nC_x =\\{(x,i): i=0,1,\\cdots,k-1\\},\\quad 0\\leq x \\leq l_n\n\\end{equation}\\]\n\nLa colecci√≥n de subconjuntos \\(\\small{\\{C_x:x = 0,1,\\ldots,l_n\\}}\\) forma una partici√≥n del espacio de estados \\(\\small{\\Omega}\\). Dado que \\(\\small{\\{X_t\\}}\\) es, por el momento, una sucesi√≥n de ensayos Bernoulli, de las definiciones anteriores se deduce que \\(\\small{Y_t}\\) tiene una matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M_t} = (p_{(x,i)(y,j)})}\\) para todo \\(\\small{t=1,2,\\ldots,n}\\), con las probabilidades de transici√≥n \\(\\small{(p_{(x,i)(y,j)})}\\) dadas por la siguiente ecuaci√≥n: para \\(\\small{1 \\leq t \\leq n}\\) y \\(\\small{0 \\leq x \\leq l_n}\\) \n\n\\[\\begin{align*}\np_{(x,i)(y,j)} & = \\mathbb{P}\\big(Y_t=(y,j)\\mid Y_{t-1}=(x,i)\\big)\\\\\n& =\\begin{cases}\nq \\quad \\text{si }y=x\\,\\text{y }j=0,\\,\\text{para }i=0,1,\\ldots, k-1\n\\\\\np \\quad \\text{si }y=x\\,\\text{y }j=i+1,\\,\\text{para }i=0,1,\\ldots, k-2\n\\\\\np \\quad \\text{si }y=x+1\\,\\text{y }j=0,\\,\\text{para }i=k-1\\,\\text{y },x=0,1,\\ldots, l_{n}-1\n\\\\\n1 \\quad \\text{si }y=x=l_{n}\\,\\text{y }j=i=k-1\n\\\\\n0 \\quad \\text{en otro caso}\n\\end{cases}\n\\end{align*}\\]\n\nA modo de ilustraci√≥n, la matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M_t}}\\) de la cadena de Markov incrustada \\(\\small{{Y_t}}\\) asociada con la variable aleatoria \\(\\small{N_{5,2}}\\) viene dada por\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\n\\begin{array}{cccccc}&\n\\begin{array}{cccccc}\n\\end{array}\n\\\\\n\\begin{array}{cccccc}\n(0,0)\\\\\n(0,1)\\\\\n(1,0)\\\\\n(1,1)\\\\\n(2,0)\\\\\n(2,1)\n\\end{array}\n&\n\\left(\n\\begin{array}{cc|cc|cc}\nq&p&0&0&0&0\\\\\nq&0&p&0&0&0\\\\\n\\hline\n0&0&q&p&0&0\\\\\n0&0&q&0&p&0\\\\\n\\hline\n0&0&0&0&q&p\\\\\n0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}_{6\\times6}\n\\end{equation}\\]\n\npara \\(\\small{1\\leq t \\leq 5.}\\)\nPara el caso donde \\(\\small{\\{X_t\\}}\\) es una sucesi√≥n de ensayos de dos estados independientes pero no id√©nticamente distribuidos con probabilidades \\(\\small{\\mathbb{P}(X_t=S)=p_t}\\) y \\(\\small{\\mathbb{P}(X_t=F)=q_t}\\) , para \\(\\small{t=1,2,\\ldots,n}\\), las matrices de transici√≥n \\(\\small{\\boldsymbol{M_t}}\\) para la cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) permanece sin cambios excepto que la probabilidad \\(\\small{p}\\) se reemplaza por \\(\\small{p_t}\\) y \\(\\small{q}\\) se reemplaza por \\(\\small{q_t}\\). En general, para ensayos de dos estados independientes pero no id√©nticamente distribuidos, las matrices de probabilidad de transici√≥n se pueden escribir como\n\n\n\\[\\begin{equation}\n\\boldsymbol{M_t}(N_{n,k})=\n\\left(\\begin{array}{cccc}\n\\boldsymbol{A_t}&\\boldsymbol{B_t}&&&\\boldsymbol{0}\\\\\n&&\\ddots&\\ddots&\\\\\n\\boldsymbol{0}&&&\\boldsymbol{A_t}&\\boldsymbol{B_t}\\\\\n&&&&\\boldsymbol{A_{t}^{\\ast}}\\\\\n\\end{array}\\right)_{d\\times d},\n\\end{equation}\\]\n\npara \\(\\small{t=1,2,\\dots,n}\\), en donde:\n\n\n\\[\\begin{equation}\n\\boldsymbol{A_t}=\n\\left(\\begin{array}{ccccc}\nq_t&p_t&0&\\cdots&0\\\\\nq_t&0&p_t&\\cdots&0\\\\\n\\vdots& &\\ddots&\\ddots&\\\\\n\\vdots& & &\\ddots&p_t\\\\\nq_t&0&0&\\cdots&0\\\\\n\\end{array}\\right)_{k\\times k},\n\\end{equation}\\]\n\n\\(\\small{\\boldsymbol{B_t}}\\) es una matriz \\(\\small{k\\times k}\\) que tiene \\(\\small{p_t}\\) en la entrada \\(\\small{(k,1)}\\) y cero en el resto, \\(\\small{\\boldsymbol{A_t}^{\\ast}}\\) es igual que \\(\\small{\\boldsymbol{A_t}}\\) excepto que su √∫ltima fila se reemplaza con \\(\\small{(0,0,...,0,1)}\\), y la dimensi√≥n de \\(\\small{\\boldsymbol{M_t}(N_{n,k})}\\) viene dado por \\(\\small{d = k(l_n+1)}\\). Por tanto, en virtud del teorema 2.1, podemos afirmar que\n\n\n\\[\\begin{equation}\n\\small{\\mathbb{P}\\big( N_{n,k}=x\\big)=\\boldsymbol{\\mathbf{\\xi}}_0 \\Big(\\prod_{t=1}^{n}\\boldsymbol{M}_t(N_{n,k})\\Big)\\boldsymbol{\\mathbf{U}'}(\\mathbf{C_x})},\\,\\,  x=1,2,\\ldots,l_n,\n\\end{equation}\\]\n\nen donde, \\(\\small{\\boldsymbol{\\mathbf{\\xi}}_0=(1,0,\\ldots,0)_{1\\times d}}\\) y \\(\\small{\\boldsymbol{\\mathbf{U}'}({C_x})}\\) es la transpuesta del vector \\(\\small{\\boldsymbol{\\mathbf{U}'}({C_x})=(0,\\ldots,0, 1,\\ldots, 1, 0,\\ldots,0)}\\) con unos en las ubicaciones asociadas con los estados en \\(\\small{C_x}\\). La ecuaci√≥n (3.8) representa la distribuci√≥n exacta de \\(\\small{N_{n,k}}\\) para ensayos independientes de dos estados distribuidos tanto de forma id√©ntica como no id√©ntica. En vista de la matriz de probabilidad de transici√≥n en la ecuaci√≥n (3.7), \\(\\small{N_{n,k}}\\) es una cadena finita de Markov incrustable de tipo binomial en el sentido de la Definici√≥n 2.7 (Koutras y Alexandrou 1995).\nSi \\(\\small{\\{X_t\\}}\\) es una Cadena de Markov no homogenea com matriz de probabilidades de transici√≥n:\n\n\n\\[\\begin{equation}\n\\left(\\begin{array}{cc}\np_{FF}(t)&p_{SS}(t)\\\\\np_{FF}(t)&p_{SS}(t)\n\\end{array}\\right),\n\\end{equation}\\]\n\nentonces, es necesaria una modificaci√≥n menor en el procedimiento de incrustaci√≥n para obtener la distribuci√≥n de \\(\\small{N_{n,k}}\\). Dado que el resultado de \\(\\small{X_{t+1}}\\), y por tanto tambi√©n de \\(\\small{Y_{t+1}}\\), ahora depende de \\(\\small{X_t}\\), cada estado de la cadena de Markov \\(\\small{Y_t}\\) debe implicar un cierto resultado de \\(\\small{X_t}\\). Este ya es el caso en nuestra definici√≥n anterior de \\(\\small{Y_t}\\), salvo para los estados con un bloque final de \\(\\small{E_t=0}\\), que puede surgir para cualquier resultado de \\(\\small{X_t}\\). Para resolver esta ambig√ºedad, definimos un estado de bloque final adicional, \\(\\small{E_t=\\gamma}\\), para corresponder al caso donde la serie de √©xitos finales es un m√∫ltiplo distinto de cero de \\(\\small{k}\\) √©xitos, y reservamos el estado \\(\\small{E_t=0}\\) para el caso donde el resultado \\(\\small{t-}\\)√©simo es un fracaso. La cadena de Markov incrustada se define entonces de la siguiente manera:\n\n\n\\[\\begin{equation}\nY_t =\n\\begin{cases}\n(x,\\gamma) & \\begin{array}{l} \\text{Si existen } x \\text{ rachas de } k \\text{ aciertos} \\\\\n\\text{consecutivos en los primeros } t \\\\\n\\text{ensayos con } m &gt; 0 \\text{ aciertos finales}\\\\\n\\text{tales que } m \\equiv k \\pmod{k} \\end{array} \\\\\n\\\\\n(x,0) & \\begin{array}{l}\\text{Si existen } x \\text{ rachas de } k \\text{ aciertos}\\\\\n\\text{consecutivos en los primeros } t\\text{ ensayos} \\\\ \\text{con } m = 0 \\text{ aciertos finales} \\text{ (}X_t=F\\text{)} \\end{array}\n\\end{cases}\n\\end{equation}\\]\n\ny \\(\\small{Y_t=(x,i)}\\), para \\(\\small{i=1,2,\\ldots,k-1}\\) se define como se indica en la ecuaci√≥n (3.3). La diferencia entre los estados \\(\\small{(x,\\gamma)}\\) y \\(\\small{ (x,0)}\\) se puede ver en el siguiente ejemplo: para una racha exitosa de longitud \\(\\small{k=2}\\), \\(\\small{Y_8=(SFFFSSSS) = (2,\\gamma)}\\) y \\(\\small{Y_8=(SFSSFSSF)= (2,0)}\\). Tenga en cuenta que el bloque final \\(\\small{E_t}\\) ahora contiene no solo la informaci√≥n requerida sobre los subpatrones sino que tambi√©n implica el resultado de \\(\\small{X_t}\\), lo que permite la asignaci√≥n de probabilidades de transici√≥n para la Cadena de Markov incustada.\nLas matrices de probabilidad de transici√≥n correspondientes a estas definiciones pueden deducirse f√°cilmente. La cadena de Markov incrustada asociada con la variable aleatoria \\(\\small{N_{5,2}}\\) como se considera en la Ecuaci√≥n (3.6) para ensayos de Bernoulli, tiene las siguientes matrices de transici√≥n \\(\\small{\\boldsymbol{M_t^{\\ast}}}\\) bajo ensayos dependientes de Markov no homog√©neos: para \\(\\small{t=1,2,\\ldots,n}\\)\n\n\n\\[\\begin{equation}\n\\boldsymbol{M_t^*}(N_{5,2})=\n\\begin{array}{cc}\n\\begin{array}{c}\n(0,0)\\\\\n(0,1)\\\\\n(1,c)\\\\\n(1,0)\\\\\n(1,1)\\\\\n(2,c)\\\\\n(2,1)\\\\\n(2,1)\n\\end{array}&\n\\left(\n\\begin{array}{cc|ccc|ccc}\np_{FF}(t)&p_{FS}(t)&0&0&0&0&0&0\\\\\np_{FS}(t)&0&p_{SS}(t)&0&0&0&0&0\\\\\n\\hline\n0&0&0&p_{SF}(t)&p_{SS}(t)&0&0&0\\\\\n0&0&0&p_{FF}(t)&p_{FS}(t)&0&0&0\\\\\n0&0&0&p_{SF}(t)&0&p_{SS}(t)&0&0\\\\\n\\hline\n0&0&0&0&0&&p_{SF}(t)&p_{SS}(t)\\\\\n0&0&0&0&0&0&p_{FF}(t)&p_{FS}(t)\\\\\n0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nNote que la estructura de ‚Äúfranja/banda‚Äù de \\(\\small{\\boldsymbol{M_t^{\\ast}}(N_{5,2})}\\) es similar con \\(\\small{\\boldsymbol{M_t}(N_{5,2})}\\) de la ecuaci√≥n (3.6) para ensayos de Bernoulli. Como es sencillo derivar la forma general de \\(\\small{\\boldsymbol{M_t^{\\ast}}(N_{n,k})}\\) an√°loga a la ecuaci√≥n (3.7), esto lo dejamos al lector interesado.\nCuando la secuencia \\(\\small{\\{X_t\\}}\\) es i.i.d., la distribuci√≥n inicial \\(\\small{\\boldsymbol{\\xi}_0}\\) puede definirse como \\(\\small{\\mathbb{P}\\big(Y_0=(0,0)\\big)=1}\\), y luego para \\(\\small{k&gt;1}\\), las probabilidades de transici√≥n \\(\\small{\\mathbb{P}\\big(Y_1=(0,1)\\mid Y_0=(0,0)\\big)=p}\\) y \\(\\small{\\mathbb{P}\\big(Y_1=(0,0)\\mid Y_0=(0,0)\\big)=q=(1-p)}\\). Sin embargo, cuando \\(\\small{\\{X_t\\}}\\) es una sucesi√≥n de variables aleatorias Markov-Dependientes , se debe tener cuidado al asumir \\(\\small{\\mathbb{P}\\big(Y_0=(0,0)\\big)=1}\\), lo que implicar√≠a que las probabilidades de transici√≥n entre \\(\\small{Y_0}\\) e \\(\\small{Y_1}\\) est√°n dadas por \\(\\small{\\mathbb{P}\\big(Y_1=(0,1)\\mid Y_0=(0,0)\\big)=p_{FS}(1)}\\) y \\(\\small{\\mathbb{P}\\big(Y_1=(0,0)\\mid Y_0=(0,0)\\big)=p_{FF}=1}\\), independiente de \\(\\small{p_{SF}}\\) y \\(\\small{p_{FF}}\\). Para evitar este tipo de sesgo, es √∫til crear un estado ficticio \\(\\small{\\emptyset}\\) como estado inicial para \\(\\small{Y_0}\\). Luego definimos \\(\\small{\\mathbb{P}\\big(Y_0=\\emptyset\\big)=1}\\), y las probabilidades de transici√≥n \\(\\small{\\mathbb{P}\\big(Y_1=(0,1)\\mid Y_0=\\emptyset\\big)=p_{s}}\\), y \\(\\small{\\mathbb{P}\\big(Y_1=(0,0)\\mid Y_0=\\emptyset\\big)=p_{f}}\\). Por tanto, para \\(\\small{N_{5,2}}\\) la correspondiente cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) se define en el espacio de estados expandido \\(\\small{\\Omega=\\{\\emptyset,(0,0),(0,1),(1,0),\\ldots\\}}\\) con matrices de probabilidad de transici√≥n:\n\n\n\\[\\begin{equation}\n\\begin{array}{cc} &\n\\begin{array}{cccccc}(0,0)&(0,1)&(1,c)&(1,0)&(1,1)&\\cdots\n\\end{array}\\\\\n\\begin{array}{cccccccc}\n\\end{array}\n&\n\\left(\n\\begin{array}{c|ccccc}\n0 &  p_{f}  & p_{s} &  0  &   0 & \\cdots \\\\\n\\hline\n\\, 0&&&&&\\\\\n0&&&\\boldsymbol{M_t}^{\\ast}(N_{5,2})&&\\\\\n0&&&&&\\\\\n\\end{array}\n\\right)\\end{array}\n\\end{equation}\\]\n\nTenga en cuenta que el procedimiento de incrustaci√≥n de cadenas finitas de Markov utilizado para obtener la distribuci√≥n exacta de \\(\\small{N_{n,k}}\\) sigue siendo el mismo, excepto por diferencias menores en las matrices de probabilidad de transici√≥n, independientemente de si la secuencia de ensayos \\(\\small{\\{X_t\\}}\\) es i.i.d., independiente pero no id√©ntica distribuida o si es Markov-Dependiente.\n\n\n\nPara una sucesi√≥n de ensayos de dos estados, la variable aleatoria \\(\\small{G_{n,k}}\\) se define como el n√∫mero de rachas exitosas de longitud mayor o igual a \\(\\small{G_{n,k}}\\). Consideremos una cadena de Markov finita \\(\\small{\\{Y_t:t=0,1,2,\\ldots,n\\}}\\) definida en el espacio de estados:\n\n\n\\[\\begin{equation}\n\\Omega =\\{(x,i):x=0,1,\\cdots,l_n\\,\\, \\text{y}\\,\\, i= \\gamma,0,1,\\cdots,k-1\\}-{\\{(0,\\gamma)\\}},\n\\end{equation}\\]\n\nen donde, \\(\\small{l_n=[(n+1)/(k+1)]}\\). Para una sucesi√≥n de resultados de los primeros \\(\\small{t}\\) ensayos con \\(\\small{m}\\) √©xitos finales, digamos \\(\\small{FS \\cdots F \\underbrace{SS \\cdots}_{m}S}\\), definimos la cadena de Markov:\n\n\n\\[\\begin{equation}\nY_t=(G_{n,k},E_t) \\quad 1\\leq t\\leq n,\n\\end{equation}\\]\n\ndonde \\(\\small{G_{n,k}}\\), es el n√∫mero de rachas exitosas de longitud mayor o igual a \\(\\small{k}\\) en la sucesi√≥n \\(\\small{\\{X_t\\}}\\), y \\(\\small{E_t}\\) es la variable del bloque final con \\(\\small{E_t=m}\\) si \\(\\small{m=0,1,2,\\ldots,k-1}\\), y \\(\\small{E_t=\\gamma}\\) si \\(\\small{m\\geq k}\\). Para ilustrar esta definici√≥n, considere una longitud de racha m√≠nima de \\(\\small{k=2}\\) y los siguientes doce resultados, de un ensayo de dos estados: \\(\\small{FSFFSSFSSSFS}\\), para los cuales \\(\\small{G_{12,2}=2}\\). Se deduce de la Ec.(3.9) que la realizaci√≥n de la Cadena de Markov \\(\\small{\\{Y_t:t=0,1,2,\\ldots,14\\}}\\) es : \\(\\small{\\{Y_1=(0,0),Y_2=(0,1),Y_3=(0,0),Y_4=(0,0),Y_5=(0,1),Y_6=(1,\\gamma),Y_7=(1,0),Y_8=(1,1),Y_9=(2,\\gamma),Y_{10}=(2,\\gamma),Y_{11}=(2,0),Y_{12}=(2,0)\\}}\\). Note que el bloque final \\(\\small{E_t=\\gamma}\\) puede ocurrir s√≥lo cuando hay al menos \\(\\small{k}\\) √©xitos finales, en cuyo caso \\(\\small{G_{n,k}\\geq k}\\) por esta raz√≥n, el estado \\(\\small{(0,\\gamma)}\\) fue excluido en la definici√≥n anterior del espacio de estados \\(\\small{\\Omega}\\).\nDe la definici√≥n de la cadena de Markov incrustada dada por la Ecu. (3.9), las probabilidades de transici√≥n de un paso en \\(\\small{\\boldsymbol{M_t}(G_{n,k})}\\) para ensayos independientes pero no identicamente distribuidos se especifican mediante la siguiente ecuaci√≥n: para \\(\\small{t=1,2,\\ldots,n}\\)\n\n\n\\[\\begin{equation}\np_{(x,i)(y,i)}(t) =\n\\begin{cases}\nq_t & \\begin{array}{l} \\text{Si}\\,\\, y=x \\,\\, \\text{y}\\,\\, j=0 \\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n \\,\\text{y}\\, i=\\gamma,0,1,\\ldots,k-1  \\end{array} \\\\\np_t & \\begin{array}{l} \\text{Si}\\,\\, y=x \\,\\, \\text{y}\\,\\, j=i=\\gamma\\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n  \\end{array}\n\\\\\np_t & \\begin{array}{l} \\text{Si}\\,\\, y=x \\,\\, \\text{y}\\,\\, j=i+1\\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n \\,\\text{y}\\, i=\\gamma,0,1,\\ldots,k-2  \\end{array}\n\\\\\np_t & \\begin{array}{l} \\text{Si}\\,\\, y=x+1,\\,i=k-1 \\,\\, \\text{y}\\, j=\\gamma \\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n-1  \\end{array}\n\\\\\n1 & \\begin{array}{l} \\text{Si}\\,\\, y=x=l_n,\\,j=x=k-1\\end{array} \\\\\n0 & \\begin{array}{l} \\text{Otro caso} \\end{array}\n\\end{cases}\\\\\n\\end{equation}\\]\n\nEn el caso especial de \\(\\small{n=5}\\) y \\(\\small{k=2}\\) la matriz de probabilidades de transici√≥n \\(\\small{\\boldsymbol{M_t}(G_{n,k})}\\) esta dada por:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M_t}(G_{5,2})=\n\\begin{array}{cc}&\n\\begin{array}{cccccc}\n\\end{array}\n\\\\\n\\begin{array}{cccccc}\n(0,0)\\\\\n(0,1)\\\\\n(1,\\gamma)\\\\\n(1,0)\\\\\n(1,1)\\\\\n(2,\\gamma)\\\\\n(2,0)\\\\\n(2,1)\n\\end{array}\n&\n\\left(\n\\begin{array}{cc|c|cc|c|cc}\nq_t&p_t&0&0&0&0&0&0\\\\\nq_t&0&p_t&0&0&0&0&0\\\\\n\\hline\n0&0&p_t&q_t&0&0&0\\\\\n\\hline\n0&0&0&q_t&p_t&0&0&0\\\\\n0&0&0&q_t&0&p_t&0&0\\\\\n\\hline\n0&0&0&0&0&p_t&q_t&0\\\\\n\\hline\n0&0&0&0&0&0&q_t&p_t\\\\\n0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\npara \\(\\small{t=1,2,\\ldots,5}\\). En general \\(\\small{\\boldsymbol{M_t}(G_{n,k})}\\) es una matriz bidiagonal de bloques de la forma: \n\n\\[\\begin{equation}\n\\left(\n\\begin{array}{ccccccc}\n\\boldsymbol{A_t}&p_t\\boldsymbol{e_k'}&&&&&\\boldsymbol{O}\\\\\n&p_t&q_t\\boldsymbol{e_1}&&\\boldsymbol{O}&&\\\\\n&&\\boldsymbol{A_t}&p_t\\boldsymbol{e_k'}&&&\\\\\n&&&\\ddots&\\ddots&&\\\\\n&&&&\\ddots&\\ddots&\\\\\n&&\\boldsymbol{O}&&&p_t&q_t\\boldsymbol{e_1}\\\\\n\\boldsymbol{O}&&&&&&\\boldsymbol{A_t^{\\ast}}\\\\\n\\end{array}\n\\right)\n\\end{equation}\\]\n\nen donde \\(\\small{\\boldsymbol{e_1}=(1,0,\\ldots,0)}\\) y \\(\\small{\\boldsymbol{e_1}=(0,\\ldots,0,1)}\\) son vectores fila unitarios \\(\\small{1\\times k}\\), y \\(\\small{\\boldsymbol{A_t}}\\) es dada por:\n\n\n\\[\\begin{equation}\n\\boldsymbol{A_t} =\\left(\n\\begin{array}{ccccc}\nq_t & p_t & 0  & \\ldots &  0 \\\\\n\\vdots & \\ddots & \\ddots  &    &   \\\\\n\\vdots &  &  \\ddots& \\ddots &   \\\\\n\\vdots&  &   &  \\ddots &p_t \\\\\nq_t&  0 & 0 &  \\cdots & 1 \\\\\n\\end{array}\n\\right)\n\\end{equation}\\]\n\nLa matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{A_t}}\\), en el contexto de la demograf√≠a, a menudo se denomina matriz de Leslie o, m√°s generalmente, matriz de tipo renovaci√≥n (v√©ase Seneta, 1981). La dimensi√≥n de \\(\\small{\\boldsymbol{A_t}(G_{n,k})}\\) es igual a \\(\\small{(l_n+1)(k+1)-1}\\). La matriz \\(\\small{\\boldsymbol{A_t^{\\ast}}}\\) en la Ec. (3.11) es igual que \\(\\small{\\boldsymbol{A_t}}\\) excepto por la √∫ltima fila, que se reemplaza por \\(\\small{(0,\\ldots,0,1)}\\)\nSi definimos la partici√≥n \\(\\small{\\{C_x:i=0,1,2,\\ldots,l_n\\}}\\) sobre \\(\\small{\\Omega}\\)\n\n\n\\[\\begin{align*}\nC_0&=\\{(0,i):i=0,1,\\ldots,k-1\\} \\\\\nC_x&=\\{(0,i):i=\\gamma,0,1,\\ldots,k-1\\},\\,\\text{para}\\, x=1,2,\\ldots,l_n\n\\end{align*}\\]\n\ny en consecuencia \\(\\small{\\mathbb{P}\\big(G_{n,k}=x\\big)=\\mathbb{P}\\big(Y_n \\in C_x \\big)}\\) para todo \\(\\small{x=0,1,2,\\ldots,l_n}\\). La funci√≥n de distribuci√≥n, los momentos y la funci√≥n generadora de probabilidad ahora se pueden calcular f√°cilmente mediante las ecuaciones (2.11), (2.12) y (2.13), respectivamente.\nPara el caso de ensayos i.i.d., todas las probabilidades de transici√≥n ser√≠an constantes y se podr√≠a llevar a cabo una extensi√≥n a los ensayos de Markov-Dependientes como se describe para el estad√≠stico \\(\\small{N_{n,k}}\\) en la secci√≥n anterior; En el resto de este cap√≠tulo sobre ensayos en dos Estados, nos centraremos principalmente en el caso de ensayos independientes pero no id√©nticamente distribuidos.\n\n\n\nLa variable aleatoria \\(\\small{M_{n,k}}\\) se define como el n√∫mero \\(\\small{k}\\) de √©xitos consecutivos superpuestos en una sucesi√≥n de \\(\\small{n}\\) ensayos independientes de dos estados. La cadena de Markov incrustada \\(\\small{\\{Y_t:t=0,1,2,\\ldots,n\\}}\\) asociada a \\(\\small{M_{n,k}}\\) puede definirse como\n\n\n\\[\\begin{align*}\nY_t=(M_{t,k},E_t),\\quad t=1,2,\\ldots,n\n\\end{align*}\\]\n\nsobre el espacio de estados\n\n\n\\[\\begin{align*}\n\\Omega &=\\{(x,i):x=0,1,\\cdots,l_n-1\\,\\, \\text{e}\\,\\, i=\\gamma, 0,1,\\cdots,k-1\\} \\\\\n& \\cup \\{(l_n,\\gamma)\\}-\\{(0,\\gamma)\\},\n\\end{align*}\\]\n\ndonde \\(\\small{l_n=n-k+1,\\, M_{n,k}}\\) es el n√∫mero de \\(\\small{k}\\) √©xitos consecutivos superpuestos en las primeros \\(\\small{t}\\) ensayos, y \\(\\small{E_t}\\) es la variable del bloque final que lleva la cuenta del n√∫mero \\(\\small{m}\\) de √©xitos finales:\n\n\n\\[\\begin{equation}\nE_t=\\begin{cases}\n\\gamma & \\text{si}\\, m\\geq k\\\\\nm & \\text{si}\\, m=0,1,\\ldots,k-1.\n\\end{cases}\n\\end{equation}\\]\n\nCon conteo superpuesto, es f√°cil verificar que las probabilidades para las matrices de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M_t}=p_{(x,i)(y,j)}(t)}\\) se pueden obtener a partir de la siguiente ecuaci√≥n:\n\n\n\\[\\begin{equation}\np_{(x,i)(y,j)}(t) =\n\\begin{cases}\nq_t & \\begin{array}{l} \\text{Si}\\,\\, y=x \\,\\, \\text{y}\\,\\, j=0 \\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n \\,\\,\\text{e}\\, i=\\gamma,0,1,\\ldots,k-1 \\end{array} \\\\\np_t & \\begin{array}{l} \\text{Si}\\,\\, y=x \\,\\, \\text{y}\\,\\, j=i+1\\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n \\,\\, \\text{e}\\,\\,i=0,1,\\ldots,k-2 \\end{array}\n\\\\\np_t & \\begin{array}{l} \\text{Si}\\,\\, y=x+1 \\,\\, \\text{y}\\,\\, j=\\gamma\\,\\,\\text{e}\\,\\,i=k-1,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n-1 \\end{array}\n\\\\\np_t & \\begin{array}{l} \\text{Si}\\, y=x+1,\\,j=i=\\gamma\\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n-1  \\end{array}\n\\\\\n1 & \\begin{array}{l} \\text{Si} \\,\\, y=x=l_n,\\,\\text{y}\\ j=i=\\gamma\\end{array} \\\\\n0 & \\begin{array}{l} \\text{Otro caso} \\end{array}\n\\end{cases}\\\\\n\\end{equation}\\]\n\nLa partici√≥n correspondiente del espacio de estados \\(\\small{\\Omega}\\) se puede especificar de la siguiente manera:\n\n\n\\[\\begin{align*}\nC_0 &=\\{(x,i):i=0,1,\\cdots,k-1\\}\\\\\nC_x &=\\{(x,i):i=\\gamma,0,1,\\cdots,k-1\\},\\, x=1,\\cdots,l_n,\\\\\nC_{l_n} &= \\{(l_n,\\gamma)\\}\n\\end{align*}\\]\n\nComo ejemplo considerese, \\(\\small{n=4}\\) y \\(\\small{k=2}\\), luego las matrices de probabilidades de transici√≥n \\(\\small{\\boldsymbol{M_t}(M_{4,2})}\\) para \\(\\small{t=1,2,3,4}\\) son:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M_t}(M_{4,2})=\n\\begin{array}{cc}&\n\\begin{array}{cccccc}\n\\end{array}\n\\\\\n\\begin{array}{cccccc}\n(0,0)\\\\\n(0,1)\\\\\n(1,\\gamma)\\\\\n(1,0)\\\\\n(1,1)\\\\\n(2,\\gamma)\\\\\n(2,0)\\\\\n(2,1)\\\\\n(3,\\gamma)\n\\end{array}\n&\n\\left(\n\\begin{array}{cc|c|cc|c|cc|c}\nq_t&p_t&0&0&0&0&0&0&0\\\\\nq_t&0&p_t&0&0&0&0&0&0\\\\\n\\hline\n0&0&0&q_t&0&p_t&0&0&0\\\\\n\\hline\n0&0&0&q_t&p_t&0&0&0&0\\\\\n0&0&0&q_t&0&p_t&0&0&0\\\\\n\\hline\n0&0&0&0&0&0&q_t&0&p_t\\\\\n\\hline\n0&0&0&0&0&0&q_t&p_t&0\\\\\n0&0&0&0&0&0&q_t&0&p_t\\\\\n\\hline\n0&0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nEn general para \\(\\small{n}\\) y \\(\\small{k}\\) arbitrareos, las matrices de probabilidad de transici√≥n contin√∫an teniendo una forma de bandas similar a \\(\\small{\\boldsymbol{M_t}(M_{4,2})}\\) en la ecuaci√≥n (3.15), y son de dimensi√≥n \\(\\small{l_n(k+1)}\\). La distribuci√≥n y los momentos de la variable aleatoria \\(\\small{M_{n,k}}\\) se pueden calcular nuevamente mediante las ecuaciones (2.11) y (2.12), respectivamente.\n\n\n\nLa Cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) asociada con la variable aleatoria, \\(\\small{E_{n,k}}\\), del n√∫mero de rachas exitosas de tama√±o exactamente \\(\\small{k}\\) en \\(\\small{n}\\) ensayos independientes de dos estados, se define por:\n\n\n\\[\\begin{equation}\nY_t=(E_{t,k},E_t)\n\\end{equation}\\]\n\nsobre el espacio de estados:\n\n\n\\[\\begin{equation}\n\\Omega =\\{(x,i):x=0,1,\\cdots,l_n\\,\\, \\text{e}\\,\\, i=\\beta,\\gamma,0,1,\\cdots,k-1\\}-\\{(0,\\gamma)\\},\n\\end{equation}\\]\n\nen donde, \\(\\small{l_n=[(n+1)/(k+1)]}\\), \\(\\small{E_{t,k}}\\) es el n√∫mero de rachas √©xitosas de longitud igual a \\(\\small{k}\\) en los primeros \\(\\small{t}\\) ensayos, y el bloque final \\(\\small{E_{t}}\\) se define en funci√≥n del n√∫mero de √©xitos finales \\(\\small{m}\\), en los primeros \\(\\small{t}\\) ensayos de la siguiente manera:\n\n\n\\[\\begin{equation}\nE_t=\\begin{cases}\nm & \\text{Si}\\,\\, m=0,1,\\ldots,k-1\\\\\n\\gamma & \\text{Si}\\,\\, m = k\\\\\n\\beta & \\text{Si}\\,\\, m&gt;k\n\\end{cases}\n\\end{equation}\\]\n\nLos dos estados del bloque final \\(\\small{\\beta}\\) e \\(\\small{\\gamma}\\) tienes la siguiente interpretaci√≥n:\n(i) Estado de espera \\(\\small{(x,\\gamma),\\,\\,x=1,2,\\dots,l_n}\\):\n\\(\\small{ Y_t=(x,\\gamma)}\\) significa que \\(\\small{m=k}\\) y que \\(\\small{x-}\\)√©sima racha exitosa de tama√±o \\(\\small{k}\\) ha ocurrido en el \\(\\small{t-}\\)√©simo ensayo, y\n(ii) Estado de desbordamiento \\(\\small{(x,\\beta),\\,\\,x=1,2,\\dots,l_n}\\):\n\\(\\small{ Y_t=(x,\\beta)}\\) significa que \\(\\small{m&gt;k}\\) y que exactamente \\(\\small{x}\\) rachas exitosas de tama√±o \\(\\small{k}\\) han aparecido antes de los √∫ltimos \\(\\small{m+1}\\) resultados \\(\\small{(F\\underbrace{S\\cdots S}_{m})}\\).\nCon estos bloques finales en mente, podemos construir f√°cilmente la partici√≥n para el espacio de estados \\(\\small{\\Omega:\\, C_0=\\{(0,i):i=\\beta,0,1,\\ldots, k-1\\} }\\) y \\(\\small{C_x=\\{(x,i):i=\\gamma,\\beta,0,1,\\ldots, k-1\\} }\\), para \\(\\small{x=1,\\ldots,l_n}\\).\nLas probabilidades para las matrices de transici√≥n \\(\\small{\\boldsymbol{M_t}(E_{t,k})}\\) de la cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\), se especifican mediante la siguiente ecuaci√≥n:\n\n\n\\[\\begin{equation}\np_{(x,i)(y,j)}(t) =\n\\begin{cases}\nq_t & \\begin{array}{l} \\text{Si}\\,\\, y=x \\,\\, \\text{y}\\,\\, j=0 \\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n \\,\\,\\text{e}\\,\\, i=\\gamma,\\beta,0,1,\\ldots,k-1 \\end{array} \\\\\np_t & \\begin{array}{l} \\text{Si}\\,\\, y=x \\,\\, \\text{y}\\,\\, j=i+1\\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n \\,\\, \\text{e}\\,\\,i=0,1,\\ldots,k-2 \\end{array}\n\\\\\np_t & \\begin{array}{l} \\text{Si}\\,\\, y=x+1 \\,\\, \\text{y}\\,\\, j=\\gamma\\,\\,\\text{e}\\,\\,i=k-1,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n-1 \\end{array}\n\\\\\np_t & \\begin{array}{l} \\text{Si}\\,\\, y=x-1,\\,\\,j=\\beta\\,\\, \\,\\,\\text{e}\\,\\, i=\\gamma\\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n  \\end{array}\n\\\\\np_t & \\begin{array}{l} \\text{Si}\\,\\, y=x,\\,\\,\\text{e}\\,\\, j=i=\\beta\\,, \\,\\,\\text{para}\\,\\, x=0,1,\\ldots,l_n  \\end{array}\n\\\\\n1 & \\begin{array}{l} \\text{Si} \\,\\, y=x=l_n\\,\\,\\text{y}\\,\\, j=i=k-1\\end{array} \\\\\n0 & \\begin{array}{l} \\text{Otro caso}. \\end{array}\n\\end{cases}\\\\\n\\end{equation}\\]\n\nA modo de ilustraci√≥n, consideremos el caso \\(\\small{n=5}\\) y \\(\\small{k=2}\\), para lo cual tenemos las matrices de probabilidad de transici√≥n:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M_t}(E_{5,2})=\n\\begin{array}{cc}&\n\\begin{array}{c}\n(0,\\beta)\\\\\n(0,0)\\\\\n(0,1)\\\\\n(1,\\gamma)\\\\\n(1,\\beta)\\\\\n(1,0)\\\\\n(1,1)\\\\\n(2,\\gamma)\\\\\n(2,\\beta)\\\\\n(2,0)\\\\\n(2,1)\n\\end{array}\n&\n\\left(\n\\begin{array}{c|cc|cc|cc|cc|cc}\nq_t&p_t&0&0&0&0&0&0&0&0&0\\\\\n\\hline\n0&q_t&p_t&0&0&0&0&0&0&0&0\\\\\n0&q_t&0&p_t&0&0&0&0&0&0&0\\\\\n\\hline\np_t&0&0&0&0&q_t&0&0&0&0&0\\\\\n0&0&0&0&p_t&q_t&0&0&0&0&0\\\\\n\\hline\n0&0&0&0&0&q_t&p_t&0&0&0&0\\\\\n0&0&0&0&0&q_t&0&p_t&0&0&0\\\\\n\\hline\n0&0&0&0&p_t&0&0&0&0&q_t&0\\\\\n0&0&0&0&0&0&0&0&p_t&q_t&0\\\\\n\\hline\n0&0&0&0&0&0&0&0&0&q_t&p_t\\\\\n0&0&0&0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nEn general, las matrices de probabilidad de transici√≥n de la cadena de Markov \\(\\small{\\{Y_t\\}}\\) asociadas con \\(\\small{E_{n,k}}\\) tienen la forma dada por la ecuaci√≥n (3.19) con dimensi√≥n \\(\\small{(l_n + 1)(k+1)+l_n}\\).\n\n\n\nSea \\(\\small{L_n(S)}\\), la duraci√≥n de la racha exitosa m√°s larga en una sucesi√≥n de ensayos de dos estados. Para el caso de \\(\\small{n}\\) lanzamientos independientes de una moneda justa, sea \\(\\small{A_n(k)}\\) el n√∫mero de secuencias de longitud \\(\\small{n}\\) en las que la racha m√°s larga de √©xitos (cara) es menor o igual a \\(\\small{k}\\). Dado que todas las sucesiones son igualmente probables con probabilidad \\(\\small{(1/2)^n}\\), la distribuci√≥n del racha m√°s largo es:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(L_n(S)\\leq k\\big)=2^{-n}A_n(k)\n\\end{equation}\\]\n\ndonde \\(\\small{A_n(k)}\\) satisface la ecuaci√≥n recursiva (Schilling 1990)\n\n\n\\[\\begin{equation}\nA_n(k)=\\begin{cases}\n\\displaystyle\\sum_{j=0}^{k}A_{n-1-j}(k) & \\text{si}\\, n &gt; k\\\\\n2^{n} & \\text{si}\\,\\, n \\leq k\\\\\n1 & \\text{si}\\,\\, k = 0\\\\\n\\end{cases}\n\\end{equation}\\]\n\nPara monedas sesgadas \\(\\small{(p\\neq1/2)}\\), el an√°lisis combinatorio es:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(L_n(S)\\leq k\\big)=\\displaystyle\\sum_{x=0}^{k}C_{n}^{(x)}(k)p^{x}q^{n-x},\n\\end{equation}\\]\n\npara \\(\\small{1 \\leq k \\leq n}\\), y \\(\\small{\\mathbb{P}\\big(L_n(S)=0 \\big)=q^{-n}}\\), donde \\(\\small{C_n^{(x)}(k)}\\) es el n√∫mero de secuencias de longitud \\(\\small{n}\\) en las que ocurren exactamente \\(\\small{x}\\) √©xitos, pero en las que no m√°s de \\(\\small{k}\\) de estos √©xitos ocurren consecutivamente. \\(\\small{C_n^{(x)}(k)}\\) se puede obtener a trav√©s de la ecuaci√≥n recursiva:\n\n\n\\[\\begin{equation}\nC_n^{(x)}(k)=\\begin{cases}\n\\displaystyle\\sum_{j=0}^{k}C_{n-1-j}^{x-j}(k) & \\text{si}\\,\\,  k&lt;x&lt;n\\\\\n\\binom{n}{x} & \\text{si}\\,\\,  x \\leq k \\leq n\\\\\n\\, 0 & \\text{si}\\,\\,k&lt;x= n\\\\\n\\end{cases}\n\\end{equation}\\]\n\nDe manera m√°s general, supongamos que las probabilidades de √©xito y fracaso podr√≠an ser diferentes en cada ensayo, iguales a \\(\\small{p_t}\\) y \\(\\small{q_t}\\), respectivamente, para \\(\\small{t=1,2,\\ldots,n}\\). El siguiente teorema deriva la distribuci√≥n de \\(\\small{L_n(S)}\\):\nTeorema 3.1 Para \\(\\small{0\\leq k\\leq n}\\),\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(L_n(S)\\leq k\\big)=\\boldsymbol{\\mathbf{\\xi}} \\Big(\\prod_{t=1}^{n}\\boldsymbol{N}_t\\Big)\\boldsymbol{\\mathbf{1}'}_{1 \\times(k+1)}\n\\end{equation}\\]\n\nen donde \\(\\small{\\boldsymbol{\\mathbf{\\xi}}=(1,0,\\ldots,0)}\\) es un vector fila unitario de tama√±o \\(\\small{1\\times (k+1)}\\) y \\(\\small{\\boldsymbol{N_t}}\\) es como se indica a continuaci√≥n, la submatriz esencial \\(\\small{(k+1)\\times (k+1)}\\) de la matriz de probabilidades de transici√≥n:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M_t}=\n\\begin{array}{cc}&\n\\begin{array}{c}\n0\\\\\n1\\\\\n\\vdots\\\\\n\\vdots\\\\\nk\\\\\n\\alpha\n\\end{array}\n&\\left(\n\\begin{array}{ccccc|c}\nq_t&p_t&0&\\cdots&0&0\\\\\nq_t&0&p_t&\\cdots&0&0\\\\\n\\vdots&&\\ddots&\\ddots&&\\vdots\\\\\n\\vdots&&\\ddots&\\ddots&\\ddots&\\vdots\\\\\nq_t&0&\\cdots&\\cdots&0&p_t\\\\\n\\hline\n0&0&\\cdots&\\cdots&0&1\\\\\n\\end{array}\n\\right)_{(k+2) \\times (k+2)}\n\\end{array}=\\left(\\begin{array}{c|c}\n\\boldsymbol{N_t} &  {C_t}\\\\\n\\hline\n\\boldsymbol{0}&  {1}\\\\\n\\end{array}\n\\right)\n\\end{equation}\\]\n\nDemostraci√≥n: La racha exitosa m√°s larga en una sucesi√≥n de ensayos de dos estados est√° relacionada con las estad√≠sticas de ejecuci√≥n \\(\\small{N_{n,k}}\\), \\(\\small{G_{n,k}}\\) y \\(\\small{M_{n,k}}\\) de la siguiente manera sencilla:\n\n\n\\[\\begin{equation}\nL_n(S)\\leq k \\,\\, \\text{si y solo si}\\,\\, N_{n,k+1} = G_{n,k+1}=M_{n,k+1}=0\n\\end{equation}\\]\n\nPor tanto, \\(\\small{\\mathbb{P}\\big(L_n(S)\\leq k\\big)=\\mathbb{P}\\big(N_{n,k+1}=0\\big)}\\), y podemos completar la demostraci√≥n considerando la Ecuaci√≥n (3.8) para \\(\\small{\\mathbb{P}\\big(N_{n,k+1}=x\\big)}\\) con \\(\\small{x=0}\\). Cambiando los estados \\(\\small{(0,0),(0,1),\\ldots,(0,k)}\\) en esta aplicaci√≥n de la Ecuaci√≥n (3.8) a los estados \\(\\small{0,1,2,\\ldots,k}\\) respectivamente, y combinando todos los dem√°s estados en el estado absorbente \\(\\small{\\alpha}\\), obtenemos:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(L_n(S)\\leq k\\big)=\\mathbb{P}\\big(N_{n,k+1}=0\\big)=\\boldsymbol{\\mathbf{\\xi}_0} \\Big(\\prod_{t=1}^{n}\\boldsymbol{M}_t\\Big)(1,\\ldots,1,0)'\n\\end{equation}\\]\n\nen donde \\(\\small{\\boldsymbol{\\xi_0}=(1,0\\ldots,0)_{1\\times(k+2)}=(\\boldsymbol{\\xi}:0)}\\). Con la notaci√≥n \\(\\small{(1,\\ldots,1,0)_{1\\times(k+2)}=(\\boldsymbol{1}:0)}\\) y haciendo uso del hecho que las matrices de transici√≥n de probabilidad tienen la forma:\n\n\n\\[\\begin{equation}\n\\prod_{t=1}^{n}\\boldsymbol{M_t}=\n\\left(\n\\begin{array}{c|c}\n\\displaystyle\\prod_{t=1}^{n}\\boldsymbol{N_t}& C_t(n)\\\\\n\\hline\n\\boldsymbol{0}&1\n\\end{array}\n\\right)\n\\end{equation}\\]\n\nluego, el teorema se sigue inmediatamente. \\(\\hspace{3cm}\\Box\\)\nColorario Dados \\(\\small{1 \\leq k \\leq n}\\) se satisface la siguiente ecuaci√≥n recursiva:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(L_n(S)\\leq k\\big)=q_n\\cdot\\mathbb{P}\\big(L_{n-1}(S)\\leq k\\big)+\\displaystyle\\sum_{i=1}^{k}q_{n-i} \\prod_{j=n-i+1}^{n}p_{j}\\cdot\\mathbb{P}\\big(L_{n-i-1}(S)\\leq k\\big)\n\\end{equation}\\]\n\ncon \\(\\small{\\mathbb{P}\\big(L_n(S)=0\\big)=\\displaystyle\\prod_{j=1}^{n}q_j}\\) y \\(\\small{\\mathbb{P}\\big(L_n(S)\\leq n\\big)\\equiv1}\\) para \\(\\small{k=m}.\\)\nDemostraci√≥n De la estructuradada dada por la Ec.(3.25) para las matrices de probabilidades de transici√≥n \\(\\small{\\boldsymbol{M_t}}\\), se sigue que:\n\n\n\\[\\begin{align*}\n\\text{(i)}\\,\\, \\boldsymbol{M_te_0'} &=q_t(1,\\ldots,1,0)'_{1\\times(k+2)}\\,\\, \\text{y} \\\\\n\\text{(ii)}\\,\\,\\boldsymbol{M_te_i'} &=p_t\\boldsymbol{e_{i-1}'},\\,\\,\\text{para}\\,\\, i=1,2,\\ldots,k,\n\\end{align*}\\]\n\nen donde \\(\\small{\\boldsymbol{e_i}=(0,\\ldots,0,1,0,\\ldots,0)}\\) es un vector fila unitario con un uno en la coordenada asociada al estado \\(\\small{i}\\), para \\(\\small{i=0,1,2,\\ldots,k}\\).\nDado que \\(\\small{\\displaystyle\\sum_{i=0}^{k}\\boldsymbol{e_i'}}\\), nuestro resultado es una consecuencia directa de (i),(ii) y multiplicaciones hacia atr√°s de la ecuaci√≥n (3.24).\nTomando \\(\\small{p_t=q_t=1/2}\\) para todo \\(\\small{t=1,2,\\ldots,n}\\) y multiplicando \\(\\small{\\mathbb{P}\\big(L_n(S)\\leq k\\big)=1}\\) por \\(\\small{2^n}\\), la ecuaci√≥n (3.26) produce la ecuaci√≥n recursiva (3.21) para \\(\\small{A_n(k)}\\). El teorema 3.1 tambi√©n se puede extender para la rachas de falla m√°s larga \\(\\small{L_n(F)}\\) y a la estad√≠stica de racha m√°s larga \\(\\small{L_n = \\max\\{L_n(S), L_n(F)\\}}\\). Para el caso i.i.d. y para \\(\\small{n}\\) grande, hay varios resultados sobresalientes sobre la duraci√≥n de la racha exitosa m√°s larga. R√©nyi (1970), Cs√∂rg√∂ (1979), Erd√∂s y R√©nyi (1970) y Erd√∂s y R√©v√©sz (1975) muestran que, cuando \\(\\small{n \\rightarrow \\infty}\\)\n\n\n\\[\\begin{equation}\n\\frac{L_n(S)}{\\log_{1/p}(n)} \\xrightarrow{a.s} 1\n\\end{equation}\\]\n\nA este resultado se le suele denominar la nueva ley de los grandes n√∫meros.\nEn el Cap√≠tulo 5, desarrollaremos una aproximaci√≥n de grande desviaci√≥n para la probabilidad de \\(\\small{L_n(S)}\\) bajo ensayos i.i.d. (y Markov-Dependientes homog√©neos):\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(L_n(S)\\leq  k\\big)\\sim \\exp\\{-n\\beta\\}\n\\end{equation}\\]\n\nen donde \\(\\small{\\beta=-\\log(\\lambda_{[1]})}\\) y \\(\\small{\\lambda_{[1]}}\\) es el valor propio m√°s grande de la submatriz de probabilidad de transici√≥n esencial \\(\\small{\\boldsymbol{N_t}}\\) (con \\(\\small{p_t}\\) y \\(\\small{q_t}\\) constantes) dada por la ecuaci√≥n (3.25).\n\n\n\nSea \\(\\small{\\Lambda=S\\cdots S}\\) el patr√≥n simple de \\(\\small{k}\\) √©xitos consecutivos y defina la variable aleatoria \\(\\small{W(\\Lambda)}\\) como el tiempo de espera para que ocurra el patr√≥n \\(\\small{\\Lambda}\\), es decir \n\n\\[\\begin{equation}\nW(\\Lambda)=\\inf\\{n:X_{n-k+1}=X_{n-k+2}=\\cdots=X_{n}=S\\}.\n\\end{equation}\\]\n\nPor ejemplo, dado \\(\\small{k=3}\\), \\(\\small{W(\\Lambda)=6}\\) significa que el patr√≥n \\(\\small{SSS}\\) ocurre por primera vez despu√©s de seis intentos, como en \\(\\small{SFFSSS}\\). La distribuci√≥n de \\(\\small{W(\\Lambda)}\\) para los ensayos de Bernoulli a menudo se denomina distribuci√≥n geom√©trica de orden \\(\\small{k}\\) (ver Aki 1985 e Hirano 1986).\nTeorema 3.2 Dado un patr√≥n de longitud \\(\\small{k\\geq 1}\\) y una sucesi√≥n de ensayos Bernoulli \\(\\small{\\{X_t\\}}\\), la distribuci√≥n de \\(\\small{W(\\Lambda)}\\) esta dada por:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(W(\\Lambda)=n\\big)=\\boldsymbol{\\xi} \\boldsymbol{N_t}^{n-1}(\\Lambda)\\big(\\boldsymbol{I-N}(\\Lambda)\\big)\\boldsymbol{1'}\n\\end{equation}\\]\n\nen donde \\(\\small{\\boldsymbol{\\xi}=(1,0,\\ldots,0)}\\) es un vector fila \\(\\small{1\\times k}\\) y \\(\\small{\\boldsymbol{N}(\\Lambda)}\\) es la submatriz de probabilidades de transici√≥n esencial:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}(\\Lambda)=\n\\begin{array}{cc}&\n\\begin{array}{c}\n0\\\\\n1\\\\\n\\vdots\\\\\n\\vdots\\\\\nk-1\\\\\n\\alpha\n\\end{array}\n&\\left(\n\\begin{array}{ccccc|c}\np&q&0&\\cdots&0&0\\\\\nq&0&p&\\cdots&0&0\\\\\n\\vdots& &\\ddots&\\ddots&&\\vdots\\\\\n\\vdots&&\\ddots&\\ddots&\\ddots&\\vdots\\\\\nq&0&\\cdots&\\cdots&0&p\\\\\n\\hline\n0&0&\\cdots&\\cdots&0&1\\\\\n\\end{array}\n\\right)_{(k+1)\\times(k+1)}\n\\end{array}=\n\\left(\n\\begin{array}{c|c}\n\\boldsymbol{N}(\\Lambda)&C\\\\\n\\hline\n\\boldsymbol{0} & 1\n\\end{array}\\right)\n\\end{equation}\\]\n\nSe deduce adem√°s que la funci√≥n generadora de probabilidad de \\(\\small{W(\\Lambda)}\\) est√° dada por:\n\n\n\\[\\begin{equation}\n\\varphi_{W}(s)=\\frac{p^ks^k(1-ps)}{1-s+qp^ks^{k+1}}\n\\end{equation}\\]\n\nPrueba. Dados \\(\\small{\\Lambda}\\),\\(\\small{}\\) y \\(\\small{k \\leq n}\\), de la definici√≥n de \\(\\small{W(\\Lambda)}\\) y \\(\\small{N_{n,k}}\\), se deduce que estas dos variables aleatorias tienen la siguiente relaci√≥n:\n\n\n\\[\\begin{equation}\nW(\\Lambda) \\leq n \\quad \\text{si y solo si}\\quad N_{n,k}\\geq 1 \\,\\,\\text{para todo }\\, n \\geq k.\n\\end{equation}\\]\n\nPor tanto \\(\\small{\\mathbb{P}\\big(W(\\Lambda)\\leq n\\big)=\\mathbb{P}\\big(N_{n,k}\\geq 1\\big)}\\) y\n\n\n\\[\\begin{align*}\n\\mathbb{P}\\big(W(\\Lambda)\\leq n\\big) &= \\mathbb{P}\\big(N_{n,k}\\geq 1\\big)-\\mathbb{P}\\big(N_{n-1,k}\\geq 1\\big), \\\\\n&=  \\mathbb{P}\\big(N_{n-1,k}= 0\\big)-\\mathbb{P}\\big(N_{n,k}= 0\\big).\n\\end{align*}\\]\n\nPuesto que s√≥lo necesitamos el resultado general de \\(\\small{\\mathbb{P}\\big(N_{n,k}= 0\\big)}\\) para completar la prueba, podemos, como en la secci√≥n anterior sobre la racha exitosa m√°s larga, reemplazar los estados \\(\\small{(0,0),\\cdots,(0,k-1)}\\) definidos en la Secci√≥n 3.2 por los estados \\(\\small{0,1,2,\\ldots,k-1}\\) y combinar todos los dem√°s estados en un estado absorbente \\(\\small{\\alpha}\\). Bajo este espacio de estados reducido, la matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M_t}(N_{n,k})}\\) se simplifica a \\(\\small{\\boldsymbol{M}(\\Lambda)}\\). La ecuaci√≥n (3.27) del teorema 3.2 es entonces una consecuencia inmediata de las ecuaciones (3.8), (3.30) y Teorema 3.1.\nNote que, para \\(\\small{0\\leq i\\leq k-1,}\\)\n\n\n\\[\\begin{equation}\n\\boldsymbol{e_iN}(\\Lambda)=q\\boldsymbol{e_0}+p\\boldsymbol{e_{i+1}}.\n\\end{equation}\\]\n\nDado \\(\\small{\\boldsymbol{\\xi=e}_0}\\), y usando del resultado de multiplicaci√≥n hacia adelante obtenemos la siguiente ecuaci√≥n recursiva:\n\n\n\\[\\begin{align*}\n\\mathbb{P}\\big(W(\\Lambda)= n\\big) &= \\boldsymbol{\\xi N}^{n-1}(\\Lambda)\\big(\\boldsymbol{I-N}(\\Lambda)\\big)\\boldsymbol{1'} \\\\\n&= \\sum_{i=1}^{k}qp^{i-1}\\mathbb{P}\\big(W(\\Lambda)=n-i\\big).\n\\end{align*}\\]\n\nLa anterior ecuaci√≥n recursivay la condici√≥n de frontera \\(\\small{\\mathbb{P}\\big(W(\\Lambda)=k\\big)=p^{k}}\\) conducen a la siguiente ecuaci√≥n recursiva para la funci√≥n generadora de probabilidad \\(\\small{\\varphi_{W}(s)}\\):\n\n\n\\[\\begin{equation}\n\\varphi_{W}(s)= s^kp^k+\\sum_{i=1}^{k}qp^{i-1}s^{i}\\varphi_{W}(s)\n\\end{equation}\\]\n\nSumando las series de potencias finitas se obtiene el resultado expl√≠cito para \\(\\small{\\varphi_{W}(s)}\\) dado en la Ec. (3.29), resultado que fue derivado por primera vez por Feller (1968) utilizando la teor√≠a de la renovaciones.\\(\\hspace{3cm}\\Box\\)\nSi definimos las matrices:\n\n\n\\[\\begin{equation}\n\\boldsymbol{A}=\\left(\n\\begin{array}{ccccc}\nq&p&0&\\cdots&0\\\\\nq&0&p& &0\\\\\n\\vdots& &\\ddots&\\ddots& \\\\\nq& & &0&p\\\\\nq&0&\\cdots&&0\\\\\n\\end{array}\n\\right)_{k\\times k},\\,\n\\boldsymbol{B}=\\left(\n\\begin{array}{ccccc}\n0&0&0&\\cdots&0\\\\\n0&0&0& &\\\\\n\\vdots& &\\ddots&\\ddots& \\\\\n0& & &0&0\\\\\np&0&\\cdots&&0\\\\\n\\end{array}\n\\right)_{k\\times k}\n\\end{equation}\\]\n\n\n\n\\[\\begin{equation}\n\\boldsymbol{A}^{\\ast}=(1)_{1\\times 1}\\,\\, \\text{y}\\,\\, \\boldsymbol{B}^{\\ast}=(0\\,\\,0\\,\\,\\cdots \\, 0\\,\\,p)'_{k\\times 1}\n\\end{equation}\\]\n\ny sea \\(\\small{W(m,\\Lambda)}\\) el tiempo de espera para la \\(\\small{m-}\\)√©sima racha de \\(\\small{k}\\) √©xitos consecutivos (sin solapamiento). De forma similar al desarrollo anterior para \\(\\small{W(\\Lambda)}\\), la distribuci√≥n de la variable aleatoria \\(\\small{W(m,\\Lambda)}\\) puede ser obtenida usando la Ecuaci√≥n (3.27) al remplazar la matriz de probabilidades de transici√≥n \\(\\small{W(\\Lambda)}\\), por:\n\n\n\\[\\begin{equation}\n\\boldsymbol{W}(m,\\Lambda)=\\left(\n\\begin{array}{ccccc}\n\\boldsymbol{A}&\\boldsymbol{A}& &\\boldsymbol{O}&\\\\\n&\\ddots & \\ddots& &\\\\\n& &\\boldsymbol{A}&\\boldsymbol{B}& \\\\\n&\\boldsymbol{O} &&\\boldsymbol{A}&\\boldsymbol{B^{\\ast}}\\\\\n& & &&\\boldsymbol{A^{\\ast}}\\\\\n\\end{array}\n\\right)_{(mk+1)\\times (mk+1)}\n\\end{equation}\\]\n\nObs√©rvese que la matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M}(\\Lambda)}\\) de la Ec. (3.28) es el caso especial de \\(\\small{\\boldsymbol{M}(m,\\Lambda)}\\) con \\(\\small{m=1}\\). Puesto que \\(\\small{W(m,\\Lambda)=\\displaystyle\\sum_{i=1}^{m}W_i(\\Lambda)}\\), donde \\(\\small{W_i(\\Lambda)}\\) representa el tiempo de espera desde la \\(\\small{(i-1)-}\\)√©sima ocurrencia hasta la \\(\\small{(i)-}\\)√©sima ocurrencia del patr√≥n \\(\\small{\\Lambda}\\), y puesto que las variables aleatorias \\(\\small{W(\\Lambda)}\\) son i.i.d., se deduce de la Ec. (3.29) que la funci√≥n generadora de probabilidad de \\(\\small{W(m,\\Lambda)}\\) es:\n\n\n\\[\\begin{equation}\n\\varphi_{W(m,\\Lambda)}^{m}(s)=\\varphi_{W}^{m}(s)=\\Bigg(\\frac{p^ks^k(1-ps)}{1-s+qp^ks^{k+1}}\\Bigg)^{m}.\n\\end{equation}\\]\n\nLa funci√≥n generadora de probabilidad \\(\\small{\\varphi_{W}(s)}\\) siempre existe para todo \\(\\small{|s| \\leq 1}\\)\nEsto se desprende de su definici√≥n y del hecho de que:\n\n\n\\[\\begin{equation}\n|\\varphi_{W}(s)|\\leq\\sum_{n=1}^{\\infty}|s^{n}|\\cdot\\mathbb{P}(W=n)\\leq\\sum_{n=1}^{\\infty}\\mathbb{P}(W=n)=1.\n\\end{equation}\\]\n\nSin embargo, la funci√≥n generadora de probabilidad \\(\\small{\\varphi_{W}(s)}\\) puede existir m√°s all√° de la regi√≥n \\(\\small{|s| \\leq 1}\\). La regi√≥n exacta var√≠a de un problema a otro. Volveremos a discutir la mayor regi√≥n de existencia de \\(\\small{\\varphi_{W}(s)}\\) en la secci√≥n 5.7.\nLa distribuci√≥n de \\(\\small{W(m,\\Lambda)}\\) tambi√©n puede obtenerse mediante la ecuaci√≥n\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(W(m,\\Lambda)=n\\big)=\\frac{1}{n!}\\frac{d^{n}}{ds^{n}}\\varphi_{W(m,\\Lambda)}(s)\\Bigr|_{s=0}.\n\\end{equation}\\]\n\nenfoque que puede obtenerse m√°s f√°cilmente utilizando software de manipulaci√≥n simb√≥lica (por ejemplo, MAPLE o MATLAB). En el cap√≠tulo 5 se ofrece un tratamiento m√°s detallado de las distribuciones de tiempo de espera para patrones simples y compuestos en ensayos i.i.d. y Markov-Dependientes multiestado.\n\n\n\nAntes de estudiar estad√≠sticas de rachas m√°s complejas, en esta secci√≥n proporcionamos algunos resultados num√©ricos para las estad√≠sticas de rachas y los tiempos de espera descritos en las secciones anteriores con el fin de ilustrar los resultados te√≥ricos. Dada la matriz (o matrices) de probabilidad de transici√≥n de la cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) , en general s√≥lo necesitamos dos tipos de f√≥rmulas, en las formas de las Ecs. (3.8) y (3.27), para evaluar las distribuciones de \\(\\small{X_n(\\Lambda)}\\) y \\(\\small{W(\\Lambda)}\\), respectivamente. Las f√≥rmulas son sencillas y eficientes desde el punto de vista computacional, adecuadas incluso para \\(\\small{n}\\) muy grandes. Los resultados num√©ricos que aqu√≠ se presentan tambi√©n pueden servir para comprobar los propios c√°lculos de programaci√≥n. En todos los ejemplos considerados, el tiempo de c√°lculo para obtener cada distribuci√≥n es m√≠nimo, una fracci√≥n de segundo en un PC actual.\nEn la Tabla 3.1 se presentan las distribuciones exactas y las medias de las variables aleatorias \\(\\small{E_{15,2},\\, G_{15,2},\\,N_{15,2},\\, M_{15,2}}\\) y \\(\\small{L_{15}(S)}\\) bajo el supuesto de que \\(\\small{\\{X_t\\}}\\)es una secuencia de ensayos independientes de dos estados con probabilidades \\(\\small{p_t=1/(t+1)}\\) para \\(\\small{t=1,2,\\ldots,15}\\).\nLa Tabla 3.2 muestra las distribuciones del tiempo de espera de la primera racha con √©xito de longitud \\(\\small{k}\\), para varios valores de \\(\\small{k}\\) y probabilidades de estado \\(\\small{p_t}\\). En los cap√≠tulos 5 y 7 se ofrecen m√°s resultados num√©ricos sobre las distribuciones del tiempo de espera.\n\n\n\nSea \\(\\small{S_{n,k}}\\) el n√∫mero total de √©xitos en rachas de √©xitos de longitud mayor o igual que \\(\\small{}\\), para \\(\\small{k=1,2,\\ldots,n}\\). Puede escribirse como\n\n\n\\[\\begin{equation}\nS_{n,k}=\\sum_{i=k}^{n}iR_n(i),\n\\end{equation}\\]\n\nen donde \\(\\small{R_n(i)}\\), para \\(\\small{i=k,\\ldots,n}\\) es el n√∫mero de rachas √©xitosas de longitud exactamente igual a \\(\\small{i}\\) en una sucesi√≥n \\(\\small{\\{X_t\\}}\\). Para \\(\\small{k=1}\\), la Ec. (3.33) es equivalente al n√∫mero total de √©xitos en la sucesi√≥n \\(\\small{\\{X_t\\}}\\), es decir:\n\n\n\\[\\begin{equation}\nS_{n,1}=\\sum_{i=k}^{n}I_{X_i},\n\\end{equation}\\]\n\nen donde \\(\\small{I_{X_i}=1}\\) cuando el \\(\\small{i-}\\)√©simo ensayo es √©xito y cero en otro caso. Si \\(\\small{\\{X_t\\}}\\) es una sucesi√≥n de ensayos Bernoulli, entonces \\(\\small{S_{n,1}}\\) tiene distribuciones binomial exacta y normal en el l√≠mite, respectivamente. De manera m√°s general, para el caso \\(\\small{\\{X_t\\}}\\) es una sucesi√≥n de variables aleatorias Markov-Dependientes, la estad√≠stica \\(\\small{S_{n,k}}\\) tambi√©n tiene una distrubuci√≥n l√≠mite normal, como determino Nagaev (1957) para \\(\\small{k=1}\\) y Fu, Lou, Bai y Li (2002) para \\(\\small{k \\geq 2}\\). En esta secci√≥n, s√≥lo estudiamos la distribuci√≥n exacta de \\(\\small{S_{n,k}}\\) con \\(\\small{k \\geq 2}\\).\nSea \\(\\small{L_j}\\), para \\(\\small{j \\geq 2}\\), la longitud de la racha de √©xitos situada entre el \\(\\small{(j-1)-}\\)√©simo y el \\(\\small{j-}\\) √©simo fallo en la sucesi√≥n \\(\\small{\\{X_t\\}}\\), con \\(\\small{L_1=0}\\) si el primer ensayo es un fallo y \\(\\small{L_1=l}\\) si los primeros \\(\\small{l}\\) ensayos son √©xitos y el \\(\\small{(j+1)-}\\)√©simo ensayo es un fallo. Para un √≠ndice de tiempo \\(\\small{t}\\) dado, sea \\(\\small{m_t}\\) el n√∫mero de fracasos en la subsecuencia \\(\\small{X_1, X_2,\\ldots, X_t}\\) y sea \\(\\small{L_t^{\\star}}\\) el n√∫mero de √©xitos que se producen despu√©s del \\(\\small{m_t-}\\)√©simo fracaso en esta subsecuencia. N√≥tese que \\(\\small{0 \\leq L_{t}^{\\star} \\leq t}\\) y \\(\\small{0\\leq L_t^{\\star} \\leq L_{m_t+1}}\\). Por otra parte, \\(\\small{S_{t,k}}\\), tal como se define en la Ec. (3.33), tambi√©n se puede escribir como:\n\n\n\\[\\begin{equation}\nS_{t,k}=\\sum_{j=1}^{m_t}L_{j}(k)+L_t^{\\star}(t),\n\\end{equation}\\]\n\ncon \n\n\\[\\begin{equation}\nL_{j}(k)=L_j\\cdot I_{\\{L_j\\geq k\\}}\\quad \\text{y}\\quad L_{j}^{\\star}(k)=L_j^{\\star}\\cdot I_{\\{L_j^{\\star} \\geq k\\}}.\n\\end{equation}\\]\n\nAc√° \\(\\small{I_{\\{L_j \\geq k\\}}}\\), es la funci√≥n indicadora del evento \\(\\small{\\{L_j \\geq k\\}}\\), es decir, es igual a uno cuando (\\(\\small{I_{\\{L_j^{\\star} \\geq k\\}}}\\), se define de manera an√°loga) Para capturar la informaci√≥n relevante en la subsucesi√≥n \\(\\small{\\{X_1,X_2,\\cdots, X_t\\}}\\) definimos una nueva sucesi√≥n de variables aleatorias en la forma del vector de dos componentes\n\n\n\\[\\begin{equation}\nY_t=\\big( S_{t,k},E_{t}(t)\\big),\\,\\, t=1,2,\\ldots,n,\n\\end{equation}\\]\n\nen donde \\(\\small{S_{t,k}}\\) indica el n√∫mero total de √©xitos en rachas exitosas de longitud mayor o igual a \\(\\small{k}\\) en los primeros \\(\\small{t}\\) ensayos, y \\(\\small{E_{t}(k)}\\) es la variable aleatoria de bloque final dada por:\n\n\n\\[\\begin{equation}\nE_{t}(k)= L_{t}^{\\star}\\big(1-I_{\\{L_j^{\\star}\\geq k\\}}\\big)+k^{+}\\cdot I_{\\{L_j^{\\star} \\geq k\\}}.\n\\end{equation}\\]\n\nEn esta expresi√≥n, el s√≠mbolo \\(\\small{k^{+}}\\) representa el estado donde \\(\\small{L_t}\\) es mayor o igual que \\(\\small{k}\\).\nEl bloque final \\(\\small{E_t(k)}\\) representa la longitud de la racha de √©xitos contando hacia atr√°s desde el \\(\\small{t-}\\)√©simo ensayo, con \\(\\small{E_t(k)=0}\\) si el \\(\\small{t-}\\)√©simo ensayo es un fracaso y \\(\\small{E_t(k)=k^{+}}\\) si la longitud es mayor o igual a \\(\\small{k}\\). M√°s espec√≠ficamente, considere que desde el 1 \\(\\small{ m_t-}\\)√©simo (o m√°s reciente) fracaso \\(\\small{F}\\) hasta el final de la subsucesi√≥n \\(\\small{\\{X_1,X_2,\\cdots, X_t\\}}\\) s√≥lo podemos tener los siguientes resultados posibles: \\(\\small{\\{F,FS,\\cdots,FS\\cdots S,\\,\\text{or}\\, S\\cdots S\\, \\text{si } m_t = 0\\}}\\); la variable aleatoria \\(\\small{E_t(k)}\\) es igual al n√∫mero de √©xitos en estos resultados si el n√∫mero es menor que \\(\\small{k}\\), y \\(\\small{E_t(k)=k^{+}}\\) si es igual o mayor que \\(\\small{k}\\). Este bloque final de los primeros \\(\\small{t}\\) ensayos proporciona informaci√≥n esencial sobre las probabilidades de transici√≥n de \\(\\small{Y_t}\\) a \\(\\small{Y_{t+1}}\\).\nDefinimos el espacio de estados\n\n\n\\[\\begin{equation}\n\\Omega =\\{(u,v):u=0,k,\\cdots,n-1,n\\,\\, \\text{y}\\,\\, v=0,1,\\cdots,k-1,k^{+}\\},\n\\end{equation}\\]\n\ncon tama√±o \\(\\small{d=\\text{card}(\\Omega)=(n-k+2)(k+1)}\\), y consideraremos aqu√≠ el caso en que la sucesi√≥n \\(\\small{\\{X_t\\}}\\) es una cadena de Markov homog√©nea con probabilidades de transici√≥n \\(\\small{p_{FF},p_{Fs},p_{SF}}\\) y \\(\\small{p_{SS}}\\). En nuestro procedimiento de recuento, la sucesi√≥n de vectores aleatorios \\(\\small{Y_t=\\big( S_{t,k},E_{t}(t)\\big),\\,\\, t=1,2,\\ldots,n,}\\) definida en \\(\\small{\\Omega}\\) obedece las siguientes reglas:\n(i) Dado \\(\\small{Y_{t-1}=(x,0)}\\), entonces \\(\\small{Y_{t}=(x,0)}\\) con probabilidad \\(\\small{p_{FF}}\\) si el resultado del \\(\\small{t-}\\)√©simo ensayo es \\(\\small{F}\\), e \\(\\small{Y_{t}=(x,1)}\\) con probabilidad \\(\\small{p_{FS}}\\) si el resultado del \\(\\small{t-}\\)√©simo ensayo es \\(\\small{S}\\).\n(ii) Dado \\(\\small{Y_{t-1}=(x,y)}\\) para \\(\\small{1\\leq y \\leq k-2}\\) entonces \\(\\small{Y_{t}=(x,0)}\\) con probabilidad \\(\\small{p_{SF}}\\) si el resultado del \\(\\small{t-}\\)√©simo ensayo es \\(\\small{F}\\), e \\(\\small{Y_{t}=(x,y+1)}\\) con probabilidad \\(\\small{p_{SS}}\\) si el resultado del \\(\\small{t-}\\)√©simo ensayo es \\(\\small{S}\\).\n(iii) Dado \\(\\small{Y_{t-1}=(x,k-1)}\\), entonces \\(\\small{Y_{t}=(x,0)}\\), con probabilidad \\(\\small{p_{SF}}\\) si el resultado del \\(\\small{t-}\\)√©simo ensayo es \\(\\small{F}\\), e \\(\\small{Y_{t-1}=(x+k,k^{+})}\\), con probabilidad \\(\\small{p_{SS}}\\) si el resultado del \\(\\small{t-}\\)√©simo ensayo es \\(\\small{S}\\).\n(iv) Dado \\(\\small{Y_{t-1}=(x,k^{+})}\\), entonces \\(\\small{Y_{t}=(x,0)}\\) con probabilidad \\(\\small{p_{SF}}\\) si el resultado del \\(\\small{t-}\\)√©simo ensayo es \\(\\small{F}\\), e \\(\\small{Y_{t}=(x+1,k^{+})}\\) con probabilidad \\(\\small{p_{SS}}\\) si el resultado del \\(\\small{t-}\\)√©simo prueba es \\(\\small{S}\\).\nA la vista de nuestra construcci√≥n, la sucesi√≥n \\(\\small{\\{Y_t = \\big( S_{t,k}, E_t(k) \\big) : t = 1, 2,..., n\\}}\\) forma una cadena de Markov homog√©nea con matriz de probabilidad de transici√≥n:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\\big( p_{(x,y)\\times(u,v)}\\big)_{d\\times d}\n\\end{equation}\\]\n\ndonde las probabilidades de transici√≥n \\(\\small{p_{(x,y)\\times(u,v)}}\\), bajo orden lexicogr√°fico de los estados \\(\\small{(\\cdot,\\cdot)}\\), se pueden especificar expl√≠citamente de la siguiente manera. Dado \\(\\small{(x,y)\\in \\Omega}\\),\n\n\n\\[\\begin{equation}\np_{(x,y)(u,v)}(t) =\n\\begin{cases}\np_{FF} & \\begin{array}{l} \\text{Si}\\,\\, y=v=0 \\,\\, \\text{y}\\,\\, u=x, \\end{array} \\\\\np_{FS} & \\begin{array}{l} \\text{Si}\\,\\, y=0,\\,v=1 \\,\\, \\text{y}\\,\\, u=x, \\end{array}\n\\\\\np_{SF} & \\begin{array}{l} \\text{Si}\\,\\, y\\neq 0,\\,v=0\\,\\, \\text{y}\\,\\, u=x, \\end{array}\n\\\\\np_{SS} & \\begin{array}{l} \\text{Si}\\,\\, 1 \\leq y \\leq k-2,\\,\\,v=y+1\\,\\, \\,\\,\\text{e}\\,\\, u=x,\\\\\n\\text{o si}\\,\\, y=k-1,\\,\\, v=k^{+}\\,\\,\\text{e}\\,\\, u=x+k,\\\\\n\\text{o si}\\,\\, y=k^{+},\\,\\, v=k^{+}\\,\\,\\text{e}\\,\\, u=x+1\\\\\n\\end{array}\n\\\\\n1 & \\begin{array}{l} \\text{Si} \\,\\, y=v\\,\\,\\text{y}\\,\\, u=x=n\\end{array} \\\\\n0 & \\begin{array}{l} \\text{Otro caso}. \\end{array}\n\\end{cases}\n\\end{equation}\\]\n\nPor lo tanto, la variable aleatoria \\(\\small{S_{n,k}}\\) es una Cadena de Markov incrustable y las probabilidades exactas se pueden obtener de:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(S_{n,k}= x\\big) = \\boldsymbol{\\xi_0 M}^{n-1}\\boldsymbol{U}(C_x),\\,\\, x=0,k,\\ldots,n\n\\end{equation}\\]\n\ndonde el vector fila \\(\\small{\\boldsymbol{\\xi_0}=(q_0,p_0,0,\\ldots,0)_{1 \\times d}}\\) es la distribuci√≥n inicial de \\(\\small{Y_1}\\), la partici√≥n \\(\\small{\\{C_x\\}}\\) se define como:\n\n\n\\[\\begin{equation}\nC_x =\\{(x,y):y=0,1,\\cdots,k-1,k^{+}\\},\\,\\,x=0,k,\\cdots,n,\n\\end{equation}\\]\n\ny \\(\\small{\\boldsymbol{U}'(C_x)}\\) es la transposici√≥n del vector fila \\(\\small{\\boldsymbol{U}(C_x)=(0,\\ldots,0,1,\\ldots,1,0,\\ldots,0)}\\) con unos en las coordenadas correspondientes a los estados de \\(\\small{C_x}\\).\nPara comprender mejor los efectos de los distintos par√°metros, en la Figura 3.1 se muestran gr√°ficamente las distribuciones de \\(\\small{S_{n,k}}\\) para algunos casos representativos con \\(\\small{n=15,30,60}\\), en los que se supone la distribuci√≥n inicial \\(\\small{\\boldsymbol{\\xi_0}=(1,0,\\ldots,0)}\\). Cuando \\(\\small{p_{SS}}\\) es peque√±o (por ejemplo, \\(\\small{p_{SS}=0.2}\\)), los efectos de los par√°metros sobre la distribuci√≥n son menos pronunciados, por lo que en la Figura 3.1 s√≥lo se presentan casos con valores grandes de \\(\\small{p_{SS}\\,(=0.8)}\\). A efectos de comparaci√≥n, tambi√©n se incluyen las esperanzas.\nPara \\(\\small{n}\\) fijo, el efecto de \\(\\small{k}\\) y \\(\\small{p_{FS}}\\) puede resumirse como sigue. Para \\(\\small{k}\\) peque√±o \\(\\small{(k=2)}\\) , la distribuci√≥n de \\(\\small{S_{n,k}}\\) se suaviza y adquiere forma de campana a medida que aumenta \\(\\small{n}\\) (de la Figura 3.1(a) a (d) a (g)), y esta tendencia se amplifica con valores mayores de \\(\\small{p_{FS}}\\). A medida que \\(\\small{k}\\) aumenta, las distribuciones se alejan de la forma normal y se vuelven muy sesgadas hacia la derecha (por ejemplo, de la Figura 3.1(d) a (e) a (f)). La distribuci√≥n de \\(\\small{S_{n,k}}\\) s√≥lo puede aproximarse a una distribuci√≥n normal cuando \\(\\small{k}\\) es mucho menor que \\(\\small{n}\\), y las aproximaciones normales deben utilizarse con precauci√≥n. En Fu, Lou, Bai y Li (2002) se ofrecen m√°s detalles sobre la distribuci√≥n l√≠mite de \\(\\small{S_{n,k}}\\).\n\n\n\n\n\n\nEn el cap√≠tulo 3, analizamos las ideas clave de la t√©cnica de Incrustaci√≥n de Cadenas de Markov Finitas (ICMF) para obtener las distribuciones exactas del n√∫mero de rachas y patrones con √©xitos en una sucesi√≥n de ensayos de dos estados. El objetivo principal de este cap√≠tulo es ampliar la t√©cnica de ICMF para estudiar el n√∫mero de rachas y patrones en una secuencia de ensayos multiestado. Podr√≠a parecer que, en principio, la ampliaci√≥n deber√≠a ser sencilla y requerir s√≥lo peque√±as modificaciones. Sin embargo, no es as√≠, especialmente cuando el patr√≥n es complejo y la sucesi√≥n \\(\\small{\\{X_t\\}}\\) est√° formada por ensayos multiestado Markov-Dependientes. Las principales dificultades se deben a la complejidad de construir una cadena de Markov finita adecuada asociada a la variable aleatoria \\(\\small{X_n(\\Lambda)}\\), especialmente en el proceso de obtenci√≥n de las probabilidades de transici√≥n. Para superar estas dificultades, introducimos el principio de avance y retroceso. En este cap√≠tulo nos centraremos en la utilizaci√≥n del principio de avance y retroceso para obtener las distribuciones de patrones simples y compuestos. De hecho, el principio de avance y retroceso desempe√±a un papel indispensable en la construcci√≥n de la Cadena de Markov Incrustada para casi todas las aplicaciones cubiertas por este libro.\n\n\n\nComencemos con el caso simple de que \\(\\small{\\{X_t\\}_{t=1}^{n}}\\) es una secuencia de i.i.d. ensayos miltiestados. Cada ensayo tiene \\(\\small{m\\,\\, (m\\geq 2)}\\) resultados posibles (estados o s√≠mbolos), etiquetados como \\(\\small{\\mathscr{S} =\\{b_1,\\ldots, b_m\\}}\\) y que ocurren con probabilidades \\(\\small{p_1,p_2,\\ldots,p_m,}\\) respectivamente. Denotamos \\(\\small{X_n(\\Lambda)}\\) al n√∫mero de patrones simples \\(\\small{\\Lambda}\\) no-superpuestos en la sucesi√≥n \\(\\small{\\{X_t\\}}\\). Primero, nos gustar√≠a presentar el principio de avance y retroceso para la t√©cnica de incrustaci√≥n de cadenas de Markov finitas, un principio que guiar√° la construcci√≥n de una cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) y la determinaci√≥n de sus matrices de probabilidad de transici√≥n. Para facilitar la discusi√≥n, el principio de avance y retroceso se introduce mediante el siguiente ejemplo.\nEjemplo 4.1 Consideremos el patr√≥n simple \\(\\small{\\Lambda=\\{b_{1}b_{1}b_{2}\\}}\\) en una sucesi√≥n de ensayos de tres estados (\\(\\small{\\mathscr{S} =\\{b_1,b_{2}, b_{3}\\}}\\)).\n(i) Descompongamos el patr√≥n \\(\\small{\\Lambda=b_{1}b_{1}b_{2}}\\) en un conjunto de subpatrones secuenciales \\(\\small{\\mathscr{S}(\\Lambda) =\\{b_1,b_{1}b_{1}, b_{1}b_{1}b_{2}\\}}\\). Definiendo\n\n\n\\[\\begin{equation}\n\\mathscr{E}=\\mathscr{S}\\, \\cup \\,\\mathscr{S}(\\Lambda)=\\{b_{1},b_{2},b_{3},b_{1}b_{1}, b_{1}b_{1}b_{2}\\}\n\\end{equation}\\]\n\ncomo un conjunto de bloques finales inducidos por el patr√≥n \\(\\small{ b_{1}b_{1}b_{2}}\\) con respecto a sucesi√≥n de ensayos \\(\\small{\\{X_t\\}}\\)\n(ii) Sea \\(\\small{{\\omega} =(x_{1},\\ldots, x_n)}\\) una realizaci√≥n de una sucesi√≥n de \\(\\small{n}\\) ensayos de tres estados. Definiendo el espacio de estados:\n\n\n\\[\\begin{equation}\n\\Omega =\\{(u,v):u=0,1,\\cdots,[n\n/3],\\,\\, v\\in \\mathscr{E}\\}\\,\\cup \\,\\{\\emptyset\\}\\, -\\,\\{(0,b_{1}b_{1}b_{2})\\}\n\\end{equation}\\]\n\ny una cadena de Markov\n\n\n\\[\\begin{equation}\n\\big\\{Y_t=\\big(X_n(\\Lambda), E_t\\big),\\,t=0,1,2,\\ldots,n\\big\\}\n\\end{equation}\\]\n\noperando sobre \\(\\small{\\omega}\\) como\n\n\n\\[\\begin{equation}\nY_t(\\omega)=(u,v),\\,\\, \\text{para}\\,\\, t=1,\\ldots,n\n\\end{equation}\\]\n\nen donde: \n\n\\[\\begin{align*}\nu &=\\begin{cases}\n\\begin{array}{l}\nX_n(\\Lambda)(\\omega)=\\,\\text{el n√∫mero total de patrones no-solapados}\\,\\Lambda\\,\\\\\n\\text{en los primeros}\\,\\, t\\,\\, \\text{ensayos contando hacia delante desde} \\\\\n\\text{el primer ensayo hasta el}\\,\\, t-√©simo\\,\\, \\text{ensayo, y}\n\\end{array}\n\\end{cases}\\\\\n\\\\\nv &=\\begin{cases}\n\\begin{array}{l}\nE_t(w) =\\,\\text{el bloque final m√°s largo en}\\ \\mathscr{S},\\\\\n\\text{contando hacia atr√°s desde}\\, X_t.\n\\end{array}\n\\end{cases}\n\\end{align*}\\]\n\nLas definiciones de \\(\\small{u}\\) y \\(\\small{v}\\) para la sucesi√≥n de los primeros \\(\\small{t}\\) ensayos se ilustran gr√°ficamente en la figura 4.1. Para que la cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) y el concepto de bloque final m√°s largo sean m√°s transparentes, consideremos la siguiente realizaci√≥n, \\(\\small{\\omega=(b_{3}b_{1}b_{2}b_{1}b_{1}b_{2}b_{1})}\\), de una sucesi√≥n de siete ensayos de tres estados. Aplicando el principio de avance y retroceso, la correspondiente del la cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) sobre \\(\\small{\\omega}\\) viene dada por \\(\\small{\\{Y_{1}(\\omega)=(0,b_{3}), Y_{2}(\\omega)=(0, b_{1}), Y_{3}(\\omega) = (0, b_{2}), Y_{4}(\\omega)= (0, b_{1}), Y_{5}(\\omega)=(0, b_{1}b_{1}), Y_{6}(\\omega) = (1, b_{1}b_{1}b_{2})\\,\\text{y}\\, Y_{7}(\\omega)=(1, b_{1})\\}}\\). Tenga en cuenta que para cada \\(\\small{\\omega}\\) dada, la realizaci√≥n de la cadena de Markov incrustada \\(\\small{Y_t(\\omega) = (u, v)}\\) est√° determinada √∫nicamente por lo anterior procedimientos (i) y (ii) bajo conteo sin superposici√≥n. En palabras sencillas, el el bloque final \\(\\small{v}\\) representa el estado de formaci√≥n del siguiente patr√≥n \\(\\small{\\Lambda}\\) para el subsecuencia \\(\\small{\\{{x_1,., ,x_t} \\}}\\) que contiene \\(\\small{u}\\) patrones completos.\n(iii) La cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) es homog√©nea y su matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M_t}= \\big(p_{(x,z),(u,v)}\\big)}\\) puede determinarse del siguiente modo. Por ejemplo, dado \\(\\small{Y_5(\\omega)=(0,b_{1}b_{1})}\\), como \\(\\small{X_{6}}\\) s√≥lo puede ser uno de los tres resultados posibles \\(\\small{b_{1}, b_{2}}\\) y \\(\\small{b_{3}}\\), el procedimiento de recuento hacia delante y hacia atr√°s da como resultado\n\n\n\\[\\begin{align*}\nY_{5}(\\omega) & \\rightarrow \\quad \\quad Y_{6}(\\omega)\n\\\\\n(0,b_{1}b_{1}) &\\rightarrow  \\begin{cases}\n\\begin{array}{cl}\n(0,b_{1}b_{1}) & \\text{si}\\,\\, X_6= b_{1}\\,\\,(\\text{con probabilidad}\\, p_{1})\\\\\n(1,b_{1}b_{1}b_{2}) & \\text{si}\\,\\, X_6= b_{2}\\,\\,(\\text{con probabilidad}\\, p_{2})\\\\\n(0,b_{3}) & \\text{si}\\,\\, X_6= b_{3}\\,\\,(\\text{con probabilidad}\\, p_{3}),\n\\end{array}\n\\end{cases}\n\\end{align*}\\]\n\ne \\(\\small{Y_5(\\omega)}\\) pasa a cualquier otro estado con probabilidad cero. De esta forma se obtienen todas las probabilidades de transici√≥n \\(\\small{\\mathbb{P}\\big(Y_t=(u,v)\\mid Y_{t-1}=(x,z)\\big)}\\). El estado ficticio \\(\\small{\\emptyset}\\) se a√±adir√° como estado inicial con \\(\\small{\\mathbb{P}\\big(Y_{0}=\\emptyset\\big)=1}\\) y con probabilidades de transici√≥n \\(\\small{\\mathbb{P}\\big(Y_{1}=b_{i}\\mid Y_0=\\emptyset\\big)=p_{i}}\\) para \\(\\small{i=1,2,3}\\). Obs√©rvese que el estado \\(\\small{(0,\\Lambda=b_{1}b_{1}b_{2})}\\) se elimin√≥ del espacio de estados, ya que siempre que el bloque final \\(\\small{v}\\) sea igual a \\(\\small{\\Lambda}\\) debe haber al menos una ocurrencia de el patr√≥n en la secuencia (es decir, \\(\\small{u\\geq1}\\) si \\(\\small{v=\\Lambda}\\)).\n(iv) Dado \\(\\small{n}\\), tenemos la siguiente partici√≥n en el espacio de estados \\(\\small{\\Omega}\\):\n\n\n\\[\\begin{align*}\n\\big\\{C_{\\emptyset} &=[\\emptyset], C_{0}=[(0,b_{1}),(0,b_{2}),(0,b_{3}),(0,b_{1}b_{1})], \\\\\n& \\,\\,\\text{y}\\,\\,C_{x}=[(x,v),v\\in \\mathscr{E}],\\, x=1,\\ldots,[n/3] \\big\\}.\n\\end{align*}\\]\n\nPara \\(\\small{n=5}\\) y la probabilidad inicial \\(\\small{\\mathbb{P}\\big(Y_0=\\emptyset \\big)\\equiv 1}\\), se deduce de los procedimientos (i) a (iv) anteriores que la cadena de Markov incrustada \\(\\small{\\{Y_t\\}_{t=0}^{5}}\\) est√° definida en el espacio de estados \\(\\small{\\Omega=\\{\\emptyset, (0, b_{1}), (0, b_{2}), (0, b_{3}), (0, b_{1}b_{1}), (1, b_{1}b_{1}b_{2}), (1, b_{1}), (1, b_{2}), (1, b_{3}), (1, b_{1}b_{1})\\}}\\) con matriz de probabilidad de transici√≥n\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\n\\begin{array}{cc}&\n\\begin{array}{c}\n\\emptyset\\\\\n(0,b_{1})\\\\\n(0,b_{2})\\\\\n(0,b_{3})\\\\\n(0,b_{1}b_{1})\\\\\n(1,b_{1}b_{1}b_{2})\\\\\n(1,b_{1})\\\\\n(1,b_{2})\\\\\n(1,b_{3})\\\\\n(1,b_{1}b_{1})\n\\end{array}\n&\n\\left(\n\\begin{array}{c|cccc|ccccc}\n0&p_{1}&p_{2}&p_{3}&0&0&0&0&0&0\\\\\n\\hline\n0&0&p_{2}&p_{3}&0&0&0&0&0&0\\\\\n0&p_{1}&p_{2}&p_{3}&0&0&0&0&0&0\\\\\n0&p_{1}&p_{2}&p_{3}&0&0&0&0&0&0\\\\\n0&0&0&p_{3}&p_{1}&p_{2}&0&0&0\\\\\n\\hline\n0&0&0&0&0&0&p_{1}&p_{2}&p_{3}&0\\\\\n0&0&0&0&0&0&0&p_{2}&p_{3}&p_{1}\\\\\n0&0&0&0&0&0&p_{1}&p_{2}&p_{3}&0\\\\\n0&0&0&0&0&0&p_{1}&p_{2}&p_{3}&0\\\\\n0&0&0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nLas probabilidades \\(\\small{\\mathbb{P}\\big(X_n(\\Lambda)=5\\big)=\\boldsymbol{\\xi_0M}^5\\boldsymbol{U'}(C_x),\\, x=0,1,}\\), pueden computarse facilmente.\nPara demostrar la aplicabilidad del principio de avance y retroceso a los patrones compuestos, consideremos el siguiente ejemplo.\nEjemplo 4.2 Dado \\(\\small{n=4}\\) y un patr√≥n compuesto \\(\\small{\\Lambda= \\Lambda_{1} \\cup \\Lambda_{2}}\\), que consiste en la uni√≥n de dos patrones simples distintos \\(\\small{ \\Lambda_{1}=b_{1}b_{2}}\\) y \\(\\small{ \\Lambda_{1}=b_{3}b_{1}}\\), estamos interesados en encontrar la distribuci√≥n de la variable aleatoria \\(\\small{X_4(\\Lambda)}\\), el n√∫mero de ocurrencias de \\(\\small{\\Lambda_{1}}\\) o \\(\\small{\\Lambda_{2}}\\) en una secuencia de cuatro ensayos i.i.d. de tres estados. Procediendo como en el ejemplo anterior, se obtiene la cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) definida en el espacio de estados\n\n\n\\[\\begin{align*}\n\\Omega &=\\big\\{\\emptyset,(0,b_{1}),(0,b_{2}),(0,b_{3}),(1,b_{1}b_{2}), (1,b_{3}b_{1}), \\\\\n& \\quad \\quad (1,b_{1}),(1,b_{2}),(1,b_{3}),(2,b_{1}b_{2}),(2,b_{3}b_{1})\\big\\}.\n\\end{align*}\\]\n\ncon matriz de probabilidades de transici√≥n:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\n\\begin{array}{cc}&\n\\begin{array}{c}\n\\emptyset\\\\\n(0,b_{1})\\\\\n(0,b_{2})\\\\\n(0,b_{3})\\\\\n(1,b_{1}b_{2})\\\\\n(1,b_{3}b_{1})\\\\\n(1,b_{1})\\\\\n(1,b_{2})\\\\\n(1,b_{3})\\\\\n(2,b_{1}b_{2})\\\\\n(2,b_{3}b_{1})\n\\end{array}\n&\n\\left(\n\\begin{array}{c|ccc|ccccc|cc}\n0&p_{1}&p_{2}&p_{3}&0&0&0&0&0&0&0\\\\\n\\hline\n0&p_{1}&0&p_{3}&p_{2}&0&0&0&0&0&0\\\\\n0&p_{1}&p_{2}&p_{3}&0&0&0&0&0&0&0\\\\\n0&0&p_{2}&p_{3}&0&p_{1}&0&0&0&0&0\\\\\n\\hline\n0&0&0&0&p_{1}&0&0&p_{2}&p_{3}&0&0\\\\\n0&0&0&0&0&0&p_{1}&p_{2}&p_{3}&0&0\\\\\n0&0&0&0&0&0&p_{1}&0&p_{3}&p_{2}&0\\\\\n0&0&0&0&0&0&p_{1}&p_{2}&p_{3}&0&0\\\\\n0&0&0&0&0&0&0&p_{2}&p_{3}&0&p_{1}\\\\\n\\hline\n0&0&0&0&0&0&0&0&0&1&0\\\\\n0&0&0&0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nLas probabilidades \\(\\small{\\mathbb{P}\\big(X_n(\\Lambda)=4\\big)=\\boldsymbol{\\xi_0M}^4\\boldsymbol{U'}(C_x),\\, x=0,1,2}\\), pueden computarse facilmente.\nEl m√©todo tambi√©n puede extenderse, con modificaciones simples, a la caso donde \\(\\small{\\{X_t\\}}\\) es una sucesi√≥n de ensayos multiestado Markov-Dependientes.\nEjemplo 4.3 Volvamos al Ejemplo 4.1, pero consideremos aqu√≠ que \\(\\small{\\{X_t\\}}\\) es una secuencia de ensayos de tres estados Markov-Dependientes con matriz de probabilidad de transici√≥n:\n\n\n\\[\\begin{equation}\n\\boldsymbol{A}=\\left(\n\\begin{array}{ccc}\np_{11}&p_{12}&p_{13}\\\\\np_{21}&p_{22}&p_{23}\\\\\np_{31}&p_{32}&p_{33}\\\\\n\\end{array}\n\\right)\n\\end{equation}\\]\n\nNuestro objetivo es determinar la distribuci√≥n del patr√≥n \\(\\small{\\Lambda=b_{1}b_{1}b_{2}}\\) en una secuencia de cinco ensayos. De forma an√°loga al Ejemplo 4.1, las probabilidades de transici√≥n de la cadena de Markov incrustada pueden obtenerse para cada estado mediante el siguiente argumento. Dado \\(\\small{Y_3 = (0, b_{1}b_{1})}\\), por ejemplo, tenemos:\n\n\n\\[\\begin{align*}\nY_3 & \\rightarrow \\quad \\quad \\, Y_{4}\\\\\n(0,b_{1}b_{1}) &\\rightarrow  \\begin{cases}\n\\begin{array}{cl}\n(0,b_{1}b_{1}) & \\text{si}\\,\\, X_{4}= b_{1}\\,\\,(\\text{con probabilidad}\\, p_{11})\\\\\n(1,b_{1}b_{1}b_{2}) & \\text{si}\\,\\, X_{4}= b_{2}\\,\\,(\\text{con probabilidad}\\, p_{12})\\\\\n(0,b_{3}) & \\text{si}\\,\\, X_{4}= b_{3}\\,\\,(\\text{con probabilidad}\\, p_{13}).\n\\end{array}\n\\end{cases}\n\\end{align*}\\]\n\nLas ecuaciones (4.4) y (4.9) son equivalentes, salvo que las probabilidades \\(\\small{p_{1}}\\),\\(\\small{p_{2}}\\) y \\(\\small{p_{3}}\\) se sustituyen por \\(\\small{p_{11}}\\),\\(\\small{p_{12}}\\) y \\(\\small{p_{13}}\\) respectivamente. Por lo tanto, la cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) se define aqu√≠ en el mismo espacio de estados \\(\\small{\\Omega}\\) y con matriz de probabilidad de transici√≥n:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\n\\begin{array}{cc}&\n\\begin{array}{c}\n\\emptyset\\\\\n(0,b_{1})\\\\\n(0,b_{2})\\\\\n(0,b_{3})\\\\\n(0,b_{1}b_{1})\\\\\n(1,b_{1}b_{1}b_{2})\\\\\n(1,b_{1})\\\\\n(1,b_{2})\\\\\n(1,b_{3})\\\\\n(1,b_{1}b_{1})\n\\end{array}\n&\n\\left(\n\\begin{array}{c|cccc|ccccc}\n0&p_{1}&p_{2}&p_{3}&0&0&0&0&0&0\\\\\n\\hline\n0&0&p_{12}&p_{13}&p_{11}&0&0&0&0&0\\\\\n0&p_{21}&p_{22}&p_{23}&0&0&0&0&0&0\\\\\n0&p_{31}&p_{32}&p_{33}&0&0&0&0&0&0\\\\\n0&0&0&p_{13}&p_{11}&p_{12}&0&0&0\\\\\n\\hline\n0&0&0&0&0&0&p_{21}&p_{22}&p_{23}&0\\\\\n0&0&0&0&0&0&0&p_{12}&p_{13}&p_{11}\\\\\n0&0&0&0&0&0&p_{21}&p_{22}&p_{23}&0\\\\\n0&0&0&0&0&0&p_{31}&p_{32}&p_{33}&0\\\\\n0&0&0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\ndonde las probabilidades de transici√≥n \\(\\small{\\mathbb{P}\\big(Y_{t}(u,v)=Y_{t-1}(x,z)\\big)}\\) se obtienen como se ilustra en la Ec. (4.9). Obs√©rvese que la matriz de probabilidades de transici√≥n de la Ec. (4.10) tiene exactamente la misma forma que la matriz de la Ec. (4.6) para el caso i.i.d..\nEn vista de las transiciones de estado esbozadas por las Ecs. (4.4) y (4.9), que conducen a las matrices de probabilidad de transici√≥n de los Ejemplos 4.1 a 4.3, dadas en las Ecs. (4.6), (4.8) y (4.10) respectivamente, definimos la siguiente notaci√≥n: dado \\(\\small{Y_{t-1} = (x, z) \\in \\Omega}\\) y \\(\\small{X_t = j\\in \\mathscr{S}}\\), \n\n\\[\\begin{equation}\n(u,v)\\equiv &lt;(x,z),j&gt;_{\\Omega}\n\\end{equation}\\]\n\ndonde el estado \\(\\small{(u,v)\\in \\Omega}\\) es el resultado del recuento hacia delante y hacia atr√°s (no solapado) cuando se incluye un resultado adicional \\(\\small{X_t=j}\\). Para cada \\(\\small{(x, z)\\in \\Omega}\\), definimos tambi√©n \\(\\small{L(z)\\in \\mathscr{S}}\\) como el √∫ltimo elemento del bloque final \\(\\small{z}\\). Entonces, para el caso general, las probabilidades de transici√≥n de la cadena de Markov incrustada \\(\\small{Y_t}\\) se especifican mediante la siguiente ecuaci√≥n:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(Y_t=(u,v)\\mid Y_{t-1}=(x,z)\\big) =\\begin{cases}\np_{ij} & \\quad\n\\begin{array}{l}\n\\text{si}\\,\\, X_{t}=j\\in\\mathscr{S},\\, L(z)=i\\\\\n\\text{y}\\,\\,(u,v)= &lt;(x,z),j&gt;_{\\Omega}\n\\end{array}\\\\\nm & \\quad \\text{en otro caso}\n\\end{cases}\n\\end{equation}\\]\n\ndonde \\(\\small{p_{ij}}\\) son las probabilidades de transici√≥n de la cadena de Markov \\(\\small{\\{X_t\\}}\\). Si \\(\\small{\\{X_t\\}}\\) es una secuencia de ensayos multiestado i.i.d., la Ec.(4.12) se convierte en\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(Y_t=(u,v)\\mid Y_{t-1}=(x,z)\\big) =\\begin{cases}\np_{j} & \\quad\n\\begin{array}{l}\n\\text{si}\\,\\, X_{t}=j\\in\\mathscr{S},\\\\\n\\text{y}\\,\\,(u,v)= &lt;(x,z),j&gt;_{\\Omega}\n\\end{array}\\\\\n0 & \\quad \\text{en otro caso}\n\\end{cases}\n\\end{equation}\\]\n\nTeorema 4.1 Suponiendo que \\(\\small{\\{X_t\\}}\\) es una cadena de Markov homog√©nea con matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{A} = \\big(p_{ij}\\big)_{m\\times m}}\\), y \\(\\small{\\Lambda=\\displaystyle{\\bigcup_{i=1}^{l}\\Lambda_{i}}}\\) es un patr√≥n compuesto generado por \\(\\small{l}\\) patrones simples distintos \\(\\small{\\Lambda_{i}}\\) que tienen la misma longitud \\(\\small{k}\\), entonces la cadena de Markov incrustada \\(\\small{\\big\\{Y_t=\\big(X_{t}(\\Lambda),E_{t} \\big),\\,t=1,2,\\,\\ldots,n\\big\\}}\\) correspondiente a la variable aleatoria \\(\\small{X_{n}(\\Lambda)}\\)\n(i) se define sobre el espacio de estados:\n\n\n\\[\\begin{align*}\\Omega &=\\{\\emptyset\\}\\, \\cup\\,\\{(x,z):x=0,1,\\cdots,[n\n/k],\\,\\, z\\in \\mathscr{E}\\}\\\\\n&\\quad- \\{(0,\\Lambda_{i}):i=1,\\cdots,l\\}\n-\\,\\{([n/k],z):k[n/k]+z(k)&gt;n\\},\\end{align*}\\]\n\nen donde \\(\\small{\\mathscr{E} =\\mathscr{S}\\,\\cup\\Bigg(\\displaystyle\\bigcup_{i=1}{\\mathscr{S}(\\Lambda_{i})\\Bigg)}}\\) y \\(\\small{z(k)\\equiv [\\text{longitud de}\\,z] \\pmod k}\\)\n(ii) tiene la matriz de probabilidades de transici√≥n: \n\n\\[\\begin{equation}\n\\boldsymbol{M}=\\big(p_{(x,z)(u,v)}\\big)_{d\\times d}\n\\end{equation}\\]\n\nen donde las probabilidades de transici√≥n estan dadas por: \n\n\\[\\begin{equation}\np_{(x,z)(u,v)}=\\begin{cases}\np_{j} & \\,\\text{si}\\, (x,z)=\\emptyset,\\,u=0,\\,v=j,\\, \\text{para todo}\\, j \\in \\mathscr{S}\\\\ \\\\\np_{ij} &\n\\begin{array}{l}\n\\text{si}\\,(u,v)=&lt;(x,z),j&gt;_{\\Omega},\\, x\\leq [n/k],\\, j\\in \\mathscr{S},\\\\\nL(z)=i,\\,\\text{y}\\,\\, kx+z(k)&lt;n\n\\end{array} \\\\ \\\\\n1 &\n\\begin{array}{l}\n\\text{si}\\,(u,v)= (x,z) ,\\, x= [n/k]\\\\\n\\,\\text{y}\\,\\, k[n/k]+z(k)=n\n\\end{array} \\\\\\\\\nm & \\text{en otro caso.}\n\\end{cases}\n\\end{equation}\\]\n\ncon \\(\\small{d=\\text{card}(\\Omega)}\\), el tama√±o del espacio de estados \\(\\small{\\Omega}\\), igual a:\n\n\n\\[\\begin{align*}d =1 & +([n/k]+1)\\times \\text{card}\\big(\\mathscr{E}\\big)-l\\\\\n& -\\text{card}\\Big(\\big\\{([n/k],z):\\,z \\in \\mathscr{E}, \\,k[n/k]+z(k)&gt;n\\big\\}\\big),\\end{align*}\\]\n\ny (iii) se obtiene la distribuci√≥n:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big( X_n(\\Lambda)=x\\big)=\\boldsymbol{\\mathbf{\\xi}}_0\\boldsymbol{M}^{n}\\boldsymbol{\\mathbf{U}'}( {C_x}),\\,\\,  x=1,2,\\ldots,[n/k],\n\\end{equation}\\]\n\nen donde \\(\\small{\\boldsymbol{\\xi}_0}\\) es la distribuci√≥n inicial especificada por \\(\\small{\\mathbb{P}\\big(Y_{0}=\\emptyset\\big)\\equiv 1}\\) y \n\n\\[\\begin{align*}\nC_{\\emptyset} &=[\\emptyset],\\, C_{0}=[(0,z):z\\in\\mathscr{S}]-[(0,\\Lambda_{i}):i=1,2,\\ldots,l], \\\\\nC_{x} &=  [(x,z):z\\in \\mathscr{E}],\\, 1\\leq x \\leq [n/k], \\, \\text{y}\\\\\nC_{[n/x]}&=[([n/k],z):z\\in \\mathscr{E},\\,k[n/k]+z(k)\\leq n]\n\\end{align*}\\]\n\nson las particiones del espacio de estados \\(\\small{\\Omega}\\).\nN√≥tese que el espacio de estados \\(\\small{\\Omega}\\) y su tama√±o \\(\\small{d}\\) son funciones de \\(\\small{n}\\), la estructura de los patrones \\(\\small{\\Lambda_{i},\\,i=1,\\ldots,l}\\) y la longitud del patr√≥n com√∫n \\(\\small{k}\\). El lector puede comprobar que los resultados de los Ejemplos 4.1 a 4.3 se deducen directamente del Teorema 4.1.\nDemostraci√≥n. Dado \\(\\small{n}\\), como la longitud de cada patr√≥n es \\(\\small{k}\\), el n√∫mero m√°ximo de patrones es \\(\\small{[n/k]}\\) (bajo conteo no solapado). El conjunto \\(\\small{\\mathscr{E} =\\mathscr{S}\\,\\cup\\Bigg(\\displaystyle\\bigcup_{i=1}{\\mathscr{S}(\\Lambda_{i})\\Bigg)}}\\) contiene todos los posibles bloques finales generados por \\(\\small{\\mathscr{S}}\\) y todos los patrones, y se deduce que para recuento hacia delante y hacia atr√°s sin solapamiento, el espacio de estados tiene la forma \\(\\small{\\big\\{(x,z): x=0,\\ldots,[n/k]},\\,z\\in\\mathscr{E}\\big\\}\\). Los estados \\(\\small{\\big\\{(0,\\Lambda_{i}): i=1,\\ldots,l}\\big\\}\\) se eliminan porque si el bloque final es \\(\\small{\\Lambda_{i}}\\), entonces debe haber al menos un patr√≥n \\(\\small{\\Lambda_{i}}\\), en la secuencia \\(\\small{(x\\geq 1)}\\), por lo que los estados \\(\\small{\\big\\{(0,\\Lambda_{i})\\big\\}}\\) son inalcanzables; por la misma raz√≥n, los estados \\(\\small{\\big\\{([n/k],z):k[k/z]+z(k)&gt;n\\big\\}}\\) tampoco pueden darse y pueden eliminarse. As√≠, el espacio de estados \\(\\small{\\Omega}\\) de la cadena de Markov incrustada tiene la forma dada por la Ec. (4.14), y su tama√±o \\(\\small{d}\\) viene determinado por la Ec.(4.17).\nDados \\(\\small{(x,z)\\in \\Omega,\\,0\\leq x \\leq [n/n]}\\), y \\(\\small{kx + z(k) &lt; n}\\), si \\(\\small{X_{t}=j\\in \\mathscr{S}}\\) y \\(\\small{(u, v) = &lt; (x, z), j &gt;_{\\Omega}}\\) , entonces, como se describe en las Ecs. (4.9) y (4.12), se deduce que\n\n\n\\[\\begin{align*}\np_{(x,z)(u,v)}=\\mathbb{P}\\big(Y_t=(u,v)\\mid Y_{t-1}=(x,z)\\big)=p_{ij},\n\\end{align*}\\]\n\ndonde \\(\\small{i=L(z)}\\). Si \\(\\small{Y_{t-1}=([n/k], z) }\\), y \\(\\small{[kn/k] + z(k) = n}\\) entonces \\(\\small{t-1\\equiv n}\\); por conveniencia, asignamos las probabilidades de transici√≥n para estos estados como \\(\\small{\\mathbb{P}\\big(Y_t=([n/k],z)\\mid Y_{t-1}=([n/k],z)\\big)\\equiv1}\\) . Esto completa la construcci√≥n de la Ec. (4.16) y la matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M}}\\) . Las particiones en el espacio de estados \\(\\small{\\Omega}\\) , dadas por la Ec. (4.19), son una consecuencia directa de la definici√≥n de la cadena de Markov incrustada introducida en la Ec. (4.3). Por lo tanto, la distribuci√≥n para el patr√≥n compuesto \\(\\small{\\Lambda}\\) en la Ec. (4.18) es una consecuencia inmediata del Teorema 2.1. Esto completa la demostraci√≥n. \\(\\hspace{1cm}\\Box\\)\nEl teorema 4.1 anterior tambi√©n es v√°lido para patrones simples, el caso especial cuando \\(\\small{l=1}\\) . Cuando las longitudes de los patrones \\(\\small{k_{i},\\, i=1,\\ldots,l}\\) no son todas iguales, el principio de avance y retroceso puede seguir utiliz√°ndose para hallar la distribuci√≥n del patr√≥n compuesto \\(\\small{\\Lambda}\\) . En principio, el procedimiento de recuento de avance y retroceso es aplicable a cualquier n√∫mero de patrones \\(\\small{l}\\) de tama√±os \\(\\small{k_{i}}\\) variables, pero no es sencillo escribir la forma general del espacio de estados y la matriz de probabilidad de transici√≥n de la cadena de Markov incrusrada. Trataremos este problema en el cap√≠tulo 5 utilizando la relaci√≥n de dualidad entre \\(\\small{X_{n}(\\Lambda)}\\) y el tiempo de espera \\(\\small{W(\\Lambda)}\\).\n\n\n\nConsideremos que la secuencia \\(\\small{\\{X_t\\}}\\) es una cadena de Markov homog√©nea definida sobre el espacio de estados \\(\\small{\\mathscr{S}=\\{a, b, c\\}}\\) con matriz de probabilidades de transici√≥n\n\n\n\\[\\begin{equation}\n\\boldsymbol{A}=\\big(p_{ij}\\big),\\, i,j=a,b,c\n\\end{equation}\\]\n\nSea \\(\\small{\\Lambda}\\) un patr√≥n simple de longitud \\(\\small{k}\\). La diferencia b√°sica entre el recuento por solapamiento y el recuento sin solapamiento es que cuando se forma el patr√≥n \\(\\small{\\Lambda}\\), una parte de A se contar√° para formar el siguiente patr√≥n \\(\\small{\\Lambda}\\) bajo el recuento por solapamiento, hasta los √∫ltimos \\(\\small{(k-1)}\\) ensayos.\nDefinici√≥n 4.1 Un bloque final \\(\\small{E^¬∞}\\) generado por el patr√≥n \\(\\small{\\Lambda}\\) es el bloque final m√°s largo \\(\\small{(E^{¬∞} \\neq \\Lambda)}\\) que, despu√©s de cada aparici√≥n de \\(\\small{\\Lambda}\\) bajo conteo superpuesto, se puede asignar como bloque final inicial para la siguiente aparici√≥n de \\(\\small{\\Lambda}\\). Escribimos \\(\\small{(E^{¬∞} \\cong \\Lambda}\\) , con respecto al conteo de superposici√≥n.\nPor ejemplo, bajo el conteo superpuesto:\n\nSi \\(\\small{\\Lambda=aca}\\), entonces \\(\\small{E^{¬∞}=a}\\),\nSi \\(\\small{\\Lambda=abcab}\\), entonces \\(\\small{E^{¬∞}=ab}\\), y\nSi \\(\\small{\\Lambda=\\underbrace{a\\cdots a}_{k}}\\), entonces \\(\\small{E^{¬∞}=\\underbrace{a\\ldots a}_{k-1}}\\).\n\nPara un patr√≥n como \\(\\small{\\Lambda=abc}\\), no existe un \\(\\small{E^{¬∞}}\\), en cuyo caso el conteo superpuesto y no superpuesto es el mismo. Tenga en cuenta que bajo el conteo superpuesto, dado que el primer patr√≥n requiere \\(\\small{k}\\) elementos y cada patr√≥n adicional requiere solo \\(\\small{k-\\text{Card}(E^{¬∞})}\\) elementos, el mayor n√∫mero posible de patrones \\(\\small{\\Lambda}\\) que pueden ocurrir en \\(\\small{n (n \\geq k)}\\) ensayos es\n\n\n\\[\\begin{equation*}\nl_{n}^{o}=1+\\bigg[\\frac{n-k}{k-\\text{Card}(E^{¬∞})}\\bigg].\n\\end{equation*} \\]\n\nPara ilustrar las diferencias menores que surgen de los dos tipos de conteo, se proporciona el siguiente ejemplo.\nEjemplo 4.4 Consideremos el n√∫mero de patrones \\(\\small{\\Lambda=aca}\\) que ocurren en \\(\\small{n=5}\\) ensayos i.i.d. de tres estados. Bajo el conteo no superpuesto, la matriz de transici√≥n de probabilidades \\(\\small{\\boldsymbol{M}}\\) asociada con la cadena de Markov incrustada\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\n\\begin{array}{cc}&\n\\begin{array}{c}\n(0,a)\\\\\n(0,b)\\\\\n(0,c)\\\\\n(0,ab)\\\\\n(1,\\Lambda)\\\\\n(1,a)\\\\\n(1,b)\\\\\n(1,c)\\\\\n(1,ac)\\\\\n\\end{array}\n&\n\\left(\n\\begin{array}{ccccccccc}\np_{a}&p_{b}&0&p_{c}&0&0&0&0&0\\\\\np_{a}&p_{b}&p_{c}&0&0&0&0&0&0\\\\\np_{a}&p_{b}&p_{c}&0&0&0&0&0&0\\\\\n0&p_{b}&p_{c}&0&p_{a}&0&0&0&0\\\\\n0&0&0&0&0&p_{a}&p_{b}&p_{c}&0\\\\\n0&0&0&0&0&p_{a}&p_{b}&0&p_{c}\\\\\n0&0&0&0&0&p_{a}&p_{b}&p_{c}&0\\\\\n0&0&0&0&0&p_{a}&p_{b}&p_{c}&0\\\\\n0&0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\ndonde \\(\\small{(1,\\Lambda)\\equiv (1,aca)}\\) . Bajo conteo de superpuesto, la matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M^{¬∞}}}\\) asociada con la cadena de Markov incrustada es\n\n\n\\[\\begin{equation}\n\\boldsymbol{M^{¬∞}}=\n\\begin{array}{cc}&\n\\begin{array}{c}\n(0,a)\\\\\n(0,b)\\\\\n(0,c)\\\\\n(0,ab)\\\\\n(1,\\Lambda)\\\\\n(1,a)\\\\\n(1,b)\\\\\n(1,c)\\\\\n(1,ac)\\\\\n(2,\\Lambda)\n\\end{array}\n&\n\\left(\n\\begin{array}{ccccc|cccc}\np_{a}&p_{b}&0&p_{c}&0&0&0&0&0&0\\\\\np_{a}&p_{b}&p_{c}&0&0&0&0&0&0&0\\\\\np_{a}&p_{b}&p_{c}&0&0&0&0&0&0&0\\\\\n0&p_{b}&p_{c}&0&p_{a}&0&0&0&0&0\\\\\n\\hline\n0&0&0&0&0&p_{a}&p_{b}&0&p_{c}&0\\\\\n\\hline\n0&0&0&0&0&p_{a}&p_{b}&0&p_{c}&0\\\\\n0&0&0&0&0&p_{a}&p_{b}&p_{c}&0&0\\\\\n0&0&0&0&0&p_{a}&p_{b}&p_{c}&0&0\\\\\n0&0&0&0&0&0&p_{b}&p_{c}&0&p_{a}\\\\\n0&0&0&0&0&0&0&0&1&0\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nLa principal diferencia entre las dos matrices surge despu√©s de que ha ocurrido el primer patr√≥n. Con probabilidad \\(\\small{p_{c}}\\) , el estado \\(\\small{(1,\\Lambda)}\\) pasa al estado \\(\\small{(1,c)}\\) bajo conteo no superpuesto, mientras que \\(\\small{(1,\\Lambda)}\\) pasa a \\(\\small{(1,ac)}\\) bajo conteo superpuesto, lo que tambi√©n implica el estado adicional \\(\\small{l_{n}^{¬∞}=(2,\\Lambda)}\\). \\(\\hspace{1cm}\\Diamond\\)\nSi \\(\\small{\\{X_t\\}}\\) es una cadena de Markov homog√©nea con probabilidades de transici√≥n dadas por la Ecuaci√≥n. (4.20), la matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M^{¬∞}}}\\) del anterior ejemplo (bajo conteo superpuesto) se convierte en:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M^{¬∞}}=\n\\begin{array}{cc}&\n\\begin{array}{c}\n\\emptyset\\\\\n(0,a)\\\\\n(0,b)\\\\\n(0,c)\\\\\n(0,ab)\\\\\n(1,\\Lambda)\\\\\n(1,a)\\\\\n(1,b)\\\\\n(1,c)\\\\\n(1,ac)\\\\\n(2,\\Lambda)\n\\end{array}\n&\n\\left(\n\\begin{array}{cccccc|ccccc}\n0&p_{a}&p_{b}&p_{c}&0&0&0&0&0&0&0\\\\\n0&p_{aa}&p_{ab}&0&p_{ac}&0&0&0&0&0&0\\\\\n0&p_{ba}&p_{bb}&p_{bc}&0&0&0&0&0&0&0\\\\\n0&p_{ca}&p_{cb}&p_{cc}&0&0&0&0&0&0&0\\\\\n0&0&p_{bb}&p_{bc}&0&p_{ab}&0&0&0&0&0\\\\\n\\hline\n0&0&0&0&0&0&p_{aa}&p_{ab}&0&p_{ac}&0\\\\\n\\hline\n0&0&0&0&0&0&p_{aa}&p_{ab}&0&p_{ac}&0\\\\\n0&0&0&0&0&0&p_{ba}&p_{bb}&p_{bc}&0&0\\\\\n0&0&0&0&0&0&p_{ca}&p_{cb}&p_{cc}&0&0\\\\\n0&0&0&0&0&0&0&p_{cb}&p_{cc}&0&p_{ca}\\\\\n0&0&0&0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\ndonde \\(\\small{p_{a},\\, p_{b}}\\), y \\(\\small{p_{c}}\\) son las probabilidades de transici√≥n dadas del estado \\(\\small{\\emptyset}\\) a los estados \\(\\small{(0, a), (0,b)}\\) y \\(\\small{(0, c)}\\), respectivamente. Nuevamente, la extensi√≥n de i.i.d. a los emnsayos Markov-Dependientes sigue siendo sencillo. El concepto considerado en el ejemplo anterior se puede extender al caso de superposici√≥n hasta los √∫ltimos \\(\\small{d}\\) ensayos \\(\\small{(1 \\leq d \\leq k ‚àí 1)}\\), como lo introdujeron Aki e Hirano (2000). Una ventaja significativa de la t√©cnica de incrustaci√≥n de cadenas finitas de Markov es que la extensi√≥n del conteo sin superposici√≥n al conteo superpuesto es directa y simple.\n\n\n\nLa distribuci√≥n del n√∫mero de patrones en serie \\(\\small{\\Lambda=\\Lambda_{1}\\ast\\Lambda_{2}}\\) se puede obtener casi de la misma manera que para un patr√≥n simple, con modificaciones menores en el estado despu√©s de que se haya producido el primer patr√≥n \\(\\small{\\Lambda_{1}}\\).\nEjemplo 4.5 Consideremos una secuencia de \\(\\small{n=5}\\) ensayos i.i.d. de tres estados extra√≠dos de \\(\\small{\\mathscr{S}=\\{a,b,c\\}}\\), y el patr√≥n de serie \\(\\small{\\Lambda}=ab\\ast cc\\) generado por los dos patrones simples \\(\\small{\\Lambda_{1}=ab}\\) y \\(\\small{\\Lambda_{2}=cc}\\). Definiendo el conjunto de bloques finales \\(\\small{\\mathscr{E}=\\{a,\\bar{a},ab\\ast,ab{\\ast}c,ab{\\ast}cc\\}}\\) y el espacio de estados\n\n\n\\[\\begin{equation}\n\\Omega=\\{\\emptyset,(0,a),(0,\\bar{a}),(0,ab{\\ast}),(0,ab{\\ast}c),(1,ab{\\ast}cc),(1,a),(1,\\bar{a})\\}\n\\end{equation}\\]\n\ndonde \\(\\small{\\bar{a}}\\) representa \\(\\small{b}\\) o \\(\\small{c}\\), y \\(\\small{ab{\\ast}}\\) representa \\(\\small{ab{\\ast}a}\\) o \\(\\small{ab{\\ast}b}\\). La correspondiente cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) tiene la matriz de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M}}\\) dada por:\n\n\n\\[\\begin{equation}\n\\boldsymbol{M}=\n\\begin{array}{cc}&\n\\begin{array}{c}\n\\emptyset\\\\\n(0,a)\\\\\n(0,\\bar{a})\\\\\n(0,ab{\\ast})\\\\\n(0,ab{\\ast}c)\\\\\n(1,ab{\\ast}cc)\\\\\n(1,a)\\\\\n(1,\\bar{a})\\\\\n\\end{array}\n&\n\\left(\n\\begin{array}{cccccccc}\n0&p_{a}&p_{b}+p_{c}&0&0&0&0&0\\\\\n0&p_{a}&p_{c}&p_{b}&0&0&0&0\\\\\n0&p_{a}&p_{b}+p_{c}&0&0&0&0&0\\\\\n0&0&0&p_{a}+p_{b}&p_{c}&0&0&0\\\\\n0&0&0&p_{a}+p_{b}&0&p_{c}&0&0\\\\\n0&0&0&0&0&0&p_{a}&p_{b}+p_{c}\\\\\n0&0&0&0&0&0&1&0\\\\\n0&0&0&0&0&0&0&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nPor lo tanto:\n\n\n\\[\\begin{equation}\n\\mathbb{P}\\big(X_{n}(\\Lambda)=x\\big)=\\boldsymbol{\\xi}_{0}\\boldsymbol{M}^{5}\\boldsymbol{U}(C_{x}),\\,x=0,1.\n\\end{equation}\\]\n\nObs√©rvese que si \\(\\small{\\{Y_t\\}}\\) est√° en el estado \\(\\small{(0, ab{\\ast})}\\) o \\(\\small{(0,ab{\\ast}c)}\\), significa que el patr√≥n \\(\\small{\\Lambda_{1}=ab}\\) ha ocurrido antes o en el \\(\\small{t-}\\)√©simo ensayo. Ahora bien, si la realizaci√≥n de \\(\\small{X_{t+1}}\\) es \\(\\small{a}\\) o \\(\\small{b}\\) , entonces \\(\\small{Y_{t+1}}\\) tiene que estar en el estado \\(\\small{(0, ab{\\ast})}\\), suceso que ocurre con probabilidad de transici√≥n \\(\\small{p_{a}+p_{b}}\\) , y si la realizaci√≥n de \\(\\small{X_{t+1}}\\) es \\(\\small{c}\\), entonces \\(\\small{Y_{t+1}}\\) avanza al estado \\(\\small{(0, ab{\\ast}c)}\\) o \\(\\small{(1, ab{\\ast}cc)}\\), respectivamente, sucesos que ocurren con probabilidad de transici√≥n \\(\\small{p_{c}}\\).\nEl ejemplo anterior pone de manifiesto las diferencias entre los patrones en series y los patrones simples en lo que respecta a sus matrices de probabilidad de transici√≥n de las cadenas de Markov incrustadas. Ampliando ligeramente el espacio de estados \\(\\small{\\Omega}\\), sustituyendo \\(\\small{(i,\\bar{a}),\\, i=0,1}\\), por \\(\\small{(i,b)}\\) y \\(\\small{(i, c)}\\), y sustituyendo \\(\\small{(0, ab{\\ast})}\\) por \\(\\small{(0, ab{\\ast}a)}\\) y \\(\\small{(0, ab{\\ast}b)}\\), el ejemplo anterior puede ampliarse f√°cilmente al caso de ensayos de tres estados Markov-Dependientes.\n\n\n\nHallar la distribuci√≥n conjunta de dos n√∫meros de rachas, digamos \\(\\small{X_n(\\Lambda_{1})}\\) y \\(\\small{X_n(\\Lambda_{2})}\\) , en una secuencia de ensayos de dos o varios estados \\(\\small{\\{X_t\\}}\\) utilizando la t√©cnica de incrustaci√≥n de cadenas de Markov finitas es similar a hallar la distribuci√≥n exacta de \\(\\small{X_n(\\Lambda)}\\) introducida en la Secci√≥n 4.2. En general, la cadena de Markov incrustada \\(\\small{\\{Y_t\\}}\\) asociada a la distribuci√≥n conjunta de \\(\\small{X_n(\\Lambda_{1})}\\) y \\(\\small{X_n(\\Lambda_{2})}\\) tiene la forma\n\n\n\\[\\begin{equation}\nY_{t}=\\big(X_{t}(\\Lambda_{1}),X_{t}(\\Lambda_{2}),E_{t}\\big),\\,t=1,2,\\ldots,n.\n\\end{equation}\\]\n\nEl espacio de estados \\(\\small{\\Omega}\\) y el bloque final \\(\\small{E_{t}}\\) para \\(\\small{\\{Y_t\\}}\\) dependen en gran medida de la estructura de los patrones \\(\\small{\\Lambda_{1}}\\) y \\(\\small{\\Lambda_{2}}\\). Las matrices de probabilidad de transici√≥n \\(\\small{\\boldsymbol{M}_{t}}\\) de la cadena de Markov inscrustada pueden construirse utilizando los mismos principios descritos en secciones anteriores. A continuaci√≥n, damos un ejemplo para demostrar el procedimiento para encontrar la distribuci√≥n conjunta.\nEjemplo 4.6 Sea \\(\\small{X_{n}}\\) el n√∫mero total de rachas de √©xito \\(\\small{X_{n}(S)}\\) y de fracaso \\(\\small{X_{n}(S)}\\) en una secuencia de \\(\\small{n}\\) ensayos de dos estados. Para cada \\(\\small{X_{n} = X_{n}(S) + X_{n}(F)}\\), y los n√∫meros de rachas \\(\\small{X_{n}(S)}\\) y \\(\\small{X_{n}(F)}\\) est√°n relacionados de la siguiente manera: si hay \\(\\small{x}\\) rachas de √©xito, entonces s√≥lo puede haber \\(\\small{x+1, x}\\), o \\(\\small{x-1}\\) rachas de fracaso. De ello se deduce que s√≥lo puede haber cuatro tipos de estados \\(\\small{Y_{t}=(X_{t}(S), X_{t}(F), E_{t})}\\), donde el bloque final \\(\\small{E_{t}}\\) es \\(\\small{S}\\) o \\(\\small{F}\\) : (i) \\(\\small{(x, x-1, S)}\\), (ii) \\(\\small{(x, x + 1, F)}\\), (iii) \\(\\small{(x, x, S)}\\) y (iv) \\(\\small{(x, x, F)}\\).\nConsideremos los resultados de diez ensayos de dos estados \\(\\small{w = (SSFFSFSSSF)}\\). La realizaci√≥n de la cadena de Markov imbricada \\(\\small{\\{Y_t\\}}\\) es \\(\\small{\\{Y_{1}=(1,0, S), Y_{2}=(1,0,S), Y_{3}=(1,1,F), Y_{4}=(1,1,F), Y_{5}=(2,1,S), Y_{6}= (2,2,F),Y_{7}=(3,2,S),Y_{8}=(3,2, S),Y_{9}=(3,2,S), Y_{10} = (3,3, F)\\}}\\). El espacio de estados \\(\\small{\\Omega}\\) tiene la forma \\(\\small{\\Omega=\\{(1,0,S), (0,1,F), (1,1,S), (1,1,F),\\ldots, (l_{n},l_{n}S), (l_{n}, l_{n},F)\\}}\\), donde \\(\\small{l_{n}=[(n+1)/2]}\\). Para el caso de ensayos de dos estados independientes pero no id√©nticamente distribuidos, la definici√≥n de \\(\\small{Y_{t}}\\) da como resultado las matrices de probabilidad de transici√≥n, para \\(\\small{t=2,3,\\ldots,n,}\\)\n\n\n\\[\\begin{equation}\n\\boldsymbol{M_{t}}=\n\\begin{array}{cc}&\n\\begin{array}{c}\n(1,0,S)\\\\\n(0,1,S)\\\\\n(1,1,S)\\\\\n(1,1,S)\\\\\n\\cdot\\\\\n\\cdot\\\\\n\\cdot\\\\\n(l_{n},l_{n}-1,S)\\\\\n(l_{n}-1,l_{n},F)\\\\\n(l_{n},l_{n},S)\\\\\n(l_{n},l_{n},F)\\\\\n\\end{array}\n&\n\\left(\n\\begin{array}{ccccccccccc}\np_{t}&0&0&q_{t}&&&&&&&\\\\\n&q_{t}&p_{t}&0&0&&&&&&\\\\\n&&p_{t}&0&0&q_{t}&&&&&\\\\\n&&&q_{t}&p_{t}&0&0&&&&\\\\\n&&&&\\ddots&\\ddots&\\ddots&\\ddots&&&\\\\\n&&&&&\\cdot&\\cdot&\\cdot&\\cdot&&\\\\\n&&&&&&\\ddots&\\ddots&\\ddots&\\ddots&\\\\\n&&&&&&&p_{t}&0&0&q_{t}\\\\\n&&&&&&&&q_{t}&p_{t}&0\\\\\n&&&&&&&&&1&0\\\\\n&&&&&&&&&&1\\\\\n\\end{array}\n\\right)\n\\end{array}\n\\end{equation}\\]\n\nDado \\(\\small{\\boldsymbol{\\xi}_{1}=(p_{1},q_{1},0,\\ldots,0)}\\) , se deduce que la distribuci√≥n conjunta de \\(\\small{X_n(S)}\\) y \\(\\small{X_n(F)}\\) est√° dada por:\n\n\n\\[\\begin{equation}\n\\small{\\mathbb{P}\\big( X_{n}(S)=x,X_{n}(F)=y\\mid \\boldsymbol{\\xi}_{1}\\big)=\\boldsymbol{\\mathbf{\\xi}}_{1} \\Big(\\prod_{t=1}^{n}\\boldsymbol{M}_{t}\\Big)\\boldsymbol{\\mathbf{U}'}(\\mathbf{C}_{(x,y)})},\n\\end{equation}\\]\n\ndonde, si \\(\\small{y= x+1}\\), entonces \\(\\small{C_{(x,x+1)}=\\{{(x, x + 1, F)}\\}}\\), si \\(\\small{y=x-1}\\), entonces \\(\\small{C_{(x, x-1)}=\\{(x, x-1, S)\\}}\\), si \\(\\small{y=x}\\) entonces \\(\\small{C_{(x,x)}=\\{(x, x, S), (x, x, F)\\}}\\), y \\(\\small{C_{(x,y)}=\\{\\emptyset\\}}\\) en cualquier otro caso.\nUna vez m√°s, con algunas modificaciones sencillas de las matrices de probabilidades de transici√≥n, los resultados anteriores tambi√©n son v√°lidos tanto para ensayos de dos estados i.i.d., como Markov-Dependientes homog√©neos y no homog√©neos. Las distribuciones marginales de \\(\\small{X_{n}(S)}\\) y \\(\\small{X_{n}(F)}\\) pueden obtenerse proyectando la distribuci√≥n conjunta sobre las particiones generadas por las variables aleatorias \\(\\small{X_{n}(S)}\\) y \\(\\small{X_{n}(F)}\\), respectivamente. De forma m√°s general, la distribuci√≥n conjunta de \\(\\small{l&gt;2}\\) variables aleatorias \\(\\small{X_{n}(\\Lambda_{1}),X_{n}(\\Lambda_{2}),\\ldots,X_{n}(\\Lambda_{l})}\\) puede obtenerse del mismo modo con una cadena de Markov \\(\\small{(l+1)-}\\)dimensional \\(\\small{\\{Y_{t} = \\big(X_{t}(\\Lambda_{1}),\\cdots, X_{t}(\\Lambda_{l}), E_{t}\\big)\\}}\\).\nFin 05 de Nov\n\n\n\n\n\n\n\nAbramson, M. and Moser, W. O. J. (1967). Permutations without rising or falling w-sequences. Annals of Mathematical Statistics 38, 1245-1254.\nAki, S. (1985). Discrete distributions of order k on a binary sequence. Annals of the Institute of Statistical Mathematics 37, 205-224.\nAki, S. (1997). On sooner and later problems between success and failure runs.Advances in Combinatorial Methods and Applications to Probability and Statistics (ed.¬†N. Balakrishnan), Birkh√§user, Boston, 385-400.\nAki, S. (1999). Distributions of runs and consecutive systems on directed trees. Annals of the Institute of Statistical Mathematics 51, 1-15.\nAki, S., Balakrishnan, N. and Mohanty, S. G. (1996). Sooner and later waiting time problems for success and failure runs in higher order Markov dependent trials. Annals of the Institute of Statistical Mathematics 48, 773-787.\nAki, S. and Hirano, K. (1988). Some characteristics of the binomial distribution of order k and related distributions. Statistical Theory and Data Analysis II (ed.¬†K. Matusita), North-Holland, Amsterdam, 211-222.\nAki, S. and Hirano K. (1999). Sooner and later waiting time problems for runs in Markov dependent bivariate trials. Annals of the Institute of Statistical Mathematics 51, 17-29.\nAki, S. and Hirano K. (2000). Numbers of success-runs of specified length until certain stopping time rules and generalized binomial distributions of order k. Annals of the Institute of Statistical Mathematics 52, 767-777.\nAki, S., Kuboki, H. and Hirano, K. (1984). On discrete distributions of order k. Annals of the Institute of Statistical Mathematics 36, 431-440.\nAntzoulakos, D. L. (1999). On waiting time problems associated with runs in Markov dependent trials. Annals of the Institute of Statistical Mathematics 51, 323-330.\nAntzoulakos, D. L. (2001). Waiting times for patterns in a sequence of multistate trials. Journal of Applied Probability 38, 508-518.\nBalakrishnan, N. and Koutras, M. V. (2002). Runs and Scans with Applications, Wiley, New York\nBalasubramanian, K., Viveros, R. and Balakrishnan, N. (1993). Sooner and later waiting time problems for Markovian Bernoulli trials. Statistics and Prob- ability Letters 18, 153‚Äì161.}\nBarnard, G. A. (1959). Control charts and stochastic processes. Journal of the Royal Statistical Society, Series B 21, 239-271.\nBarton, D. E. and David, F. N. (1958). Non-randomness in a sequence of two alternatives: II. Runs test. Biometrika 45, 253-256.\nBateman, G. (1948). On the power function of the longest run as a test for randomness in a sequence of alternatives. Biometrika 35, 97-112.\nBoutsikas, M. V. and Koutras, M. V. (2000a). Generalized reliability bounds for coherent structures. Journal of Applied Probability 37, 778-794.\nBoutsikas, M. V. and Koutras, M. V. (2000b). Reliability approximation for Markov chain imbeddable systems. Methodology and Computing in Applied Probability 2, 393-411.\nBrook, D. and Evans, D. A. (1972). An approach to the probability distribution of cusum run length. Biometrika 59, 539-549.\nCai, J. (1994). Reliability of a large consecutive-k-out-of-r-from-n:F system with unequal component-reliability. IEEE Transactions on Reliability 43, 107‚Äì 111.\nCarlitz, L. (1964). Extended Bernoulli and Eulerian numbers. Duke Mathematical Journal 31, 667-689.\nChao, M. T. (1999). Applications of Markov chains in quality-related matters. Statistical Process Monitoring and Optimization (eds.¬†S. H. Park and G. G. Vining), Marcel Dekker, New York, 175-188.\nChao, M. T. and Fu, J. C. (1989). A limit theorem of certain repairable systems. Annals of the Institute of Statistical Mathematics 41, 809‚Äì818.\nChao, M. T. and Fu, J. C. (1991). The reliability of large series system under a Markovian structure. Advances in Applied Probability 23, 894-908.\nChao, M. T., Fu, J. C. and Koutras, M. V. (1995). Survey of reliability stud- ies of consecutive-k-out-of-n: F and related systems. IEEE Transactions on Reliability 44, 120-127.\nChao, M. T. and Lin, G. D. (1984). Economical design of large consecutive-k- out-of-n:F systems. IEEE Transactions on Reliability 33, 411-413.\nChen, J. and Glaz, J. (1997). Approximations and inequalities for the distribution of a scan statistic for 0-1 Bernoulli trials. Advances in the Theory and Practice of Statistics (eds.¬†N. L. Johnson and N. Balakrishnan), Wiley, New York, 285-298.\nChen, J. and Glaz, J. (1999). Approximations for the distribution and the moments of discrete scan statistics. Scan Statistics and Applications (eds.¬†J. Glaz and N. Balakrishnan), Birkh√§user, Boston, 27-66.\nCheung, L. K. W. (2002). Statistical Pattern Recognition in Genomic DNA Sequences. Ph.D.¬†Dissertation, Department of Statistics, University of Manitoba, Canada.\nChiang, D. T. and Niu, S. C. (1981). Reliability of consecutive-k-out-of-n:F sys- tems. IEEE Transactions on Reliability 30, 87-89.\nChrysaphinou, O. and Papastavridis, S. (1988). A limit theorem on the number of overlapping appearances of a pattern in a sequence of independent trials. Probability Theory and Related Fields 79, 129-143.\nCochran, W. G. (1938). An extension of Gold‚Äôs method for examining the apparent persistence of one type of weather. Quarterly Journal of the Royal Meteorological Society 64, 631-634.\nCs√∂rg√∂, S. (1979). Erd√∂s-R√©nyi laws. Annals of Statistics 7, 772-787. David, F. N. (1947). A power function for tests of randomness in a sequence of alternatives. Biometrika 34, 335-339.\nDavid, F. N. and Barton, D. E. (1962). Combinatorial Chance, Hafner, New York. Derman, G., Lieberman, G. J. and Ross, S. M. (1982). On the consecutive-k-out- of-n:F system. IEEE Transactions on Reliability 31, 57-63.\nDillon, J. F. and Roselle, D. P. (1969). Simon Newcomb‚Äôs problem. SIAM Journal on Applied Mathematics 17, 1086-1093.\nDoi, M. and Yamamoto, E. (1998). On the joint distribution of runs in a sequence of multi-state trials. Statistics and Probability Letters 39, 133-141.\nDwass, M. (1973). The number of increases in a random permutation. Journal of Combinatorial Theory, Series A 15, 192-199.\nEbneshahrashoob, M. and Sobel, M. (1990). Sooner and later problems for Bernoulli trials: frequency and run quotas. Statistics and Probability Letters 9, 5-11.\nErd√∂s, P. and R√©nyi, A. (1970). On a new law of large numbers. Journal d‚ÄôAnalyse Math√©matique 23, 103-111.\nErd√∂s, P. and R√©v√©sz, P. (1975). On the length of the longest head-run. Topics in Information Theory, Colloquia Mathematica Societatis J√°nos Bolyai, 16 (eds.¬†I. Csiszar and P. Elias; Keszthely, Hungary), North-Holland, Amster- dam, 219-228.\nEwan, W. D. and Kemp, K. W. (1960). Sampling inspection of continuous pro- cesses with no autocorrelation between successive results. Biometrika 47, 363-380.\nFeller, W. (1968). An Introduction to Probability Theory and Its Applications (Vol. I, 3rd ed.), Wiley, New York.\nFu, J. C. (1985). Reliability of consecutive-k-out-of-n:F system. IEEE Transac- tions on Reliability 34, 127-130.\nFu, J. C. (1986). Reliability of consecutive-k-out-of-n:F systems with (k-1) step Markov dependence. IEEE Transactions on Reliability 35, 602-606.\nFu, J. C. (1995). Exact and limiting distributions of the number of successions in a random permutation. Annals of the Institute of Statistical Mathematics 47, 435-446.\nFu, J. C. (1996). Distribution theory of runs and patterns associated with a sequence of multi-state trials. Statistica Sinica 6, 957-974.\nFu, J. C. (2001). Distribution of scan statistics for a sequence of bi-state trials Journal of Applied Probability 38, 1-9.\nFu, J. C. and Chang, Y. M. (2002). On probability generating functions for wait- ing time distributions of compound patterns in a sequence of multistate trials. Journal of Applied Probability 39, 70-80.\nFu, J. C. and Hu, B. (1987). On reliability of a large consecutive-k-out-of-n:F sys- tem with k-1 step Markov dependence. IEEE Transactions on Reliability 36, 75-77.\nFu, J. C. and Koutras, M. V. (1994). Distribution theory of runs: a Markov chain approach. Journal of the American Statistical Association 89, 1050-1058.\nFu, J. C. and Lou, W. Y. W. (1991). On reliabilities of certain large linearly connected engineering systems. Statistics and Probability Letters 12, 291-296.\nFu, J. C. and Lou, W. Y. W. (2000a). On the exact distribution of SECON and its application. Statistica Sinica 10, 999-1010.\nFu, J. C. and Lou, W. Y. W. (2000b). Joint distribution of rises and falls. Annals of the Institute of Statistical Mathematics 52, 415-425.\nFu, J. C., Lou, W. Y. W., Bai, Z. D. and Li, G. (2002). The exact and limiting distributions for the number of successes in success runs within a sequence of Markov-dependent two-state trials. Annals of the Institute of Statistical Mathematics 54, 719-730.\nFu, J. C., Lou, W. Y. W. and Chen, S. C. (1999). On the probability of pattern matching in nonaligned DNA sequences: a finite Markov chain imbedding approach. Scan Statistics and Applications (eds.¬†J. Glaz and N. Balakrish- nan), Birkh√§user, Boston, 287-302.\nFu, J. C., Lou, W. Y. W. and Wang, Y. J. (1999). On the exact distributions of Eulerian and Simon Newcomb numbers associated with random permuta- tions. Statistics and Probability Letters 42, 115‚Äì125.\nFu, J. C., Shmueli, G. and Chang, Y. M. (2002). A unified Markov chain approach for computing the run length distribution for control charts with simple or compound rules. Technical Report, Department of Statistics, University of Manitoba.\nFu, J. C., Spiring, F. A. and Xie, H. (2002). On the average run lengths of quality control schemes using a Markov chain approach. Statistics and Probability Letters 56, 369-380.\nGlaz, J. (1989). Approximations and bounds for the distribution of the scan statistic. Journal of the American Statistical Association 84, 560-566.\nGlaz, J. (1992). Approximations for tail probabilities and moments of the scan statistic. Computational Statistics and Data Analysis 14, 213-227.\nGlaz, J., Naus, J. I. and Wallenstein, S. (2001). Scan Statistics, Springer-Verlag, New York.\nGodbole, A. P. (1990). Specific formulae for some success run distributions. Statistics and Probability Letters 10, 119-124.\nGodbole, A. P. (1991). Poisson approximations for runs and patterns of rare events. Advances in Applied Probability 23, 851-865.\nGoncharov, V. L. (1944). On the field of combinatory analysis. Isvestija Akad. Nauk. SSSR. Ser. Math. 8, 3-48 (in Russian); English translation: Translations of the AMS Ser. Math. 19 (1962), 1-46.\nGoodman, L. A. (1958). Simplified runs tests and likelihood ratio tests for Markoff chains. Biometrika 45, 181-197.\nHan, Q. and Aki, S. (1998). Formulae and recursions for the joint distributions of success runs of several lengths in a two-state Markov chain. Statistics and Probability Letters 40, 203-214.\nHan, Q. and Aki, S. (2000a). Sooner and later waiting time problems based on a dependent sequence. Annals of the Institute of Statistical Mathematics 52, 407-414.\nHan, Q. and Aki, S. (2000b). Waiting time problems in a two-state Markov chain. Annals of the Institute of Statistical Mathematics 52, 778-789.\nHirano, K. (1986). Some properties of the distributions of order k. Fibonacci Numbers and Their Applications (eds.¬†A. N. Philippou, G. E. Bergum, and A. F. Horadam), Reidel, Dordrecht, 43-53.\nHirano, K. and Aki, S. (1987). Properties of the extended distributions of order k. Statistics and Probability Letters 6, 67-69.\nHirano, K. and Aki, S. (1993). One number of occurrences of success runs of specified length in a two-state Markov chain. Statistica Sinica 3, 313-320.\nHuntington, R. J. and Naus, J. I. (1975). A simpler expression for kth nearest neighbor coincidence probabilities. Annals of Probability 3, 894-896.\nHwang, F. K. (1982). Fast solutions for consecutive-k-out-of-n:F system. IEEE Transactions on Reliability 31, 447-448.\nHwang, F. K. (1986). Simplified reliabilities for consecutive-k-out-of-n systems.SIAM Journal on Algebraic and Discrete Methods 7, 258-264.\nJackson, D. M. and Reilly, J. W. (1976). Permutations with a prescribed number of p-runs. Ars Combinatoria 1, 297-305.\nJohnson, B. C. (2001). Distribution of increasing l-sequences in a random permutation. Methodology and Computing in Applied Probability 3, 35-49.\nJohnson, B. C. (2002). The distribution of increasing 2-sequences in random per- mutations of arbitrary multi-sets. Statistics and Probability Letters 59, 67-74.\nJohnson, B. C and Fu, J. C. (2000). The distribution of increasing l-sequences in random permutations: A Markov chain approach. Statistics and Probability Letters 49, 337-344.\nKaplansky, I. (1944). Symbolic solution of certain problems in permutations. Bul- letin of the American Mathematical Society 50, 906-914.\nKarlin, S. and McGregor, J. (1959). Coincident probabilities. Pacific Journal of Mathematics 9, 1141-1164.\nKontoleon, J. M. (1980). Reliability determination of a r-successive-out-of-n:F system. IEEE Transactions on Reliability 29, 437.\nKossow, A. and Preuss, W. (1989). Reliability of consecutive-k-out-of-n:F system with nonidentical component reliabilities. IEEE Transaction on Reliability 38, 229-233.\nKoutras, M. V. (1996a). On a Markov chain approach for the study of reliability structures. Journal of Applied Probability 33, 357-367.\nKoutras, M. V. (1996b). On a waiting time distribution in a sequence of Bernoulli trials. Annals of the Institute of Statistical Mathematics 48, 789-806.\nKoutras, M. V. (1997a). Waiting time distributions associated with runs of fixed length in two-state Markov chains. Annals of the Institute of Statistical Mathematics 49, 123-139.\nKoutras, M. V. (1997b). Waiting times and number of appearances of events in a sequence of discrete random variables. Advances in Combinatorial Meth- ods and Applications to Probability and Statistics (ed.¬†N. Balakrishnan), Birkh√§user, Boston, 363-384.\nKoutras, M. V. (2003). Applications of Markov chains to the distribution the- ory of runs and patterns. Handbook of Statistics 21: Stochastic Processes, Modeling and Simulation (eds.¬†D. N. Shanbhag and C. R. Rao), Elsevier, Amsterdam, in press.\nKoutras, M. V. and Alexandrou, V. (1995). Runs, scans and urn model distributions: a unified Markov chain approach. Annals of the Institute of Statistical Mathematics 47, 743-766.\nKoutras, M. V. and Alexandrou, V. (1997a). Non-parametric randomness tests based on success runs of fixed length. Statistics and Probability Letters 32, 393-404.\nKoutras, M. V. and Alexandrou, V. (1997b). Sooner waiting time problems in a sequence of trinary trials. Journal of Applied Probability 34, 593‚Äì609.\nKoutras, M. V. and Papastavridis, S. G. (1993). Application of the Stein-Chen method for bounds and limit theorems in the reliability of coherent struc- tures. Naval Research Logistics 40, 617-631.\nLing, K. D. (1992). A generalization of the sooner and later waiting time problems for Bernoulli trials: frequency quota. Statistics and Probability Letters 14, 401-405.\nLing, K. D and Low, T. Y. (1993). On the soonest and the latest waiting time distributions: succession quotas. Communications in Statistics Theory and Methods 22, 2207-2221.\nLou, W. Y. W. (1996). On runs and longest run tests: method of finite Markov chain imbedding. Journal of the American Statistical Association 91, 1595‚Äì 1601.\nLou, W. Y. W. (1997). An application of the method of finite Markov chain imbedding to runs tests. Statistics and Probability Letters 31, 155‚Äì161.\nLou, W. Y. W. (2000). The exact distribution of the continuity of care measure NOP. Statistics and Probability Letters 48, 361‚Äì368.\nLou, W. Y. W. (2001). The distribution of the usual provider continuity index under Markov dependence. Statistics and Probability Letters 54, 269‚Äì276.\nLou, W. Y. W. (2003). The exact distribution of the K-tuple statistic for sequence homology. Statistics and Probability Letters 1, 51-59.\nLucas, J. M. and Crosier, R. B. (1982). Fast initial response for CUSUM quality control schemes: Give your CUSUM a head start. Technometrics 24, 199-205.\nMacMahon, P. A. (1915). Combinatory Analysis, Cambridge University Press, London.\nMohanty, S. G. (1994). Success runs of length k in Markov dependent trials. Annals of the Institute of Statistical Mathematics 46, 777-796.\nMontgomery, D. C. (2001). Introduction to Statistical Quality Control (4th ed.). Wiley, New York.\nMood, A. M. (1940). The distribution theory of runs. Annals of Mathematical Statistics 11, 367‚Äì392.\nMosteller, F. (1941). Note on an application of runs to quality control charts. Annals of Mathematical Statistics 12, 228-232.\nMuselli, M. (2000). Useful inequalities for the longest run distribution. Statistics and Probability Letters 46, 239-249.\nNagaev, S. V. (1957). Some limit theorems for stationary Markov chains. Theory of Probability and its Applications 2, 378-406.\nNaus, J. I. (1965). The distribution of the size of the maximum cluster of points on a line. Journal of the American Statistical Association 60, 532-538.\nNaus, J. I. (1974). Probabilities for a generalized birthday problem. Journal of the American Statistical Association 69, 810-815\nNaus, J. I. (1982). Approximations for distributions of scan statistics. Journal of the American Statistical Association 77, 177-183.\nNishimura, K. and Sibuya, M. (1997). Extended Stirling family of discrete probability distributions. Communications in Statistics Theory and Methods 26, 1727-1744.\nPapastavridis, S. G. (1988). A Weibull limit for the reliability of a consecutive k-within-m-out-of-n system. Advances in Applied Probability 20, 690-692.\nPapastavridis, S. G. and Koutras, M. V. (1993). Bounds for reliability of consec- utive k-within-m-out-of-n:F systems. IEEE Transactions on Reliability 42, 156-160.\nPhilippou, A. N. (1986). Distributions and Fibonacci polynomials of order k, longest runs, and reliability of consecutive-k-out-of-n:F systems. Fibonacci Numbers and Their Applications (eds.¬†A. N. Philippou, G. E. Bergum and A. F. Horadam), Reidel, Dordrecht, 203-227.\nPhilippou, A. N., Georghiou, C. and Philippou, G. N. (1983). A generalized geometric distribution and some of its properties. Statistics and Probability Letters 1, 171‚Äì175.\nPhilippou, A. N. and Makri, F. S. (1986). Success runs and longest runs. Statistics and Probability Letters 4, 211‚Äì215.\nPyke, R. (1961). Markov renewal processes: definitions and preliminary proper- ties. Annals of Mathematical Statistics 32, 1231-1242.\nReilly, J. W. and Tanny, S. M. (1979). Counting successions in permutations. Studies in Applied Mathematics 61, 73-81.\nR√©nyi, A (1970). Probability Theory, American Elsevier Publishing Company Inc., New York.\nRiordan, J. (1958). An Introduction to Combinatorial Analysis, Wiley, New York.\nRoselle, D. P. (1968). Permutations by number of rises and successions. Proceed- ings of the American Mathematical Society 19, 8-16. Ross, S. M. (2000). Introduction to Probability Models (7th ed.), Academic Press, San Diego.\nRubin, G., McCulloch, C. E. and Shapiro, M. A. (1990). Multinomial runs tests to detect clustering in constrained free recall. Journal of the American Sta- tistical Association 85, 315-320.\nSaperstein, B. (1972). The generalized birthday problem. Journal of the American Statistical Association 67, 425-428.\nSchilling, M. F. (1990). The longest run of heads. The College Mathematics Jour- nal 21, 196-207.\nSeneta, E. (1981). Non-negative Matrices and Markov Chains (2nd ed.), Springer- Verlag, New York.\nSheng, K. N. and Naus, J. I. (1994). Pattern matching between two non-aligned random sequences. Bulletin of Mathematical Biology 56, 1143-1162.\nSteinwachs, D. M. (1979). Measuring provider continuity in ambulatory care. Medical Care 17, 551-565.\nSwed, F. S. and Eisenhart, C. (1943). Tables for testing randomness of grouping in a sequence of alternatives. Annals of Mathematical Statistics 14, 66-87.\nTanny, S. (1973). A probabilistic interpretation of Eulerian numbers. Duke Math- ematical Journal 40, 717-722.\nTanny, S. M. (1976). Permutations and successions. Journal of Combinatorial Theory, Series A 21, 196-202.\nVaggelatou, E. (2003). On the length of the longest run in a multi-state Markov chain. Statistics and Probability Letters 62, 211‚Äì221.\nUchida, M. and Aki, S. (1995). Sooner and later waiting time problems in a two- state Markov chain. Annals of the Institute of Statistical Mathematics 47, 415-433\nWald, A. and Wolfowitz, J. (1940). On a test whether two samples are from the same population. Annals of Mathematical Statistics 11, 147-162.\nWigle, D. T. (1982). Prevalence of selected chronic diseases in Canada, 1978-1979. Chronic Disease in Canada 3, 9.\nWishart, J. and Hirshfeld, H. O. (1936). A theorem concerning the distribution of joins between line segments. Journal of the London Mathematical Society 11, 227-235.\nWolfowitz, J. (1943). On the theory of runs with some applications to quality control. Annals of Mathematical Statistics 14, 280-288.\nWorpitzky, J. (1883). Studien √ºber die Bernoullischen und Eulerschen Zahlen. Journal f√ºr die reine und angewandte Mathematik 94, 203-232.",
    "crumbs": [
      "Trabajo Grado"
    ]
  },
  {
    "objectID": "Trabajo_Grado.html#rachas-y-escaners-con-aplicaciones",
    "href": "Trabajo_Grado.html#rachas-y-escaners-con-aplicaciones",
    "title": "Vladimir Sanchez Tenjo",
    "section": "Rachas y Escaners con Aplicaciones",
    "text": "Rachas y Escaners con Aplicaciones\n\nPrefacio\nEl concepto de rachas se entiende f√°cilmente y los procedimientos inferenciales basados en rachas son a menudo heur√≠sticamente simples de seguir e implementar. Sin embargo, un estudio te√≥rico de rachas requiere cuidado y uso de una amplia gama de t√©cnicas especiales. Este volumen proporciona una descripci√≥n completa y exhaustiva de varios desarrollos te√≥ricos y aplicados sobre problemas que involucran rachas y escaners\nEste volumen contiene doce cap√≠tulos y puede clasificarse en t√©rminos generales en tres partes: la Parte A, que comprende los Cap√≠tulos 2 y 3, y se ocupa principalmente del tiempo de espera para la primera aparici√≥n de rachas y sus aplicaciones; La Parte B, que comprende los Cap√≠tulos 4 a 8, se ocupa del tiempo de espera para la ocurrencia m√∫ltiple de rachas, el n√∫mero de ocurrencia de rachas, problemas de tiempo de espera tardia y temprana relacionados con rachas, distribuciones de rachas multivariadas y sus aplicaciones; y la Parte C, que comprende los Cap√≠tulos 9 a 12, y se ocupa principalmente del tiempo de espera para el primer escaner, escaners m√∫ltiples, el n√∫mero de escaners y sus aplicaciones.\nLa extensi√≥n de este volumen, as√≠ como la extensa bibliograf√≠a al final del mismo (la mayor parte de los √∫ltimos veinte a√±os) proporciona un amplio testimonio del notable crecimiento que este tema de investigaci√≥n ha experimentado en el pasado reciente. Aunque hemos analizado varias aplicaciones diferentes de estadist√≠cas de rachas y escaneo (con tres cap√≠tulos dedicados a ellas),creemos que hay mucho m√°s potencial para muchas m√°s aplicaciones diversas y espero sinceramente que este volumen permita y anime a los investigadores aplicados en esta direcci√≥n. Para ayudar a los lectores interesados en este proceso, tambi√©n hemos incluido en la Bibliograf√≠a algunas referencias adicionales que se relacionan con esta √°rea de investigaci√≥n pero que no han sido citadas directamente en el texto.\nEn un volumen de esta naturaleza y tama√±o, inevitablemente habr√° omisi√≥n de algunos resultados que deber√≠an haberse incluido en este volumen. Aseguramos que tal omisi√≥n es s√≥lo accidental y de ninguna manera se debe a una antipat√≠a personal no cient√≠fica.\nAlentamos a los lectores a comentar sobre el contenido de este volumen y les agradecemos de antemano por informarnos sobre cualquier error, tergiversaci√≥n u omisi√≥n.\nNos complace reconocer el apoyo y el aliento del Sr.¬†Steve Quigley de John Wiley & Sons, Inc., durante todo el transcurso de este proyecto. Se agradece la ayuda administrativa y editorial brindada por la Sra. Heather Haselkorn y el Sr.¬†Andrew Prince de John Wiley & Sons, Inc. Tambi√©n agradecemos a la Sra. Debbie Iscoe (Mississauga, Ontario, Canad√°) por componer todo el volumen, a la Sra. Roza Garden (Atenas, Grecia) por mecanografiar algunas partes del volumen y al Dr.¬†Michael Boutsikas por ayudarnos a la preparaci√≥n de figuras.\nLa redacci√≥n de este volumen comenz√≥ en 1995 y concluy√≥ en el verano de 2001. Durante este per√≠odo bastante largo, disfrutamos del apoyo, la cooperaci√≥n y la inmensa paciencia de nuestras familias. A todos ellos va nuestro agradecimiento muy especial.\n\n\nIntroducci√≥n y comentarios hist√≥ricos\n\n¬øQU√â SON LAS RACHAS?\nEl concepto y el uso potencial de las rachas se pueden explicar incluso a un principiante en estad√≠stica en t√©rminos simples, ya que el t√©rmino racha se usa en el campo de la probabilidad y la estad√≠stica de la misma manera que se usa en el lenguaje com√∫n. Un significado no t√©cnico com√∫nmente entendido del t√©rmino racha es una sucesi√≥n ininterrumpida y as√≠ es exactamente como definiremos y usaremos las rachas en el libro. Concretamente, en un experimento que involucra diferentes elementos (o resultados), una racha de un determinado tipo de elemento(s) es una sucesi√≥n ininterrumpida de dichos elementos delimitada en cada extremo por otros tipos de elementos o por el principio o el final de la sucesi√≥n completa. Por ejemplo, en la secuencia binaria \\(\\small{1100011101}\\), primero tenemos una racha de dos \\(\\small{1}'\\)s, luego una racha de tres \\(\\small{0}'\\)s, una racha de tres \\(\\small{1}'\\)s, una racha de un \\(\\small{0}\\) y finalmente una racha de un \\(\\small{1}\\). Por tanto, tenemos cinco rachas en esa sucesi√≥n binaria.\nAunque aqu√≠ hemos ilustrado el n√∫mero de rachas como una estad√≠stica, es posible, por supuesto, definir algunas otras estad√≠sticas basadas en las rachas. Por ejemplo, podemos considerar la longitud m√°xima de racha (que es \\(\\small{3}\\)), o la longitud m√≠nima de rachas (que es \\(\\small{1}\\)), o la diferencia entre el n√∫mero de rachas de \\(\\small{1}'\\)s y de \\(\\small{0}'\\)s (que es \\(\\small{3 - 2 = 1}\\))\nLa definici√≥n anterior de racha es simple y f√°cil de introducir con una sola forma de contar. Sin embargo, si consideramos rachas de una longitud espec√≠fica (digamos, \\(\\small{2}\\)), es posible introducir diferentes formas de contar. Por ejemplo, si permitimos el conteo superpuesto, entonces la segunda racha de tres \\(\\small{0}'\\)s en la anterior sucesi√≥n binaria puede considerarse como dos rachas de dos \\(\\small{0}'\\)s. Por otro lado, si utilizamos un conteo no superpuesto, entonces la segunda rachas de tres \\(\\small{0}'\\)s puede considerarse como una √∫nica racha de \\(\\small{0}'\\)s.\n\n\n¬øPOR QU√â RACHAS?\nLas rachas y los problemas asociados siempre han atra√≠do la atenci√≥n de probabilistas y estad√≠sticos desde el principio. Ya en \\(\\small{1738}\\), De Moivre discuti√≥ el siguiente problema: ¬øCu√°l es la probabilidad de obtener una racha de longitud \\({r}\\) o m√°s en \\(n\\) ensayos? Sin embargo, hubo un error en la f√≥rmula de De Moivre (\\(\\small{1738}\\), Doctrine of Chance, Problema 88); pero De Moivre hab√≠a utilizado la f√≥rmula correcta en sus ejemplos num√©ricos. Simpson (1740), Laplace (1812) y Todhunter (1865) realizaron m√°s debates sobre este problema. Curiosamente, Marbe (1916, 1934) utiliz√≥ observaciones sobre rachas para respaldar la teor√≠a que propuso de que si una moneda da ‚Äúcara‚Äù con mucha frecuencia, entonces la probabilidad de obtener ‚Äúcruz‚Äù en el lanzamiento disminuye.\nA pesar de que los problemas relacionados con las rachas se estaban discutiendo en probabilidad y combinatoria desde la publicaci√≥n de Doctrine of Chance por De Moivre en \\(\\small{1738}\\), se necesitaron m√°s de dos siglos para desarrollar una buena aplicaci√≥n de las rachas en estad√≠stica. Wald y Wolfowitz (1940) utilizaron rachas para establecer una prueba de dos muestras que es intuitivamente simple y puede explicarse f√°cilmente de la siguiente manera.\nSea \\(\\small{X_1,X_2,\\ldots, X_m}\\) una muestra aleatoria de una poblaci√≥n con funci√≥n de distribuci√≥n acumulativa \\(\\small{F_X(x)}\\), y sea \\(\\small{Y_1, Y_2,..., Y_n}\\) otra muestra aleatoria independiente de una poblaci√≥n con funci√≥n de distribuci√≥n acumulativa \\(\\small{F_Y(x)}\\). El problema inferencial de inter√©s es contrastar las hip√≥tesis \\(\\small{H_0 : F_X(x) = F_Y(x)}\\) para todo \\(x\\), frente a la alternativa \\(\\small{H_a: F_X(x) \\neq F_Y(x)}\\) para alg√∫n \\(x\\). Wald y Wolfowitz (1940) luego sugirieron combinar las dos muestras, organizar las observaciones \\(\\small{m+n}\\) en orden creciente de magnitud, reemplazar los valores ordenados por \\(\\small{0}\\) o \\(1\\) dependiendo de si se originaron a partir de la muestra \\(\\small{X}\\) o la muestra \\(\\small{Y}\\), respectivamente, y utilizar el n√∫mero total de rachas en esa sucesi√≥n binaria como estad√≠stica de prueba. Dado que se espera que los valores de \\(\\small{X}\\) y \\(\\small{Y}\\) est√©n completamente mezclados entre s√≠ bajo la hip√≥tesis nula, lo que resulta en un valor grande para el n√∫mero total de racha, Wald y Wolfowitz (1940) propusieron rechazar la hip√≥tesis nula para valores peque√±os del n√∫mero total de rachas; los valores cr√≠ticos se pueden determinar f√°cilmente para los valores dados de los tama√±os de muestra \\(m\\) y \\(n\\) y el nivel deseado de significancia \\(\\small{\\alpha}\\). Wald y Wolfowitz (1940) lograron demostrar que esta prueba de rachas de dos muestras es, de hecho, consistente, lo que significa que la potencia de la prueba tiende a \\(\\small{1}\\) cuando los tama√±os de muestra \\(m\\) y \\(n\\) tienden a \\(\\infty\\).\nDesde entonces, se han desarrollado con √©xito una variedad de aplicaciones diferentes de rachas y estad√≠sticas basadas en rachas en una amplia gama de √°reas de la estad√≠stica, as√≠ como en disciplinas aplicadas. En este libro, nuestro objetivo es reunir varios desarrollos te√≥ricos que se han realizado sobre rachas y estad√≠sticas relacionadas y muchas aplicaciones diferentes de estos resultados. Una aplicaci√≥n estad√≠stica significativa de las rachas, anterior al trabajo de Wald y Wolfowitz (1940), se debe a De Forest (1876), quien sugiri√≥ usar rachas en la sucesi√≥n de signos de los residuos para evaluar la adecuaci√≥n de una curva ajustada a un conjunto de datos observados; V√©ase Stigler (1978) para algunos detalles sobre este tema.\nAunque esta secci√≥n ha proporcionado una breve rese√±a hist√≥rica del trabajo sobre rachas y sus aplicaciones, se presentar√°n m√°s detalles en varios lugares pertinentes de este libro. Los lectores interesados tambi√©n pueden consultar el art√≠culo de Weiss (1985) y los libros de Stigler (1986) y Hald (1990) para obtener informaci√≥n adicional.\n\n\n\n¬øPara qu√© sirven las rachas?\nSiguiendo la l√≠nea de la prueba de rachas de dos muestras descrita en la √∫ltima secci√≥n, el n√∫mero de rachas tambi√©n se puede utilizar para desarrollar algunas pruebas de aleatoriedad. Espec√≠ficamente, sean \\(\\small{X_1,X_2,\\ldots,X_n}\\), \\(n\\) variables aleatorias con una funci√≥n de distribuci√≥n acumulativa conjunta \\(\\small{F(x_2,x_2,\\ldots, x_n)}\\). El problema de inter√©s es probar la hip√≥tesis \\(\\small{H_0: X_i's}\\) son independientes y est√°n distribuidas id√©nticamente (i.i.d.), es decir, \\(\\small{F(x_1, ...,x_n) = \\displaystyle\\prod_{i=1}^{n}F ^{*}_i(x)}\\), donde \\(\\small{F^{*}_i(x)}\\) es una funci√≥n de distribuci√≥n acumulativa univariada continua. Podemos considerar la secuencia de signos de las diferencias \\(\\small{X_2-X_2, X_3 - X_2,\\ldots, X_n - X_{n-1}}\\) y definir una racha positiva como una racha de signos correspondientes a diferencias sucesivas positivas y una racha negativa como una racha de signos correspondientes a diferencias sucesivas negativas. Ahora se pueden proponer diferentes procedimientos de prueba en funci√≥n del n√∫mero de rachas positivas y negativas o de la longitud de estas. Dependiendo de la alternativa considerada, se puede elegir una regi√≥n cr√≠tica apropiada. Por ejemplo, si el problema es probar la aleatoriedad frente a la alternativa de que hay una tendencia en \\(\\small{X_1, X_2,\\ldots, X_n}\\), ser√° razonable rechazar \\(\\small{H_0}\\) si los n√∫meros de rachas positivas y negativas son demasiado peque√±as. Si la alternativa fuera especificar la direcci√≥n de la tendencia, entonces podr√≠amos optar por utilizar una de ellas (la que sea apropiada). Por otro lado, si el problema es probar la aleatoriedad frente a la alternativa de que hay muchos ciclos cortos presentes en \\(\\small{X_1,X_2,\\ldots, X_n}\\), entonces ser√° razonable rechazar \\(\\small{H_0}\\) si el n√∫mero de racahs positivas y negativas son demasiado grandes.\nOtra aplicaci√≥n de similar naturaleza surge en el control estad√≠stico de calidad o monitoreo de procesos. Aqu√≠, asumimos que tenemos una caracter√≠stica medible en los art√≠culos que se producen y que esta caracter√≠stica tiene l√≠mites de control superior e inferior (a veces, solo uno de esos l√≠mites). Se supone que el proceso de producci√≥n est√° bajo control si produce muchos art√≠culos conformes y se declara fuera de control si en cualquier momento se produce una cantidad inusualmente grande de art√≠culos no conformes. En concreto, podemos considerar que el proceso de producci√≥n est√° fuera de control si, entre las mediciones realizadas en \\(n\\) art√≠culos consecutivos, la longitud m√°xima de racha positiva o negativa es demasiado grande. Por ejemplo, Deming (1972) ha sugerido una tolerancia hasta una longitud m√°xima de \\(\\small{6}\\) y m√°s all√° para concluir que el proceso de producci√≥n se est√° saliendo de control. Deming (1972) tambi√©n ha planteado otro esquema de monitoreo de procesos en el que observamos la longitud m√°xima de la racha positiva y negativa respecto de la media, es decir, longitud de racha por encima y por debajo de la media, respestivamente. De manera similar, Kitagawa y Seguchi (1956, 1957) han se√±alado la importancia del estudio de las distribuciones relacionadas con rachas m√∫ltiples en relaci√≥n con los m√©todos de control estad√≠stico.\nCon base en ideas similares, tambi√©n se han utilizado el n√∫mero y la longitud de las rachas para desarrollar pruebas no param√©tricas de simetr√≠a de la distribuci√≥n de la cual se obtuvieron datos de muestra; v√©anse, por ejemplo, Cohen y Menjoge (1988), McWilliams (1990), Henze (1993) y Modarres y Gastwirth (1996, 1998). En este contexto, suponiendo que se conoce la mediana poblacional \\(\\small{\\mu}\\) (y se toma como cero, sin p√©rdida de generalidad), los valores absolutos de las observaciones negativas y positivas se juntan, se hace un recuento de las rachas de valores de un mismo lado y luego se proponen las estad√≠sticas de prueba en funci√≥n de estas rachas. Sin embargo, observe una diferencia clave en este problema: el n√∫mero de valores a un lado de la mediana es una variable aleatoria aunque el tama√±o de la muestra \\(n\\) en s√≠ sea fijo. El trabajo de Balakrishnan y Frattina (2000) y Balakrishnan y Ng (2001) sobre pruebas de precedencia m√°xima, en las que dos muestras de unidades se someten a una prueba de vida √∫til y s√≥lo se observan unos pocos fallos tempranos de las unidades en ambas muestras, tambi√©n utilizan de manera similar el longitud m√°xima de racha (correspondiente a fallas de la muestra ‚Äúcontrol‚Äù) como estad√≠stica de prueba.\nLas rachas tambi√©n desempe√±an un papel fundamental en las pruebas de demostraci√≥n iniciales (start-up demonstration testing, en ingles). En esta experimentaci√≥n, un dispositivo (como un generador de energ√≠a, una cortadora de c√©sped o una bater√≠a de autom√≥vil) se prueba repetidamente y despu√©s de cada ensayo simplemente se observa si ha tenido un aranque exitoso o no. El plan/dise√±o de muestreo de aceptaci√≥n utilizado por el minorista (o el consumidor) puede aceptar ese equipo si se logra un n√∫mero prescrito de arranques exitosos consecutivos (es decir, una rachas de √©xitos) antes de una cierta cantidad de pruebas, y rechazar ese equipo en caso contrario; v√©ase, por ejemplo, Hahn y Gage (1983).\nNuestra aplicaci√≥n final es en sistemas de confiabilidad. As√≠ como las estad√≠sticas de orden son fundamentales para los sistemas \\(k\\)-out-of-\\(n:F\\), las rachas(de hecho, la longitud de la racha m√°s larga) son fundamentales para los sistemas \\(k\\)-out-of-\\(n:F\\) consecutivos. Imaginemos que tenemos un sistema que consta de \\(n\\) componentes y todos los \\(n\\) componentes funcionan de forma independiente. En cualquier momento s√≥lo existen dos estados posibles para los componentes y para todo el sistema: operativo o averiado. As√≠, se dice que dicho sistema es un sistema \\(k\\)-out-of-\\(n:F\\), consecutivo si falla s√≥lo cuando al menos \\(k\\) componentes consecutivos han fallado, y funcionar√° mientras no hayan fallado \\(k\\) componentes sucesivos; v√©ase, por ejemplo, Chiang y Niu (1981) o el art√≠culo de revisi√≥n de Chao, Fu y Koutras (1995).\n\nDE LAS RACHA A LOS ESCANERS\nEn el an√°lisis de ensayos experimentales cuyos resultados pueden clasificarse en dos categor√≠as exclusivas, una pregunta que surge naturalmente es si se podr√≠an establecer criterios razonables que proporcionen evidencia de agrupamiento de cualquiera de las dos categor√≠as. Estos criterios podr√≠an luego usarse para detectar cambios en el proceso subyacente que genera la serie de resultados.\nConsideremos una sucesi√≥n \\(\\small{X_1,\\cdots, X_n}\\) de \\(n=lm\\) \\(\\small{(m \\geq 2)}\\) y \\(\\small{l &gt; 1}\\) enteros) resultados binarios. El problema de inter√©s es nuevamente probar la hip√≥tesis nula de que \\(\\small{X_i}\\) son independientes con probabilidad de √©xito constante. Un criterio simple y com√∫nmente utilizado es dividir los \\(n\\) ensayos en \\(l\\) grupos separados de \\(m\\) ensayos consecutivos cada uno y observar el n√∫mero de √©xitos dentro de cada grupo. Si alg√∫n grupo tiene ‚Äúdemasiados‚Äù √©xitos (digamos, \\(k\\) o m√°s), se recibir√° una se√±al de que se ha producido un cambio en el proceso subyacente. Si \\(k\\) es cercano a \\(m\\), entonces podemos denominar al grupo de \\(m\\) ensayos consecutivos una racha de √©xitos ‚Äúcasi perfecta‚Äù.\nOtro criterio muy utilizado se basa en la superposici√≥n de grupos de \\(m\\) ensayos sucesivos. Con esta configuraci√≥n, en cada ensayo contamos el n√∫mero de √©xitos en los √∫ltimos \\(m\\) ensayos, y la frecuente aparici√≥n de ventanas de rachas ‚Äúcasi perfectas‚Äù podr√≠a servir como un indicio de un cambio en el proceso subyacente. Es claro que el caso aqu√≠ discutido consiste en una generalizaci√≥n natural del concepto de racha; Adem√°s, ofrece una estad√≠stica de prueba alternativa eficiente y fascinante en una variedad de campos donde tradicionalmente se han utilizado los criterios cl√°sicos de rachas.\nConsideremos, por ejemplo, el siguiente modelo que tiene su origen en la biolog√≠a molecular. Al estudiar secuencias de amino√°cidos se utilizan varios esquemas de clasificaci√≥n, incluido un alfabeto qu√≠mico de ocho letras, un alfabeto funcional de cuatro letras, un alfabeto de carga de tres letras, etc.; v√©ase, por ejemplo, Karlin y Ghandour (1985), Karlin y MacKen (1991), Karlin y Altschul (1993), Karlin y Cardon (1994) y Waterman (2000). Con el fin de desarrollar medidas cuantitativas para evaluar e interpretar las heterogeneidades gen√≥micas entre diferentes especies o unidades sujetas a diferentes qu√≠micos infecciosos y/o varios niveles de corrupci√≥n, los bi√≥logos moleculares comparan sus secuencias de ADN y buscan subsecuencias alineadas largas que coincidan en la mayor√≠a de sus posiciones. Aparentemente, una coincidencia inusualmente larga, es decir, la ocurrencia de una racha ‚Äúcasi perfecto‚Äù o escaner, ofrece una fuerte evidencia de similitud entre los sujetos bajo inspecci√≥n.\nCon el objetivo de establecer un modelo matem√°tico para aplicaciones de esta naturaleza, denotemos por \\(\\small{Z_{i1}, Z_{i2}, i = 1,2,\\ldots}\\), dos secuencias de amino√°cidos de un alfabeto finito. Se dir√° que las dos secuencias coinciden en posici√≥n (\\(i\\geq 1\\)) si \\(\\small{Z_{i1}= Z_{i1}}\\), en cuyo caso dejamos que \\(\\small{X_i}\\) sea \\(\\small{1}\\) (y \\(\\small{0}\\) en caso contrario). Entonces, el n√∫mero de coincidencias en una ventana de longitud \\(m\\) se describe mediante el proceso de sumas m√≥viles \\(\\small{S_i =}\\tiny{\\displaystyle\\sum_{j=1}^{i+m-1}X_i}\\) con \\(\\small{i \\in\\{1,2,\\ldots\\}}\\) y la coincidencia ‚Äúcasi perfecta‚Äù en la posici√≥n \\(\\small{i}\\) se puede describir mediante el evento \\(\\small{S_i \\geq k}\\) (\\(\\small{k}\\) es un n√∫mero entero, lo suficientemente cercano a \\(\\small{m}\\)).\nLos resultados te√≥ricos sobre el tiempo de espera para la primera (o m√°s generalmente, la \\(r\\)-√©sima) ocurrencia de tal evento, o el n√∫mero de ocurrencias de ellos en una secuencia de tama√±o dado, son de gran importancia pr√°ctica para establecer e investigar pruebas estad√≠sticas apropiadas que detectar√≠an la hip√≥tesis nula de que las dos secuencias son id√©nticas; v√©anse, por ejemplo, Karlin y Ost (1988), Glaz y Naus (1991) y Glaz y Balakrishnan (1999).\nLos escaners tambi√©n desempe√±an un papel fundamental en varias otras √°reas cient√≠ficas. Por ejemplo, en un modelo de confiabilidad que se introdujo recientemente con el nombre de sistema \\(k-within-consecutive-out-of-n\\), la ocurrencia de un escaner (ejecuci√≥n ‚Äúcasi perfecta‚Äù de componentes fallidos) indica una falla del sistema; v√©ase Papastavridis y Koutras (1994). En la teor√≠a del control de calidad estad√≠stico, un modelo m√°s sensible (en comparaci√≥n con el modelo basado en rachas descrito anteriormente en la Secci√≥n 1.3) se obtiene al declarar que un proceso est√° fuera de control siempre que \\(\\small{k}\\) de \\(\\small{n}\\) puntos consecutivos caigan en la zona cr√≠tica; ver Greenberg (1970) y Saperstein (1973). Del mismo modo, en las pruebas de demostraci√≥n de inicio ( startup demonstration testing, en ingles), el concepto de escaner puede explotarse para establecer procedimientos eficientes de aceptaci√≥n/rechazo para la unidad bajo inspecci√≥n.\nEn este libro, adem√°s de presentar todos los detalles te√≥ricos relacionados con rachas, escaners y estad√≠sticas relacionadas, tambi√©n consideraremos todas estas aplicaciones, elaboraremos metodolog√≠as apropiadas y las ilustraremos con muchos ejemplos num√©ricos. Mientras lo hacemos, tambi√©n discutiremos algunas modificaciones, extensiones y generalizaciones de estos problemas que pueden hacerlos m√°s √∫tiles y aplicables a situaciones pr√°cticas de la vida real.\n\n\nQUE ESPERAR\nAunque todas las aplicaciones citadas en las dos √∫ltimas secciones se basan en rachas de diferentes maneras, est√° bastante claro que algunos problemas de tiempo de espera est√°n asociados con todas ellas. Tambi√©n es evidente que las distribuciones de probabilidad de la variable tiempo de espera (hasta que ocurran algunas rachas de cierto tipo, por ejemplo) y el n√∫mero de rachas est√°n bastante relacionadas. Por lo tanto, es √∫til y revelador estudiar las distribuciones de los tiempos de espera asociados con las rachas y luego utilizar estas distribuciones para abordar los diversos problemas aplicados mencionados en las dos √∫ltimas secciones. √âste es precisamente el objetivo y prop√≥sito de este libro. Para facilitar la presentaci√≥n de todos los desarrollos relevantes, el resto de este libro se ha dividido en tres partes naturales de la siguiente manera:\n\nParte A: incluye los Cap√≠tulos 2 y 3 que se ocupa principalmente del tiempo de espera para la primera aparici√≥n de rachas y su aplicaci√≥n a una variedad de problemas. En el Cap√≠tulo 3 se detallan varias aplicaciones interesantes en √°reas tan diversas como confiabilidad, control de calidad, estad√≠stica no param√©trica, meteorolog√≠a y ciencias ambientales.\nParte B: incluye los Cap√≠tulos 4 a 8 y se centra principalmente en algunas extensiones y generalizaciones de los resultados discutidos en la Parte A. Espec√≠ficamente, incluye discusiones detalladas sobre el tiempo de espera para la ocurrencia m√∫ltiple de rachas, sobre el n√∫mero de ocurrencias de rachas, sobre problemas de tiempo de espera tardia y temprana que involucran racha y sobre distribuciones multivariadas relacionadas con la ocurrencia de rachas. Finalmente, se describen algunas aplicaciones diversas de estos resultados.\nParte C: incluye los cap√≠tulos 9 a 12 y se ocupa de las distribuciones relacionadas con las estad√≠sticas de escaneo, que son generalizaciones naturales del principio de rachas. La organizaci√≥n de la Parte C es similar a la utilizada para la Parte B, es decir, comenzamos nuestra discusi√≥n con la distribuci√≥n del tiempo de espera para la primera ocurrencia de escaners, procedemos a los problemas de tiempo de espera de m√∫ltiples escaners y finalmente discutimos la distribuci√≥n del n√∫mero de ocurrencias de escaners en un n√∫mero fijo de resultados. El libro concluye con el Cap√≠tulo 12, donde se describen las aplicaciones de escaners a una variedad de problemas.",
    "crumbs": [
      "Trabajo Grado"
    ]
  },
  {
    "objectID": "Podcast.html",
    "href": "Podcast.html",
    "title": "Podcast",
    "section": "",
    "text": "En esta secci√≥n comparto algunos de los podcasts que escucho, una mezcla de los que siguen activos y otros que ya no producen episodios, pero que siguen siendo muy valiosos.\n\n\n\nLex Fridman Podcast\nConversaciones profundas sobre inteligencia artificial, tecnolog√≠a, ciencia y filosof√≠a.\nThe Diary of a CEO (Stephen Bartlett)\nEntrevistas inspiradoras con l√≠deres, emprendedores y creadores de impacto.\nRadio Ambulante\nHistorias latinoamericanas narradas con gran calidad period√≠stica y humana.\nTED Talks Daily\nIdeas y conferencias de TED en formato breve y accesible.\nDiana Uribe.fm\nHistoria, cultura y an√°lisis contados con un estilo cercano y narrativo.\nBBVA Aprendemos juntos 2030\nEntrevistas inspiradoras con diferentes personas a cerca de como afrontar la vida de la mejor manera a partir de herramientas, conocimientos y experiencias.\nmixxi.io\nPodcast diario de tecnolog√≠a que explica la actualidad de una forma amena, clara y consisa.\nQuillete Podcast\nDebates academicos sobre ciencia, pol√≠tica,filosofia y cultura.\nLa Fonda Filos√≥fica\nIdeas de la filosofia explicadas de manera clara.\nLa Muralla y los Libros\nConversaciones sobre producci√≥n literararia, ferias, talleres, editoriales, libros, eventos. (Argentina)\nDescarga Cultura (UNAM)\nLiteratura contemporanea, cl√°sicos universales, m√∫sica, teatro, etc.\nLa filosof√≠a no sirve para nada\nRefexiones sobre temas actuales desde la ciencia y la filosof√≠a.\nLa biblioteca de Julio\nSobre el universo de Julio Cortazar\nHuberman Lab\nExploraci√≥n de temas de neurociencia.\n\n\n\n\n\nEl Test de Turing\nConversaciones sobre inteligencia artificial, filosof√≠a y futuro tecnol√≥gico.\nDOAC (nombre completo por confirmar)\nExploraci√≥n cr√≠tica de temas actuales en ciencia y sociedad.\nEl Oficio de leer\nExploraci√≥n cr√≠tica de temas actuales en ciencia y sociedad.\nEl resto es literatura\nBiograf√≠as y libros.\nComo funcionan las cosas\nNarraciones singularidades sobre como ‚Äòfuncionan‚Äô diferentes cosas/temas desde la soledad hasta ‚Äòdejar de funcionar‚Äô.\nA Fondo Recopilaci√≥n de los audios de las entrevistas del programa ‚ÄúA Fondo‚Äù emitido por la televisi√≥n p√∫blica espa√±ola (TVE) entre los a√±os 1976 y 1981, dirigido y presentado por el periodista Joaqu√≠n Soler Serrano.",
    "crumbs": [
      "Podcast"
    ]
  },
  {
    "objectID": "Libros_0001.html",
    "href": "Libros_0001.html",
    "title": "Preguntas, ideas, pensamientos a partir de libros.",
    "section": "",
    "text": "Ac√° ire agregando algunas de las cosas que m√°s me llegan de lo que este leyendo, algunas que ya tengo anotadas (o releyendo)‚Ä¶ Mucho y todo de esto ser√°n citas textuales/literales, en algunas ocaciones hare comentarios desde mi ignoracia tratado de enriquecer esto‚Ä¶no abra noveda. O trayendo una referencia/cita de Borges a Bacon en el Inmortal: ‚Ä¶toda novedad no es m√°s que olvido.\n\n\nCritical Meme Reader III: Breaking the Meme\n\n\n\n\nContexto/Intro\n\n\nEl t√©rmino/concepto ‚Äòmeme‚Äô como objeto de estudio lo vi por primera vez en R. Dawkins (en su libro El gen ego√≠sta de 1976), por all√° en en el 2014-2015. All√≠ el autor utiliza el t√©rmino para describir una unidad de informaci√≥n cultural que se transmite de una persona a otra, similar a c√≥mo los genes transmiten informaci√≥n biol√≥gica. En este sentido, los memes pueden ser ideas, historias, h√°bitos, comportamientos, estilos, o pr√°cticas que se propagan dentro de una cultura. Argumenta que as√≠ como los genes compiten por su supervivencia a trav√©s de la selecci√≥n natural/evoluci√≥n, los memes compiten por ser difundidos y adoptados por individuos dentro de una sociedad. Por tanto los memes m√°s exitosos son aquellos que son m√°s eficaces/eficientes en entenderse y ser replicados. Ejemplos de memes pueden ser melod√≠as pegajosas, obras de arte, lemas publicitarios, modas, mitos, rituales religiosos,pinturas rupestre, obras arquitect√≥nicas ‚Ä¶Ac√° me atrevo a votar una idea : que los memes en todas sus expresiones son estados hacia donde la informacion/materia converge en el sentido de funci√≥n y forma, i.e., si una forma de comunicaci√≥n es funcional y operativa esta se integrara a los sistemas vivos.\n\n\nOtro autor que conozco que explora el concepto desde otra perpectiva (la antropolog√≠a) es Michael Taussig en  M√≠mesis and Alterity - 1993, estudia/explora la forma en que las miembros de una cultura adoptan la naturaleza, comportamientos y la cultura de otra lo que el autor llama el proceso de mimesis, al mismo tiempo que la niegan y se distancian de ella,  el proceso de alteridad. Me llegan imagenes de las paginas de Cien a√±os de soledad, puntualmente en las que el gitano Melqu√≠ades trae inventos cient√≠ficos a Macondo de otros lugares que no pasan atren la atenci√≥n Jos√© Arcadio (proceso de m√≠mesis), llevandole a la locura. Por otro lado esta el papel de √örsula (proceso de alteridad). Nota: Taussig toma una postura limitante hacia el alcance de m√©todo de estudio de la antropolog√≠a, para acceder/explicar a una cultura a trav√©s de otra.\n\n\nUna autora de referencia es Susan Blackmore, que en su libro  La m√°quina de los memes-1999, expandi√≥ la idea de Dawkins y explor√≥ c√≥mo los memes influyen en la evoluci√≥n cultural. Seg√∫n Blackmore, los seres humanos no solo son replicadores biol√≥gicos sino tambi√©n replicadores mem√©ticos, y esto ha tenido un impacto significativo en la evoluci√≥n de nuestras sociedades y culturas. Una de las tesis principales es que ‚Äòla cultura es una masa de memes‚Äô. Se√±ala los mitos, los inventos, el lenguaje y los sistemas pol√≠ticos como estructuras hechas de memes. No todo es un meme.En el contexto cultural y social, los memes se ven como veh√≠culos de comunicaci√≥n y expresi√≥n que reflejan y a menudo critican la realidad social. En las redes sociales, por ejemplo, los memes a menudo son im√°genes o videos con texto superpuesto que transmiten ideas, humor o cr√≠ticas de manera r√°pida y accesible. Desde una perspectiva evolutiva, la propagaci√≥n de memes puede ser vista como una forma de evoluci√≥n cultural paralela a la evoluci√≥n biol√≥gica. Los memes exitosos pueden influir en el comportamiento y las creencias de grandes grupos de personas, y, por lo tanto, pueden tener un impacto significativo en la direcci√≥n en la que una cultura evoluciona."
  },
  {
    "objectID": "Peliculas.html",
    "href": "Peliculas.html",
    "title": "Peliculas",
    "section": "",
    "text": "Pel√≠culas en las que encontre muchas preguntas nuevas y algunas respuestas que necesitaba justificar\n\n10000 A.C.\nMatriz (La Trilog√≠a)\n2001: Odisea en el espacio\nHannibal\nLa llegada\nMad Max\nEl club de la pelea\nGladiador\n300\nHannibal\nUna mente brillante\nInmortales\nEl apostador\nWatchmen\nLa ciudad del pecado\nKick-Ass\nTransformer 1\nPulp Fiction\nEl gran Lebowski\nFargo\nAsesinos por naturaleza\nEl silencio de los inocentes\nBlade Runner\nEx-Machina\nAtlas de las nubes\nVecinos invasores\nEl gran truco\nOrigen\nSin l√≠mites\nElysium\nEterno resplandor\nRango\nMi vecino Totoro\nLa naranja mec√°nica",
    "crumbs": [
      "Pel√≠culas"
    ]
  },
  {
    "objectID": "Podcast.html#actuales",
    "href": "Podcast.html#actuales",
    "title": "Podcast",
    "section": "",
    "text": "Lex Fridman Podcast\nConversaciones profundas sobre inteligencia artificial, tecnolog√≠a, ciencia y filosof√≠a.\nThe Diary of a CEO (Stephen Bartlett)\nEntrevistas inspiradoras con l√≠deres, emprendedores y creadores de impacto.\nRadio Ambulante\nHistorias latinoamericanas narradas con gran calidad period√≠stica y humana.\nTED Talks Daily\nIdeas y conferencias de TED en formato breve y accesible.\nDiana Uribe.fm\nHistoria, cultura y an√°lisis contados con un estilo cercano y narrativo.\nBBVA Aprendemos juntos 2030\nEntrevistas inspiradoras con diferentes personas a cerca de como afrontar la vida de la mejor manera a partir de herramientas, conocimientos y experiencias.\nmixxi.io\nPodcast diario de tecnolog√≠a que explica la actualidad de una forma amena, clara y consisa.\nQuillete Podcast\nDebates academicos sobre ciencia, pol√≠tica,filosofia y cultura.\nLa Fonda Filos√≥fica\nIdeas de la filosofia explicadas de manera clara.\nLa Muralla y los Libros\nConversaciones sobre producci√≥n literararia, ferias, talleres, editoriales, libros, eventos. (Argentina)\nDescarga Cultura (UNAM)\nLiteratura contemporanea, cl√°sicos universales, m√∫sica, teatro, etc.\nLa filosof√≠a no sirve para nada\nRefexiones sobre temas actuales desde la ciencia y la filosof√≠a.\nLa biblioteca de Julio\nSobre el universo de Julio Cortazar\nHuberman Lab\nExploraci√≥n de temas de neurociencia.",
    "crumbs": [
      "Podcast"
    ]
  },
  {
    "objectID": "Podcast.html#pausados-o-finalizados",
    "href": "Podcast.html#pausados-o-finalizados",
    "title": "Podcast",
    "section": "",
    "text": "El Test de Turing\nConversaciones sobre inteligencia artificial, filosof√≠a y futuro tecnol√≥gico.\nDOAC (nombre completo por confirmar)\nExploraci√≥n cr√≠tica de temas actuales en ciencia y sociedad.\nEl Oficio de leer\nExploraci√≥n cr√≠tica de temas actuales en ciencia y sociedad.\nEl resto es literatura\nBiograf√≠as y libros.\nComo funcionan las cosas\nNarraciones singularidades sobre como ‚Äòfuncionan‚Äô diferentes cosas/temas desde la soledad hasta ‚Äòdejar de funcionar‚Äô.\nA Fondo Recopilaci√≥n de los audios de las entrevistas del programa ‚ÄúA Fondo‚Äù emitido por la televisi√≥n p√∫blica espa√±ola (TVE) entre los a√±os 1976 y 1981, dirigido y presentado por el periodista Joaqu√≠n Soler Serrano.",
    "crumbs": [
      "Podcast"
    ]
  },
  {
    "objectID": "Podcast_lexfridman.html",
    "href": "Podcast_lexfridman.html",
    "title": "Preguntas, ideas, pensamientos a partir de podcast.",
    "section": "",
    "text": "Ac√° residen algunas de las cosas que mas me llamaron la atenci√≥n de lo que escuche en cada uno de estos textos. Mucho de esto ser√°n citas textuales/literales, en algunas ocaciones hare comentarios desde mi ignoracia tratado de enriquecer esto‚Ä¶\n\n\n\nLex Fridman Podcast\n\n\n\n\n Episodio #393. Andrew Huberman: Relaciones, Drama, Traici√≥n, Sexo y Amor \n\n\n\nComo podemos acceder a nuestra conciencia‚Ä¶\n\n\nTea\n\n\nSobre tener hijos en familia:  Los hijos aportan un tremendo significado a nuestras vidas, seriamos unos idiotas si no formamos familia‚Ä¶\n\n\n\nPalabras de A. Camus citadas por Lex:  En medio del invierno descubri que dentro de mi existia un verano invencible \n\nA continuaci√≥n, me permito extender el texto, ya que esta cita pertenece a uno de mis autores de referencia. Se trata de uno de sus libros m√°s personales, tanto a nivel biogr√°fico como en cuanto a la calidad de la prosa‚Ä¶\n\n A mediod√≠a, sobre las laderas medio arenosas y cubiertas por heliotropos como por una espuma que hubieran dejado al retirarse las olas furiosas de los √∫ltimos d√≠as, miraba el mar, que a esa hora se agitaba apenas con un movimiento fatigado, y calmaba esa doble sed que no se puede enga√±ar mucho tiempo sin que el ser se seque, quiero decir amar y admirar. En no ser amado s√≥lo hay mala suerte: en no amar hay desgracia. Hoy en d√≠a todos morimos de esa desgracia. Porque la sangre, los odios, descarnan el coraz√≥n; la prolongada reivindicaci√≥n de la justicia agota el amor que, sin embargo, la hizo nacer. En el clamor en que vivimos, el amor es imposible y la justicia no basta. Por eso Europa odia el d√≠a y no sabe m√°s que oponer injusticia a la injusticia. Pero para impedir que la justicia, hermoso fruto naranja que no contiene m√°s que una pulpa amarga y seca, se agoste, volv√≠a a descubrir en Tipasa que hab√≠a que guardar intactas dentro de uno mismo una frescura, una fuente de alegr√≠a; amar el d√≠a que escapa a la injusticia y volver al combate con esa luz conquistada. Volv√≠a a encontrar all√≠ la antigua belleza, un cielo joven, y ponderaba mi suerte, comprendiendo por fin que en los peores a√±os de nuestra locura el recuerdo de este cielo no me hab√≠a abandonado nunca. Era √©l quien, para concluir, me hab√≠a impedido perder la esperanza. Yo hab√≠a sabido siempre que las ruinas de Tipasa eran m√°s j√≥venes que nuestras obras en construcci√≥n o nuestros escombros. El mundo empezaba all√≠ cada d√≠a con una luz siempre nueva. ¬°Oh, luz!, √©se es el grito de todos los personajes enfrentados, en el drama antiguo, a su destino. Ese √∫ltimo recurso era tambi√©n el nuestro y ahora yo lo sab√≠a. En mitad del invierno aprend√≠a por fin que hab√≠a en m√≠ un verano invencible.  Tomado de ‚ÄúRetorno a Tipasa‚Äù en su libro ‚ÄúEl verano‚Äù \n\n\n\n\nEpisodio #403 - Lisa Randall: Materia Oscura, F√≠sica Te√≥rica y Eventos de Extinci√≥n\n\n\n\n¬øComo se antropomorfisa la materia oscura?\n\n\n¬øLa materia oscura tiene alguina estructura que le permite interactua internamente, como lo hace la materia estandar con las fuerzar/interacciones conocidas (gravitacional, nuclear d√©bil, electromagn√©tica, nuclear fuerte)?\n\n\n¬øQue forma tiene la materia oscura?\n\n\n¬øComo podemos medir aquello que no vemos?\n\n\n¬øEs mas probable que perescamos debido a una extincion causada por acontecimientos/eventos generados por humanos o por otros exteriores al nivel solar/galactico ?\n\n\n¬øComo experimentaron los dinosuarios la extinci√≥n? (Esta pregunta planteada por Lex va mas hacia la experiencia visula del impacto del meteorito)\n\n\nCita mencionada por sobre el libro de la autora acerca de abordar lo bello/sublime en la fisica (y en el conocimiento en geeral, agregaria):\n\n ¬øQui√©n, si gritara yo, me escuchar√≠a  en los celestes coros? Y si un √°ngel inopinadamente me ci√±era contra su coraz√≥n, la fuerza de su ser me borrar√≠a; porque la belleza no es sino el nacimiento de lo terrible; un algo que nosotros podemos admirar y soportar tan s√≥lo en la medida en que se aviene, desde√±oso, a existir sin destruirnos. Todo √°ngel es terrible. \n\nTomado de la Primera Elieg√≠a del libro Eleg√≠as de Duino de R. M. Rilke\n\n\n\n\n¬øPuede existir algo analogo a lo que es la vida-inteligente en el campo de la materia oscura? Es decir, si bien en el plano de la materia ordinaria (materia bari√≥nica), se ha generado todo lo que posemos observar y nombramos como realidad. ¬ø Que implicaria que esto pasara dentro de la materia oscura, algun tipo de interaciones complejas que dieran origen a sistemas mas elaborados?\n\n\n¬ø Qu√© es el modelo est√°ndar de particulas, como genera/sostiene todo el funcionamiento de la realidad y como encaja la materia oscura en este modelo?\n\n\n¬øPuede la ciencia descubrir la realidad?\n\n\nLa respuesta dada por Lissa a la pregunta ret√≥rica echa por Lex (¬øCuales crees son los limites de la ciencia?) me parece muy sugestiva y convincente.\n\n - Soy lo suficientemente inteligente como para saber que no tengo idea, y adem√°s ni siquiera esta claro que es/significa ‚Äòciencia‚Äô. Porque existe la ciencia que hacemos, que la fisica de particulas en la que tratamos encontrar cosas fundamentales y descubrir cuales son sus efectos. Hay ciencias como la biolog√≠a, que se encuentra en un nivel superior en la que el tipo de preguntas que aborda/hace y formas de medir/contrastar es diferentes. Ahora bien el tipo de ciencia que sucedera en una epoca/era mas n√∫merica o incluso de IA o algo as√≠; ¬øque significar√° responder una pregunta: significa que podemos predecirlo, significa que reproducirlo? Por tanto creo que nos estamos encontrando con una especie de redefinici√≥n de lo entendemos de ciencia como seres humanos. Entonces en t√©rminos de la ciencia que actualmente se hace no creo que podamos responder a esa pregunta hasta que llegemos all√≠‚Ä¶ Si piensas en cuanto a avanzado la ciencia en el √∫ltimo siglo o siglo y medio, es increible‚Ä¶  Creeria que es prematuro, decir que se conocen las limitaciones‚Ä¶ \n\n\n\n¬øCual es para ti, la diferencia entre fisica y matem√°ticas, en la forma en que nos ayudan a comprender el mundo?\n\n\n - Creo que existe mucha m√°s superposici√≥n entre estas dos, de la que realmente se aprecia‚Ä¶  Una vez m√°s las preguntas que se abordan son diferentes en cada √°rea. A los matem√°ticos les gusta la estructura misma, los f√≠sicos se tratan de concentrar en las consecuncias para el mundo‚Ä¶ Se convierte casi en una cuesti√≥n sociologica, de cuanto deberia ser uno u otro. Creo que uno puede quedar atrapado en los problemas mismos, y aveces en los metodos y simplemente hacer otros ejemplos. Por lo tanto los verdaderos conocimientos sobre fisica, a menudo provienen de personas que piensan tanto en fisicas como en matem√°ticas. \n\n\n57:25 Acerca de las implicanciones de la IA la forma en que va afectar el futuro y la ciencia en particular, Lex plantea la siguiente pregunta que me resulta muy importante y curiosa: ¬øQue tan especiales son los humanos, para poder descubrir ideas/conocimientos nuevas sobre el universo/cosmos?\n\n\n Depende de que tipo de conocimiento y que vamos a descubrir, porque es dificil pensar el algo que no existe‚Ä¶digo se podria dar un paso atras con internet (es como un poco intentar manejar cuatro dimensiones, volver a tres dimensiones para regresar a algo que puedes imaginar), as√≠ que puedes decir muchas cosas en un nivel muy diferente acerca de internet. Se puede decir que a ayudado a muchas cosas, tomo vida en cierto sentido; pero es algo que podemos domesticar‚Ä¶ Yo misma no hubiese podido escribir libros si internet no existiera, porque no abria tenido tiempo de ir a la biblioteca y buscarlo todo‚Ä¶ En cierto sentido la IA podria ser una herramienta que nos ayude a ir un paso mas all√° de lo que hacemos y de una forma mas eficiente, como ya lo esta haciendo. O bien podria ser la parte opuesta, como la parte de internet que no podemos controlar que esta arruinando la politica‚Ä¶ Luego existen cosas m√°s grandes sobre las cuales la gente especula, acerca que la IA puede hacer sus propias cosas‚Ä¶ pero en t√©rminos de resolver las cosas estamos en las primeras etapas \n\n\nLos grandes modelos de lenguaje son mas o menos generalizaciones de cosas qeu tenemos\n\n\n1:02:35(Pregunta de Lex a Lisa) ¬øCual es para ti, el problema sin resolver mas hermoso/interesante de la fisica?\n\n\n - La mayoria de las preguntas, las grandes preguntas, tienen que ver con lo que subyace a las cosas como: ¬øCual fue su origen? ¬øQue hay en su base?‚Ä¶ Tambien existen preguntas basicas: ¬øA donde nos llevara la ciencia? ¬øCuanto podemos enterder?‚Ä¶ Hay preguntas del corte ¬øComo llegamos aqu√≠? ¬øQue subyace a esto?‚Ä¶ Hay preguntas muy profundas como: ¬øQue fracci√≥n estamos viendo realmente? ¬øSi existe otras fuerzas, si hay otra forma de ver lo que nos rodea? ¬øExisten universos mas all√° del nuestro? Si son tan diferentes, ¬øComo podemos siquiera comprenderlos, detectarlos?‚Ä¶ Hay mucho que ver con ir m√°s all√°. Siempre se trata de ir mas all√° de nuestra experiencia y visi√≥n limitadas, y tratar de ver lo que hay detr√°s, tanto a peque√±a como gran escala‚Ä¶Simplemente no sabemos las respuestas‚Ä¶ Me gustaria pensar que entendemos m√°s sobre materia oscura, energia oscura, dimensiones adicionales, etc; Cosas en la que se esta trabajando, porque probablemente existe mucho m√°s all√° de lo que se ha encontrado y que esta por decubrir.\n\n\n\n¬øLa f√≠sica puede cambiar mas alla del universo observable?\n\n\n1:05:25Consejo para los jovenes cientificos.\n\n\n - Deben creer firmemente en lo que haces y al mismo tiempo cuestionarlo a todo momento‚Ä¶Lograr ese equilirio, a veces ayuda colaborar con otros‚Ä¶ Saber que puedes tener buenas y sabiendo que todas puedesn estar equivocadas‚Ä¶ Una cuarda floja dificil de caminar, pero se debe hacer.  - Intentar descubrir por qu√© las cosas son como son‚Ä¶es bueno hacerlo desde un punto de vista te√≥rico eficaz y un paso a la vez.  \n\n\n¬øLo que percibimos como bello/sublime se debe a como hemos evolucionado, ?\n\n\n‚ÄúLo importante es no dejar de cuestionarse. La curiosidad tiene su propia raz√≥n de ser.‚Äù\n\n\n\nEpisodio #404 -\n\n\n Esto estara en otro sitio a futuro"
  },
  {
    "objectID": "Libros_02.html",
    "href": "Libros_02.html",
    "title": "Literatura",
    "section": "",
    "text": "La literatura ha sido otro de mis grandes intereses, una forma de di√°logo con las grandes ideas, la filosof√≠a y la belleza del lenguaje. Estos son algunos de los libros y autores que m√°s me han marcado:\n\nAs√≠ habl√≥ Zaratustra - F. Nietzsche\n\nLa gaya ciencia - F. Nietzsche\n\nM√°s all√° del bien y del mal - F. Nietzsche\n\nSiddhartha ‚Äî H. Hesse\n\nEl lobo estepario - H. Hesse\n\nEl libro del desasosiego - F. Pessoa\n\nC√≥mo leer y por qu√© - Harold Bloom\nC√≥mo hablar de libros que no se han le√≠do - P. Bayard\nFragmentos - G. Steiner\n\nElogio del Caminar - D. Le Breton\n\nEl tatuaje - D. Le Breton\n\nEnsayos y poemas ‚Äî P. Val√©ry\n\nNo leer ‚Äî A. Zambra\n\nEsto es agua - D. F. Wallace\nEl lector - B. Schlink\nCartas a un joven disidente - C. Hitchens\nDe que hablo cuando hablo de correr - H. Murakami\nDe que hablo cuando hablo de escribir - H. Murakami\nTao Te King - Lao Ts√©\nI Ching. El libro de las mutaciones - R. Wilhelm\nPoemas de la locura - Friedrich H√∂lderlin\nNo hay nadie en casa - D. Ugre≈°iƒá\nUna ofrenda musical - L. Sagasti\nMishima o la visi√≥n del vac√≠o - M. Yourcenar\nLos Upanishad esenciales - Pensamiento Hindu\nEl Aleph - J. L Borges\nInquisiciones - J. L Borges\nYo, etc√©tera - S. Sontang\nMar√≠a Antioneta S. Zweig\nEl tiempo en la historia - G. J. Whitrow\nEl extra√±o caso del Dr.¬†Jekyll y Mr.¬†Hyde - R. L. Stevenson\nEl decamer√≥n - G. Boccaccio\nAsesinatos S.L. - J. London & R. L. Fish\nAntifr√°gil - N. Taleb\nSilencioso tao - R. Smullya\nMeditaciones sobre la vida - N. Robert\n\nEjercicios de estilo - Q. Raymond\nEl ABC de la lectura - E. L. Pound\nEl ojo y el espiritu - M. Merleau-Ponty\nEl Aprendiz de Mago - E. Rosero\n\n\n\n\nEsta lista no es exhaustiva ni pretende ser un canon, sino un registro de aquellas lecturas que han dejado huella en mi forma de pensar y sentir.",
    "crumbs": [
      "Libros"
    ]
  },
  {
    "objectID": "Libros_02.html#nota-personal",
    "href": "Libros_02.html#nota-personal",
    "title": "Literatura",
    "section": "",
    "text": "Esta lista no es exhaustiva ni pretende ser un canon, sino un registro de aquellas lecturas que han dejado huella en mi forma de pensar y sentir.",
    "crumbs": [
      "Libros"
    ]
  }
]