---
output:
  pdf_document:
    latex_engine: xelatex
header-includes:
  - '<style>.my-large-equation { font-size: 24px; }</style>'
  - '<style>.my-small-equation { font-size: 12px; }</style>'
editor_options: 
  markdown: 
    wrap: 72
---


## Teoría de distribución de Rachas y Patrones y sus aplicaciones. Un enfoque de Incrustación de Cadenas de Markov Finitas.

### Prologo
<p>El propósito de este libro es ofrecer una introducción rigurosa y
exhaustiva a la técnica de *Incrustación de Cadenas de Markov Finitas
(ICMF)* para estudiar las distribuciones de *Rachas* y *Patrones* desde
un punto de vista unificado e intuitivo, alejado de las líneas
tradicionales de la combinatoria. A lo largo de las dos últimas décadas,
se han obtenido mediante este enfoque un número considerable de nuevos
resultados relacionados con las distribuciones de rachas y patrones.</p>

<p>


El tema central de la Incrustación de Cadenas de Markov Finitas (ICMF),
como su nombre indica, es incrustar adecuadamente las variables
aleatorias de interés en el marco de una cadena de Markov finita, y las
representaciones resultantes de las distribuciones subyacentes son
compactas y muy susceptibles de un estudio más profundo de las
propiedades asociadas. En este libro, el concepto de <em>ICMF</em> se
desarrolla sistemáticamente y se ilustra su utilidad mediante
aplicaciones prácticas a diversos campos, como la fiabilidad de los
sistemas de ingeniería, la comprobación de hipótesis, el control de
calidad y la medición de la continuidad en el sector sanitario.

<p>

<p>

Este libro está restringido a espacios muestrales discretos, una
restricción que sirve para que este trabajo sea accesible a una
audiencia más amplia al simplificar los resultados teóricos y sus
aplicaciones. Las rachas y patrones considerados aquí se definen en gran
medida en sucesiones de ensayos Markov-Dependientes de dos o múltiples
estados, con aplicaciones prácticas en mente; los definidos sobre
permutaciones aleatorias de números enteros, como los números de
Eulerian y Simon Newcomb, también se tratan utilizando un procedimiento
de inserción adicional. El contenido de este libro está orientado
principalmente a los investigadores que utilizan la teoría de la
distribución de rachas y patrones en diversos ámbitos aplicados de la
estadística, la probabilidad y la combinatoria, pero también podría
servir de base de un curso de temas especiales de un semestre de
duración en cuarto curso de licenciatura o a nivel de primer año de
posgrado.\

<p>

<p>Deseamos agradecer la ayuda de Y. M. Chang y B. C. Johnson en la
corrección de los primeros borradores del libro, así como el aliento de
nuestros colegas de la Universidad de Manitoba y la Universidad de
Toronto.</p>

<p>También estamos en deuda con nuestras familias por su inagotable
apoyo. Por último, queremos agradecer a la Sra. E. H. Chionh, de World
Scientific Publishing Co. por su paciencia y apoyo administrativo.</p>

### Introdución

La ocurrencia de *rachas* y *patrones* en una sucesión de resultados de
ensayos discretos o permutaciones aleatorias es un concepto importante
en diversas áreas de la ciencia, como la ingeniería de confiabilidad, el
control de calidad, la psicología, la sociología, la comparación de
*secuencias de ADN* y la comprobación de hipótesis. Resultados de las
distribuciones de probabilidad de rachas y patrones elementales se
obtuvieron esporádicamente en la literatura hasta aproximadamente la
década de 1940, cuando se publicaron una serie de estudios pioneros
sobre rachas y patrones más complejos: por ejemplo, *Wishart e Hirshfeld
(1936), Cochran (1938), Mood (1940), Wald y Wolfowitz (1940), Mosteller
(1941) y Wolfowitz (1943).* La mayoría de estos estudios se centraron en
hallar la distribución condicional de las rachas de éxito dado el número
total de éxitos en una sucesión de ensayos de dos estados. Un libro
reciente reciente de *Balakrishnan y Koutras (2002)*, ofrece una buena
revisión exhaustiva de los avances históricos y actuales en la teoría de
la distribución de rachas y las estadísticas de escaneo.

Tradicionalmente, las distribuciones de rachas y patrones se estudiaban
mediante análisis combinatorio. Por ejemplo, Mood (1940) escribió: *"El
problema de la distribución es, por supuesto, combinatorio, y todo el
desarrollo depende de algunas identidades del análisis combinatorio".*
Sin embargo, encontrar las identidades combinatorias apropiadas para
derivar las distribuciones de probabilidad puede ser difícil, si no
imposible, para rachas y patrones complejos, y quizá sea ésta la razón
por la que las distribuciones exactas de muchos estadísticos comunes
definidos en rachas y patrones siguen siendo desconocidas. Además las
identidades requeridas a menudo difieren incluso para rachas y patrones
similares, y por lo tanto, incluso en el caso más sencillo de ensayos
independientes e idénticamente distribuidas *(i.i.d.)* de dos estados
(los llamados *"ensayos de Bernoulli"*), cada nuevo problema de
distribución generalmente tiene que estudiarse caso por caso utilizando
el enfoque combinatorio. Por ejemplo, sólo hace relativamente poco
tiempo *Philippou y Makri (1986) e Hirano (1986)*, de forma
independiente y mediante análisis combinatorio, obtuvieron la
distribución exacta de la estadística de racha tradicional
$\small{N_{n,k}}$, del número de rachas de $k$ éxitos consecutivos
no-solapados en una secuencia de $n$ ensayos Bernoulli:

<!---Ecuación 1.1--->

::: math
```{=tex}
\begin{equation}
\mathbb{P}(N_{n,k}=x)=\sum_{m=0}^{k-1}\sum_{x_1+x_2+\cdots+\\
kx_k=n-m-km}\binom{x_1+x_2+\cdots+x_k+x}{x_1,x_2,\cdots,x_k,x}p^n\Big(\frac{q}{p}\Big)^{x_1+x_2+\cdots+x_k}
\end{equation}
```
:::

para $x=0,1,\ldots,[n/k]$, con probabilidades de éxito y fracaso
denotadas por $p$ y $q=1-p$, respectivamente. [Otro método para
determinar una distribución de probabilidad exacta consiste en derivar
la función generadora $\small{\varphi(s)}$ para la variable aleatoria
entera no negativa $\small{X_n(\Lambda)}$ asociada con el patrón
$\small{\Lambda}$ (por ejemplo, $\small{X_n(\Lambda)}$ podría ser el
número de apariciones del patrón $\small{\Lambda}$ en $n$ ensayos) y, a
continuación, diferenciar $\small{\varphi(s)}$ $x$ veces para obtener la
función de distribución de probabilidad *(fdp)* dada por
$\small{\mathbb{P}(X_n(\Lambda) = x)}$ este enfoque fue introducido por
Feller (1968) utilizando la teoría de los sucesos recurrentes. Por
ejemplo, para la función generadora del tiempo de espera
$\small{W(\Lambda)}$, el número de ensayos Bernoulli hasta la primera
aparición del patrón $\small{\Lambda}$ consistente en $k$ éxitos
consecutivos, fue dada por Feller
como:]{style="background-color:#CBEFF9;"}

<!---Ecuación 1.2--->

::: math
```{=tex}
\begin{equation}
\varphi_{W}(s)=\frac{p^ks^k(1-ps)}{1-s+qp^ks^{k+1}}
\end{equation}
```
:::

Para rachas y patrones más complejos, las funciones generadoras pueden
ser difíciles de diferenciar un gran número de veces y es posible que
sea necesario emplear técnicas de aproximación. Feller utilizó el método
de expansión de fracciones parciales, que puede requerir métodos
numéricos eficientes para calcular raíces de polinomios. A traves del
libro estudiaremos problemas de distribución de rachas y patrones desde
un punto de vista, en nuestra opinión, más unificado e intuitivo,
alejado de las líneas de la combinatoria tradicional. [El enfoque
adoptado consiste en incrustar adecuadamente la variable aleatoria
$\small{X_n(\Lambda)}$ en una cadena de Markov finita $\small{\{Y_t\}}$,
de modo que la probabilidad de $\small{X_n(\Lambda)}=x$ pueda expresarse
en términos de la probabilidad de que el estado de la cadena de Markov
al momento $\small{n}$, $\small{Y_n}$, se encuentre en un subconjunto
$\small{C_x}$ del espacio de estados, es
decir:]{style="background-color:#FAFAD9;"}

<!---Ecuación 1.3--->

::: math
```{=tex}
\begin{equation}
\mathbb{P}\{X_n(\Lambda)=x\}=\mathbb{P}(Y_n \in C_x)
\end{equation}
```
:::

[donde la probabilidad del lado derecho se puede calcular fácilmente
mediante las matrices de probabilidad de transición de la cadena de
Markov.]{style="background-color:#FAFAD9;"} Esta representación de la
distribución subyacente de $\small{X_n(\Lambda)}$ es compacta, fácil de
calcular y bastante susceptible de análisis posteriores. El método
depende en gran medida de la capacidad de construir una cadena de Markov
adecuada asociada con la variable aleatoria $\small{X_n(\Lambda)}$, pero
una vez construida la cadena, la linealidad de la cadena de Markov
reduce la complejidad computacional a menudo asociada con técnicas
combinatorias y de funciones generadoras para calcular los *fdp's*
exactas de rachas y patrones.

Los primeros resultados de la teoría de la distribución de rachas y
patrones se derivaron casi exclusivamente bajo el supuesto de ensayos
Bernoulli o ensayos *i.i.d.* multiestados. Una gran ventaja de la
técnica de incrustación de cadenas finitas de Markov es que se puede
aplicar no sólo a casos de ensayos *i.i.d.* , también para ensayos
multiestado Markov-dependientes, eso si, con poco esfuerzo adicional.
Independientemente de los procedimientos de conteo especificados para
patrones superpuestos (conteo superpuesto versus no superpuesto);
también se puede extender a varios tipos de rachas y patrones en
permutaciones aleatorias. Recientemente, este método ha sido adoptado
por varios investigadores para estudiar diversas distribuciones de
rachas y patrones: por ejemplo, *Antzoulakos (1999, 2001), Boutsikas y
Koutras (2000a,b), Doi y Yamamoto (1998), Fu (1985, 1986, 1996), Pu y
Koutras (1994), Fu y Lou (2000a,b), Han y Aki (2000a,b), Johnson (2002),
Koutras (1996a,b, 1997a,b, 2003), Koutras y Alexandrou (1995), Lou
(1996, 2000, 2001) y Nishimura y Sibuya (1997)*. Tocaremos algunos de
estos trabajos recientes, pero nuestras formulaciones correspondientes
pueden diferir ligeramente para tratar todos los problemas utilizando un
enfoque de incrustación común.

Este libro no es una revisión de la teoría de rachas y patrones, ni
pretende ser utilizado principalmente como un libro de texto de curso;
está dirigido principalmente a investigadores en estadística aplicada y
probabilidad que estén interesados en utilizar la técnica de
incrustación de cadenas finitas de Markov para estudiar las
distribuciones de rachas y patrones que surgen en aplicaciones
específicas. El contenido del libro se basa en gran medida en
desarrollos recientes en esta área, pero se presenta de una manera que
no requiere conocimiento de conceptos avanzados en matemáticas o
probabilidad; Se supone que se tiene experiencia en teoría de la
probabilidad, al nivel de, por ejemplo, el libro de Feller (1968) *"Una
introducción a la teoría de la probabilidad y sus aplicaciones, Volumen
I".* El libro está organizado como sigue. En el **Capítulo 2**,
presentamos las ideas y técnicas básicas de incrustación de cadenas
finitas de Markov. Este capítulo sienta las bases para calcular los
*fdp's* de rachas y patrones, incluidas las distribuciones de tiempo de
espera. El **Capítulo 3** examina las distribuciones de rachas y
patrones asociados con los ensayos de dos estados, y en el **Capítulo
4**, se trata la extensión a los ensayos de múltiples estados a través
del *principio de avance y retroceso*. El **Capítulo 5** estudia
principalmente las distribuciones de tiempo de espera de patrones
simples y compuestos, así como sus funciones generadoras y
aproximaciones de grandes desviaciones. En el **Capítulo 6**, la técnica
de incrustación de cadenas finitas de Markov se extiende al estudio de
distribuciones de patrones en permutaciones aleatorias de números
enteros, centrándose en detalle en los números de *Euler y Simon
Newcomb*. El **Capítulo 7** cubre varias aplicaciones de la teoría de la
distribución de rachas y patrones en las áreas de confiabilidad de
sistemas de ingeniería, pruebas de hipótesis, medición de continuidad en
atención médica y control de calidad.

### Capitulo 2: Incrustación de Cadenas de Markov Finitas

#### 2.1 Cadena de Markov Finita

Sea $\small{\Omega=\{1,2,\ldots,m\}}\quad(m<\infty)$ un espacio de
estados finito, y $\small{\mathcal{Y_t}=\{Y_0,Y_1,\ldots,Y_t,\ldots\}}$
una familia de variables aleatorias definidas sobre
$\small{\Omega}$.[(proceso
estocástico).]{style="background-color:#F0F8CD;"}

**Definición 2.1** Decimos que la familia/colección de variables
aleatorias $\small{\{\mathcal{Y_t}\}}$ es cadena de Markov si, para toda
sucesión $\small{\{Y_0=i_0,Y_1=i_1,\ldots,Y_{t-1}=i_{t-1},Y_t=i_t\}},$
con $\small{t\in \{1,2,\cdots\}}$, se tiene que:

<!---Ecuación 2.1--->

::: math
```{=tex}
\begin{equation}
\mathbb{P}(Y_t=i_t \mid Y_{t-1}=i_{t-1},\ldots,Y_0=i_0)=\mathbb{P}(Y_t=i_t \mid Y_{t-1}=i_{t-1})
\end{equation}
```
:::

En otras palabras, la sucesión de variables aleatorias es una cadena de
Markov si la probabilidad de que el sistema entre en el estado
$\small{i_t}$ en el momento $\small{t}$ depende sólo del estado
inmediatamente anterior $\small{i_{t-i}}$ en el momento $\small{t-1}$. O
más sucintamente, visto desde el estado en el momento $\small{t- 1}$, el
futuro es independiente del pasado. Las probabilidades condicionales.

<!---Ecuación 2.2--->

::: math
```{=tex}
\begin{equation}
\mathbb{P}(Y_t=j \mid Y_{t-1}=i)\equiv p_{ij}
\end{equation}
```
:::

$\small{i,j \in \Omega}$, se denominan probabilidades de transición de
un paso para el sistema en el momento $t$. Las probabilidades de
transición $\small{p_{ij}(t), 1 \leq i,j \leq m}$, pueden representarse
como una matriz $m\times m$

<!---Ecuación 2.2.1--->

::: math
```{=tex}
\begin{equation}
\boldsymbol{M_t}=(p_{ij(t)})=\begin{pmatrix}
p_{11}(t) & p_{12}(t) & \cdots & p_{1m}(t)\\
p_{21}(t) & p_{22}(t) & \cdots & p_{2m}(t)\\
\vdots & \ddots & \ddots & \cdots\\
p_{m1}(t) &p_{m2}(t) & \cdots & p_{mm}(t)\\
\end{pmatrix}_{m\times m}
\end{equation}
```
:::

Las matrices $\small{\boldsymbol{M_t},\,\, t=1,2,\ldots,}$ son llamadas
*matrices de probabilidades de transición de un paso* o simplemente
*matrices de transición de un paso*.

**Proposición.** La matriz de probabilidades de transición
$\small{\boldsymbol{M_t}=(p_{ij}(t))}$ cumplen las siguientes
propiedades, para cada tiempo $\small{t}$:

1.  $\small{(p_{ij(t)}) \geq 0}$ para todo $\small{t}$.
2.  $\small{\displaystyle\sum_{j}p_{ij}=1}$, es decir, en cada momento
    del tiempo $\small{t}$, el proceso cambia de estado (puede ser
    permanecer en el mismo estado) con probabibilidad $\small{1}$.

**Definición 2.2:** Una cadena de Markov $\small{\{Y_0,Y_1,\dots\}}$, es
*homogenea* si las probabilidades de transición son constantes en el
tiempo, *i.e* $\small{\mathbb{P}(Y_t=j \mid Y_{t-1}=i)}=p_{ij}$ para
todo par $\small{(i,j)\in \Omega \times \Omega=\Omega^2}$ y todo
$\small{t=1,2,\ldots}$

Esta definición equivale a decir que las matrices de probabilidad de
transición de una cadena de Markov homogénea pueden representarse
mediante la única matriz:

<!-- Equación (2.2.2) -->

::: math
```{=tex}
\begin{equation}
\boldsymbol{M=M_t}=(p_{ij}(t)), \quad \text{para todo } t=1,2,\ldots
\end{equation}
```
:::

en donde las probabilidades de transición $\small{p_{ij}}$ son
independientes del índice del tiempo $\small{t}$.

El conjunto de probabilidades en el momento $\small{0}$, denotada como
$\small{\mathbb{P}(Y_0 = i)}$ para $i = 1,\ldots,m$ se conoce como la
*distribución inicial* de la cadena de Markov. Dada una distribución de
probablidad inicial y las probabilidades de transición de una cadena de
Markov, la *distribución conjunta* de la cadena se puede calcular de la
siguiente manera:

<!-- Equación (2.3) -->

::: math
```{=tex}
\begin{equation}
\begin{split}
\mathbb{P}(Y_n=i_n,\ldots,Y_1=i_1,Y_0=i_0) = &  \mathbb{P}(Y_n=i_n \mid Y_{n-1}=i_{n-1})\cdots \\
 & \cdots \mathbb{P}(Y_1=i_1 \mid Y_0=i_0)\mathbb{P}(Y_{0}=i_{0}).
\end{split}
\end{equation}
```
:::

Las cadenas de Markov se han utilizado en el modelado de una gran
cantidad de aplicaciones. Aquí damos dos ejemplos simples que se ven a
menudo en la teoría de probabilidad aplicada:

**Ejemplo 2.1** (El problema de la ruina del jugador). Considere un
jugador que gana y pierde un dólar con probabilidades $p$ y $q = 1-p$,
respectivamente. Supongamos que el jugador tiene un capital inicial de
$\small{a}$ dólares. El jugador deja de jugar cuando se queda sin
capital ("arruinado") o cuando alcanza una fortuna de $\small{a + b}$
dólares (con ganancia neta $\small{b > 0}$).

La sucesión del monto de capital del jugador,
$\small{\{Y_t: t = 0,1,2, \ldots\}}$, forma una cadena de Markov
*homogénea* con espacio de estados
$\small{\Omega= \{0,1, 2, \ldots, a-1,a,a + 1,\ldots, a + b}\}$ y las
siguientes probabilidades de transición:

<!-- Equación (2.3.1) -->

::: math
```{=tex}
\begin{equation} 
p_{ij}=\begin{cases}
p\quad \text{si } j=i+1\\
q\quad \text{si } j=i-1
\end{cases}
\end{equation}
```
:::

para $\small{i=1,2,\ldots,a+b-1,\, p_{00}=p_{a+b,a+b}=1}$ y cero en
cualquier otro caso. Los estados $\small{0}$ y $\small{a+b}$ se
denominan *absorbentes*, ya que, una vez alcanzados nunca se sale de
estos. La Cadena de Markov tine la matriz de problabilidades de
transición:

<!---Matriz de probabilidades de transición del problema de la ruina del jugador-->

<!-- Equación (2.3.2) -->

::: math
```{=tex}
\begin{equation} 
\boldsymbol{M}=\begin{array}{cc} &
\begin{array}{cccccccc}
\end{array}
\\
\begin{array}{ccc}
0 \\
1 \\
\vdots\\
\cdot \\
a-1 \\
a\\
a+1\\ 
\vdots\\
a+b
\end{array}
&
\left(
\begin{array}{cccccccc}
1 & 0 & 0 & 0 &  &  &   &   \\
q & 0 & p & 0 &  &  &   &  \\
& \ddots & \ddots & \ddots &   &   &\boldsymbol{0}   &  \\
&  &  \ddots & \ddots & \ddots &   &   &   \\
&  &   &  q & 0& p &  &   \\
& \boldsymbol{0} &  &   &   \ddots & \ddots & \ddots & \\
&  &  &  &  & q & 0 & p \\
&  &  &  &  & 0 & 0 & 1 \\
\end{array}
\right)
\end{array}
\end{equation}
```
:::

en donde ${\mathbf{0}}$ representa un matriz de ceros y la cadena tiene
distribución de probabilidad inicial $\small{\mathbb{P}(Y_0=a)=1}$.

**Ejemplo 2.2** (Modelo de Urnas). Considere una sucesión de ensayos
independientes, cada uno de los cuales consiste en insertar una bola al
azar en una de $\small{k}$ urnas. Decimos que el sistema
$\small{\{Y_t : t = 0,1,\ldots\}}$ está en estado $\small{i}$, si
exactamente $\small{i}$ urnas están ocupadas. Este sistema forma una
cadena de Markov en el espacio de estados
$\small{\Omega = \{0,1,\ldots, k\}}$ con probabilidades de transición

<!-- Equación (2.3.3) -->

::: math
```{=tex}
\begin{equation}
p_{ij}=\begin{cases}
\frac{i}{k}  \quad\quad  \text{si } j=i\\
\frac{k-i}{k}\quad \text{ si } j=i+1\\
0 \quad \quad \text{en otro caso}
\end{cases}
\end{equation}
```
:::

para $\small{i=0,1,\ldots,k}$ y distribución de probabilidad inicial
$\small{\mathbb{P}(Y_0=0)=1}$. La matriz de probabilidades de transición
esta dada por: <!-- Equación (2.3.4) -->

::: math
```{=tex}
\begin{equation}
\boldsymbol{M}=\begin{array}{cc} &
\begin{array}{ccccccc}
\end{array}
\\
\begin{array}{ccc}
0 \\
1 \\
\\
\vdots\\
i\\
\vdots\\
k-1\\
k
\end{array}
&
\left(
\begin{array}{ccccccc}
0 & 1 & 0 &   &  &  &     \\
0 & \frac{1}{k} & \frac{k-1}{k}  & 0 &  & \boldsymbol{0} &      \\
&  & \ddots & \ddots &   &   &      \\
&  &        & \frac{i}{k} & \frac{k-i}{k} &   &       \\
&   &   &  & \ddots& \ddots &    \\
&   & \boldsymbol{0} &   &   & \frac{k-1}{k} & \frac{1}{k}  \\
&   &  &   &   & 0 & 1
\end{array}
\right)
\end{array}
\end{equation}
```
:::

Se pueden encontrar más ejemplos de este tipo en *Feller (1968)* y *Ross
(2000)*. Por supuesto, también habrá muchos más ejemplos de cadenas de
Markov en secciones posteriores de este libro.

#### 2.2 Ecuación de Chapman-Kolmogorov

Para una cadena de Markov no homogénea $\small{\{Y_t\}}$, las
probabilidades de transición de $\small{n}$ pasos
$\small{\mathbb{P}(Y_t= j \mid Y_{t-n} = i) = p_{ij}^{(n)}(t)}$ se
pueden obtener a partir de las probabilidades de transición de un paso
por una identidad importante conocida como *Ecuación de
Chapman-Kolmogorov*. Si $\small{n = 2}$, tenemos, para
$\small{t \geq 2}$,

<!--Ecuación (2.4): Chapman Kolmogorov-->

::: math
```{=tex}
\begin{equation}
p_{ij}^{(2)}(t) = \sum_{k\in \Omega}\mathbb{P}(Y_{t-1}=k \mid  Y_{t-2}=i)\mathbb{P}(Y_{t}=j \mid  Y_{t-1}=k)=\sum_{k\in \Omega} p_{ik}(t-1)^{}p_{kj}^{}(t)
\end{equation}
```
:::

que corresponde a sumar todos los posibles $\small{k}$ estados
intermedios en la transición del estado $\small{i}$ al estado
$\small{j}$.

Si $\small{\{Y_t\}}$ es una cadena de Markov homogénea, entonces la
ecuación anterior (2.4) genera las probabilidades de transición de dos
pasos $\small{(n = 2)}$

<!--Ecuación (2.5): Chapman Kolmogorov HOMO-->

::: math
```{=tex}
\begin{equation}
p_{ij}^{(2)} = \sum_{ k \in \Omega}\mathbb{P}(Y_{t-1}=k  \mid  Y_{t-2}=i)\mathbb{P}(Y_{t}=j \mid  Y_{t-1}=k)=\sum_{k\in \Omega} p_{ik}p_{kj}
\end{equation}
```
:::

las cuales son independientes de $\small{t}$. Por lo tanto, de la
ecuación (2.5), la matriz de probabilidades de transición de dos pasos
$\small{\boldsymbol{M}^{(2)} = (p_{ij}^{(2)})}$ satisface la identidad
$\small{\boldsymbol{M}^{(2)}= \boldsymbol{M}^2}$. De manera analoga,
para las probabilidades de transición de $\small{n}$ pasos de una cadena
de *Markov homogénea*, la identidad de Chapman-Kolmogorov:

<!-- Ec. (2.6) Chapman- Kolmogorov n-pasos --->

::: math
```{=tex}
\begin{equation}
p_{ij}^{(n)} = \sum_{k \in \Omega} p_{ik}^{(s)}p_{kj}^{(n-s)}
\end{equation}
```
:::

se mantiene para cada paso intermedio $\small{s = 1,\ldots, n -1}$. Se
deduce de las ecuaciones. (2.5) y arterior-(2.6) que

<!--Ec. (2.7) Chapman- Kolmogorov Matricial--->

::: math
```{=tex}
\begin{equation}
\boldsymbol{M}^{(n)}= \boldsymbol{M}^{(s)}\boldsymbol{M}^{(n-s)}=\boldsymbol{M}^{n}
\end{equation}
```
:::

Para una cadena de Markov homogénea $\small{\{Y_t\}}$, y cualquier
subconjunto $\small{{C}}$ del espacio de estados $\small{\Omega}$, se
deduce de la Ec.(2.7) que la probabilidad condicional del sistema
$\small{Y_n}$ resida en $\small{{C}}$ en el índice de tiempo
$\small{n}$, dada la distribución de probabilidad inicial
$\small{\boldsymbol{\mathbf{\xi}}_0 = \big(\mathbb{P}(Y_0 = 1), \cdots,P(Y_0 = m)\big)}$
es:

<!-- Equación (2.8) -->

::: math
```{=tex}
\begin{equation}
\mathbb{P}(Y_n \in {C} \mid \boldsymbol{\mathbf{\xi}}_0)=\boldsymbol{\mathbf{\xi}}_0 \boldsymbol{M}^{n}\boldsymbol{\mathbf{U}'}({C})
\end{equation}
```
:::

en donde $\small{\boldsymbol{\mathbf{U}'}({C})}$ es la traspuesta de
$\small{\boldsymbol{\mathbf{U}}({C})}$, con
$\small{\boldsymbol{\mathbf{U}}( {C})=\displaystyle\sum_{i \in C}e_i}$ y
$\small{\boldsymbol{e}_i=(0,\ldots,1,\ldots,0)_{1\times m}}$ es un
vector canónico con un $\small{1}$ correspondiente al $i$-ésimo estado y
cero en los otros. De manera más general, si $\small{\{Y_t\}}$ es una
cadena de Markov no homogénea, se puede demostrar (ver, *Feller 1968*)
que la probabilidad condicional de $\small{Y_n \in {C} }$ dado
$\small{\boldsymbol{\xi}_0}$ se puede expresar simplemente como

<!-- Equación (2.9) -->

::: math
```{=tex}
\begin{equation}
\mathbb{P}(Y_n \in  {C} \mid \boldsymbol{\mathbf{\xi}}_0)=\boldsymbol{\mathbf{\xi}}_0 \Big(\prod_{t=1}^{n}\boldsymbol{M_t}\Big)\boldsymbol{\mathbf{U}'}({C})
\end{equation}
```
:::

Las ecuaciones (2.8) y (2.9) son dos herramientas indispensables para
evaluar las probabilidades de diversos eventos asociados con cadenas de
Markov homogéneas y no homogéneas, respectivamente.

#### 2.3 Cadena de Markov con estructura de árbol.

Con el fin de ampliar las posibles aplicaciones, es útil considerar una
extensión simple de la metodología anterior a cadenas de Markov
definidas en espacios de estados de diferentes tamaños. Sea
$\small\{Y_t\}$ una sucesión de variables aleatorias definidas en una
familia de espacios de estados $\small{\{\Omega_t\}}$, respectivamente.
La sucesión $\small{\{Y_t\}}$ se denomina *cadena de Markov con
estructura de árbol* si $\small{\{Y_t\}}$ es una cadena de Markov con
matrices de transición

<!-- Equación (2.9.1) -->

::: math
```{=tex}
\begin{equation}
\boldsymbol{M_t}=(p_{ij}(t)), \quad \text{para todo } t=1,2,\ldots,
\end{equation}
```
:::

en donde, para cada $\small{i \in {\Omega}_{t-1}}$ y
$\small{j \in {\Omega}_{t}}$

<!-- Equación (2.9.2) -->

::: math
```{=tex}
\begin{equation}
p_{ij}(t)=\mathbb{P}(Y_t=j\mid Y_{t-1}=i).
\end{equation}
```
:::

Obsérvese que los espacios de estados de la colección
$\small{\{\Omega_t\}}$ pueden tener tamaños diferentes, las matrices de
transición $\small{\boldsymbol{M_t}}$ pueden ser rectangulares en lugar
de cuadradas; es decir, $\small{\boldsymbol{M_t},\, t = 1, 2, \ldots,}$
son matrices de orden
$\small{\text{card}(\Omega_{t-1}) \times \text{card}(\Omega_{t})}$,
donde $\small{\text{card}(\Omega)}$ representa el número cardinal del
espacio de estados $\small{\Omega}$. La sucesión de matrices de
probabilidad de transición $\small{\{\boldsymbol{M_t}}\}$ sigue
determinando la cadena de Markov $\small\{{Y_t}\}$ estructurada en
árbol, y la ecuación de *Chapman-Kolmogorov* sigue siendo aplicable.

Para cualquier subconjunto $\small{ {C}\subseteq \Omega_n}$, la
probabilidad condicional de $\small{Y_n\in {C}}$ dada la distribución de
probabilidad inicial $\small{\boldsymbol{\xi}_0}$, puede calcularse vía:

<!-- Equación (2.10) -->

::: math
```{=tex}
\begin{equation}
\mathbb{P}(Y_n \in {C} \mid \boldsymbol{\mathbf{\xi}}_0)=\boldsymbol{\mathbf{\xi}}_0 \Big(\prod_{t=1}^{n}\boldsymbol{M_t}\Big)\boldsymbol{\mathbf{U}'}_{n}({C})
\end{equation}
```
:::

siendo
$\small{\boldsymbol{\mathbf{U}}_{n}({C})=\displaystyle\sum_{i \in C}\boldsymbol{e}_i}$
y
$\small{\boldsymbol{e}_i=(0,\ldots,1,\ldots,0)_{1\times card(\Omega_n)}}$
es un vector unitario de tamaño $\small{1\times card(\Omega_n)}$ con un
$\small{1}$ asociado al $i$-ésimo estado. Si todo los espacios de
estados son iguales $\small{(\Omega_1=\cdots=\Omega_n)}$,entonces la
*Eq. (2.10)* se reduce a *Eq. (2.9)*.

#### 2.4 Rachas y Patrones

Tradicionalmente, dentro de una sucesión de ensayos Bernoulli (i.i.d.
éxito-fracaso), una *racha* denota una sucesión de éxitos o fracasos
consecutivos. Por ejemplo una racha de éxitos de tamaño 4 implica el
patrón $\small{SSSS}$. Varias de las estadísticas de *rachas* que se
utilizan a menudo en estadística y probabilidad aplicada para una
sucesión de $n$ ensayos Bernoulli son:

*(i)* $\small{N_{n,k}}$ el número rachas de $\small{k}$ éxitos
consecutivos no solapados, en el sentido del conteo de Feller (1968);

*(ii)* $\small{M_{n,k}}$ el número de rachas de $\small{k}$ éxitos
consecutivos solapados;

*(iii)* $\small{E_{n,k}}$ el número de rachas de éxitos de tamaño
exactamente igual a $\small{k}$, en el sentido del conteo de *Mood
(1940)*;

*(iv)* $\small{G_{n,k}}$ el número de rachas de éxitos de tamaño mayor o
igual que $\small{k}$ ;

*(v)* $\small{L_{n}(S)}$ el tamaño de la racha de éxitos más larga.

Quizás la forma más sencilla de comprender las definiciones dadas de
estas estadísticas de rachas y el procedimiento de conteo de solapado/no
solapado, sea mediante el siguiente ejemplo. Supongamos que hay
$\small{n = 10}$ ensayos de Bernoulli, con realización
$\small{SSFSSSSFFF}$. Entonces $\small{L_{10}(S) = 4}$, y para
$\small{k = 2}$, tenemos
$\small{N_{10,2} = 3, M_{10,2} = 4, E_{10,2} = 1}$ y
$\small{G_{10,2} = 2}$

De las definiciones de estas estadísticas de rachas, se deduce por
inspección que las siguientes relaciones siempre son verdaderas:

<!-- Equación (2.10.1) -->

::: math
```{=tex}
\begin{equation}
E_{n,k}\leq G_{n,k} \leq N_{n,k} \leq M_{n,k}\\
E_{n,k} = G_{n,k} - G_{n,k+1}\\
L_n(S)<k\quad\text{si y solo si }N_{n,k}=0
\end{equation}
```
:::

[Para ampliar las definiciones de rachas, consideremos una sucesión de
$\small{n}$ ensayos multiestados $\small{\{{X}\}_{t=1}^{n}}$, cada una
de las cuales tiene $\small{m \geq 2}$ estados o símbolos como posibles
resultados. Estos símbolos se denotan por $\small{b_1,b_2,\ldots,b_m}$ y
ocurren con probabilidades $\small{p_1,p_2,\ldots,p_m}$,
respectivamente. A continuación, definimos tres tipos de patrones
generales: un *patrón simple*, un *patrón compuesto* y un *patrón en
serie*.]{style="background-color:#FBF9C9;"}

[**Definición 2.3** Decimos que $\small{\Lambda}$ es un *patron simple*,
si esta conformado por una determinada serie de $\small{k}$ símbolos,
*i.e*, $\small{\Lambda=b_{i_1}b_{i_2}\cdots b_{i_k}}$ con
$\small{i_j\in \{1,2,\ldots,m\}}$, para todo $\small{j=1,\dots,k}$. La
longitud del patrón es fija y los símbolos en el patrón puede
repetirse.]{style="background-color:#FEFF5B;"}

Las rachas de éxito y fracaso de tamaño $\small{k}$ son por tanto
patrones simples según esta definición, y de hecho cualquier sucesión de
éxitos y fracasos de longitud fija, digamos $\small{\Lambda =SSFSF}$,
puede considerarse un patrón simple dentro de una sucesión de de
$\small{n}$ ensayos de dos estados $\small{(m = 2)}$.

Ahora, sean $\small{\Lambda_1}$ y $\small{\Lambda_2}$ dos patrones
simples de longitudes/tamaños $\small{k_1}$ y $\small{k_2}$ ,
respectivamente. Decimos que $\small{\Lambda_1}$ y $\small{\Lambda_2}$
son *distintos* si ni $\small{\Lambda_1}$ incluye a $\small{\Lambda_2}$
ni $\small{\Lambda_2}$ incluye a $\small{\Lambda_1}$. Definimos
$\small{\Lambda_1 \cup\Lambda_2}$ como la ocurrencia de uno de los dos
patrón $\small{\Lambda_1}$ o $\small{\Lambda_2}$ , y definimos
$\small{\Lambda_1 \ast\Lambda_2}$ como la ocurrencia de patrón
$\small{\Lambda_1}$ seguido del patrón $\small{\Lambda_1}$ (quizás con
una separación entre ellos).

**Definición 2.4** Decimos que $\small{\Lambda}$ es un *patrón
compuesto* si es la unión de $\small{1 < l <\infty}$ patrones simples
distintos solapados/no solapados, es decir,
$\small{\Lambda=\displaystyle\bigcup_{i=1}^{l}\Lambda_i}$.

**Definición 2.5** Decimos $\small{\Lambda}$ es un *patrón en serie* si
$\small{\Lambda}$ está compuesto por una sucesión ordenada de
$\small{1 < l <\infty}$ patrones simples distintos no superpuestos
$\small{\Lambda_i}$, es decir,
$\small{\Lambda=\Lambda_1 \ast\Lambda_2\ast\cdots\Lambda_l}$

[A lo largo de este libro, la variable aleatoria $\small{X_n(\Lambda)}$
representa el número de ocurrencias del patrón $\small{\Lambda}$ en una
sucesión de $\small{n}$ ensayos multiestado, utilizando el recuento con
solapamiento o sin solapamiento]{style="background-color:#B7F7E9;"}.
Para aclarar las tres definiciones de patrones y los dos métodos de
recuento para los ensayos multiestado, presentamos el siguiente ejemplo.

**Ejemplo 2.3** Sea $\small{\{X_t\}_{t=1}^{16}}$ una sucesión de
dieciséis ensayos de un proceso de cuatro estados, en donde los
resultados posibles para cada ensayo son $\small{A, G, C}$ y
$\small{T}$. Sea $\small{\Lambda_1=AGAG}$ y $\small{\Lambda_2=AGT}$ dos
patrones simples distintos, $\small{\Lambda=\Lambda_1 \cup\Lambda_2}$ un
patrón compuesto y $\small{\Lambda^{\ast}=\Lambda_1 \ast\Lambda_2}$ un
*patron en serie*. Supongamos que la realización de esta sucesión de
dieciséis ensayos es $\small{TAGAGAGTCAGAGTCC}$, entonces:

*(i)* $\small{X_{16}(\Lambda_1)}$ es $\small{3}$ con *conteo solapado* y
es $\small{2}$ con *conteo no solapado*,

*(ii)* $\small{X_{16}(\Lambda)}$ es $\small{5}$ con *conteo solapado* y
es $\small{3}$ con *conteo no solapado*,

*(iii)* $\small{X_{16}(\Lambda^{\ast})}$ es igual a $\small{1}$.

*(iv)* $\small{X_{16}(\Lambda_2)}$ es $\small{2}$.

Las definiciones anteriores de rachas y patrones en una sucesión de
ensayos de múltiples estados también se pueden extender a *permutaciones
aleatorias* $\small{\{\pi : \pi=(\pi (1),\ldots,\pi(n)) \}}$ de
$\small{n}$ enteros $\small{\{1, 2, \ldots, n\}}$. Por ejemplo, el
número Euleriano $\small{E(\pi, n)}$, el número de aumentos en una
permutación aleatoria $\small{\pi}$ (ver Carlitz 1964, Tanny 1973 y
Worpitzky 1883), podría verse como una variable aleatoria
$\small{X_n(\Lambda)}$ con el patrón $\small{\Lambda}$ siendo un
aumento. Matemáticamente, el número de Euler se puede definir como

<!-- Equación (2.10.2) -->

::: math
```{=tex}
\begin{equation}
E(\pi,n)=X_n(\Lambda)=\displaystyle \sum_{i=0}^{n-1}I(\pi,i),
\end{equation}
```
:::

en donde <!-- Equación (2.10.3) -->

::: math
```{=tex}
\begin{equation}
I(\pi,i)=\begin{cases}
1 \quad \text{si }\pi(i)<\pi(i+1) \\
0 \quad \text{en otro caso }
\end{cases}
\end{equation}
```
:::

$$I(\pi,i)=\begin{cases}
1 \quad \text{si }\pi(i)<\pi(i+1) \\
0 \quad \text{en otro caso,}
\end{cases}$$

para $\small{i=1,\ldots,n-1}$, con $\small{I(\pi,i)=1}$ por convención
(la *brecha* inicial que precede a la primera permutación siempre se
considera un aumento). Por ejemplo, el número de aumentos
$\small{E(\pi, 9)}$ en la permutación aleatoria
$\small{\pi = (321459768)}$ de 9 números enteros son 5.

En vista de las definiciones y ejemplos anteriores, uno debería esperar
que la distribución exacta de la variable aleatoria
$\small{X_n(\Lambda)}$ dependa en gran medida de tres factores
importantes:

[(a) la estructura del patrón $\small{\Lambda}$
,]{style="background-color:#CCFFCC;"}

<span style="background-color:#FFFFCC;"> (b) la estructura de la
sucesión $\small{\{{X}\}_{t=1}^{n}}$ de $n$ ensayos (o permutaciones
aleatorias),

</span> [(c) el procedimiento de conteo (conteo superpuesto o no
superpuesto).]{style="background-color:#E8EAF6;"}

Debido a estos factores, la determinación analítica de distribuciones
exactas mediante enfoques tradicionales como la combinatoria puede ser
bastante desafiante y generalmente compleja, involucrando identidades
especiales y un álgebra extensa. En consecuencia, las distribuciones
exactas de muchas estadísticas utilizadas en aplicaciones prácticas
nunca se han estudiado utilizando tales métodos, especialmente cuando
los ensayos subyacentes no son *i.i.d.* (por ejemplo,
Markov-dependientes).

[En la siguiente subsección, describimos una técnica que permite obtener
una representación matricial compacta para la distribución exacta de una
manera relativamente simple y universal al incorporar la variable
aleatoria $\small{X_n(\Lambda)}$ en una cadena de Markov finita; la
expresión resultante también es muy adecuada para un análisis más
detallado de propiedades estadísticas, para el desarrollo de
aproximaciones de grandes desviaciones y para una implementación
numérica eficiente para el cálculo de probabilidades
exactas.]{style="background-color:#EFDCFB;"}

#### 2.5 Incrustación de Cadenas de Markov Finitas

La técnica de Incrustación de Cadenas de Markov Finitas (ICMF) para
encontrar la distribución de la variable aleatoria
$\small{X_n(\Lambda)}$ tiene sus orígenes en una serie de artículos de
*Fu (1985, 1986)*, *Fu* y *Hu (1987)*, *Chao* y *Fu (1989, 1991)*, y
*Fu* y *Lou (1991)*. El término *"Cadena de Markov Finita Incrustable"*
para describir una variable aleatoria fue introducido formalmente por
*Fu y Koutras (1994)*.

Sea $\small{\Gamma_n=\{0,1\ldots,n\}}$ un conjunto de indices, y
$\small{\Omega=\{a_1,a_2,\ldots,a_m\}}$ un espacio de estados finito.

**Definicion 2.6** La variable aleatoria no negativa de valores enteros
$\small{X_n(\Lambda)}$, es una *cadena de Markov finita incrustable* si:

(a). Existe una cadena de Markov finita $\small{\{Y_t:t\in \Gamma\}}$
definida sobre un espacio de estados $\small{\Omega}$ finito, con vector
de probabilidades inicial $\small{\boldsymbol{\xi}_0}$.

(b). Existe una partición finita $\small{\{C_x:x=0,1,\ldots,l_n\}}$
sobre el espacio de estado $\small{\Omega}$.

(c). Para todo $\small{x=0,1,\ldots,l_m}$ tenemos:
$$\small{\mathbb{P}\{X_n(\Lambda)=x\}=\mathbb{P}\{Y_n\in C_x \mid \boldsymbol{\xi}_0\}.}$$
Sea $\small{\{\boldsymbol{M}_t\}_{t=1}^{n}}$ una sucesión de matrices de
probabilidades de transición de orden $\small{m\times m}$ de una cadena
finita de Markov $\small{\{Y_t\}}$ definida sobre un espacio de estados
$\small{\Omega}$ con distribución de probablidad inicial
$\small{\boldsymbol{\xi}_0=\big(\mathbb{P}\{Y_0=a_1\},\mathbb{P}\{Y_0=a_2\},\ldots,\mathbb{P}\{Y_0=a_m\}\big)}$

**Teorema 2.1** Si $\small{X_n(\Lambda)}$ es una *cadena finita de
Markov incrustable*, entoces

<!-- Equación (2.11) -->

::: math
```{=tex}
\begin{equation}
\mathbb{P}\{ X_n(\Lambda)=x\}=\boldsymbol{\mathbf{\xi}}_0 \Big(\prod_{t=1}^{n}\boldsymbol{M}_t\Big)\boldsymbol{\mathbf{U}'}({C_x})
\end{equation}
```
:::

siendo
$\small{\boldsymbol{\mathbf{U}}({C_x})=\displaystyle\sum_{r: a_r\in C_x}\boldsymbol{e}_r}$
y $\small{\boldsymbol{e}_r=(0,\ldots,1,\ldots,0)_{1\times m}}$ es un
vector unitario de tamaño $\small{1\times m}$ con un $\small{1}$
asociado al estado $\small{a_r}$ e $\small{\boldsymbol{\mathbf{\xi}}_0}$
vector de probabilidades iniciales, y
$\small{\boldsymbol{M}_t\,,\,\,t=1,\dots,n}$ son las matrices de
probabilidades de transición de la cadena de Markov incrustada.

**Prueba:** Dado que $\small{X_n(\Lambda)}$ es una cadena de Markov
finita incrustable, se deduce de *Definición 2.6(a)* de que existe una
cadena de Markov finita $\small{\{Y_t : t\in \Gamma_n \}}$ con
probabilidades iniciales $\small{\boldsymbol{\mathbf{\xi}}_0}$. Luego
por la *ecuación de Chapman-Kolmogorov* descrita en Sección 2.2, para
cada $\small{a_r\in \Omega}$, tenemos

<!-- Equación (2.11.1)-->

::: math
```{=tex}
\begin{equation}
\mathbb{P}(Y_n =a_r \mid \boldsymbol{\mathbf{\xi}}_0)=\boldsymbol{\mathbf{\xi}}_0 \Big(\prod_{t=1}^{n}\boldsymbol{M}_t\Big)\boldsymbol{e_r'}
\end{equation}
```
:::

Además, de las Definiciones *2.6(b)* y *(c)* se deduce que, para cada
$\small{x =0,1\ldots,l_n}$,

<!-- Equación (2.11.2)-->

::: math
```{=tex}
\begin{equation}
\begin{split}
\mathbb{P}\{ X_n(\Lambda)=x\} & =  \mathbb{P}(Y_n \in C_x \mid \boldsymbol{\mathbf{\xi}}_0) \\
 & = \sum_{a_r\in C_x}\mathbb{P}\{Y_n=a_r\mid \boldsymbol{\mathbf{\xi}_0}\}\\
 & = \sum_{a_r\in C_x} \boldsymbol{\mathbf{\xi}}_0 \Big(\prod_{t=1}^{n}\boldsymbol{M}_t\Big)\boldsymbol{e_r'}\\
 & = \boldsymbol{\mathbf{\xi}}_0 \Big(\prod_{t=1}^{n}\boldsymbol{M}_t\Big)\boldsymbol{\mathbf{U}'}( {C_x})\quad \quad \quad \quad \quad \Box
\end{split}
\end{equation} \Box
```
:::

El $\small{k-}ésimo$ momento
$\small{\mathbb{E}\{X_n^k(\Lambda)\},\,\,k=1,2,\ldots,}$ puede
expresarse como:

<!-- Equaciín 2.12-->

::: math
```{=tex}
\begin{equation}
\mathbb{E}\{X_n^k(\Lambda)\}=\boldsymbol{\mathbf{\xi}}_0 \Big(\prod_{t=1}^{n}\boldsymbol{M}_t\Big)\boldsymbol{{V}_k'}
\end{equation}
```
:::

en donde

<!-- Equación (2.12.1)-->

::: math
```{=tex}
\begin{equation}
\boldsymbol{{V}_k'}=\sum_{x=0}^{l_n}x^{k}\boldsymbol{U}(\mathbf{C_x})
\end{equation}
```
:::

De manera ánaloga la *función generadora de probabilidad* de la variable
aleatoria $\small{X_n(\Lambda)}$ puede escribirse como:

<!-- Equación 2.13-->

::: math
```{=tex}
\begin{equation}
\psi(s)= \boldsymbol{\mathbf{\xi}}_0 \Big(\prod_{t=1}^{n}\boldsymbol{M}_t\Big)\boldsymbol{W'}(s)
\end{equation}
```
:::

en donde <!-- Equación (2.13.1)-->

::: math
```{=tex}
\begin{equation}
\boldsymbol{W}(s)=\sum_{x=0}^{l_n}s^{x}\boldsymbol{U}(\mathbf{C_x})
\end{equation}
```
:::

Los funciones generadoras de probabilidad y de momentos se discutirán
dentro del contexto de aplicaciones específicas en secciones
posteriores.

**Ejemplo 2.4** (Número de parejas de resultados sucesivos idénticos).
Sea $\small{\{X_t:t = 0,1,\ldots, n\}}$ una sucesión de $\small{n}$
ensayos Markov-dependientes homogéneos con $\small{m}$ estados y matriz
de probabilidad de transición
$\small{\boldsymbol{A}_{m\times m} = \big(P_{ij}\big)}$ y una
distribución de probabilidad inicial
$\small{\boldsymbol{\xi}_0=\big(\mathbb{P}\{X_0=1\},\mathbb{P}\{X_0=2\},\ldots,\mathbb{P}\{X_0=m\}\big)=(1/m,1/m,\ldots,1/m)}$.
Definiendo una sucesión de funciones indicadoras

<!-- Equación (2.13.2)-->

::: math
```{=tex}
\begin{equation}
I_i=\begin{cases}
1 \quad \text{si }X_t=X_{t-1}\\
0 \quad \text{en otro caso}
\end{cases}
\end{equation}
```
:::

para todo $\small{t=1,\ldots,n}$

En este ejemplo, nos interesa el número de veces que un resultado
particular (uno de $\small{m}$ resultados posibles) en un ensayo
determinado se repite en el ensayo inmediatamente siguiente. En términos
matemáticos, definimos el patrón $\small{\Lambda}$ para denotar dicho
resultado repetido, un patrón que está presente en el índice de tiempo
$\small{1 \leq t \leq n}$ si $\small{X_{t-1} = X_t}$ o, de manera
equivalente en términos de la función indicadora anterior, si
$\small{I_t = 1}$. La estadística de rachas:

<!-- Equación (2.13.3)-->

::: math
```{=tex}
\begin{equation}
X_n(\Lambda)= \sum_{t=1}^{n}I_t
\end{equation}
```
:::

corresponde al número de veces que ocurrió el patrón $\small{\Lambda}$
en la sucesión $\small{\{X\}_{t=0}^{n}}$ de $\small{n}$ ensayos
Markov-dependientes con $\small{m}$ estados. En el sector sanitario, por
ejemplo, la estadística $\small{X_n(\Lambda)/n}$ se conoce como $SECON$
y forma la medida principal de continuidad secuencial en una serie de
$\small{n}$ visitas de pacientes a $\small{m}$ posibles proveedores de
atención sanitaria ( *Steinwachs 1979*).

Una dificultad aquí es que las variables aleatorias $\small{\{I_t\}}$ no
son independientes y no conforman una cadena de Markov, incluso si la
sucesión $\small{\{X\}_{t=0}^{n}}$ se extrajera de ensayos *i.i.d.* de
$\small{m}$ estados. De hecho, se puede demostrar que las variables
aleatorias $\small{\{I_t\}}$ son dependientes y están correlacionadas
positivamente probando que $\small{Cov(I_i, I_j) > 0}$ para todo
$\small{i}$ y $\small{j}$, con $\small{Cov(I_i, I_j) \rightarrow 0}$
cuando $\small{\mid i-j \mid\rightarrow 0}$. Sin embargo, como se indica
a continuación, la distribución exacta aún se puede obtener fácilmente
utilizando la técnica de incrustación de cadenas de Markov finitas.

Primero, descomponemos la matriz de probabilidad de transición
$\small{\boldsymbol{A}}$ en dos matrices $\small{\boldsymbol{G}}$ y
$\small{\boldsymbol{D}}$, donde la matriz $\small{\boldsymbol{D}}$
contiene sólo los elementos diagonales de $\small{\boldsymbol{A}}$; es
decir:

<!-- Equación (2.13.4)-->

::: math
```{=tex}
\begin{equation}
\boldsymbol{A}_{m\times m}=\boldsymbol{G}_{m\times m}+\boldsymbol{D}_{m\times m}
\end{equation}
```
:::

en donde: <!-- Equación (2.13.5)-->

::: math
```{=tex}
\begin{equation}
\boldsymbol{G}_{m\times m}=
\begin{pmatrix}
0 & p_{ij} & \cdots \\
  & \ddots &        \\
\cdots & p_{ij} & 0
\end{pmatrix}
\quad \text{y} \quad

\boldsymbol{D}_{m\times m}=
\begin{pmatrix}
p_{11} &  & \boldsymbol{0} \\
  & \ddots &        \\
\boldsymbol{0} &   & p_{mm}
\end{pmatrix}
\end{equation}
```
:::

Sea
$\small{\Omega=\{(u,v): u = 0,\ldots,n, \text{ y }v = 1,2,\ldots, m\}}$
el espacio de estados que contiene un total de $\small{(n+1)m}$ estados.
Dado $\small{n}$, se define una cadena de Markov homogénea y finita
$\small{\{Y_t: t\in \Gamma\}}$ en el espacio de estados $\small{\Omega}$
como

<!-- Equación (2.13.6)-->

::: math
```{=tex}
\begin{equation}
Y_t=\begin{cases}
\Big(\displaystyle\sum_{i=1}^{t}I_i, X_t \Big) \quad \text{si } 1 \leq t \leq n\\
\big(0,X_0\big) \quad t=0
\end{cases}
\end{equation}
```
:::

con matriz de probabilidades de transición:

<!-- Equación (2.13.7)-->

::: math
```{=tex}
\begin{equation}
\boldsymbol{M}=\begin{pmatrix}
\boldsymbol{G} & \boldsymbol{D} & \boldsymbol{O} & \cdots & \boldsymbol{O}\\
\boldsymbol{O} & \boldsymbol{G} & \boldsymbol{D} & \cdots & \boldsymbol{O} \\
\vdots & \ddots & \ddots & \ddots & \vdots \\
\boldsymbol{O} & \cdots & \cdots & \boldsymbol{G}& \boldsymbol{D}\\
\boldsymbol{O} & \boldsymbol{O} & \cdots & \boldsymbol{O}& \boldsymbol{I}\\
\end{pmatrix}
\end{equation}
```
:::

donde $\small{\boldsymbol{M}}$ es una matriz
$\small{(n + 1)m \times (n + 1)m}$, $\small{\boldsymbol{O}}$ representa
la matriz cero $\small{m\times m}$ e $\small{\boldsymbol{I}}$ es la
matriz identidad $\small{m\times m}$. Los estados en
$\small{\boldsymbol{M}}$ están ordenados en orden lexicográfico
(diccionario). Por último, defininiendo la partición
$\small{\{C_x: x=0,1,2,\ldots,n\}}$ en el espacio de estados
$\small{\boldsymbol{\Omega}}$ como

<!-- Equación (2.13.8)-->

::: math
```{=tex}
\begin{equation}
C_x=\{(x,v): v=1,2,\ldots,m\}
\end{equation}
```
:::

Dadas las definiciones anteriores para la cadena de Markov
$\small\{Y_t\}$, la variable aleatoria $\small{X_n(\Lambda)}$ es, según
la Definición 2.6, una cadena de Markov finita incrustable y su
distribución exacta se desprende del *Teorema 2.1*: para
$\small{0 \leq x \leq n}$,

<!--Equación 2.14-->

::: math
```{=tex}
\begin{equation}
\mathbb{P}\{X_n(\Lambda)=x\}=\boldsymbol{\xi_0}\begin{pmatrix}
\boldsymbol{G} & \boldsymbol{D} & \boldsymbol{O} & \cdots & \boldsymbol{O}\\
\boldsymbol{O} & \boldsymbol{G} & \boldsymbol{D} & \cdots & \boldsymbol{O} \\
\vdots & \ddots & \ddots & \ddots & \vdots \\
\boldsymbol{O} & \cdots & \cdots & \boldsymbol{G}& \boldsymbol{D}\\
\boldsymbol{O} & \boldsymbol{O} & \cdots & \boldsymbol{O}& \boldsymbol{I}\\
\end{pmatrix}^{n}\boldsymbol{U'}(C_x)
\end{equation}
```
:::

donde $\small{\boldsymbol{\xi_0}(\pi_0,0,\ldots,0)_{(n+1)\times m}}$ es
la distribución inicial del vector de estado $\small{Y_0}$, y
$\small{\boldsymbol{U'}(C_x): (0,\ldots, 0, \underbrace{1, 1, ..., 1}_{C_x}, 0,\ldots,0)}$
es un vector de fila $\small{1 \times(n+1)m}$ con $\small{1}$ en las
coordenadas asociadas con los estados en $\small{C_x}$ y cero en otros
posiciones. En el *Capítulo 7* se darán más detalles y un ejemplo
numérico de este problema.

*Koutras y Alexandrou (1995)* introdujeron la noción de variables
incrustables en cadenas finitas de Markov de tipo binomial *(MVBS)*, y
muchas estadísticas comunes para rachas y patrones caen en esta
categoría especial. Sea la partición
$\small{ \{C_x\}=\{[(x, v): v=1,...,r], \text{ para } x = 0, 1,\ldots, l_n\}}$,
la partición del espacio de estados $\small{\Omega}$.

**Definición 2.7** Una variable aleatoria $\small{X_n(\Lambda)}$ es una
cadena de Markov finita incrustable de tipo binomial si:

*(i)* $\small{X_n(\Lambda)}$ es una cadena de Markov finita incrustable
como en la *Definición 2.6*.

*(ii)* $\small{\mathbb{P}\{Y_t=(y,j) \mid Y_{t-1} =(x,i)\} \equiv 0}$
para todo $\small{y\neq x}$ o $\small{x + 1}$.

Para cualquier $\small{MVB}$, introduzca dos matrices de probabilidad de
transición $\small{r\times r}$:

<!-- Equación (2.14.1)-->

::: math
```{=tex}
\begin{equation}
\boldsymbol{A_t}(x) = \big(a_{ij}(t)\big) = \Big(\mathbb{P}\{Y_t = (x,j)\mid Y_{t−1} = (x, i)\}\Big)
\end{equation}
```
:::

y <!-- Equación (2.14.2)-->

::: math
```{=tex}
\begin{equation}
\boldsymbol{B_t}(x) = \big(b_{ij}(t)\big) = \Big(\mathbb{P}\{Y_t = (x+1,j)\mid Y_{t−1} = (x, i)\}\Big)
\end{equation}
```
:::

Por tanto las matrices de probabilidad de transición
$\small{\boldsymbol{M_t}}$ de la cadena de Markov incrustada tienen la
siguiente forma: <!-- Equación (2.15)-->

::: math
```{=tex}
\begin{equation}
\boldsymbol{M}=\begin{pmatrix}

\boldsymbol{A}_t(0) & \boldsymbol{B}_t(0) & \boldsymbol{O} & \cdots &\cdots  & \boldsymbol{O} \\

\boldsymbol{O} &\boldsymbol{A}_t(1) & \boldsymbol{B}_t(1)  & \boldsymbol{O} & \cdots  & \boldsymbol{O}\\

\vdots & \boldsymbol{O} & \ddots & \ddots & \ddots & \vdots \\
\vdots & \ddots & \boldsymbol{O}& \ddots & \ddots & \boldsymbol{O} \\
\vdots & \cdots & \cdots & \boldsymbol{O}& \boldsymbol{A}_t(l_n-1) & \boldsymbol{B}_t(l_n-1) \\
\boldsymbol{O} & \boldsymbol{O} & \cdots &  \boldsymbol{O}& \boldsymbol{O} &  \boldsymbol{A}_t(l_n) \\
\end{pmatrix}
\end{equation}
```
:::

para $\small{t = 1,\ldots,n}$, en donde los estados están ordenados en
orden lexicográfico (diccionario). Hay muchas estadísticas para rachas y
patrones con matrices de transición que tienen esta forma, como, por
ejemplo, las estadísticas de rachas
$\small{N_{n,k},\, M_{n,k}\, \text{y}\, G_{n,k}}$ introducidas en la
*Sección 2.4* (y estudiadas más a fondo en el Capítulo 3).

Para $\small{MVB´s}$, se puede derivar una ecuación recursiva eficiente
para la distribución de $\small{X_n(\Lambda)}$, que aprovecha
parcialmente la estructura de bandas de las matrices de probabilidad de
transición $\small{\boldsymbol{M}_t}$. Sea el vector fila
$\small{\boldsymbol{\alpha}_t(x)=\big(\mathbb{P}\{Y_t=(x,1)\},\ldots, \mathbb{P}\{Y_t=(x,1)\}\big)}$
, para $\small{t= 1,\ldots, n}$, de modo que la probabilidad de
$\small{X_n(\Lambda)=x}$ se puede representar como

<!-- Equación 2.16-->

::: math
```{=tex}
\begin{equation}
\mathbb{P}\{X_n(\Lambda)=x \mid \boldsymbol{\xi}_0\}=
\boldsymbol{\alpha}_n(x)\boldsymbol{1}', \, \text{para toda}\,\,
x=0,1,\dots,l_n
\end{equation}
```
:::

donde $\small{\boldsymbol{1}'=(1,\ldots,1)'}$. Descomponga
$\small{\boldsymbol{M}_t}$ como
$\small{\boldsymbol{M}_t=\boldsymbol{K}_t+\boldsymbol{H}_t}$, donde
$\small{\boldsymbol{K}_t}$ es una matriz diagonal con componentes
$\small{\boldsymbol{A}_t(x)}$, para $\small{x = 0,1,\ldots,l_n}$, y
$\small{\boldsymbol{H}_t}$ es una matriz diagonal superior con
componentes $\small{\boldsymbol{B}_t(x)}$, para
$\small{x = 0,1,\ldots,l_{n-1}}$. A partir de la multiplicación hacia
atrás,
$\small{\boldsymbol{\mathbf{\xi}}_0 \Big(\displaystyle\prod_{j=1}^{t}\boldsymbol{M}_j\Big)=\boldsymbol{\mathbf{\xi}}_0 \Big(\displaystyle\prod_{j=1}^{t-1}\boldsymbol{M}_j\Big)\boldsymbol{M}_t=\boldsymbol{\mathbf{\xi}}_0 \Big(\displaystyle\prod_{j=1}^{t-1}\boldsymbol{M}_j\Big)\big(\boldsymbol{K}_t+\boldsymbol{H}_t\big)}$,
puede demostrarse que se cumplen las siguientes ecuaciones recursivas:

<!--Equación 2.17--->

::: math
```{=tex}
\begin{align*} 
\boldsymbol{\alpha_t}(0)&=\boldsymbol{\alpha_{t-1}}(0)\boldsymbol{A_t}(0) \\ 
\boldsymbol{\alpha_t}(X)&=
\boldsymbol{\alpha_{t-1}}(x-1)\boldsymbol{B_{t-1}}(t-1)+\boldsymbol{\alpha_{t-1}}(x)\boldsymbol{A_t}(x),\, x=1,\ldots,l_n.
\end{align*}
```
:::

La *ecuación (2.17)* proporciona un algoritmo eficiente para calcular
las probabilidades
$\small{ \mathbb{P}\{X_n(\Lambda)=x \mid\boldsymbol{\xi}_0\}=\boldsymbol{\alpha}_n(x)\boldsymbol{1}', \, \text{para toda }\, x=0,1,\dots,l_n}$,
y esto es especialmente importante cuando la dimensión de las matrices
de transición $\small{\boldsymbol{M_t}}$ es grande y el esfuerzo
computacional para calcular ingenuamente
$\small{\boldsymbol{\mathbf{\xi}}_0 \Big(\displaystyle\prod_{t=1}^{n}\boldsymbol{M}_t\Big)\boldsymbol{U'}(C_x)}$
se vuelve prohibitivo. A partir de la multiplicación hacia atrás, la
técnica de incrustación de cadenas finitas de Markov a menudo
proporciona una ecuación recursiva en una forma similar a la *ecuación
(2.17)*, una forma que, en general, no puede obtenerse tan fácilmente
mediante los métodos combinatorios o de renovación tradicionales.

#### 2.6 Estados Absorbentes

En esta sección se derivan algunas expresiones útiles para la
probabilidad de entrar en un estado absorbente. Para mayor claridad de
la exposición, nos centraremos en las cadenas de Markov homogéneas, pero
las ideas pueden generalizarse fácilmente a casos no homogéneos.

Un estado $\small{\alpha \in \Omega}$ se llama estado absorbente si, una
vez que el sistema entra en el estado $\small{\alpha}$, nunca sale; es
decir, $\small{p_{\alpha\alpha}\equiv 1}$ (y
$\small{p_{\alpha\beta}\equiv 0}$ para cualquier
$\small{\alpha\neq\beta}$). Sea $\small{A=\{\alpha_1,\ldots,\alpha_k\}}$
el conjunto de todos los estados absorbentes de una cadena de Markov
homogénea $\small{\{Y_t\}}$ con una matriz de probabilidad de transición
$\small{\boldsymbol{M}}$. Bajo una disposición apropiada del espacio de
estados, la matriz de probabilidad de transición
$\small{\boldsymbol{M}}$ siempre se puede escribir de la siguiente
forma:

<!---Ecuación. (2.18) --->

::: math
```{=tex}
\begin{equation}
\boldsymbol{M}=\left(\begin{array}{c|c}
\boldsymbol{N}_{(m-k)\times (m-k)} & \boldsymbol{C}_{(m-k)\times (m-k)}\\
\hline  
\boldsymbol{O}_{k\times (m-k)} & \boldsymbol{1}_{k \times k} 
\end{array}\right)
\end{equation}
```
:::

donde $\small{m}$ y $\small{k}$ $\small{(m>k)}$ son los números de
estados en $\small{\Omega}$ y $\small{A}$, respectivamente. La matriz
$\small{\boldsymbol{N}}$ definida por la ecuación. (2.18) se conoce como
la *submatriz de probabilidad de transición esencial de la cadena de
Markov*. Desempeña un papel importante en el estudio de las
distribuciones exactas de *variables aleatorias incrustables en cadenas
de Markov*, especialmente para las distribuciones asociadas de tiempos
de espera.

Sea
$\small{\boldsymbol{\xi_{0}}=\big(\boldsymbol{\xi}:\boldsymbol{0}\big)_{1\times m}}$
la distribución inicial, donde
$\small{\boldsymbol{\xi}=(\xi_1,\ldots,\xi_{m-k}), \, \boldsymbol{0}=(0,\ldots,0)_{1\times k}}$
y $\small{\displaystyle{\sum_{i=1}^{m-k}\xi_i=1}}$ y sea
$\small{\big(\boldsymbol{1:0}\big)_{1\times m}}$ un vector fila, en
donde $\small{\boldsymbol{1}=(1,\ldots,1)_{1\times (m-k)}}$ La razón por
la que suponemos que la distribución inicial tiene la forma
$\small{\big(\boldsymbol{\xi_0}:\boldsymbol{0}\big)}$ es estrictamente
por razones prácticas, ya que la mayoría de los sistemas siempre
comienzan en un estado no absorbente.

**Teorema 2.2** Dada una matriz de probabilidad de transición
$\small{\boldsymbol{M}}$ de una cadena de Markov homogénea
$\small{\{Y_t\}}$ en la forma de la *ecuación (2.18)*, la probabilidad
para el índice de tiempo $\small{n}$ cuando el sistema ingresa por
primera vez al conjunto de estados absorbentes puede ser obtenida como:

<!--Equación 2.19 -->

::: math
```{=tex}
\begin{equation}
\mathbb{P}\big(Y_n\in A,Y_{n-1}\notin A,\ldots,  Y_1\notin A \mid \boldsymbol{\xi_0}\big)=\boldsymbol{\xi N}^{n-1}\boldsymbol{(I-N)1'}
\end{equation}
```
:::

**Demostración:** Dado que $\small{\boldsymbol{M}}$ tiene la forma de la
*Equación 2.18*, se sigue que:

<!--Equación 2.20 -->

::: math
```{=tex}
\begin{equation}
\mathbf{M}^{n-1}=\left(\begin{array}{c|c}
\boldsymbol{N}^{n-1} & \boldsymbol{K}_{n-1}\\
\hline  
\boldsymbol{O} & \boldsymbol{I}
\end{array}\right)
\end{equation}
```
:::

en donde
$\small{\boldsymbol{K}_{n-1}=\big( \boldsymbol{I}+\boldsymbol{N}+\cdots+\boldsymbol{N}^{n-2}\big)\boldsymbol{C}}$.
Además, como todos los estados en $\small{\boldsymbol{A}}$ son estados
absorbentes, de la ecuación de Chapman-Kolmogorov se deduce que:

<!---Ecuación 2.21--->

::: math
```{=tex}
\begin{align*} 
\mathbb{P}\big(Y_{n-1}\notin A,\cdots,  Y_1\notin A \mid \boldsymbol{\xi_0}\big) & =\mathbb{P}\big(Y_{n-1}\in \Omega-A\mid \boldsymbol{\xi_0}\big)\\
& =\big(\boldsymbol{\xi_0}:\boldsymbol{0}\big) \boldsymbol{ M}^{n-1}\big(\boldsymbol{1}:\boldsymbol{0}\big)'.
\end{align*}
```
:::

Luego la ecuación (2.19) puede entonces deducirse utilizando las
ecuaciones (2.20) y (2.21) a traves de:

<!---Ecuación (2.20) y (2.21) --->

::: math
```{=tex}
\begin{align*} 
 & \quad \, \, \mathbb{P}\big(Y_n\in A,Y_{n-1}\notin A,\ldots,  Y_1\notin A \mid \boldsymbol{\xi_0}\big)\\
& =\mathbb{P}\big(Y_{n-1}\notin A,\ldots,  Y_1\notin A \mid \boldsymbol{\xi_0}\big)-\mathbb{P}\big(Y_n\notin A,Y_{n-1}\notin A,\ldots,  Y_1\notin A \mid \boldsymbol{\xi_0}\big)\\
& = \big(\boldsymbol{\xi_0}:\boldsymbol{0}\big) \boldsymbol{ M}^{n-1}\big(\boldsymbol{I-M}\big)\big(\boldsymbol{1}:\boldsymbol{0}\big)' \\ 
& =\boldsymbol{\xi N}^{n-1}\boldsymbol{(I-N)1'}.\hspace{8cm} \Box
\end{align*}
```
:::

En vista de las *Ecs. (2.20) y (2.21)*, los siguientes teoremas son
inmediatos.

**Teorema 2.3** Para todo estado $\small{i\in \Omega-A}$

<!--Equación 2.22-->

::: math
```{=tex}
\begin{align*} 
\mathbb{P}\big(Y_{n-1}=i,Y_{n-2}\notin A,\ldots,  Y_1\notin A \mid \boldsymbol{\xi_0}\big)= \boldsymbol{\xi N}^{n-1}\boldsymbol{e_i'}.
\end{align*}
```
:::

**Prueba**. Utilizando los mismos argumentos que en la demostración del
*Teorema 2.2* y reemplazando $\small{\boldsymbol{1'}}$ por
$\small{\boldsymbol{e_i'}}$, la *Ec. (2.22)* se sigue directamente de
las ecuaciones *(2.20) y (2.21)*. $\hspace{1cm} \Box$

**Teorema 2.4** Para cualquier estado absorbente $\small{j \in A}$, la
probabilidad del sistema para llegar por primera vez al estado
absorbente $\small{j}$ en el $\small{n}-$ésimo ensayo es:

<!--Equación 2.23-->

::: math
```{=tex}
\begin{align*} 
\mathbb{P}\big(Y_{n}=j,Y_{n-1}\notin A,\ldots,  Y_1\notin A \mid \boldsymbol{\xi_0}\big)= \boldsymbol{\xi N}^{n-1}{C_j'}.
\end{align*}
```
:::

en donde, $\small{C_j'}$ es la $\small{j}-$ésima columna de la matriz
$\small{\boldsymbol{C}}$.

**Prueba:** Para cualquier $\small{j \in A}$, de la definición de la
cadena de Markov y del *Teorema 2.3* se deduce que:

<!--Prueba teorema 2.4-->

::: math
```{=tex}
\begin{align*} 
& \quad \, \mathbb{P}\big(Y_{n-1}=j,Y_{n-1}\notin A,\ldots,  Y_1\notin A \mid \boldsymbol{\xi_0}\big)\\
& = \sum_{i\in \Omega-A}\mathbb{P}\big(Y_{n-1}=i,Y_{n-2}\notin A,\ldots,  Y_1\notin A \mid \boldsymbol{\xi_0}\big)\times \mathbb{P}\big( Y_n=j\mid Y_{n-1}=i \big)\\
&= \sum_{i\in \Omega-A}\boldsymbol{\xi N}^{n-1}{e_i'}p_{ij}\\
&= \boldsymbol{\xi N}^{n-1}\sum_{i\in \Omega-A}{e_i'}p_{ij}\\
&= \boldsymbol{\xi N}^{n-1}{C_j'}\hspace{8cm}
\end{align*}
```
:::

Para ilustrar los *teoremas 2.2* a *2.4* y sus relaciones,
proporcionamos el siguiente ejemplo sencillo.

**Ejemplo 2.5** Sea $\small{\{Y_t\}}$ una cadena de Markov homogénea
definida en el espacio de estados $\small{\{1, 2, 3, 4\}}$ con
distribución inicial
$\small{\boldsymbol{\xi_0}=\big(\xi : 0 \big)=(1,0:0,0)}$ y matriz de
probabilidad de transición

::: math
```{=tex}
\begin{equation}
\boldsymbol{M}=\begin{array}{cccc}&
\begin{array}{cccc}
\end{array}
\\
\begin{array}{ccc}
1 \\
2 \\
3\\
4\\
\end{array}
&
\left(
\begin{array}{cc|cc}
1/2 & 1/4 & 1/4  &  0 \\
1/3 & 1/3 & 0 &  1/3 \\
\hline
0& 0  &  1 & 0 \\
0&  0 & 0 &  1
\end{array}
\right)
\end{array}
\end{equation}
```
:::

en donde $\small{A=\{3,4\}}$ es el conjunto de estados absorbentes. Para
$\small{n = 3}$ (tercer ensayo), las probabilidades de entrada del
sistema en los estados absorbentes $\small{3}$ y $\small{4}$ son,
respectivamente:

<!--Ejemplo 2.5.3-->

::: math
```{=tex}
\begin{equation}
\mathbb{P}\big(Y_{3}=3,Y_{2}\notin A,Y_1\notin A \mid \boldsymbol{\xi_0}\big)=(0,1)
\left(\begin{array}{cc}
1/2 & 1/4\\
1/3 & 1/3\\
\end{array} \right)^{2}
\left(\begin{array}{c}
1/4\\
0\\
\end{array} \right)=\frac{1}{12}
\end{equation}
```
:::

y <!--Ejemplo 2.5.3-->

::: math
```{=tex}
\begin{equation}
\mathbb{P}\big(Y_{3}=4,Y_{2}\notin A,Y_1\notin A \mid \boldsymbol{\xi_0}\big)=(0,1)
\left(\begin{array}{cc}
1/2 & 1/4\\
1/3 & 1/3\\
\end{array} \right)^{2}
\left(\begin{array}{c}
0\\
1/3\\
\end{array} \right)=\frac{5}{72}.
\end{equation}
```
:::

Además, por el *Teorema 2.2*, la probabilidad de que el sistema entre
por primera vez en el subconjunto $\small{A=\{3,4\}}$ en el tercer
ensayo es

<!--Ejemplo 2.5.4-->

::: math
```{=tex}
\begin{align*}
& \quad \,\, \mathbb{P}\{Y_3\in A,Y_{2}\notin A,Y_1\notin A \mid \boldsymbol{\xi_0}\}\\
&=\boldsymbol{\xi N}^{3-1}\boldsymbol{(I-N)1'}\\
&=(0,1)
\left(\begin{array}{cc}
1/2 & 1/4\\
1/3 & 1/3\\
\end{array} \right)^{2}
\left[ 
\left(\begin{array}{cc}
1 & 0\\
0 & 1\\
\end{array} \right)-
\left(\begin{array}{cc}
1/2 & 1/4\\
1/3 & 1/3\\
\end{array} \right)
\right]
\left(\begin{array}{c}
1\\
1\\
\end{array} \right)\\
& =\frac{11}{72}
\end{align*}
```
:::

Como verificación de los resultados anteriores, observemos que:

<!--Ejemplo 2.5.5-->

::: math
```{=tex}
\begin{align*}
\mathbb{P}\big(Y_3\in A,Y_{2}\notin A,Y_1\notin A \mid \boldsymbol{\xi_0}\big)& =
 \mathbb{P}\big(Y_3= 3,Y_{2}\notin A,Y_1\notin A \mid \boldsymbol{\xi_0} \big)\\
&+ \mathbb{P}\big(Y_3= 4,Y_{2}\notin A,Y_1\notin A \mid \boldsymbol{\xi_0}\\
&= \frac{11}{72} \hspace{5cm}\Diamond
\end{align*}
```
:::

De forma más general, puesto que para cada $\small{i\in \Omega-A}$

::: math
```{=tex}
\begin{align*} 
\sum_{j\in A}p_{ij}= 1- \sum_{j \in \Omega- A}p_{il}
\end{align*}
```
:::

luego se deduce que
$\small{\displaystyle\sum_{j\in A}C_j'=\boldsymbol{(I-N)1'}}$, y por
tanto

<!--Ecuación 2.24-->

::: math
```{=tex}
\begin{align*} 
\sum_{j\in A}\boldsymbol{\xi N}^{n-1}C_j'=\boldsymbol{\xi N}^{n-1}\boldsymbol{(I-N)1'}
\end{align*}
```
:::

#### 2.7 Probabilidad de entrada inicial // Probabilidades de primera visita\*\*

Utilizando las ideas de la *sección 2.6*, podemos encontrar la
probabilidad de que se produzca la primera entrada para cualquier
subconjunto $\small{B\subset \Omega}$. Dado el subconjunto $\small{B}$,
la matriz de probabilidad de transición $\small{\boldsymbol{M}}$ de una
cadena de Markov $\small{\{Y_t\}}$ homogénea siempre puede disponerse de
la siguiente forma:

<!--Ecuación 2.25-->

::: math
```{=tex}
\begin{equation} 
\boldsymbol{M}=
\begin{array}{cc}
{\Omega-B} \\B \end{array}
\left(\begin{array}{c|c}
\boldsymbol{N} & \boldsymbol{B}\\
\hline
\boldsymbol{J} &  \boldsymbol{Q}
\end{array}
\right)
\end{equation}
```
:::

**Teorema 2.5** Sea $\small{\{Y_t\}}$ una cadena de Markov homogénea con
matriz de probabilidad de transición $\small{\boldsymbol{M}}$, en la
forma de la *ecuación (2.25)*, y con distribución inicial
$\small{\boldsymbol{\xi=(1:0)}}$. Entonces, para un subconjunto
$\small{B}$ de tamaño $\small{k}$ contenido en el espacio de estados
$\small{\Omega}$ de tamaño $\small{m}$, se cumplen las siguientes
relaciones:

*(i)* Para todo $\small{j \in B}$

<!--Ecuación 2.26-->

::: math
```{=tex}
\begin{equation}
\mathbb{P}\big(Y_n =j,Y_{n-1}\notin B,\cdots,Y_1\notin B \mid \boldsymbol{\xi_0}\big)=\boldsymbol{\xi N}^{n-1}\boldsymbol{B_j'},
\end{equation}
```
:::

en donde $\small{B_j'}$ es la $\small{j}-$ésima columna de la matriz
$\small{\boldsymbol{B}_{(m-k)\times k}}$ y

*(ii)*

::: math
<!--Ecuación 2.27-->

```{=tex}
\begin{align*}
& \quad \,\, \mathbb{P}\big(Y_n \in B,Y_{n-1}\notin B,\cdots,Y_1\notin B \mid \boldsymbol{\xi_0}\big)\\
&=\boldsymbol{\xi N}^{n-1}\boldsymbol{(I-N)1'}\\
&=\sum_{j\in B}\boldsymbol{\xi N}^{n-1}{B'}_j,
\end{align*}
```
:::

**Prueba.** Defina una nueva cadena de Markov $\small{\{Z_t\}}$ en el
espacio de estados $\small{\Omega}$, donde $\small{\{Z_t\}}$ es igual a
$\small{\{Y_t\}}$para todos los estados $\small{i \in \Omega-B}$ y donde
todos los estados $\small{j \in B}$ se toman como estados absorbentes.
Entonces la matriz de probabilidad de transición
$\small{\boldsymbol{M^{\star}}}$ para la cadena de Markov
$\small{\{Z_t\}}$ tiene la forma

<!--Ecuación/Prueba-teorema 2.5.1-->

::: math
```{=tex}
\begin{equation}
\boldsymbol{M}^{\star}=\big(p_{ij}^{\ast}\big)=
\left(\begin{array}{c|c}
\boldsymbol{N} & \boldsymbol{B}   \\
\hline
\boldsymbol{O} &  \boldsymbol{I}
\end{array}
\right).
\end{equation}
```
:::

Dado que, para cada $\small{n}$ <!--Ecuación/Prueba-teorema 2.5.2-->

::: math
```{=tex}
\begin{equation}
\mathbb{P}\big(Y_n =j,Y_{n-1} \notin B,\cdots, Y_1\notin B,Y_1\notin B \mid \boldsymbol{\xi_0}\big)=\mathbb{P}\big(Z_n =j,Z_{n-1} \notin B,\cdots, Y_1\notin B,Z_1\notin B \mid \boldsymbol{\xi_0}\big),
\end{equation}
```
:::

El resultado *(i)* se desprende del *teorema 2.4.* De manera similar, el
*resultado (ii)* se sigue inmediatamente a partir de *(i)* y el hecho de
que $\small{\boldsymbol{(I-N)1'}=\displaystyle\sum_{j\in B}{B'}_j}$.
$\hspace{1cm}\Box$

La prueba anterior está guiada por el hecho de que todos los estados en
$\small{B}$ son estados absorbentes con respecto a la nueva cadena de
Markov $\small{\{Z_t\}}$ y, por lo tanto, por ejemplo, para cada
$\small{i \in \Omega-B}$, la probabilidad
$\small{\mathbb{P}(Z_{n-1}=i)}$ se puede dividir en dos partes de la
siguiente manera:

<!--Ecuación/Prueba-teorema 2.5.3-->

::: math
```{=tex}
\begin{align*}
\mathbb{P}\big(Z_{n-1} = i \mid \boldsymbol{\xi_0}\big) & =
\mathbb{P}\big(Z_{n-1} =i, Z_{n-2} \notin B,\cdots, Z_1\notin B \mid \boldsymbol{\xi_0}\big)\\
& + \mathbb{P}\big(Z_{n-1} =i \text{ y por lo menos uno de } Z_{n-2},\cdots ,Z_1 \text{ esta dentro de } B \mid \boldsymbol{\xi_0}\big)
\end{align*}
```
:::

en donde la segunda parte es siempre cero (ya que
$\small{i \in \Omega-B}$ y $\small{p_{ij}^{\ast}\equiv 0}$ para todos
$\small{j \in B}$). Tenga en cuenta que, en el *teorema 2.5*, asumimos
la distribución inicial $\small{(\boldsymbol{\xi:0})}$), lo que equivale
a decir $\small{\mathbb{P}\big(Y_0\in B\big)\equiv 1}$. En consecuencia,
la probabilidad
$\small{\mathbb{P}\big(Y_n \in B,Y_{n-1}\notin B,\cdots,Y_1 \notin B \mid \boldsymbol{\xi_0}\big)}$
se conoce como probabilidad de primera entrada.

**Ejemplo 2.6** Sea $\small{\{Y_t\}}$ una cadena de Markov homogénea
definida en el espacio de estados $\small{\Omega=\{1,2,3,4,5\}}$ con
matriz de probabilidad de transición

<!--Ecuación/Ejemplo 2.6.1-->

::: math
```{=tex}
\begin{equation}
\boldsymbol{M}=
\begin{array}{ccccc}&
\begin{array}{ccccc}
\end{array}
\\
\begin{array}{ccccc}
1 \\
2 \\
3\\
4\\
5
\end{array}
&
\left(
\begin{array}{ccccc}
1/2 & 1/4 & 1/4  & 0 &  0 \\
1/4 & 1/2  & 0  &  1/4 & 0 \\
1/4 & 1/4  &  0 & 0 & 1/2 \\
0&  0 & 0 &  1 &0 \\
0&  0 & 0 &  0 & 1 \\
\end{array}
\right)
\end{array}
\end{equation}
```
:::

Supongamos que $\small{B = \{3, 4\}}$, entonces la matriz de
probabilidad de transición de $\small{B = \{Y_t\}}$ se puede reorganizar
como:

<!--Ecuación/Ejemplo 2.6.2-->

::: math
```{=tex}
\begin{equation}
\boldsymbol{M}=
\begin{array}{ccccc}&
\begin{array}{ccccc}
\end{array}
\\
\begin{array}{ccccc}
1 \\
2 \\
3\\
4\\
5
\end{array}
&
\left(
\begin{array}{ccc|cc}
1/2 & 1/4 & 0  & 1/4 &  0 \\
1/4 & 1/2  & 0  &  0 & 1/4 \\
0 & 0 &  1 & 0 & 0 \\
\hline
1/4 &  1/4 & 1/2 &  0 & 0 \\
0&  0 & 0 &  0 & 1 \\
\end{array}
\right)
\end{array}
\end{equation}
```
:::

Dada una distribución inicial de $\small{Y_0}$, digamos
$\small{\mathbb{P}(Y_0=1)=1}$, la probabilidad de primera entrada para
$\small{Y_n=3}$, es

<!--Ecuación/Ejemplo 2.6.3-->

::: math
```{=tex}
\begin{align*}
& \quad \,\mathbb{P}\big(Y_n =3,Y_{n-1} \notin B,\cdots,Y_1\notin B \mid Y_0 = 1\big)
\\
& =(0,0,1)
\left(\begin{array}{ccc}
1/2 & 1/4 & 0\\
1/4 & 1/2 & 0\\
0 & 0 & 1
\end{array} \right)^{n-1}
\left(\begin{array}{c}
1/4\\
0\\
0
\end{array} \right)\\
\end{align*}
```
:::

Para $\small{n = 3}$, obtenemos que
$\small{\mathbb{P}\big(Y_n =3,Y_{3} \notin B,Y_1\notin B \mid Y_0 = 1\big)=5/64}$.
Tenga en cuenta que dado que el estado "$\small{5}$" es un estado
absorbente, los cálculos se pueden reducir aún más a:

<!--Ecuación/Ejemplo 2.6.4-->

::: math
```{=tex}
\begin{equation}
 \mathbb{P}\big(Y_n =3,Y_{n-1} \notin B,\cdots,Y_1\notin B \mid Y_0 = 1\big)=(1,0)
\left(\begin{array}{ccc}
1/2 & 1/4 \\
1/4 & 1/2 
\end{array} \right)^{n-1}
\left(\begin{array}{c}
1/4\\
0
\end{array} \right) \hspace{5cm}\Diamond
  \end{equation}
```
:::

Sea $\small{A}$ el conjunto que contenga todos los estados absorbentes
de $\small{\{Y_t\}}$ y sea $\small{B^{\ast}= A \cup B}$. La matriz de
probabilidad de transición $\small{\boldsymbol{M^{*}}}$ ,
correspondiente a la cadena de Markov asociada $\small{\{Z_t\}}$ en la
que todos los estados en $\small{B^{\ast}}$ se toman como estados
absorbentes, puede entonces reordenarse como:

<!--Ecuación/Ejemplo 2.6.5-->

::: math
```{=tex}
\begin{equation} 
\boldsymbol{M^{\ast}}=
\begin{array}{cc}
{\Omega-B^{\ast}} \\B^{\ast} \end{array}
\left(\begin{array}{c|c}
\boldsymbol{N^{\ast}} & \boldsymbol{B^{\ast}}\\
\hline
\boldsymbol{J} &  \boldsymbol{Q}
\end{array}
\right)
\end{equation}
```
:::

en donde $\small{\boldsymbol{N^{*}}}$ es la submatriz esencial de
$\small{\boldsymbol{M^{*}}}$, y $\small{\boldsymbol{B^{*}}}$ es la
matriz formada a partir de $\small{\boldsymbol{M^{*}}}$ mediante la
eliminación de todas las columnas asociadas con los estados en
$\small{\Omega-B^{*}}$ y de todas las filas asociadas con los estados en
$\small{B^{*}}$. Entonces se cumple el siguiente corolario.

**Colorario:** Para todo $\small{j\in B}$

<!--Ecuación 2.28--->

::: math
```{=tex}
\begin{equation}
\mathbb{P}\big(Y_n =j,Y_{n-1} \notin B,\cdots,Y_1\notin B \mid (\boldsymbol{\xi}:\boldsymbol{0}) \big)= \boldsymbol{\xi^{\ast}}(\boldsymbol{N^{\ast}})^{n-1}B_{j}^{*'},
\end{equation}
```
:::

siendo $\small{B_{j}^{*'}}$ la $j-$ésima columna de la matriz
$\small{\boldsymbol{B^{\ast}}}$

La prueba del corolario anterior es sencilla y se deja en manos del
lector. Tenga en cuenta que el tamaño de la matriz
$\small{\boldsymbol{N^{\ast}}}$ es menor o igual que el tamaño de
$\small{\boldsymbol{N}}$.

### Capitulo 3: Rachas y Patrones en una sucesión de ensayos de dos estados

#### 3.1 Introducción:

Aunque las rachas y patrones en una sucesión de ensayos de Bernoulli son
casos especiales de los ensayos multiestados, merecen un capítulo aparte
debido a su larga historia, la gran cantidad de resultados asociados y
su amplia aplicación a numerosos campos. El enfoque de este capítulo
será derivar las distribuciones para las estadísticas de rachas más
comunes y útiles en ensayos de Bernoulli mediante la técnica de
*incrustación de cadenas finitas de Markov*, y también en extender estos
resultados a secuencias de ensayos de dos estados dependientes de
Markov. También se presentan técnicas para obtener ecuaciones recursivas
y funciones generadoras de probabilidad de estadísticas de rachas a
través del enfoque de incrustación de cadenas finitas de Markov. Estas
herramientas pueden ser muy útiles para estudiar ciertas características
de las distribuciones de rachas, como la media, la varianza y los
momentos superiores.

En este capítulo se tratan las siguientes estadísticas de rachas,
definidas tradicionalmente en una secuencia de $\small{n}$ ensayos de
Bernoulli:

*(i)* $\small{N_{n,k}}$ el número de $\small{k}$ éxitos consecutivos no
superpuestos;

*(ii)* $\small{G_{n,k}}$ el número de rachas exitosas de tamaño mayor o
igual a $\small{k}$.

*(iii)* $\small{M_{n,k}}$ el número de $\small{k}$ éxitos consecutivos
solapados.

*(iv)* $\small{E_{n,k}}$ el número de rachas de exctamente $\small{k}$
éxitos.

*(v)* $\small{L_{n,k}}$ el tamaño de la racha de exitos más larga;

*(vi)* $\small{S_{n,k}}$ el número total de éxitos en rachas exitosas de
longitud mayor o igual a $\small{k}$ .

También se trata la distribución del tiempo de espera de una racha de
éxitos y se incluyen algunos resultados numéricos para las
distribuciones de las estadísticas de las rachas anteriores.

#### 3.2 Número de $\small{k}$ éxitos consecutivos no superpuestos

El número de rachas de $\small{k}$ éxitos consecutivos no superpuestos,
$\small{N_{n,k}}$, en una secuencia de $\small{n}$ ensayos de Bernoulli
es probablemente la estadística de ejecuciones más importante, no sólo
por su amplia aplicación a diversas áreas sino también por su conexión
con otras estadísticas de rachas; En teoría de la distribución, la
distribución de $\small{N_{n,k}}$ se conoce como distribución binomial
de orden $\small{k}$. *Philippou* y *Makri (1986)* e *Hirano (1986)*
dieron de forma independiente una fórmula para la distribución exacta de
$\small{N_{n,k}}$ en una secuencia de $\small{n}$ ensayos de Bernoulli
como:

<!--Ecuación 3.1--->

::: math
```{=tex}
\begin{equation}
\mathbb{P}(N_{n,k}=x)=\sum_{m=0}^{k-1}\sum_{x_1+x_2+\cdots+\\
kx_k=n-m-km}\binom{x_1+x_2+\cdots+x_k+x}{x_1,x_2,\cdots,x_k,x}p^n\Big(\frac{q}{p}\Big)^{x_1+x_2+\cdots+x_k},
\end{equation}
```
:::

en donde, $\small{x=0,1,\ldots,[n/k]}\,$ ($\small{[n/k]}$ la parte
entera de $\small{n/k}$) y con probabilidades de éxito $\small{p}$ y
fracaso $\small{p=1-p}$. *Godbole (1990)* dio una fórmula alternativa
para la función de probabilidad de $\small{N_{n,k}}$ con $\small{k>1}$:

<!--Ecuación 3.2--->

::: math
```{=tex}
\begin{align*}
\mathbb{P}(N_{n,k}=x) &=\sum_{[(n-kx)/k]\leq y \leq n-kx} \binom{y+x}{x}q^yp^{n-y}\\
& \times \sum_{0 \leq j \leq  [(n-kx-y)/k]}(-1)^j \binom{y+1}{j} \binom{n-kx-jk}{y},
\end{align*}
```
:::

para $\small{x=0,1,\ldots,[n/k]}\,$. La fórmula (3.2) tiene la ventaja
sobre la (3.1) de que es más fácil de evaluar por computadora para
$\small{n}\,$ grande. *Hirano* y *Aki (1987, 1993)* estudiaron algunas
propiedades de esta distribución y ampliaron los resultados al caso de
ensayos de Markov dependientes de dos estados.

Para comenzar nuestro estudio de $\small{N_{n,k}}$ utilizando el método
de incrustación de cadenas finitas de Markov, consideremos el espacio de
estados

<!--Partición de espacios de estados --->

::: math
```{=tex}
\begin{equation}
\Omega =\{(x,i):x=0,1,\cdots,l_n\, \text{y}\, 0,1,\cdots,k-1\},
\end{equation}
```
:::

en donde, $\small{l_n=[n/k]}\,$ es el número máximo de rachas exitosas
no superpuestas de longitud $\small{k}$ que pueden ocurrir en
$\small{n}$ ensayos. Ahora definamos la Cadena de Markov finita
homogenea $\small{\{Y_t:t=0,1,\ldots,n\}}\,$ sobre $\small{\Omega}\,$
como sigue:

<!--Equacion 3.3--->

::: math
```{=tex}
\begin{equation}
Y_t=(N_{t,k},E_{t}),\quad \text{para }1\leq t \leq n,
\end{equation}
```
:::

donde $\small{N_{n,k}}$ es el número de $\small{k}$ éxitos consecutivos
no superpuestos que ocurrieron durante los primeros $\small{t}$ ensayos
$\small{X_1,X_2,\ldots,X_n}$. El "bloque final" $\small{E_t}$ es igual a
$\small{m}$ módulo $\small{k}$, donde $\small{m}$ representa el número
de éxitos finales (posiblemente cero) que existen en la sucesión después
de las primeros $\small{t}$ ensayos:

<!--Equacion 3.3.1-->

::: math
```{=tex}
\begin{equation}
FFSSF\underbrace{SS\cdots S}_{m}.
\end{equation}
```
:::

Observemos que $\small{E_t=0}$ si $\small{m}$ es un múltiplo positivo de
$\small{k}$ o si el $\small{t-}$ésimo resultado es $\small{F}$. Esta
variable de bloque final realiza un seguimiento del número de éxitos en
una posible racha parcial asociada con en el $\small{t-}$ésimo ensayo.
Por ejemplo, dados $\small{n=10}$ ensayos de Bernoulli con resultados
$\small{\{FSFFSSSFSS\}}$ y una duración de ejecución exitosa elegida de
$\small{k=2}$, la realización de la cadena de Markov incorporada
$\small{\{Y_t: t = 1,2,\ldots, 10\}}$ con respecto a estos diez
resultados es:
$\small{\{Y_1=(0,0), Y_2 = (0, 1), Y_3=(0,0), Y_4=(0,0),Y_5= (0,1),Y_6 = (1,0), Y_7=(1, 1), Y_8=(1,0),Y_9=(1,1), Y_{10}=(2,0)\}}$.
Tenga en cuenta que para una secuencia dada de resultados
$\small{\{FS\cdots SF\}}$, la realización de $\small{\{Y_t\}}$ es
siempre única.

Definir los subconjuntos

<!--Equación 3.4--->

::: math
```{=tex}
\begin{equation}
C_x =\{(x,i): i=0,1,\cdots,k-1\},\quad 0\leq x \leq l_n
\end{equation}
```
:::

La colección de subconjuntos $\small{\{C_x:x = 0,1,\ldots,l_n\}}$ forma
una partición del espacio de estados $\small{\Omega}$. Dado que
$\small{\{X_t\}}$ es, por el momento, una sucesión de ensayos Bernoulli,
de las definiciones anteriores se deduce que $\small{Y_t}$ tiene una
matriz de probabilidad de transición
$\small{\boldsymbol{M_t} = (p_{(x,i)(y,j)})}$ para todo
$\small{t=1,2,\ldots,n}$, con las probabilidades de transición
$\small{(p_{(x,i)(y,j)})}$ dadas por la siguiente ecuación: para
$\small{1 \leq t \leq n}$ y $\small{0 \leq x \leq l_n}$
<!--Ecuacion  3.5-->

::: math
```{=tex}
\begin{align*}
p_{(x,i)(y,j)} & = \mathbb{P}\big(Y_t=(y,j)\mid Y_{t-1}=(x,i)\big)\\
& =\begin{cases}
q \quad \text{si }y=x\,\text{y }j=0,\,\text{para }i=0,1,\ldots, k-1
\\
p \quad \text{si }y=x\,\text{y }j=i+1,\,\text{para }i=0,1,\ldots, k-2
\\
p \quad \text{si }y=x+1\,\text{y }j=0,\,\text{para }i=k-1\,\text{y },x=0,1,\ldots, l_{n}-1
\\
1 \quad \text{si }y=x=l_{n}\,\text{y }j=i=k-1
\\
0 \quad \text{en otro caso}
\end{cases}
\end{align*}
```
:::

A modo de ilustración, la matriz de probabilidad de transición
$\small{\boldsymbol{M_t}}$ de la cadena de Markov incrustada
$\small{{Y_t}}$ asociada con la variable aleatoria $\small{N_{5,2}}$
viene dada por

<!----Ecuación 3.6--->

::: math
```{=tex}
\begin{equation}
\boldsymbol{M}=
\begin{array}{cccccc}&
\begin{array}{cccccc}
\end{array}
\\
\begin{array}{cccccc}
(0,0)\\
(0,1)\\
(1,0)\\
(1,1)\\
(2,0)\\
(2,1)
\end{array}
&
\left(
\begin{array}{cc|cc|cc}
q&p&0&0&0&0\\
q&0&p&0&0&0\\
\hline
0&0&q&p&0&0\\
0&0&q&0&p&0\\
\hline
0&0&0&0&q&p\\
0&0&0&0&0&1\\
\end{array}
\right)
\end{array}_{6\times6}
\end{equation}
```
:::

para $\small{1\leq t \leq 5.}$

Para el caso donde $\small{\{X_t\}}$ es una sucesión de ensayos de dos
estados independientes pero no idénticamente distribuidos con
probabilidades $\small{\mathbb{P}(X_t=S)=p_t}$ y
$\small{\mathbb{P}(X_t=F)=q_t}$ , para $\small{t=1,2,\ldots,n}$, las
matrices de transición $\small{\boldsymbol{M_t}}$ para la cadena de
Markov incrustada $\small{\{Y_t\}}$ permanece sin cambios excepto que la
probabilidad $\small{p}$ se reemplaza por $\small{p_t}$ y $\small{q}$ se
reemplaza por $\small{q_t}$. En general, para ensayos de dos estados
independientes pero no idénticamente distribuidos, las matrices de
probabilidad de transición se pueden escribir como

<!----Ecuación 3.7--->

::: math
```{=tex}
\begin{equation}
\boldsymbol{M_t}(N_{n,k})=
\left(\begin{array}{cccc}
\boldsymbol{A_t}&\boldsymbol{B_t}&&&\boldsymbol{0}\\
&&\ddots&\ddots&\\
\boldsymbol{0}&&&\boldsymbol{A_t}&\boldsymbol{B_t}\\
&&&&\boldsymbol{A_{t}^{\ast}}\\
\end{array}\right)_{d\times d},
\end{equation}
```
:::

para $\small{t=1,2,\dots,n}$, en donde:

<!----Ecuación 3.7.1--->

::: math
```{=tex}
\begin{equation}
\boldsymbol{A_t}=
\left(\begin{array}{ccccc}
q_t&p_t&0&\cdots&0\\
q_t&0&p_t&\cdots&0\\
\vdots& &\ddots&\ddots&\\
\vdots& & &\ddots&p_t\\
q_t&0&0&\cdots&0\\
\end{array}\right)_{k\times k},
\end{equation}
```
:::

$\small{\boldsymbol{B_t}}$ es una matriz $\small{k\times k}$ que tiene
$\small{p_t}$ en la entrada $\small{(k,1)}$ y cero en el resto,
$\small{\boldsymbol{A_t}^{\ast}}$ es igual que
$\small{\boldsymbol{A_t}}$ excepto que su última fila se reemplaza con
$\small{(0,0,...,0,1)}$, y la dimensión de
$\small{\boldsymbol{M_t}(N_{n,k})}$ viene dado por
$\small{d = k(l_n+1)}$. Por tanto, en virtud del *teorema 2.1*, podemos
afirmar que

<!----Ecuación 3.8--->

::: math
```{=tex}
\begin{equation}
\small{\mathbb{P}\big( N_{n,k}=x\big)=\boldsymbol{\mathbf{\xi}}_0 \Big(\prod_{t=1}^{n}\boldsymbol{M}_t(N_{n,k})\Big)\boldsymbol{\mathbf{U}'}(\mathbf{C_x})},\,\,  x=1,2,\ldots,l_n,
\end{equation}
```
:::

en donde,
$\small{\boldsymbol{\mathbf{\xi}}_0=(1,0,\ldots,0)_{1\times d}}$ y
$\small{\boldsymbol{\mathbf{U}'}({C_x})}$ es la transpuesta del vector
$\small{\boldsymbol{\mathbf{U}'}({C_x})=(0,\ldots,0, 1,\ldots, 1, 0,\ldots,0)}$
con unos en las ubicaciones asociadas con los estados en $\small{C_x}$.
La *ecuación (3.8)* representa la distribución exacta de
$\small{N_{n,k}}$ para ensayos independientes de dos estados
distribuidos tanto de forma idéntica como no idéntica. En vista de la
matriz de probabilidad de transición en la *ecuación (3.7)*,
$\small{N_{n,k}}$ es una cadena finita de Markov incrustable de tipo
binomial en el sentido de la Definición 2.7 *(Koutras y Alexandrou
1995)*.

Si $\small{\{X_t\}}$ es una Cadena de Markov no homogenea com matriz de
probabilidades de transición:

<!----Ecuación 3.8.1--->

::: math
```{=tex}
\begin{equation}
\left(\begin{array}{cc}
p_{FF}(t)&p_{SS}(t)\\
p_{FF}(t)&p_{SS}(t)
\end{array}\right),
\end{equation}
```
:::

entonces, es necesaria una modificación menor en el procedimiento de
incrustación para obtener la distribución de $\small{N_{n,k}}$. Dado que
el resultado de $\small{X_{t+1}}$, y por tanto también de
$\small{Y_{t+1}}$, ahora depende de $\small{X_t}$, cada estado de la
cadena de Markov $\small{Y_t}$ debe implicar un cierto resultado de
$\small{X_t}$. Este ya es el caso en nuestra definición anterior de
$\small{Y_t}$, salvo para los estados con un bloque final de
$\small{E_t=0}$, que puede surgir para cualquier resultado de
$\small{X_t}$. Para resolver esta ambigüedad, definimos un estado de
bloque final adicional, $\small{E_t=\gamma}$, para corresponder al caso
donde la serie de éxitos finales es un múltiplo distinto de cero de
$\small{k}$ éxitos, y reservamos el estado $\small{E_t=0}$ para el caso
donde el resultado $\small{t-}$ésimo es un fracaso. La cadena de Markov
incrustada se define entonces de la siguiente manera:

<!----Ecuación 3.8.2--->

::: math
```{=tex}
\begin{equation}
Y_t =
\begin{cases}
(x,\gamma) & \begin{array}{l} \text{Si existen } x \text{ rachas de } k \text{ aciertos} \\
\text{consecutivos en los primeros } t \\
\text{ensayos con } m > 0 \text{ aciertos finales}\\
\text{tales que } m \equiv k \pmod{k} \end{array} \\
\\
(x,0) & \begin{array}{l}\text{Si existen } x \text{ rachas de } k \text{ aciertos}\\
\text{consecutivos en los primeros } t\text{ ensayos} \\ \text{con } m = 0 \text{ aciertos finales} \text{ (}X_t=F\text{)} \end{array}
\end{cases}
\end{equation}
```
:::

y $\small{Y_t=(x,i)}$, para $\small{i=1,2,\ldots,k-1}$ se define como se
indica en la *ecuación (3.3)*. La diferencia entre los estados
$\small{(x,\gamma)}$ y $\small{ (x,0)}$ se puede ver en el siguiente
ejemplo: para una racha exitosa de longitud $\small{k=2}$,
$\small{Y_8=(SFFFSSSS) = (2,\gamma)}$ y $\small{Y_8=(SFSSFSSF)= (2,0)}$.
Tenga en cuenta que el bloque final $\small{E_t}$ ahora contiene no solo
la información requerida sobre los subpatrones sino que también implica
el resultado de $\small{X_t}$, lo que permite la asignación de
probabilidades de transición para la Cadena de Markov incustada.

Las matrices de probabilidad de transición correspondientes a estas
definiciones pueden deducirse fácilmente. La cadena de Markov incrustada
asociada con la variable aleatoria $\small{N_{5,2}}$ como se considera
en la *Ecuación (3.6)* para ensayos de Bernoulli, tiene las siguientes
matrices de transición $\small{\boldsymbol{M_t^{\ast}}}$ bajo ensayos
dependientes de Markov no homogéneos: para $\small{t=1,2,\ldots,n}$

<!----Equación 3.8.3----->

::: math
```{=tex}
\begin{equation}
\boldsymbol{M_t^*}(N_{5,2})=
\begin{array}{cc}
\begin{array}{c} 
(0,0)\\
(0,1)\\
(1,c)\\
(1,0)\\
(1,1)\\
(2,c)\\
(2,1)\\
(2,1)
\end{array}& 
\left(
\begin{array}{cc|ccc|ccc}
p_{FF}(t)&p_{FS}(t)&0&0&0&0&0&0\\
p_{FS}(t)&0&p_{SS}(t)&0&0&0&0&0\\
\hline
0&0&0&p_{SF}(t)&p_{SS}(t)&0&0&0\\
0&0&0&p_{FF}(t)&p_{FS}(t)&0&0&0\\
0&0&0&p_{SF}(t)&0&p_{SS}(t)&0&0\\
\hline
0&0&0&0&0&&p_{SF}(t)&p_{SS}(t)\\
0&0&0&0&0&0&p_{FF}(t)&p_{FS}(t)\\
0&0&0&0&0&0&0&1\\
\end{array}
\right)
\end{array}
\end{equation}
```
:::

Note que la estructura de "franja/banda" de
$\small{\boldsymbol{M_t^{\ast}}(N_{5,2})}$ es similar con
$\small{\boldsymbol{M_t}(N_{5,2})}$ de la *ecuación (3.6)* para ensayos
de Bernoulli. Como es sencillo derivar la forma general de
$\small{\boldsymbol{M_t^{\ast}}(N_{n,k})}$ análoga a la ecuación (3.7),
esto lo dejamos al lector interesado.

Cuando la secuencia $\small{\{X_t\}}$ es i.i.d., la distribución inicial
$\small{\boldsymbol{\xi}_0}$ puede definirse como
$\small{\mathbb{P}\big(Y_0=(0,0)\big)=1}$, y luego para $\small{k>1}$,
las probabilidades de transición
$\small{\mathbb{P}\big(Y_1=(0,1)\mid Y_0=(0,0)\big)=p}$ y
$\small{\mathbb{P}\big(Y_1=(0,0)\mid Y_0=(0,0)\big)=q=(1-p)}$. Sin
embargo, cuando $\small{\{X_t\}}$ es una sucesión de variables
aleatorias Markov-Dependientes , se debe tener cuidado al asumir
$\small{\mathbb{P}\big(Y_0=(0,0)\big)=1}$, lo que implicaría que las
probabilidades de transición entre $\small{Y_0}$ e $\small{Y_1}$ están
dadas por
$\small{\mathbb{P}\big(Y_1=(0,1)\mid Y_0=(0,0)\big)=p_{FS}(1)}$ y
$\small{\mathbb{P}\big(Y_1=(0,0)\mid Y_0=(0,0)\big)=p_{FF}=1}$,
independiente de $\small{p_{SF}}$ y $\small{p_{FF}}$. Para evitar este
tipo de sesgo, es útil crear un estado ficticio $\small{\emptyset}$ como
estado inicial para $\small{Y_0}$. Luego definimos
$\small{\mathbb{P}\big(Y_0=\emptyset\big)=1}$, y las probabilidades de
transición
$\small{\mathbb{P}\big(Y_1=(0,1)\mid Y_0=\emptyset\big)=p_{s}}$, y
$\small{\mathbb{P}\big(Y_1=(0,0)\mid Y_0=\emptyset\big)=p_{f}}$. Por
tanto, para $\small{N_{5,2}}$ la correspondiente cadena de Markov
incrustada $\small{\{Y_t\}}$ se define en el espacio de estados
expandido $\small{\Omega=\{\emptyset,(0,0),(0,1),(1,0),\ldots\}}$ con
matrices de probabilidad de transición:

<!--Ecuación 3.8.4-->

::: math
```{=tex}
\begin{equation}
\begin{array}{cc} &
\begin{array}{cccccc}(0,0)&(0,1)&(1,c)&(1,0)&(1,1)&\cdots
\end{array}\\
\begin{array}{cccccccc}
\end{array}
&
\left(
\begin{array}{c|ccccc}
0 &  p_{f}  & p_{s} &  0  &   0 & \cdots \\
\hline
\, 0&&&&&\\
0&&&\boldsymbol{M_t}^{\ast}(N_{5,2})&&\\
0&&&&&\\
\end{array}
\right)\end{array}
\end{equation}
```
:::

Tenga en cuenta que el procedimiento de incrustación de cadenas finitas
de Markov utilizado para obtener la distribución exacta de
$\small{N_{n,k}}$ sigue siendo el mismo, excepto por diferencias menores
en las matrices de probabilidad de transición, independientemente de si
la secuencia de ensayos $\small{\{X_t\}}$ es *i.i.d.*, independiente
pero no idéntica distribuida o si es Markov-Dependiente.

#### 3.3 Número de rachas exitosas de longitud mayor o igual a $\small{k}$

Para una sucesión de ensayos de dos estados, la variable aleatoria
$\small{G_{n,k}}$ se define como el número de rachas exitosas de
longitud mayor o igual a $\small{G_{n,k}}$. Consideremos una cadena de
Markov finita $\small{\{Y_t:t=0,1,2,\ldots,n\}}$ definida en el espacio
de estados:

<!--Partición de espacios de estados 3.3.1--->

::: math
```{=tex}
\begin{equation}
\Omega =\{(x,i):x=0,1,\cdots,l_n\,\, \text{y}\,\, i= \gamma,0,1,\cdots,k-1\}-{\{(0,\gamma)\}},
\end{equation}
```
:::

en donde, $\small{l_n=[(n+1)/(k+1)]}$. Para una sucesión de resultados
de los primeros $\small{t}$ ensayos con $\small{m}$ éxitos finales,
digamos $\small{FS \cdots F \underbrace{SS \cdots}_{m}S}$, definimos la
cadena de Markov:

<!-- Ecuación 3.9--->

::: math
```{=tex}
\begin{equation}
Y_t=(G_{n,k},E_t) \quad 1\leq t\leq n,
\end{equation}
```
:::

donde $\small{G_{n,k}}$, es el número de rachas exitosas de longitud
mayor o igual a $\small{k}$ en la sucesión $\small{\{X_t\}}$, y
$\small{E_t}$ es la variable del bloque final con $\small{E_t=m}$ si
$\small{m=0,1,2,\ldots,k-1}$, y $\small{E_t=\gamma}$ si
$\small{m\geq k}$. Para ilustrar esta definición, considere una longitud
de racha mínima de $\small{k=2}$ y los siguientes doce resultados, de un
ensayo de dos estados: $\small{FSFFSSFSSSFS}$, para los cuales
$\small{G_{12,2}=2}$. Se deduce de la *Ec.(3.9)* que la realización de
la Cadena de Markov $\small{\{Y_t:t=0,1,2,\ldots,14\}}$ es :
$\small{\{Y_1=(0,0),Y_2=(0,1),Y_3=(0,0),Y_4=(0,0),Y_5=(0,1),Y_6=(1,\gamma),Y_7=(1,0),Y_8=(1,1),Y_9=(2,\gamma),Y_{10}=(2,\gamma),Y_{11}=(2,0),Y_{12}=(2,0)\}}$.
Note que el bloque final $\small{E_t=\gamma}$ puede ocurrir sólo cuando
hay al menos $\small{k}$ éxitos finales, en cuyo caso
$\small{G_{n,k}\geq k}$ por esta razón, el estado $\small{(0,\gamma)}$
fue excluido en la definición anterior del espacio de estados
$\small{\Omega}$.

De la definición de la cadena de Markov incrustada dada por la *Ecu.
(3.9)*, las probabilidades de transición de un paso en
$\small{\boldsymbol{M_t}(G_{n,k})}$ para ensayos independientes pero no
identicamente distribuidos se especifican mediante la siguiente
ecuación: para $\small{t=1,2,\ldots,n}$

<!----Ecuación 3.10--->

::: math
```{=tex}
\begin{equation}
p_{(x,i)(y,i)}(t) =
\begin{cases}
q_t & \begin{array}{l} \text{Si}\,\, y=x \,\, \text{y}\,\, j=0 \,\,\text{para}\,\, x=0,1,\ldots,l_n \,\text{y}\, i=\gamma,0,1,\ldots,k-1  \end{array} \\
p_t & \begin{array}{l} \text{Si}\,\, y=x \,\, \text{y}\,\, j=i=\gamma\,\,\text{para}\,\, x=0,1,\ldots,l_n  \end{array}
\\ 
p_t & \begin{array}{l} \text{Si}\,\, y=x \,\, \text{y}\,\, j=i+1\,\,\text{para}\,\, x=0,1,\ldots,l_n \,\text{y}\, i=\gamma,0,1,\ldots,k-2  \end{array} 
\\
p_t & \begin{array}{l} \text{Si}\,\, y=x+1,\,i=k-1 \,\, \text{y}\, j=\gamma \,\,\text{para}\,\, x=0,1,\ldots,l_n-1  \end{array}
\\
1 & \begin{array}{l} \text{Si}\,\, y=x=l_n,\,j=x=k-1\end{array} \\
0 & \begin{array}{l} \text{Otro caso} \end{array}
\end{cases}\\
\end{equation}
```
:::

En el caso especial de $\small{n=5}$ y $\small{k=2}$ la matriz de
probabilidades de transición $\small{\boldsymbol{M_t}(G_{n,k})}$ esta
dada por:

<!----Ecuación 3.10.1--->

::: math
```{=tex}
\begin{equation}
\boldsymbol{M_t}(G_{5,2})=
\begin{array}{cc}&
\begin{array}{cccccc}
\end{array}
\\
\begin{array}{cccccc}
(0,0)\\
(0,1)\\
(1,\gamma)\\
(1,0)\\
(1,1)\\
(2,\gamma)\\
(2,0)\\
(2,1)
\end{array}
&
\left(
\begin{array}{cc|c|cc|c|cc}
q_t&p_t&0&0&0&0&0&0\\
q_t&0&p_t&0&0&0&0&0\\
\hline
0&0&p_t&q_t&0&0&0\\
\hline
0&0&0&q_t&p_t&0&0&0\\
0&0&0&q_t&0&p_t&0&0\\
\hline
0&0&0&0&0&p_t&q_t&0\\
\hline
0&0&0&0&0&0&q_t&p_t\\
0&0&0&0&0&0&0&1\\
\end{array}
\right)
\end{array}
\end{equation}
```
:::

para $\small{t=1,2,\ldots,5}$. En general
$\small{\boldsymbol{M_t}(G_{n,k})}$ es una matriz bidiagonal de bloques
de la forma: <!----Ecuación 3.11--->

::: math
```{=tex}
\begin{equation}
\left( 
\begin{array}{ccccccc}
\boldsymbol{A_t}&p_t\boldsymbol{e_k'}&&&&&\boldsymbol{O}\\
&p_t&q_t\boldsymbol{e_1}&&\boldsymbol{O}&&\\
&&\boldsymbol{A_t}&p_t\boldsymbol{e_k'}&&&\\
&&&\ddots&\ddots&&\\
&&&&\ddots&\ddots&\\
&&\boldsymbol{O}&&&p_t&q_t\boldsymbol{e_1}\\
\boldsymbol{O}&&&&&&\boldsymbol{A_t^{\ast}}\\
\end{array}
\right)
\end{equation}
```
:::

en donde $\small{\boldsymbol{e_1}=(1,0,\ldots,0)}$ y
$\small{\boldsymbol{e_1}=(0,\ldots,0,1)}$ son vectores fila unitarios
$\small{1\times k}$, y $\small{\boldsymbol{A_t}}$ es dada por:

<!----Ecuación 3.11.1--->

::: math
```{=tex}
\begin{equation}
\boldsymbol{A_t} =\left(
\begin{array}{ccccc}
q_t & p_t & 0  & \ldots &  0 \\
\vdots & \ddots & \ddots  &    &   \\
\vdots &  &  \ddots& \ddots &   \\
\vdots&  &   &  \ddots &p_t \\
q_t&  0 & 0 &  \cdots & 1 \\
\end{array}
\right)
\end{equation}
```
:::

La matriz de probabilidad de transición $\small{\boldsymbol{A_t}}$, en
el contexto de la demografía, a menudo se denomina matriz de Leslie o,
más generalmente, matriz de tipo renovación (véase *Seneta, 1981*). La
dimensión de $\small{\boldsymbol{A_t}(G_{n,k})}$ es igual a
$\small{(l_n+1)(k+1)-1}$. La matriz $\small{\boldsymbol{A_t^{\ast}}}$ en
la *Ec. (3.11)* es igual que $\small{\boldsymbol{A_t}}$ excepto por la
última fila, que se reemplaza por $\small{(0,\ldots,0,1)}$

Si definimos la partición $\small{\{C_x:i=0,1,2,\ldots,l_n\}}$ sobre
$\small{\Omega}$

<!----Ecuación 3.11.2--->

::: math
```{=tex}
\begin{align*} 
C_0&=\{(0,i):i=0,1,\ldots,k-1\} \\ 
C_x&=\{(0,i):i=\gamma,0,1,\ldots,k-1\},\,\text{para}\, x=1,2,\ldots,l_n
\end{align*}
```
:::

y en consecuencia
$\small{\mathbb{P}\big(G_{n,k}=x\big)=\mathbb{P}\big(Y_n \in C_x \big)}$
para todo $\small{x=0,1,2,\ldots,l_n}$. La función de distribución, los
momentos y la función generadora de probabilidad ahora se pueden
calcular fácilmente mediante las ecuaciones (2.11), (2.12) y (2.13),
respectivamente.

Para el caso de ensayos *i.i.d.*, todas las probabilidades de transición
serían constantes y se podría llevar a cabo una extensión a los ensayos
de Markov-Dependientes como se describe para el estadístico
$\small{N_{n,k}}$ en la sección anterior; En el resto de este capítulo
sobre ensayos en dos Estados, nos centraremos principalmente en el caso
de ensayos independientes pero no idénticamente distribuidos.

#### 3.4 Número de $\small{k}$ éxitos consecutivos solapados

La variable aleatoria $\small{M_{n,k}}$ se define como el número
$\small{k}$ de éxitos consecutivos superpuestos en una sucesión de
$\small{n}$ ensayos independientes de dos estados. La cadena de Markov
incrustada $\small{\{Y_t:t=0,1,2,\ldots,n\}}$ asociada a
$\small{M_{n,k}}$ puede definirse como

<!----Ecuación 3.12--->

::: math
```{=tex}
\begin{align*} 
Y_t=(M_{t,k},E_t),\quad t=1,2,\ldots,n
\end{align*}
```
:::

sobre el espacio de estados

<!----Ecuación 3.12.1--->

::: math
```{=tex}
\begin{align*} 
\Omega &=\{(x,i):x=0,1,\cdots,l_n-1\,\, \text{e}\,\, i=\gamma, 0,1,\cdots,k-1\} \\
& \cup \{(l_n,\gamma)\}-\{(0,\gamma)\},
\end{align*}
```
:::

donde $\small{l_n=n-k+1,\, M_{n,k}}$ es el número de $\small{k}$ éxitos
consecutivos superpuestos en las primeros $\small{t}$ ensayos, y
$\small{E_t}$ es la *variable del bloque final* que lleva la cuenta del
número $\small{m}$ de éxitos finales:

<!--Eciación 3.13--->

::: math
```{=tex}
\begin{equation}
E_t=\begin{cases}
\gamma & \text{si}\, m\geq k\\
m & \text{si}\, m=0,1,\ldots,k-1.
\end{cases}
\end{equation}
```
:::

Con conteo superpuesto, es fácil verificar que las probabilidades para
las matrices de probabilidad de transición
$\small{\boldsymbol{M_t}=p_{(x,i)(y,j)}(t)}$ se pueden obtener a partir
de la siguiente ecuación:

<!----Ecuación 3.14--->

::: math
```{=tex}
\begin{equation}
p_{(x,i)(y,j)}(t) =
\begin{cases}
q_t & \begin{array}{l} \text{Si}\,\, y=x \,\, \text{y}\,\, j=0 \,\,\text{para}\,\, x=0,1,\ldots,l_n \,\,\text{e}\, i=\gamma,0,1,\ldots,k-1 \end{array} \\
p_t & \begin{array}{l} \text{Si}\,\, y=x \,\, \text{y}\,\, j=i+1\,\,\text{para}\,\, x=0,1,\ldots,l_n \,\, \text{e}\,\,i=0,1,\ldots,k-2 \end{array}
\\ 
p_t & \begin{array}{l} \text{Si}\,\, y=x+1 \,\, \text{y}\,\, j=\gamma\,\,\text{e}\,\,i=k-1,\,\text{para}\,\, x=0,1,\ldots,l_n-1 \end{array} 
\\
p_t & \begin{array}{l} \text{Si}\, y=x+1,\,j=i=\gamma\,\,\text{para}\,\, x=0,1,\ldots,l_n-1  \end{array}
\\
1 & \begin{array}{l} \text{Si} \,\, y=x=l_n,\,\text{y}\ j=i=\gamma\end{array} \\
0 & \begin{array}{l} \text{Otro caso} \end{array}
\end{cases}\\
\end{equation}
```
:::

La partición correspondiente del espacio de estados $\small{\Omega}$ se
puede especificar de la siguiente manera:

<!----Ecuación 3.14.1--->

::: math
```{=tex}
\begin{align*} 
C_0 &=\{(x,i):i=0,1,\cdots,k-1\}\\
C_x &=\{(x,i):i=\gamma,0,1,\cdots,k-1\},\, x=1,\cdots,l_n,\\
C_{l_n} &= \{(l_n,\gamma)\}
\end{align*}
```
:::

Como ejemplo considerese, $\small{n=4}$ y $\small{k=2}$, luego las
matrices de probabilidades de transición
$\small{\boldsymbol{M_t}(M_{4,2})}$ para $\small{t=1,2,3,4}$ son:

<!----Ecuación 3.15--->

::: math
```{=tex}
\begin{equation}
\boldsymbol{M_t}(M_{4,2})=
\begin{array}{cc}&
\begin{array}{cccccc}
\end{array}
\\
\begin{array}{cccccc}
(0,0)\\
(0,1)\\
(1,\gamma)\\
(1,0)\\
(1,1)\\
(2,\gamma)\\
(2,0)\\
(2,1)\\
(3,\gamma)
\end{array}
&
\left(
\begin{array}{cc|c|cc|c|cc|c}
q_t&p_t&0&0&0&0&0&0&0\\
q_t&0&p_t&0&0&0&0&0&0\\
\hline
0&0&0&q_t&0&p_t&0&0&0\\
\hline
0&0&0&q_t&p_t&0&0&0&0\\
0&0&0&q_t&0&p_t&0&0&0\\
\hline
0&0&0&0&0&0&q_t&0&p_t\\
\hline
0&0&0&0&0&0&q_t&p_t&0\\
0&0&0&0&0&0&q_t&0&p_t\\
\hline
0&0&0&0&0&0&0&0&1\\
\end{array}
\right)
\end{array}
\end{equation}
```
:::

En general para $\small{n}$ y $\small{k}$ arbitrareos, las matrices de
probabilidad de transición continúan teniendo una forma de bandas
similar a $\small{\boldsymbol{M_t}(M_{4,2})}$ en la *ecuación (3.15)*, y
son de dimensión $\small{l_n(k+1)}$. La distribución y los momentos de
la variable aleatoria $\small{M_{n,k}}$ se pueden calcular nuevamente
mediante las ecuaciones (2.11) y (2.12), respectivamente.

#### 3.5 Número de Rachas de exactamente $\small{k}$ éxitos.

La Cadena de Markov incrustada $\small{\{Y_t\}}$ asociada con la
variable aleatoria, $\small{E_{n,k}}$, del número de rachas exitosas de
tamaño exactamente $\small{k}$ en $\small{n}$ ensayos independientes de
dos estados, se define por:

<!--Ecuación 3.16-->

::: math
```{=tex}
\begin{equation}
Y_t=(E_{t,k},E_t)
\end{equation}
```
:::

sobre el espacio de estados:

<!--Ecuación 3.16.1--->

::: math
```{=tex}
\begin{equation}
\Omega =\{(x,i):x=0,1,\cdots,l_n\,\, \text{e}\,\, i=\beta,\gamma,0,1,\cdots,k-1\}-\{(0,\gamma)\},
\end{equation}
```
:::

en donde, $\small{l_n=[(n+1)/(k+1)]}$, $\small{E_{t,k}}$ es el número de
rachas éxitosas de longitud igual a $\small{k}$ en los primeros
$\small{t}$ ensayos, y el *bloque final* $\small{E_{t}}$ se define en
función del número de éxitos finales $\small{m}$, en los primeros
$\small{t}$ ensayos de la siguiente manera:

<!---Ecuación 3.17--->

::: math
```{=tex}
\begin{equation}
E_t=\begin{cases}
m & \text{Si}\,\, m=0,1,\ldots,k-1\\
\gamma & \text{Si}\,\, m = k\\
\beta & \text{Si}\,\, m>k
\end{cases}
\end{equation}
```
:::

Los dos estados del bloque final $\small{\beta}$ e $\small{\gamma}$
tienes la siguiente interpretación:

*(i)* Estado de espera $\small{(x,\gamma),\,\,x=1,2,\dots,l_n}$:

$\small{ Y_t=(x,\gamma)}$ significa que $\small{m=k}$ y que
$\small{x-}$ésima racha exitosa de tamaño $\small{k}$ ha ocurrido en el
$\small{t-}$ésimo ensayo, y

*(ii)* Estado de desbordamiento $\small{(x,\beta),\,\,x=1,2,\dots,l_n}$:

$\small{ Y_t=(x,\beta)}$ significa que $\small{m>k}$ y que exactamente
$\small{x}$ rachas exitosas de tamaño $\small{k}$ han aparecido antes de
los últimos $\small{m+1}$ resultados
$\small{(F\underbrace{S\cdots S}_{m})}$.

Con estos bloques finales en mente, podemos construir fácilmente la
partición para el espacio de estados
$\small{\Omega:\, C_0=\{(0,i):i=\beta,0,1,\ldots, k-1\} }$ y
$\small{C_x=\{(x,i):i=\gamma,\beta,0,1,\ldots, k-1\} }$, para
$\small{x=1,\ldots,l_n}$.

Las probabilidades para las matrices de transición
$\small{\boldsymbol{M_t}(E_{t,k})}$ de la cadena de Markov incrustada
$\small{\{Y_t\}}$, se especifican mediante la siguiente ecuación:

<!----Ecuación 3.18--->

::: math
```{=tex}
\begin{equation}
p_{(x,i)(y,j)}(t) =
\begin{cases}
q_t & \begin{array}{l} \text{Si}\,\, y=x \,\, \text{y}\,\, j=0 \,\,\text{para}\,\, x=0,1,\ldots,l_n \,\,\text{e}\,\, i=\gamma,\beta,0,1,\ldots,k-1 \end{array} \\
p_t & \begin{array}{l} \text{Si}\,\, y=x \,\, \text{y}\,\, j=i+1\,\,\text{para}\,\, x=0,1,\ldots,l_n \,\, \text{e}\,\,i=0,1,\ldots,k-2 \end{array}
\\ 
p_t & \begin{array}{l} \text{Si}\,\, y=x+1 \,\, \text{y}\,\, j=\gamma\,\,\text{e}\,\,i=k-1,\,\text{para}\,\, x=0,1,\ldots,l_n-1 \end{array} 
\\
p_t & \begin{array}{l} \text{Si}\,\, y=x-1,\,\,j=\beta\,\, \,\,\text{e}\,\, i=\gamma\,\,\text{para}\,\, x=0,1,\ldots,l_n  \end{array}
\\
p_t & \begin{array}{l} \text{Si}\,\, y=x,\,\,\text{e}\,\, j=i=\beta\,, \,\,\text{para}\,\, x=0,1,\ldots,l_n  \end{array}
\\
1 & \begin{array}{l} \text{Si} \,\, y=x=l_n\,\,\text{y}\,\, j=i=k-1\end{array} \\
0 & \begin{array}{l} \text{Otro caso}. \end{array}
\end{cases}\\
\end{equation}
```
:::

A modo de ilustración, consideremos el caso $\small{n=5}$ y
$\small{k=2}$, para lo cual tenemos las matrices de probabilidad de
transición:

<!----Ecuación 3.19--->

::: math
```{=tex}
\begin{equation}
\boldsymbol{M_t}(E_{5,2})=
\begin{array}{cc}&
\begin{array}{c}
(0,\beta)\\
(0,0)\\
(0,1)\\
(1,\gamma)\\
(1,\beta)\\
(1,0)\\
(1,1)\\
(2,\gamma)\\
(2,\beta)\\
(2,0)\\
(2,1)
\end{array}
&
\left(
\begin{array}{c|cc|cc|cc|cc|cc}
q_t&p_t&0&0&0&0&0&0&0&0&0\\
\hline
0&q_t&p_t&0&0&0&0&0&0&0&0\\
0&q_t&0&p_t&0&0&0&0&0&0&0\\
\hline
p_t&0&0&0&0&q_t&0&0&0&0&0\\
0&0&0&0&p_t&q_t&0&0&0&0&0\\
\hline
0&0&0&0&0&q_t&p_t&0&0&0&0\\
0&0&0&0&0&q_t&0&p_t&0&0&0\\
\hline
0&0&0&0&p_t&0&0&0&0&q_t&0\\
0&0&0&0&0&0&0&0&p_t&q_t&0\\
\hline
0&0&0&0&0&0&0&0&0&q_t&p_t\\
0&0&0&0&0&0&0&0&0&0&1\\
\end{array}
\right)
\end{array}
\end{equation}
```
:::

En general, las matrices de probabilidad de transición de la cadena de
Markov $\small{\{Y_t\}}$ asociadas con $\small{E_{n,k}}$ tienen la forma
dada por la *ecuación (3.19*) con dimensión
$\small{(l_n + 1)(k+1)+l_n}$.

#### 3.6 La distribución de la Racha de éxitos más larga

Sea $\small{L_n(S)}$, la duración de la racha exitosa más larga en una
sucesión de ensayos de dos estados. Para el caso de $\small{n}$
lanzamientos independientes de una moneda justa, sea $\small{A_n(k)}$ el
número de secuencias de longitud $\small{n}$ en las que la racha más
larga de éxitos (cara) es menor o igual a $\small{k}$. Dado que todas
las sucesiones son igualmente probables con probabilidad
$\small{(1/2)^n}$, la distribución del racha más largo es:

<!--Ecuación 3.20--->

::: math
```{=tex}
\begin{equation}
\mathbb{P}\big(L_n(S)\leq k\big)=2^{-n}A_n(k)
\end{equation}
```
:::

donde $\small{A_n(k)}$ satisface la ecuación recursiva *(Schilling
1990)*

<!--Ecuación 3.21--->

::: math
```{=tex}
\begin{equation}
A_n(k)=\begin{cases}
\displaystyle\sum_{j=0}^{k}A_{n-1-j}(k) & \text{si}\, n > k\\
2^{n} & \text{si}\,\, n \leq k\\
1 & \text{si}\,\, k = 0\\
\end{cases}
\end{equation}
```
:::

Para monedas sesgadas $\small{(p\neq1/2)}$, el análisis combinatorio es:

<!--Ecuación 3.22--->

::: math
```{=tex}
\begin{equation}
\mathbb{P}\big(L_n(S)\leq k\big)=\displaystyle\sum_{x=0}^{k}C_{n}^{(x)}(k)p^{x}q^{n-x},
\end{equation}
```
:::

para $\small{1 \leq k \leq n}$, y
$\small{\mathbb{P}\big(L_n(S)=0 \big)=q^{-n}}$, donde
$\small{C_n^{(x)}(k)}$ es el número de secuencias de longitud
$\small{n}$ en las que ocurren exactamente $\small{x}$ éxitos, pero en
las que no más de $\small{k}$ de estos éxitos ocurren consecutivamente.
$\small{C_n^{(x)}(k)}$ se puede obtener a través de la ecuación
recursiva:

<!--Ecuación 3.23--->

::: math
```{=tex}
\begin{equation}
C_n^{(x)}(k)=\begin{cases}
\displaystyle\sum_{j=0}^{k}C_{n-1-j}^{x-j}(k) & \text{si}\,\,  k<x<n\\
\binom{n}{x} & \text{si}\,\,  x \leq k \leq n\\
\, 0 & \text{si}\,\,k<x= n\\
\end{cases}
\end{equation}
```
:::

De manera más general, supongamos que las probabilidades de éxito y
fracaso podrían ser diferentes en cada ensayo, iguales a $\small{p_t}$ y
$\small{q_t}$, respectivamente, para $\small{t=1,2,\ldots,n}$. El
siguiente teorema deriva la distribución de $\small{L_n(S)}$:

**Teorema 3.1** Para $\small{0\leq k\leq n}$,

<!--Ecuación 3.24--->

::: math
```{=tex}
\begin{equation}
\mathbb{P}\big(L_n(S)\leq k\big)=\boldsymbol{\mathbf{\xi}} \Big(\prod_{t=1}^{n}\boldsymbol{N}_t\Big)\boldsymbol{\mathbf{1}'}_{1 \times(k+1)}
\end{equation}
```
:::

en donde $\small{\boldsymbol{\mathbf{\xi}}=(1,0,\ldots,0)}$ es un vector
fila unitario de tamaño $\small{1\times (k+1)}$ y
$\small{\boldsymbol{N_t}}$ es como se indica a continuación, la
*submatriz esencial* $\small{(k+1)\times (k+1)}$ de la matriz de
probabilidades de transición:

<!--Ecuación 3.25--->

::: math
```{=tex}
\begin{equation}
\boldsymbol{M_t}=
\begin{array}{cc}&
\begin{array}{c}
0\\
1\\
\vdots\\
\vdots\\
k\\
\alpha
\end{array}
&\left(
\begin{array}{ccccc|c}
q_t&p_t&0&\cdots&0&0\\
q_t&0&p_t&\cdots&0&0\\
\vdots&&\ddots&\ddots&&\vdots\\
\vdots&&\ddots&\ddots&\ddots&\vdots\\
q_t&0&\cdots&\cdots&0&p_t\\
\hline
0&0&\cdots&\cdots&0&1\\
\end{array}
\right)_{(k+2) \times (k+2)}
\end{array}=\left(\begin{array}{c|c}
\boldsymbol{N_t} &  {C_t}\\
\hline
\boldsymbol{0}&  {1}\\
\end{array}
\right)
\end{equation}
```
:::

**Demostración:** La racha exitosa más larga en una sucesión de ensayos
de dos estados está relacionada con las estadísticas de ejecución
$\small{N_{n,k}}$, $\small{G_{n,k}}$ y $\small{M_{n,k}}$ de la siguiente
manera sencilla:

<!--Ecuación 3.25.1--->

::: math
```{=tex}
\begin{equation}
L_n(S)\leq k \,\, \text{si y solo si}\,\, N_{n,k+1} = G_{n,k+1}=M_{n,k+1}=0
\end{equation}
```
:::

Por tanto,
$\small{\mathbb{P}\big(L_n(S)\leq k\big)=\mathbb{P}\big(N_{n,k+1}=0\big)}$,
y podemos completar la demostración considerando la *Ecuación (3.8)*
para $\small{\mathbb{P}\big(N_{n,k+1}=x\big)}$ con $\small{x=0}$.
Cambiando los estados $\small{(0,0),(0,1),\ldots,(0,k)}$ en esta
aplicación de la *Ecuación (3.8)* a los estados $\small{0,1,2,\ldots,k}$
respectivamente, y combinando todos los demás estados en el estado
absorbente $\small{\alpha}$, obtenemos:

<!--Ecuación 3.25.2--->

::: math
```{=tex}
\begin{equation}
\mathbb{P}\big(L_n(S)\leq k\big)=\mathbb{P}\big(N_{n,k+1}=0\big)=\boldsymbol{\mathbf{\xi}_0} \Big(\prod_{t=1}^{n}\boldsymbol{M}_t\Big)(1,\ldots,1,0)'
\end{equation}
```
:::

en donde
$\small{\boldsymbol{\xi_0}=(1,0\ldots,0)_{1\times(k+2)}=(\boldsymbol{\xi}:0)}$.
Con la notación
$\small{(1,\ldots,1,0)_{1\times(k+2)}=(\boldsymbol{1}:0)}$ y haciendo
uso del hecho que las matrices de transición de probabilidad tienen la
forma:

<!--Ecuación 3.25.3--->

::: math
```{=tex}
\begin{equation}
\prod_{t=1}^{n}\boldsymbol{M_t}=
\left(
\begin{array}{c|c}
\displaystyle\prod_{t=1}^{n}\boldsymbol{N_t}& C_t(n)\\
\hline
\boldsymbol{0}&1
\end{array}
\right)
\end{equation}
```
:::

luego, el teorema se sigue inmediatamente. $\hspace{3cm}\Box$

**Colorario** Dados $\small{1 \leq k \leq n}$ se satisface la siguiente
ecuación recursiva:

<!--Ecuación 3.26--->

::: math
```{=tex}
\begin{equation}
\mathbb{P}\big(L_n(S)\leq k\big)=q_n\cdot\mathbb{P}\big(L_{n-1}(S)\leq k\big)+\displaystyle\sum_{i=1}^{k}q_{n-i} \prod_{j=n-i+1}^{n}p_{j}\cdot\mathbb{P}\big(L_{n-i-1}(S)\leq k\big)
\end{equation}
```
:::

con
$\small{\mathbb{P}\big(L_n(S)=0\big)=\displaystyle\prod_{j=1}^{n}q_j}$ y
$\small{\mathbb{P}\big(L_n(S)\leq n\big)\equiv1}$ para $\small{k=m}.$

**Demostración** De la estructuradada dada por la Ec.(3.25) para las
matrices de probabilidades de transición $\small{\boldsymbol{M_t}}$, se
sigue que:

<!--Ecuación 3.26.1--->

::: math
```{=tex}
\begin{align*} 
\text{(i)}\,\, \boldsymbol{M_te_0'} &=q_t(1,\ldots,1,0)'_{1\times(k+2)}\,\, \text{y} \\ 
\text{(ii)}\,\,\boldsymbol{M_te_i'} &=p_t\boldsymbol{e_{i-1}'},\,\,\text{para}\,\, i=1,2,\ldots,k,
\end{align*}
```
:::

en donde $\small{\boldsymbol{e_i}=(0,\ldots,0,1,0,\ldots,0)}$ es un
vector fila unitario con un uno en la coordenada asociada al estado
$\small{i}$, para $\small{i=0,1,2,\ldots,k}$.

Dado que $\small{\displaystyle\sum_{i=0}^{k}\boldsymbol{e_i'}}$, nuestro
resultado es una consecuencia directa de (i),(ii) y multiplicaciones
hacia atrás de la *ecuación (3.24)*.

Tomando $\small{p_t=q_t=1/2}$ para todo $\small{t=1,2,\ldots,n}$ y
multiplicando $\small{\mathbb{P}\big(L_n(S)\leq k\big)=1}$ por
$\small{2^n}$, la ecuación (3.26) produce la ecuación recursiva (3.21)
para $\small{A_n(k)}$. El teorema 3.1 también se puede extender para la
rachas de falla más larga $\small{L_n(F)}$ y a la estadística de racha
más larga $\small{L_n = \max\{L_n(S), L_n(F)\}}$. Para el caso *i.i.d.*
y para $\small{n}$ grande, hay varios resultados sobresalientes sobre la
duración de la racha exitosa más larga. *Rényi (1970), Csörgö (1979)*,
Erdös y Rényi (1970) y Erdös y Révész (1975) muestran que, cuando
$\small{n \rightarrow \infty}$

<!--Ecuación 3.26.2--->

::: math
```{=tex}
\begin{equation} 
\frac{L_n(S)}{\log_{1/p}(n)} \xrightarrow{a.s} 1
\end{equation}
```
:::

A este resultado se le suele denominar la nueva ley de los grandes
números.

En el Capítulo 5, desarrollaremos una aproximación de grande desviación
para la probabilidad de $\small{L_n(S)}$ bajo ensayos *i.i.d.* (y
Markov-Dependientes homogéneos):

<!--Ecuación 3.26.3--->

::: math
```{=tex}
\begin{equation} 
\mathbb{P}\big(L_n(S)\leq  k\big)\sim \exp\{-n\beta\}
\end{equation}
```
:::

en donde $\small{\beta=-\log(\lambda_{[1]})}$ y $\small{\lambda_{[1]}}$
es el valor propio más grande de la submatriz de probabilidad de
transición esencial $\small{\boldsymbol{N_t}}$ (con $\small{p_t}$ y
$\small{q_t}$ constantes) dada por la *ecuación (3.25)*.

#### 3.7 Distribución del tiempo de espera de una Racha Exitosa

Sea $\small{\Lambda=S\cdots S}$ el patrón simple de $\small{k}$ éxitos
consecutivos y defina la variable aleatoria $\small{W(\Lambda)}$ como el
tiempo de espera para que ocurra el patrón $\small{\Lambda}$, es decir
<!--Ecuación 3.26.3--->

::: math
```{=tex}
\begin{equation} 
W(\Lambda)=\inf\{n:X_{n-k+1}=X_{n-k+2}=\cdots=X_{n}=S\}.
\end{equation}
```
:::

Por ejemplo, dado $\small{k=3}$, $\small{W(\Lambda)=6}$ significa que el
patrón $\small{SSS}$ ocurre por primera vez después de seis intentos,
como en $\small{SFFSSS}$. La distribución de $\small{W(\Lambda)}$ para
los ensayos de Bernoulli a menudo se denomina distribución geométrica de
orden $\small{k}$ (ver Aki 1985 e Hirano 1986).

**Teorema 3.2** Dado un patrón de longitud $\small{k\geq 1}$ y una
sucesión de ensayos Bernoulli $\small{\{X_t\}}$, la distribución de
$\small{W(\Lambda)}$ esta dada por:

<!--Ecuación 3.27.0--->

::: math
```{=tex}
\begin{equation} 
\mathbb{P}\big(W(\Lambda)=n\big)=\boldsymbol{\xi} \boldsymbol{N_t}^{n-1}(\Lambda)\big(\boldsymbol{I-N}(\Lambda)\big)\boldsymbol{1'}
\end{equation}
```
:::

en donde $\small{\boldsymbol{\xi}=(1,0,\ldots,0)}$ es un vector fila
$\small{1\times k}$ y $\small{\boldsymbol{N}(\Lambda)}$ es la submatriz
de probabilidades de transición esencial:

<!--Ecuación 3.28--->

::: math
```{=tex}
\begin{equation}
\boldsymbol{M}(\Lambda)=
\begin{array}{cc}&
\begin{array}{c}
0\\
1\\
\vdots\\
\vdots\\
k-1\\
\alpha
\end{array}
&\left(
\begin{array}{ccccc|c}
p&q&0&\cdots&0&0\\
q&0&p&\cdots&0&0\\
\vdots& &\ddots&\ddots&&\vdots\\
\vdots&&\ddots&\ddots&\ddots&\vdots\\
q&0&\cdots&\cdots&0&p\\
\hline
0&0&\cdots&\cdots&0&1\\
\end{array}
\right)_{(k+1)\times(k+1)}
\end{array}=
\left(
\begin{array}{c|c}
\boldsymbol{N}(\Lambda)&C\\
\hline
\boldsymbol{0} & 1
\end{array}\right)
\end{equation}
```
:::

Se deduce además que la función generadora de probabilidad de
$\small{W(\Lambda)}$ está dada por:

<!---Ecuación 3.29--->

::: math
```{=tex}
\begin{equation}
\varphi_{W}(s)=\frac{p^ks^k(1-ps)}{1-s+qp^ks^{k+1}}
\end{equation}
```
:::

**Prueba.** Dados $\small{\Lambda}$,$\small{}$ y $\small{k \leq n}$, de
la definición de $\small{W(\Lambda)}$ y $\small{N_{n,k}}$, se deduce que
estas dos variables aleatorias tienen la siguiente relación:

<!---Ecuación 3.29.1--->

::: math
```{=tex}
\begin{equation}
W(\Lambda) \leq n \quad \text{si y solo si}\quad N_{n,k}\geq 1 \,\,\text{para todo }\, n \geq k.
\end{equation}
```
:::

Por tanto
$\small{\mathbb{P}\big(W(\Lambda)\leq n\big)=\mathbb{P}\big(N_{n,k}\geq 1\big)}$
y

<!---Ecuación 3.30--->

::: math
```{=tex}
\begin{align*} 
 \mathbb{P}\big(W(\Lambda)\leq n\big) &= \mathbb{P}\big(N_{n,k}\geq 1\big)-\mathbb{P}\big(N_{n-1,k}\geq 1\big), \\ 
 &=  \mathbb{P}\big(N_{n-1,k}= 0\big)-\mathbb{P}\big(N_{n,k}= 0\big).
\end{align*}
```
:::

Puesto que sólo necesitamos el resultado general de
$\small{\mathbb{P}\big(N_{n,k}= 0\big)}$ para completar la prueba,
podemos, como en la sección anterior sobre la racha exitosa más larga,
reemplazar los estados $\small{(0,0),\cdots,(0,k-1)}$ definidos en la
*Sección 3.2* por los estados $\small{0,1,2,\ldots,k-1}$ y combinar
todos los demás estados en un estado absorbente $\small{\alpha}$. Bajo
este espacio de estados reducido, la matriz de probabilidad de
transición $\small{\boldsymbol{M_t}(N_{n,k})}$ se simplifica a
$\small{\boldsymbol{M}(\Lambda)}$. La ecuación (3.27) del teorema 3.2 es
entonces una consecuencia inmediata de las ecuaciones (3.8), (3.30) y
Teorema 3.1.

Note que, para $\small{0\leq i\leq k-1,}$

<!---Ecuación 3.30.1--->

::: math
```{=tex}
\begin{equation}
\boldsymbol{e_iN}(\Lambda)=q\boldsymbol{e_0}+p\boldsymbol{e_{i+1}}.
\end{equation}
```
:::

Dado $\small{\boldsymbol{\xi=e}_0}$, y usando del resultado de
multiplicación hacia adelante obtenemos la siguiente ecuación recursiva:

<!---Ecuación 3.31--->

::: math
```{=tex}
\begin{align*} 
 \mathbb{P}\big(W(\Lambda)= n\big) &= \boldsymbol{\xi N}^{n-1}(\Lambda)\big(\boldsymbol{I-N}(\Lambda)\big)\boldsymbol{1'} \\ 
 &= \sum_{i=1}^{k}qp^{i-1}\mathbb{P}\big(W(\Lambda)=n-i\big).
\end{align*}
```
:::

La anterior ecuación recursivay la condición de frontera
$\small{\mathbb{P}\big(W(\Lambda)=k\big)=p^{k}}$ conducen a la siguiente
ecuación recursiva para la función generadora de probabilidad
$\small{\varphi_{W}(s)}$:

<!---Ecuación 3.31.1--->

::: math
```{=tex}
\begin{equation}
\varphi_{W}(s)= s^kp^k+\sum_{i=1}^{k}qp^{i-1}s^{i}\varphi_{W}(s)
\end{equation}
```
:::

Sumando las series de potencias finitas se obtiene el resultado
explícito para $\small{\varphi_{W}(s)}$ dado en la Ec. (3.29), resultado
que fue derivado por primera vez por Feller (1968) utilizando la teoría
de la renovaciones.$\hspace{3cm}\Box$

Si definimos las matrices:

<!---Ecuación 3.31.2--->

::: math
```{=tex}
\begin{equation}
\boldsymbol{A}=\left(
\begin{array}{ccccc}
q&p&0&\cdots&0\\
q&0&p& &0\\
\vdots& &\ddots&\ddots& \\
q& & &0&p\\
q&0&\cdots&&0\\
\end{array}
\right)_{k\times k},\,
\boldsymbol{B}=\left(
\begin{array}{ccccc}
0&0&0&\cdots&0\\
0&0&0& &\\
\vdots& &\ddots&\ddots& \\
0& & &0&0\\
p&0&\cdots&&0\\
\end{array}
\right)_{k\times k}
\end{equation}
```
:::

<!---Ecuación 3.31.1--->

::: math
```{=tex}
\begin{equation}
\boldsymbol{A}^{\ast}=(1)_{1\times 1}\,\, \text{y}\,\, \boldsymbol{B}^{\ast}=(0\,\,0\,\,\cdots \, 0\,\,p)'_{k\times 1}
\end{equation}
```
:::

y sea $\small{W(m,\Lambda)}$ el tiempo de espera para la
$\small{m-}$ésima racha de $\small{k}$ éxitos consecutivos (sin
solapamiento). De forma similar al desarrollo anterior para
$\small{W(\Lambda)}$, la distribución de la variable aleatoria
$\small{W(m,\Lambda)}$ puede ser obtenida usando la Ecuación (3.27) al
remplazar la matriz de probabilidades de transición
$\small{W(\Lambda)}$, por:

<!---Ecuación 3.31.3--->

::: math
```{=tex}
\begin{equation}
\boldsymbol{W}(m,\Lambda)=\left(
\begin{array}{ccccc}
\boldsymbol{A}&\boldsymbol{A}& &\boldsymbol{O}&\\
 &\ddots & \ddots& &\\
 & &\boldsymbol{A}&\boldsymbol{B}& \\
 &\boldsymbol{O} &&\boldsymbol{A}&\boldsymbol{B^{\ast}}\\
 & & &&\boldsymbol{A^{\ast}}\\
\end{array}
\right)_{(mk+1)\times (mk+1)}
\end{equation}
```
:::

Obsérvese que la matriz de probabilidad de transición
$\small{\boldsymbol{M}(\Lambda)}$ de la *Ec. (3.28)* es el caso especial
de $\small{\boldsymbol{M}(m,\Lambda)}$ con $\small{m=1}$. Puesto que
$\small{W(m,\Lambda)=\displaystyle\sum_{i=1}^{m}W_i(\Lambda)}$, donde
$\small{W_i(\Lambda)}$ representa el tiempo de espera desde la
$\small{(i-1)-}$ésima ocurrencia hasta la $\small{(i)-}$ésima ocurrencia
del patrón $\small{\Lambda}$, y puesto que las variables aleatorias
$\small{W(\Lambda)}$ son *i.i.d.*, se deduce de la Ec. (3.29) que la
función generadora de probabilidad de $\small{W(m,\Lambda)}$ es:

<!---Ecuación 3.32--->

::: math
```{=tex}
\begin{equation}
\varphi_{W(m,\Lambda)}^{m}(s)=\varphi_{W}^{m}(s)=\Bigg(\frac{p^ks^k(1-ps)}{1-s+qp^ks^{k+1}}\Bigg)^{m}.
\end{equation}
```
:::

La función generadora de probabilidad $\small{\varphi_{W}(s)}$ siempre
existe para todo $\small{|s| \leq 1}$

Esto se desprende de su definición y del hecho de que:

<!---Ecuación 3.32.1--->

::: math
```{=tex}
\begin{equation}
|\varphi_{W}(s)|\leq\sum_{n=1}^{\infty}|s^{n}|\cdot\mathbb{P}(W=n)\leq\sum_{n=1}^{\infty}\mathbb{P}(W=n)=1.
\end{equation}
```
:::

Sin embargo, la función generadora de probabilidad
$\small{\varphi_{W}(s)}$ puede existir más allá de la región
$\small{|s| \leq 1}$. La región exacta varía de un problema a otro.
Volveremos a discutir la mayor región de existencia de
$\small{\varphi_{W}(s)}$ en la sección 5.7.

La distribución de $\small{W(m,\Lambda)}$ también puede obtenerse
mediante la ecuación

<!---Ecuación 3.32.2--->

::: math
```{=tex}
\begin{equation}
\mathbb{P}\big(W(m,\Lambda)=n\big)=\frac{1}{n!}\frac{d^{n}}{ds^{n}}\varphi_{W(m,\Lambda)}(s)\Bigr|_{s=0}.
\end{equation}
```
:::

enfoque que puede obtenerse más fácilmente utilizando software de
manipulación simbólica (por ejemplo, MAPLE o MATLAB). En el capítulo 5
se ofrece un tratamiento más detallado de las distribuciones de tiempo
de espera para patrones simples y compuestos en ensayos *i.i.d.* y
Markov-Dependientes multiestado.

#### 3.8 Ejemplos numéricos

Antes de estudiar estadísticas de rachas más complejas, en esta sección
proporcionamos algunos resultados numéricos para las estadísticas de
rachas y los tiempos de espera descritos en las secciones anteriores con
el fin de ilustrar los resultados teóricos. Dada la matriz (o matrices)
de probabilidad de transición de la cadena de Markov incrustada
$\small{\{Y_t\}}$ , en general sólo necesitamos dos tipos de fórmulas,
en las formas de las *Ecs. (3.8)* y *(3.27)*, para evaluar las
distribuciones de $\small{X_n(\Lambda)}$ y $\small{W(\Lambda)}$,
respectivamente. Las fórmulas son sencillas y eficientes desde el punto
de vista computacional, adecuadas incluso para $\small{n}$ muy grandes.
Los resultados numéricos que aquí se presentan también pueden servir
para comprobar los propios cálculos de programación. En todos los
ejemplos considerados, el tiempo de cálculo para obtener cada
distribución es mínimo, una fracción de segundo en un PC actual.

En la *Tabla 3.1* se presentan las distribuciones exactas y las medias
de las variables aleatorias
$\small{E_{15,2},\, G_{15,2},\,N_{15,2},\, M_{15,2}}$ y
$\small{L_{15}(S)}$ bajo el supuesto de que $\small{\{X_t\}}$es una
secuencia de ensayos independientes de dos estados con probabilidades
$\small{p_t=1/(t+1)}$ para $\small{t=1,2,\ldots,15}$.

La *Tabla 3.2* muestra las distribuciones del tiempo de espera de la
primera racha con éxito de longitud $\small{k}$, para varios valores de
$\small{k}$ y probabilidades de estado $\small{p_t}$. En los capítulos 5
y 7 se ofrecen más resultados numéricos sobre las distribuciones del
tiempo de espera.

#### 3.9 Número de éxitos en rachas éxitosas de longitud mayor o igual que $\small{k}$.

Sea $\small{S_{n,k}}$ el número total de éxitos en rachas de éxitos de
longitud mayor o igual que $\small{}$, para $\small{k=1,2,\ldots,n}$.
Puede escribirse como

<!---Ecuación 3.33--->

::: math
```{=tex}
\begin{equation}
S_{n,k}=\sum_{i=k}^{n}iR_n(i),
\end{equation}
```
:::

en donde $\small{R_n(i)}$, para $\small{i=k,\ldots,n}$ es el número de
rachas éxitosas de longitud exactamente igual a $\small{i}$ en una
sucesión $\small{\{X_t\}}$. Para $\small{k=1}$, la Ec. (3.33) es
equivalente al número total de éxitos en la sucesión $\small{\{X_t\}}$,
es decir:

<!---Ecuación 3.33.1--->

::: math
```{=tex}
\begin{equation}
S_{n,1}=\sum_{i=k}^{n}I_{X_i},
\end{equation}
```
:::

en donde $\small{I_{X_i}=1}$ cuando el $\small{i-}$ésimo ensayo es éxito
y cero en otro caso. Si $\small{\{X_t\}}$ es una sucesión de ensayos
Bernoulli, entonces $\small{S_{n,1}}$ tiene distribuciones binomial
exacta y normal en el límite, respectivamente. De manera más general,
para el caso $\small{\{X_t\}}$ es una sucesión de variables aleatorias
Markov-Dependientes, la estadística $\small{S_{n,k}}$ también tiene una
distrubución límite normal, como determino *Nagaev (1957)* para
$\small{k=1}$ y *Fu, Lou, Bai y Li (2002)* para $\small{k \geq 2}$. En
esta sección, sólo estudiamos la distribución exacta de
$\small{S_{n,k}}$ con $\small{k \geq 2}$.

Sea $\small{L_j}$, para $\small{j \geq 2}$, la longitud de la racha de
éxitos situada entre el $\small{(j-1)-}$ésimo y el $\small{j-}$ ésimo
fallo en la sucesión $\small{\{X_t\}}$, con $\small{L_1=0}$ si el primer
ensayo es un fallo y $\small{L_1=l}$ si los primeros $\small{l}$ ensayos
son éxitos y el $\small{(j+1)-}$ésimo ensayo es un fallo. Para un índice
de tiempo $\small{t}$ dado, sea $\small{m_t}$ el número de fracasos en
la subsecuencia $\small{X_1, X_2,\ldots, X_t}$ y sea
$\small{L_t^{\star}}$ el número de éxitos que se producen después del
$\small{m_t-}$ésimo fracaso en esta subsecuencia. Nótese que
$\small{0 \leq L_{t}^{\star} \leq t}$ y
$\small{0\leq L_t^{\star} \leq L_{m_t+1}}$. Por otra parte,
$\small{S_{t,k}}$, tal como se define en la *Ec. (3.33)*, también se
puede escribir como:

<!---Ecuación 3.34--->

::: math
```{=tex}
\begin{equation}
S_{t,k}=\sum_{j=1}^{m_t}L_{j}(k)+L_t^{\star}(t),
\end{equation}
```
:::

con <!---Ecuación 3.35--->

::: math
```{=tex}
\begin{equation}
L_{j}(k)=L_j\cdot I_{\{L_j\geq k\}}\quad \text{y}\quad L_{j}^{\star}(k)=L_j^{\star}\cdot I_{\{L_j^{\star} \geq k\}}.
\end{equation}
```
:::

Acá $\small{I_{\{L_j \geq k\}}}$, es la función indicadora del evento
$\small{\{L_j \geq k\}}$, es decir, es igual a uno cuando
($\small{I_{\{L_j^{\star} \geq k\}}}$, se define de manera análoga) Para
capturar la información relevante en la subsucesión
$\small{\{X_1,X_2,\cdots, X_t\}}$ definimos una nueva sucesión de
variables aleatorias en la forma del vector de dos componentes

<!---Ecuación 3.36--->

::: math
```{=tex}
\begin{equation}
Y_t=\big( S_{t,k},E_{t}(t)\big),\,\, t=1,2,\ldots,n,
\end{equation}
```
:::

en donde $\small{S_{t,k}}$ indica el número total de éxitos en rachas
exitosas de longitud mayor o igual a $\small{k}$ en los primeros
$\small{t}$ ensayos, y $\small{E_{t}(k)}$ es la variable aleatoria de
*bloque final* dada por:

<!---Ecuación 3.35--->

::: math
```{=tex}
\begin{equation}
E_{t}(k)= L_{t}^{\star}\big(1-I_{\{L_j^{\star}\geq k\}}\big)+k^{+}\cdot I_{\{L_j^{\star} \geq k\}}.
\end{equation}
```
:::

En esta expresión, el símbolo $\small{k^{+}}$ representa el estado donde
$\small{L_t}$ es mayor o igual que $\small{k}$.

El bloque final $\small{E_t(k)}$ representa la longitud de la racha de
éxitos contando hacia atrás desde el $\small{t-}$ésimo ensayo, con
$\small{E_t(k)=0}$ si el $\small{t-}$ésimo ensayo es un fracaso y
$\small{E_t(k)=k^{+}}$ si la longitud es mayor o igual a $\small{k}$.
Más específicamente, considere que desde el 1 $\small{ m_t-}$ésimo (o
más reciente) fracaso $\small{F}$ hasta el final de la subsucesión
$\small{\{X_1,X_2,\cdots, X_t\}}$ sólo podemos tener los siguientes
resultados posibles:
$\small{\{F,FS,\cdots,FS\cdots S,\,\text{or}\, S\cdots S\, \text{si } m_t = 0\}}$;
la variable aleatoria $\small{E_t(k)}$ es igual al número de éxitos en
estos resultados si el número es menor que $\small{k}$, y
$\small{E_t(k)=k^{+}}$ si es igual o mayor que $\small{k}$. Este bloque
final de los primeros $\small{t}$ ensayos proporciona información
esencial sobre las probabilidades de transición de $\small{Y_t}$ a
$\small{Y_{t+1}}$.

Definimos el espacio de estados

<!--Ecuación 3.37------>

::: math
```{=tex}
\begin{equation}
\Omega =\{(u,v):u=0,k,\cdots,n-1,n\,\, \text{y}\,\, v=0,1,\cdots,k-1,k^{+}\},
\end{equation}
```
:::

con tamaño $\small{d=\text{card}(\Omega)=(n-k+2)(k+1)}$, y
consideraremos aquí el caso en que la sucesión $\small{\{X_t\}}$ es una
cadena de Markov homogénea con probabilidades de transición
$\small{p_{FF},p_{Fs},p_{SF}}$ y $\small{p_{SS}}$. En nuestro
procedimiento de recuento, la sucesión de vectores aleatorios
$\small{Y_t=\big( S_{t,k},E_{t}(t)\big),\,\, t=1,2,\ldots,n,}$ definida
en $\small{\Omega}$ obedece las siguientes reglas:

*(i)* Dado $\small{Y_{t-1}=(x,0)}$, entonces $\small{Y_{t}=(x,0)}$ con
probabilidad $\small{p_{FF}}$ si el resultado del $\small{t-}$ésimo
ensayo es $\small{F}$, e $\small{Y_{t}=(x,1)}$ con probabilidad
$\small{p_{FS}}$ si el resultado del $\small{t-}$ésimo ensayo es
$\small{S}$.

*(ii)* Dado $\small{Y_{t-1}=(x,y)}$ para $\small{1\leq y \leq k-2}$
entonces $\small{Y_{t}=(x,0)}$ con probabilidad $\small{p_{SF}}$ si el
resultado del $\small{t-}$ésimo ensayo es $\small{F}$, e
$\small{Y_{t}=(x,y+1)}$ con probabilidad $\small{p_{SS}}$ si el
resultado del $\small{t-}$ésimo ensayo es $\small{S}$.

*(iii)* Dado $\small{Y_{t-1}=(x,k-1)}$, entonces $\small{Y_{t}=(x,0)}$,
con probabilidad $\small{p_{SF}}$ si el resultado del $\small{t-}$ésimo
ensayo es $\small{F}$, e $\small{Y_{t-1}=(x+k,k^{+})}$, con probabilidad
$\small{p_{SS}}$ si el resultado del $\small{t-}$ésimo ensayo es
$\small{S}$.

*(iv)* Dado $\small{Y_{t-1}=(x,k^{+})}$, entonces $\small{Y_{t}=(x,0)}$
con probabilidad $\small{p_{SF}}$ si el resultado del $\small{t-}$ésimo
ensayo es $\small{F}$, e $\small{Y_{t}=(x+1,k^{+})}$ con probabilidad
$\small{p_{SS}}$ si el resultado del $\small{t-}$ésimo prueba es
$\small{S}$.

A la vista de nuestra construcción, la sucesión
$\small{\{Y_t = \big( S_{t,k}, E_t(k) \big) : t = 1, 2,..., n\}}$ forma
una cadena de Markov homogénea con matriz de probabilidad de transición:

<!---Ecuación 3.37.7--->

::: math
```{=tex}
\begin{equation}
\boldsymbol{M}=\big( p_{(x,y)\times(u,v)}\big)_{d\times d}
\end{equation}
```
:::

donde las probabilidades de transición $\small{p_{(x,y)\times(u,v)}}$,
bajo orden lexicográfico de los estados $\small{(\cdot,\cdot)}$, se
pueden especificar explícitamente de la siguiente manera. Dado
$\small{(x,y)\in \Omega}$,

<!----Ecuación 3.38--->

::: math
```{=tex}
\begin{equation}
p_{(x,y)(u,v)}(t) =
\begin{cases}
p_{FF} & \begin{array}{l} \text{Si}\,\, y=v=0 \,\, \text{y}\,\, u=x, \end{array} \\
p_{FS} & \begin{array}{l} \text{Si}\,\, y=0,\,v=1 \,\, \text{y}\,\, u=x, \end{array}
\\ 
p_{SF} & \begin{array}{l} \text{Si}\,\, y\neq 0,\,v=0\,\, \text{y}\,\, u=x, \end{array} 
\\
p_{SS} & \begin{array}{l} \text{Si}\,\, 1 \leq y \leq k-2,\,\,v=y+1\,\, \,\,\text{e}\,\, u=x,\\
\text{o si}\,\, y=k-1,\,\, v=k^{+}\,\,\text{e}\,\, u=x+k,\\
\text{o si}\,\, y=k^{+},\,\, v=k^{+}\,\,\text{e}\,\, u=x+1\\
\end{array}
\\
1 & \begin{array}{l} \text{Si} \,\, y=v\,\,\text{y}\,\, u=x=n\end{array} \\
0 & \begin{array}{l} \text{Otro caso}. \end{array}
\end{cases}
\end{equation}
```
:::

Por lo tanto, la variable aleatoria $\small{S_{n,k}}$ es una Cadena de
Markov incrustable y las probabilidades exactas se pueden obtener de:

<!---Ecuación 3.39--->

::: math
```{=tex}
\begin{equation} 
\mathbb{P}\big(S_{n,k}= x\big) = \boldsymbol{\xi_0 M}^{n-1}\boldsymbol{U}(C_x),\,\, x=0,k,\ldots,n
\end{equation}
```
:::

donde el vector fila
$\small{\boldsymbol{\xi_0}=(q_0,p_0,0,\ldots,0)_{1 \times d}}$ es la
distribución inicial de $\small{Y_1}$, la partición $\small{\{C_x\}}$ se
define como:

<!---Ecuación 3.37.7--->

::: math
```{=tex}
\begin{equation}
C_x =\{(x,y):y=0,1,\cdots,k-1,k^{+}\},\,\,x=0,k,\cdots,n,
\end{equation}
```
:::

y $\small{\boldsymbol{U}'(C_x)}$ es la transposición del vector fila
$\small{\boldsymbol{U}(C_x)=(0,\ldots,0,1,\ldots,1,0,\ldots,0)}$ con
unos en las coordenadas correspondientes a los estados de $\small{C_x}$.

Para comprender mejor los efectos de los distintos parámetros, en la
Figura 3.1 se muestran gráficamente las distribuciones de
$\small{S_{n,k}}$ para algunos casos representativos con
$\small{n=15,30,60}$, en los que se supone la distribución inicial
$\small{\boldsymbol{\xi_0}=(1,0,\ldots,0)}$. Cuando $\small{p_{SS}}$ es
pequeño (por ejemplo, $\small{p_{SS}=0.2}$), los efectos de los
parámetros sobre la distribución son menos pronunciados, por lo que en
la Figura 3.1 sólo se presentan casos con valores grandes de
$\small{p_{SS}\,(=0.8)}$. A efectos de comparación, también se incluyen
las esperanzas.

Para $\small{n}$ fijo, el efecto de $\small{k}$ y $\small{p_{FS}}$ puede
resumirse como sigue. Para $\small{k}$ pequeño $\small{(k=2)}$ , la
distribución de $\small{S_{n,k}}$ se suaviza y adquiere forma de campana
a medida que aumenta $\small{n}$ (de la Figura 3.1(a) a (d) a (g)), y
esta tendencia se amplifica con valores mayores de $\small{p_{FS}}$. A
medida que $\small{k}$ aumenta, las distribuciones se alejan de la forma
normal y se vuelven muy sesgadas hacia la derecha (por ejemplo, de la
Figura 3.1(d) a (e) a (f)). La distribución de $\small{S_{n,k}}$ sólo
puede aproximarse a una distribución normal cuando $\small{k}$ es mucho
menor que $\small{n}$, y las aproximaciones normales deben utilizarse
con precaución. En *Fu, Lou, Bai y Li (2002)* se ofrecen más detalles
sobre la distribución límite de $\small{S_{n,k}}$.

### Capitulo 4: Rachas y Patrones en ensayos Multi-Estados

#### 4.1 Introducción

En el capítulo 3, analizamos las ideas clave de la técnica de
Incrustación de Cadenas de Markov Finitas (ICMF) para obtener las
distribuciones exactas del número de rachas y patrones con éxitos en una
sucesión de ensayos de dos estados. El objetivo principal de este
capítulo es ampliar la técnica de ICMF para estudiar el número de rachas
y patrones en una secuencia de ensayos multiestado. Podría parecer que,
en principio, la ampliación debería ser sencilla y requerir sólo
pequeñas modificaciones. Sin embargo, no es así, especialmente cuando el
patrón es complejo y la sucesión $\small{\{X_t\}}$ está formada por
ensayos multiestado Markov-Dependientes. Las principales dificultades se
deben a la complejidad de construir una cadena de Markov finita adecuada
asociada a la variable aleatoria $\small{X_n(\Lambda)}$, especialmente
en el proceso de obtención de las probabilidades de transición. Para
superar estas dificultades, introducimos el *principio de avance y
retroceso*. En este capítulo nos centraremos en la utilización del
*principio de avance y retroceso* para obtener las distribuciones de
patrones simples y compuestos. De hecho, el *principio de avance y
retroceso* desempeña un papel indispensable en la construcción de la
Cadena de Markov Incrustada para casi todas las aplicaciones cubiertas
por este libro.

#### 4.2 Principio de avance y retroceso con recuento sin solapamiento

Comencemos con el caso simple de que $\small{\{X_t\}_{t=1}^{n}}$ es una
secuencia de *i.i.d.* ensayos miltiestados. Cada ensayo tiene
$\small{m\,\, (m\geq 2)}$ resultados posibles (estados o símbolos),
etiquetados como $\small{\mathscr{S} =\{b_1,\ldots, b_m\}}$ y que
ocurren con probabilidades $\small{p_1,p_2,\ldots,p_m,}$
respectivamente. Denotamos $\small{X_n(\Lambda)}$ al número de patrones
simples $\small{\Lambda}$ *no-superpuestos* en la sucesión
$\small{\{X_t\}}$. Primero, nos gustaría presentar el *principio de
avance y retroceso* para la técnica de incrustación de cadenas de Markov
finitas, un principio que guiará la construcción de una cadena de Markov
incrustada $\small{\{Y_t\}}$ y la determinación de sus matrices de
probabilidad de transición. Para facilitar la discusión, el principio de
avance y retroceso se introduce mediante el siguiente ejemplo.

**Ejemplo 4.1** Consideremos el patrón simple
$\small{\Lambda=\{b_{1}b_{1}b_{2}\}}$ en una sucesión de ensayos de tres
estados ($\small{\mathscr{S} =\{b_1,b_{2}, b_{3}\}}$).

*(i)* Descompongamos el patrón $\small{\Lambda=b_{1}b_{1}b_{2}}$ en un
conjunto de *subpatrones secuenciales*
$\small{\mathscr{S}(\Lambda) =\{b_1,b_{1}b_{1}, b_{1}b_{1}b_{2}\}}$.
Definiendo

<!---Ecuación 4.1--->

::: math
```{=tex}
\begin{equation}
\mathscr{E}=\mathscr{S}\, \cup \,\mathscr{S}(\Lambda)=\{b_{1},b_{2},b_{3},b_{1}b_{1}, b_{1}b_{1}b_{2}\}
\end{equation}
```
:::

como un conjunto de bloques finales inducidos por el patrón
$\small{ b_{1}b_{1}b_{2}}$ con respecto a sucesión de ensayos
$\small{\{X_t\}}$

*(ii)* Sea $\small{{\omega} =(x_{1},\ldots, x_n)}$ una realización de
una sucesión de $\small{n}$ ensayos de tres estados. Definiendo el
espacio de estados:

<!---Ecuación 4.2--->

::: math
```{=tex}
\begin{equation}
\Omega =\{(u,v):u=0,1,\cdots,[n
/3],\,\, v\in \mathscr{E}\}\,\cup \,\{\emptyset\}\, -\,\{(0,b_{1}b_{1}b_{2})\}
\end{equation}
```
:::

y una cadena de Markov

<!---Ecuación 4.3--->

::: math
```{=tex}
\begin{equation}
\big\{Y_t=\big(X_n(\Lambda), E_t\big),\,t=0,1,2,\ldots,n\big\}
\end{equation}
```
:::

operando sobre $\small{\omega}$ como

<!---Ecuación 4.3.1--->

::: math
```{=tex}
\begin{equation}
Y_t(\omega)=(u,v),\,\, \text{para}\,\, t=1,\ldots,n
\end{equation}
```
:::

en donde: <!---Ecuación 4.3.2--->

::: math
```{=tex}
\begin{align*} 
u &=\begin{cases}
\begin{array}{l} 
X_n(\Lambda)(\omega)=\,\text{el número total de patrones no-solapados}\,\Lambda\,\\
\text{en los primeros}\,\, t\,\, \text{ensayos contando hacia delante desde} \\
\text{el primer ensayo hasta el}\,\, t-ésimo\,\, \text{ensayo, y}
\end{array} 
\end{cases}\\
\\
v &=\begin{cases}
\begin{array}{l} 
E_t(w) =\,\text{el bloque final más largo en}\ \mathscr{S},\\
\text{contando hacia atrás desde}\, X_t.
\end{array}
\end{cases}
\end{align*}
```
:::

Las definiciones de $\small{u}$ y $\small{v}$ para la sucesión de los
primeros $\small{t}$ ensayos se ilustran gráficamente en la figura 4.1.
Para que la cadena de Markov incrustada $\small{\{Y_t\}}$ y el concepto
de bloque final más largo sean más transparentes, consideremos la
siguiente realización,
$\small{\omega=(b_{3}b_{1}b_{2}b_{1}b_{1}b_{2}b_{1})}$, de una sucesión
de siete ensayos de tres estados. Aplicando el principio de avance y
retroceso, la correspondiente del la cadena de Markov incrustada
$\small{\{Y_t\}}$ sobre $\small{\omega}$ viene dada por
$\small{\{Y_{1}(\omega)=(0,b_{3}), Y_{2}(\omega)=(0, b_{1}), Y_{3}(\omega) = (0, b_{2}), Y_{4}(\omega)= (0, b_{1}), Y_{5}(\omega)=(0, b_{1}b_{1}), Y_{6}(\omega) = (1, b_{1}b_{1}b_{2})\,\text{y}\, Y_{7}(\omega)=(1, b_{1})\}}$.
Tenga en cuenta que para cada $\small{\omega}$ dada, la realización de
la cadena de Markov incrustada $\small{Y_t(\omega) = (u, v)}$ está
determinada únicamente por lo anterior procedimientos *(i)* y *(ii)*
bajo conteo sin superposición. En palabras sencillas, el el bloque final
$\small{v}$ representa el estado de formación del siguiente patrón
$\small{\Lambda}$ para el subsecuencia $\small{\{{x_1,., ,x_t} \}}$ que
contiene $\small{u}$ patrones completos.

*(iii)* La cadena de Markov incrustada $\small{\{Y_t\}}$ es homogénea y
su matriz de probabilidad de transición
$\small{\boldsymbol{M_t}= \big(p_{(x,z),(u,v)}\big)}$ puede determinarse
del siguiente modo. Por ejemplo, dado
$\small{Y_5(\omega)=(0,b_{1}b_{1})}$, como $\small{X_{6}}$ sólo puede
ser uno de los tres resultados posibles $\small{b_{1}, b_{2}}$ y
$\small{b_{3}}$, el procedimiento de recuento hacia delante y hacia
atrás da como resultado

<!---Ecuación 4.4--->

::: math
```{=tex}
\begin{align*} 
Y_{5}(\omega) & \rightarrow \quad \quad Y_{6}(\omega)
\\ 
(0,b_{1}b_{1}) &\rightarrow  \begin{cases}
\begin{array}{cl} 
(0,b_{1}b_{1}) & \text{si}\,\, X_6= b_{1}\,\,(\text{con probabilidad}\, p_{1})\\
(1,b_{1}b_{1}b_{2}) & \text{si}\,\, X_6= b_{2}\,\,(\text{con probabilidad}\, p_{2})\\
(0,b_{3}) & \text{si}\,\, X_6= b_{3}\,\,(\text{con probabilidad}\, p_{3}),
\end{array}
\end{cases}
\end{align*}
```
:::

e $\small{Y_5(\omega)}$ pasa a cualquier otro estado con probabilidad
cero. De esta forma se obtienen todas las probabilidades de transición
$\small{\mathbb{P}\big(Y_t=(u,v)\mid Y_{t-1}=(x,z)\big)}$. El estado
ficticio $\small{\emptyset}$ se añadirá como estado inicial con
$\small{\mathbb{P}\big(Y_{0}=\emptyset\big)=1}$ y con probabilidades de
transición
$\small{\mathbb{P}\big(Y_{1}=b_{i}\mid Y_0=\emptyset\big)=p_{i}}$ para
$\small{i=1,2,3}$. Obsérvese que el estado
$\small{(0,\Lambda=b_{1}b_{1}b_{2})}$ se eliminó del espacio de estados,
ya que siempre que el bloque final $\small{v}$ sea igual a
$\small{\Lambda}$ debe haber al menos una ocurrencia de el patrón en la
secuencia (es decir, $\small{u\geq1}$ si $\small{v=\Lambda}$).

*(iv)* Dado $\small{n}$, tenemos la siguiente partición en el espacio de
estados $\small{\Omega}$:

<!---Ecuación 4.5---->

::: math
```{=tex}
\begin{align*} 
\big\{C_{\emptyset} &=[\emptyset], C_{0}=[(0,b_{1}),(0,b_{2}),(0,b_{3}),(0,b_{1}b_{1})], \\ 
& \,\,\text{y}\,\,C_{x}=[(x,v),v\in \mathscr{E}],\, x=1,\ldots,[n/3] \big\}.
\end{align*}
```
:::

Para $\small{n=5}$ y la probabilidad inicial
$\small{\mathbb{P}\big(Y_0=\emptyset \big)\equiv 1}$, se deduce de los
procedimientos *(i)* a *(iv)* anteriores que la cadena de Markov
incrustada $\small{\{Y_t\}_{t=0}^{5}}$ está definida en el espacio de
estados
$\small{\Omega=\{\emptyset, (0, b_{1}), (0, b_{2}), (0, b_{3}), (0, b_{1}b_{1}), (1, b_{1}b_{1}b_{2}), (1, b_{1}), (1, b_{2}), (1, b_{3}), (1, b_{1}b_{1})\}}$
con matriz de probabilidad de transición

<!----Ecuación 4.6--->

::: math
```{=tex}
\begin{equation}
\boldsymbol{M}=
\begin{array}{cc}&
\begin{array}{c}
\emptyset\\
(0,b_{1})\\
(0,b_{2})\\
(0,b_{3})\\
(0,b_{1}b_{1})\\
(1,b_{1}b_{1}b_{2})\\
(1,b_{1})\\
(1,b_{2})\\
(1,b_{3})\\
(1,b_{1}b_{1})
\end{array}
&
\left(
\begin{array}{c|cccc|ccccc}
0&p_{1}&p_{2}&p_{3}&0&0&0&0&0&0\\
\hline
0&0&p_{2}&p_{3}&0&0&0&0&0&0\\
0&p_{1}&p_{2}&p_{3}&0&0&0&0&0&0\\
0&p_{1}&p_{2}&p_{3}&0&0&0&0&0&0\\
0&0&0&p_{3}&p_{1}&p_{2}&0&0&0\\
\hline
0&0&0&0&0&0&p_{1}&p_{2}&p_{3}&0\\
0&0&0&0&0&0&0&p_{2}&p_{3}&p_{1}\\
0&0&0&0&0&0&p_{1}&p_{2}&p_{3}&0\\
0&0&0&0&0&0&p_{1}&p_{2}&p_{3}&0\\
0&0&0&0&0&0&0&0&0&1\\
\end{array}
\right)
\end{array}
\end{equation}
```
:::

Las probabilidades
$\small{\mathbb{P}\big(X_n(\Lambda)=5\big)=\boldsymbol{\xi_0M}^5\boldsymbol{U'}(C_x),\, x=0,1,}$,
pueden computarse facilmente.

Para demostrar la aplicabilidad del principio de avance y retroceso a
los patrones compuestos, consideremos el siguiente ejemplo.

**Ejemplo 4.2** Dado $\small{n=4}$ y un patrón compuesto
$\small{\Lambda= \Lambda_{1} \cup \Lambda_{2}}$, que consiste en la
unión de dos patrones simples distintos
$\small{ \Lambda_{1}=b_{1}b_{2}}$ y $\small{ \Lambda_{1}=b_{3}b_{1}}$,
estamos interesados en encontrar la distribución de la variable
aleatoria $\small{X_4(\Lambda)}$, el número de ocurrencias de
$\small{\Lambda_{1}}$ o $\small{\Lambda_{2}}$ en una secuencia de cuatro
ensayos *i.i.d.* de tres estados. Procediendo como en el ejemplo
anterior, se obtiene la cadena de Markov incrustada $\small{\{Y_t\}}$
definida en el espacio de estados

<!---Ecuación 4.7---->

::: math
```{=tex}
\begin{align*} 
\Omega &=\big\{\emptyset,(0,b_{1}),(0,b_{2}),(0,b_{3}),(1,b_{1}b_{2}), (1,b_{3}b_{1}), \\ 
& \quad \quad (1,b_{1}),(1,b_{2}),(1,b_{3}),(2,b_{1}b_{2}),(2,b_{3}b_{1})\big\}.
\end{align*}
```
:::

con matriz de probabilidades de transición:

<!----Ecuación 4.8--->

::: math
```{=tex}
\begin{equation}
\boldsymbol{M}=
\begin{array}{cc}&
\begin{array}{c}
\emptyset\\
(0,b_{1})\\
(0,b_{2})\\
(0,b_{3})\\
(1,b_{1}b_{2})\\
(1,b_{3}b_{1})\\
(1,b_{1})\\
(1,b_{2})\\
(1,b_{3})\\
(2,b_{1}b_{2})\\
(2,b_{3}b_{1})
\end{array}
&
\left(
\begin{array}{c|ccc|ccccc|cc}
0&p_{1}&p_{2}&p_{3}&0&0&0&0&0&0&0\\
\hline
0&p_{1}&0&p_{3}&p_{2}&0&0&0&0&0&0\\
0&p_{1}&p_{2}&p_{3}&0&0&0&0&0&0&0\\
0&0&p_{2}&p_{3}&0&p_{1}&0&0&0&0&0\\
\hline
0&0&0&0&p_{1}&0&0&p_{2}&p_{3}&0&0\\
0&0&0&0&0&0&p_{1}&p_{2}&p_{3}&0&0\\
0&0&0&0&0&0&p_{1}&0&p_{3}&p_{2}&0\\
0&0&0&0&0&0&p_{1}&p_{2}&p_{3}&0&0\\
0&0&0&0&0&0&0&p_{2}&p_{3}&0&p_{1}\\
\hline
0&0&0&0&0&0&0&0&0&1&0\\
0&0&0&0&0&0&0&0&0&0&1\\
\end{array}
\right)
\end{array}
\end{equation}
```
:::

Las probabilidades
$\small{\mathbb{P}\big(X_n(\Lambda)=4\big)=\boldsymbol{\xi_0M}^4\boldsymbol{U'}(C_x),\, x=0,1,2}$,
pueden computarse facilmente.

El método también puede extenderse, con modificaciones simples, a la
caso donde $\small{\{X_t\}}$ es una sucesión de ensayos multiestado
Markov-Dependientes.

**Ejemplo 4.3** Volvamos al Ejemplo 4.1, pero consideremos aquí que
$\small{\{X_t\}}$ es una secuencia de ensayos de tres estados
Markov-Dependientes con matriz de probabilidad de transición:

<!----Ecuación 4.8.1--->

::: math
```{=tex}
\begin{equation}
\boldsymbol{A}=\left(
\begin{array}{ccc}
p_{11}&p_{12}&p_{13}\\
p_{21}&p_{22}&p_{23}\\
p_{31}&p_{32}&p_{33}\\
\end{array}
\right)
\end{equation}
```
:::

Nuestro objetivo es determinar la distribución del patrón
$\small{\Lambda=b_{1}b_{1}b_{2}}$ en una secuencia de cinco ensayos. De
forma análoga al Ejemplo 4.1, las probabilidades de transición de la
cadena de Markov incrustada pueden obtenerse para cada estado mediante
el siguiente argumento. Dado $\small{Y_3 = (0, b_{1}b_{1})}$, por
ejemplo, tenemos:

<!---Ecuación 4.9--->

::: math
```{=tex}
\begin{align*} 
Y_3 & \rightarrow \quad \quad \, Y_{4}\\
(0,b_{1}b_{1}) &\rightarrow  \begin{cases}
\begin{array}{cl} 
(0,b_{1}b_{1}) & \text{si}\,\, X_{4}= b_{1}\,\,(\text{con probabilidad}\, p_{11})\\
(1,b_{1}b_{1}b_{2}) & \text{si}\,\, X_{4}= b_{2}\,\,(\text{con probabilidad}\, p_{12})\\
(0,b_{3}) & \text{si}\,\, X_{4}= b_{3}\,\,(\text{con probabilidad}\, p_{13}).
\end{array}
\end{cases}
\end{align*}
```
:::

Las ecuaciones (4.4) y (4.9) son equivalentes, salvo que las
probabilidades $\small{p_{1}}$,$\small{p_{2}}$ y $\small{p_{3}}$ se
sustituyen por $\small{p_{11}}$,$\small{p_{12}}$ y $\small{p_{13}}$
respectivamente. Por lo tanto, la cadena de Markov incrustada
$\small{\{Y_t\}}$ se define aquí en el mismo espacio de estados
$\small{\Omega}$ y con matriz de probabilidad de transición:

<!----Ecuación 4.10--->

::: math
```{=tex}
\begin{equation}
\boldsymbol{M}=
\begin{array}{cc}&
\begin{array}{c}
\emptyset\\
(0,b_{1})\\
(0,b_{2})\\
(0,b_{3})\\
(0,b_{1}b_{1})\\
(1,b_{1}b_{1}b_{2})\\
(1,b_{1})\\
(1,b_{2})\\
(1,b_{3})\\
(1,b_{1}b_{1})
\end{array}
&
\left(
\begin{array}{c|cccc|ccccc}
0&p_{1}&p_{2}&p_{3}&0&0&0&0&0&0\\
\hline
0&0&p_{12}&p_{13}&p_{11}&0&0&0&0&0\\
0&p_{21}&p_{22}&p_{23}&0&0&0&0&0&0\\
0&p_{31}&p_{32}&p_{33}&0&0&0&0&0&0\\
0&0&0&p_{13}&p_{11}&p_{12}&0&0&0\\
\hline
0&0&0&0&0&0&p_{21}&p_{22}&p_{23}&0\\
0&0&0&0&0&0&0&p_{12}&p_{13}&p_{11}\\
0&0&0&0&0&0&p_{21}&p_{22}&p_{23}&0\\
0&0&0&0&0&0&p_{31}&p_{32}&p_{33}&0\\
0&0&0&0&0&0&0&0&0&1\\
\end{array}
\right)
\end{array}
\end{equation}
```
:::

donde las probabilidades de transición
$\small{\mathbb{P}\big(Y_{t}(u,v)=Y_{t-1}(x,z)\big)}$ se obtienen como
se ilustra en la *Ec. (4.9).* Obsérvese que la matriz de probabilidades
de transición de la *Ec. (4.10)* tiene exactamente la misma forma que la
matriz de la *Ec. (4.6)* para el caso *i.i.d.*.

En vista de las transiciones de estado esbozadas por las *Ecs. (4.4) y
(4.9)*, que conducen a las matrices de probabilidad de transición de los
*Ejemplos 4.1 a 4.3*, dadas en las Ecs. (4.6), (4.8) y (4.10)
respectivamente, definimos la siguiente notación: dado
$\small{Y_{t-1} = (x, z) \in \Omega}$ y
$\small{X_t = j\in \mathscr{S}}$, <!--Ecu. 4.11-->

::: math
```{=tex}
\begin{equation}
(u,v)\equiv <(x,z),j>_{\Omega}
\end{equation}
```
:::

donde el estado $\small{(u,v)\in \Omega}$ es el resultado del recuento
hacia delante y hacia atrás (no solapado) cuando se incluye un resultado
adicional $\small{X_t=j}$. Para cada $\small{(x, z)\in \Omega}$,
definimos también $\small{L(z)\in \mathscr{S}}$ como el último elemento
del bloque final $\small{z}$. Entonces, para el caso general, las
probabilidades de transición de la cadena de Markov incrustada
$\small{Y_t}$ se especifican mediante la siguiente ecuación:

<!---Ec. 4.12--->

::: math
```{=tex}
\begin{equation}
\mathbb{P}\big(Y_t=(u,v)\mid Y_{t-1}=(x,z)\big) =\begin{cases}
p_{ij} & \quad 
\begin{array}{l}
\text{si}\,\, X_{t}=j\in\mathscr{S},\, L(z)=i\\
\text{y}\,\,(u,v)= <(x,z),j>_{\Omega}
\end{array}\\
m & \quad \text{en otro caso}
\end{cases}
\end{equation}
```
:::

donde $\small{p_{ij}}$ son las probabilidades de transición de la cadena
de Markov $\small{\{X_t\}}$. Si $\small{\{X_t\}}$ es una secuencia de
ensayos multiestado *i.i.d.*, la *Ec.(4.12)* se convierte en

<!---Ec. 4.13--->

::: math
```{=tex}
\begin{equation}
\mathbb{P}\big(Y_t=(u,v)\mid Y_{t-1}=(x,z)\big) =\begin{cases}
p_{j} & \quad 
\begin{array}{l}
\text{si}\,\, X_{t}=j\in\mathscr{S},\\
\text{y}\,\,(u,v)= <(x,z),j>_{\Omega}
\end{array}\\
0 & \quad \text{en otro caso}
\end{cases}
\end{equation}
```
:::

**Teorema 4.1** Suponiendo que $\small{\{X_t\}}$ es una cadena de Markov
homogénea con matriz de probabilidad de transición
$\small{\boldsymbol{A} = \big(p_{ij}\big)_{m\times m}}$, y
$\small{\Lambda=\displaystyle{\bigcup_{i=1}^{l}\Lambda_{i}}}$ es un
patrón compuesto generado por $\small{l}$ patrones simples distintos
$\small{\Lambda_{i}}$ que tienen la misma longitud $\small{k}$, entonces
la cadena de Markov incrustada
$\small{\big\{Y_t=\big(X_{t}(\Lambda),E_{t} \big),\,t=1,2,\,\ldots,n\big\}}$
correspondiente a la variable aleatoria $\small{X_{n}(\Lambda)}$

*(i)* se define sobre el espacio de estados:

<!---Ecuación 4.14---->

::: math
```{=tex}
\begin{align*}\Omega &=\{\emptyset\}\, \cup\,\{(x,z):x=0,1,\cdots,[n
/k],\,\, z\in \mathscr{E}\}\\
&\quad- \{(0,\Lambda_{i}):i=1,\cdots,l\}
-\,\{([n/k],z):k[n/k]+z(k)>n\},\end{align*}
```
:::

en donde
$\small{\mathscr{E} =\mathscr{S}\,\cup\Bigg(\displaystyle\bigcup_{i=1}{\mathscr{S}(\Lambda_{i})\Bigg)}}$
y $\small{z(k)\equiv [\text{longitud de}\,z] \pmod k}$

*(ii)* tiene la matriz de probabilidades de transición:
<!--Ec. 4.15---->

::: math
```{=tex}
\begin{equation}
\boldsymbol{M}=\big(p_{(x,z)(u,v)}\big)_{d\times d}
\end{equation}
```
:::

en donde las probabilidades de transición estan dadas por:
<!--Ec. 4.16---->

::: math
```{=tex}
\begin{equation}
p_{(x,z)(u,v)}=\begin{cases}
p_{j} & \,\text{si}\, (x,z)=\emptyset,\,u=0,\,v=j,\, \text{para todo}\, j \in \mathscr{S}\\ \\
p_{ij} & 
\begin{array}{l}
\text{si}\,(u,v)=<(x,z),j>_{\Omega},\, x\leq [n/k],\, j\in \mathscr{S},\\
L(z)=i,\,\text{y}\,\, kx+z(k)<n
\end{array} \\ \\
1 & 
\begin{array}{l}
\text{si}\,(u,v)= (x,z) ,\, x= [n/k]\\
\,\text{y}\,\, k[n/k]+z(k)=n
\end{array} \\\\
m & \text{en otro caso.}
\end{cases}
\end{equation}
```
:::

con $\small{d=\text{card}(\Omega)}$, el tamaño del espacio de estados
$\small{\Omega}$, igual a:

<!---Ecuación 4.17---->

::: math
```{=tex}
\begin{align*}d =1 & +([n/k]+1)\times \text{card}\big(\mathscr{E}\big)-l\\
& -\text{card}\Big(\big\{([n/k],z):\,z \in \mathscr{E}, \,k[n/k]+z(k)>n\big\}\big),\end{align*}
```
:::

y *(iii)* se obtiene la distribución:

<!---Ecuación 4.18---->

::: math
```{=tex}
\begin{equation}
\mathbb{P}\big( X_n(\Lambda)=x\big)=\boldsymbol{\mathbf{\xi}}_0\boldsymbol{M}^{n}\boldsymbol{\mathbf{U}'}( {C_x}),\,\,  x=1,2,\ldots,[n/k],
\end{equation}
```
:::

en donde $\small{\boldsymbol{\xi}_0}$ es la distribución inicial
especificada por $\small{\mathbb{P}\big(Y_{0}=\emptyset\big)\equiv 1}$ y
<!---Ec. 4.19---->

::: math
```{=tex}
\begin{align*} 
C_{\emptyset} &=[\emptyset],\, C_{0}=[(0,z):z\in\mathscr{S}]-[(0,\Lambda_{i}):i=1,2,\ldots,l], \\ 
C_{x} &=  [(x,z):z\in \mathscr{E}],\, 1\leq x \leq [n/k], \, \text{y}\\
C_{[n/x]}&=[([n/k],z):z\in \mathscr{E},\,k[n/k]+z(k)\leq n]
\end{align*}
```
:::

son las particiones del espacio de estados $\small{\Omega}$.

Nótese que el espacio de estados $\small{\Omega}$ y su tamaño
$\small{d}$ son funciones de $\small{n}$, la estructura de los patrones
$\small{\Lambda_{i},\,i=1,\ldots,l}$ y la longitud del patrón común
$\small{k}$. El lector puede comprobar que los resultados de los
Ejemplos 4.1 a 4.3 se deducen directamente del Teorema 4.1.

**Demostración**. Dado $\small{n}$, como la longitud de cada patrón es
$\small{k}$, el número máximo de patrones es $\small{[n/k]}$ (bajo
conteo no solapado). El conjunto
$\small{\mathscr{E} =\mathscr{S}\,\cup\Bigg(\displaystyle\bigcup_{i=1}{\mathscr{S}(\Lambda_{i})\Bigg)}}$
contiene todos los posibles bloques finales generados por
$\small{\mathscr{S}}$ y todos los patrones, y se deduce que para
recuento hacia delante y hacia atrás sin solapamiento, el espacio de
estados tiene la forma
$\small{\big\{(x,z): x=0,\ldots,[n/k]},\,z\in\mathscr{E}\big\}$. Los
estados $\small{\big\{(0,\Lambda_{i}): i=1,\ldots,l}\big\}$ se eliminan
porque si el bloque final es $\small{\Lambda_{i}}$, entonces debe haber
al menos un patrón $\small{\Lambda_{i}}$, en la secuencia
$\small{(x\geq 1)}$, por lo que los estados
$\small{\big\{(0,\Lambda_{i})\big\}}$ son inalcanzables; por la misma
razón, los estados $\small{\big\{([n/k],z):k[k/z]+z(k)>n\big\}}$ tampoco
pueden darse y pueden eliminarse. Así, el espacio de estados
$\small{\Omega}$ de la cadena de Markov incrustada tiene la forma dada
por la *Ec. (4.14)*, y su tamaño $\small{d}$ viene determinado por la
*Ec.(4.17).*

Dados $\small{(x,z)\in \Omega,\,0\leq x \leq [n/n]}$, y
$\small{kx + z(k) < n}$, si $\small{X_{t}=j\in \mathscr{S}}$ y
$\small{(u, v) = < (x, z), j >_{\Omega}}$ , entonces, como se describe
en las Ecs. *(4.9)* y *(4.12)*, se deduce que

<!---Ecu. 4.19.1--->

::: math
```{=tex}
\begin{align*} 
p_{(x,z)(u,v)}=\mathbb{P}\big(Y_t=(u,v)\mid Y_{t-1}=(x,z)\big)=p_{ij},
\end{align*}
```
:::

donde $\small{i=L(z)}$. Si $\small{Y_{t-1}=([n/k], z) }$, y
$\small{[kn/k] + z(k) = n}$ entonces $\small{t-1\equiv n}$; por
conveniencia, asignamos las probabilidades de transición para estos
estados como
$\small{\mathbb{P}\big(Y_t=([n/k],z)\mid Y_{t-1}=([n/k],z)\big)\equiv1}$
. Esto completa la construcción de la *Ec. (4.16)* y la matriz de
probabilidad de transición $\small{\boldsymbol{M}}$ . Las particiones en
el espacio de estados $\small{\Omega}$ , dadas por la *Ec. (4.19)*, son
una consecuencia directa de la definición de la cadena de Markov
incrustada introducida en la *Ec. (4.3)*. Por lo tanto, la distribución
para el patrón compuesto $\small{\Lambda}$ en la Ec. (4.18) es una
consecuencia inmediata del *Teorema 2.1*. Esto completa la demostración.
$\hspace{1cm}\Box$

El *teorema 4.1* anterior también es válido para patrones simples, el
caso especial cuando $\small{l=1}$ . Cuando las longitudes de los
patrones $\small{k_{i},\, i=1,\ldots,l}$ no son todas iguales, el
principio de avance y retroceso puede seguir utilizándose para hallar la
distribución del patrón compuesto $\small{\Lambda}$ . En principio, el
procedimiento de recuento de avance y retroceso es aplicable a cualquier
número de patrones $\small{l}$ de tamaños $\small{k_{i}}$ variables,
pero no es sencillo escribir la forma general del espacio de estados y
la matriz de probabilidad de transición de la cadena de Markov
incrusrada. Trataremos este problema en el capítulo 5 utilizando la
relación de dualidad entre $\small{X_{n}(\Lambda)}$ y el tiempo de
espera $\small{W(\Lambda)}$.

#### 4.3 Conteo Solapado

Consideremos que la secuencia $\small{\{X_t\}}$ es una cadena de Markov
homogénea definida sobre el espacio de estados
$\small{\mathscr{S}=\{a, b, c\}}$ con matriz de probabilidades de
transición

<!---Ec. 4.20---->

::: math
```{=tex}
\begin{equation}
\boldsymbol{A}=\big(p_{ij}\big),\, i,j=a,b,c
\end{equation}
```
:::

Sea $\small{\Lambda}$ un patrón simple de longitud $\small{k}$. La
diferencia básica entre el recuento por solapamiento y el recuento sin
solapamiento es que cuando se forma el patrón $\small{\Lambda}$, una
parte de A se contará para formar el siguiente patrón $\small{\Lambda}$
bajo el *recuento por solapamiento*, hasta los últimos $\small{(k-1)}$
ensayos.

**Definición 4.1** Un bloque final $\small{E^°}$ generado por el patrón
$\small{\Lambda}$ es el bloque final más largo
$\small{(E^{°} \neq \Lambda)}$ que, después de cada aparición de
$\small{\Lambda}$ bajo conteo superpuesto, se puede asignar como bloque
final inicial para la siguiente aparición de $\small{\Lambda}$.
Escribimos $\small{(E^{°} \cong \Lambda}$ , con respecto al conteo de
superposición.

Por ejemplo, bajo el conteo superpuesto:

-   Si $\small{\Lambda=aca}$, entonces $\small{E^{°}=a}$,
-   Si $\small{\Lambda=abcab}$, entonces $\small{E^{°}=ab}$, y
-   Si $\small{\Lambda=\underbrace{a\cdots a}_{k}}$, entonces
    $\small{E^{°}=\underbrace{a\ldots a}_{k-1}}$.

Para un patrón como $\small{\Lambda=abc}$, no existe un $\small{E^{°}}$,
en cuyo caso el conteo superpuesto y no superpuesto es el mismo. Tenga
en cuenta que bajo el conteo superpuesto, dado que el primer patrón
requiere $\small{k}$ elementos y cada patrón adicional requiere solo
$\small{k-\text{Card}(E^{°})}$ elementos, el mayor número posible de
patrones $\small{\Lambda}$ que pueden ocurrir en $\small{n (n \geq k)}$
ensayos es

<!----- Ec. 4.21 ----->

::: math
```{=tex}
\begin{equation*} 
l_{n}^{o}=1+\bigg[\frac{n-k}{k-\text{Card}(E^{°})}\bigg].
\end{equation*} 
```
:::

Para ilustrar las diferencias menores que surgen de los dos tipos de
conteo, se proporciona el siguiente ejemplo.

**Ejemplo 4.4** Consideremos el número de patrones $\small{\Lambda=aca}$
que ocurren en $\small{n=5}$ ensayos *i.i.d.* de tres estados. Bajo el
conteo no superpuesto, la matriz de transición de probabilidades
$\small{\boldsymbol{M}}$ asociada con la cadena de Markov incrustada

<!----Ecuación 4.21.1--->

::: math
```{=tex}
\begin{equation}
\boldsymbol{M}=
\begin{array}{cc}&
\begin{array}{c}
(0,a)\\
(0,b)\\
(0,c)\\
(0,ab)\\
(1,\Lambda)\\
(1,a)\\
(1,b)\\
(1,c)\\
(1,ac)\\
\end{array}
&
\left(
\begin{array}{ccccccccc}
p_{a}&p_{b}&0&p_{c}&0&0&0&0&0\\
p_{a}&p_{b}&p_{c}&0&0&0&0&0&0\\
p_{a}&p_{b}&p_{c}&0&0&0&0&0&0\\
0&p_{b}&p_{c}&0&p_{a}&0&0&0&0\\
0&0&0&0&0&p_{a}&p_{b}&p_{c}&0\\
0&0&0&0&0&p_{a}&p_{b}&0&p_{c}\\
0&0&0&0&0&p_{a}&p_{b}&p_{c}&0\\
0&0&0&0&0&p_{a}&p_{b}&p_{c}&0\\
0&0&0&0&0&0&0&0&1\\
\end{array}
\right)
\end{array}
\end{equation}
```
:::

donde $\small{(1,\Lambda)\equiv (1,aca)}$ . Bajo conteo de superpuesto,
la matriz de probabilidad de transición $\small{\boldsymbol{M^{°}}}$
asociada con la cadena de Markov incrustada es

<!----Ecuación 4.21.2--->

::: math
```{=tex}
\begin{equation}
\boldsymbol{M^{°}}=
\begin{array}{cc}&
\begin{array}{c}
(0,a)\\
(0,b)\\
(0,c)\\
(0,ab)\\
(1,\Lambda)\\
(1,a)\\
(1,b)\\
(1,c)\\
(1,ac)\\
(2,\Lambda)
\end{array}
&
\left(
\begin{array}{ccccc|cccc}
p_{a}&p_{b}&0&p_{c}&0&0&0&0&0&0\\
p_{a}&p_{b}&p_{c}&0&0&0&0&0&0&0\\
p_{a}&p_{b}&p_{c}&0&0&0&0&0&0&0\\
0&p_{b}&p_{c}&0&p_{a}&0&0&0&0&0\\
\hline
0&0&0&0&0&p_{a}&p_{b}&0&p_{c}&0\\
\hline
0&0&0&0&0&p_{a}&p_{b}&0&p_{c}&0\\
0&0&0&0&0&p_{a}&p_{b}&p_{c}&0&0\\
0&0&0&0&0&p_{a}&p_{b}&p_{c}&0&0\\
0&0&0&0&0&0&p_{b}&p_{c}&0&p_{a}\\
0&0&0&0&0&0&0&0&1&0\\
\end{array}
\right)
\end{array}
\end{equation}
```
:::

La principal diferencia entre las dos matrices surge después de que ha
ocurrido el primer patrón. Con probabilidad $\small{p_{c}}$ , el estado
$\small{(1,\Lambda)}$ pasa al estado $\small{(1,c)}$ bajo conteo no
superpuesto, mientras que $\small{(1,\Lambda)}$ pasa a $\small{(1,ac)}$
bajo conteo superpuesto, lo que también implica el estado adicional
$\small{l_{n}^{°}=(2,\Lambda)}$. $\hspace{1cm}\Diamond$

Si $\small{\{X_t\}}$ es una cadena de Markov homogénea con
probabilidades de transición dadas por la Ecuación. (4.20), la matriz de
probabilidad de transición $\small{\boldsymbol{M^{°}}}$ del anterior
ejemplo (bajo conteo superpuesto) se convierte en:

<!----Ecuación 4.21.3--->

::: math
```{=tex}
\begin{equation}
\boldsymbol{M^{°}}=
\begin{array}{cc}&
\begin{array}{c}
\emptyset\\
(0,a)\\
(0,b)\\
(0,c)\\
(0,ab)\\
(1,\Lambda)\\
(1,a)\\
(1,b)\\
(1,c)\\
(1,ac)\\
(2,\Lambda)
\end{array}
&
\left(
\begin{array}{cccccc|ccccc}
0&p_{a}&p_{b}&p_{c}&0&0&0&0&0&0&0\\
0&p_{aa}&p_{ab}&0&p_{ac}&0&0&0&0&0&0\\
0&p_{ba}&p_{bb}&p_{bc}&0&0&0&0&0&0&0\\
0&p_{ca}&p_{cb}&p_{cc}&0&0&0&0&0&0&0\\
0&0&p_{bb}&p_{bc}&0&p_{ab}&0&0&0&0&0\\
\hline
0&0&0&0&0&0&p_{aa}&p_{ab}&0&p_{ac}&0\\
\hline
0&0&0&0&0&0&p_{aa}&p_{ab}&0&p_{ac}&0\\
0&0&0&0&0&0&p_{ba}&p_{bb}&p_{bc}&0&0\\
0&0&0&0&0&0&p_{ca}&p_{cb}&p_{cc}&0&0\\
0&0&0&0&0&0&0&p_{cb}&p_{cc}&0&p_{ca}\\
0&0&0&0&0&0&0&0&0&0&1\\
\end{array}
\right)
\end{array}
\end{equation}
```
:::

donde $\small{p_{a},\, p_{b}}$, y $\small{p_{c}}$ son las probabilidades
de transición dadas del estado $\small{\emptyset}$ a los estados
$\small{(0, a), (0,b)}$ y $\small{(0, c)}$, respectivamente. Nuevamente,
la extensión de *i.i.d.* a los emnsayos Markov-Dependientes sigue siendo
sencillo. El concepto considerado en el ejemplo anterior se puede
extender al caso de superposición hasta los últimos $\small{d}$ ensayos
$\small{(1 \leq d \leq k − 1)}$, como lo introdujeron *Aki e Hirano
(2000)*. Una ventaja significativa de la técnica de incrustación de
cadenas finitas de Markov es que la extensión del conteo sin
superposición al conteo superpuesto es directa y simple.

#### 4.4 Patrones en Serie

La distribución del número de patrones en serie
$\small{\Lambda=\Lambda_{1}\ast\Lambda_{2}}$ se puede obtener casi de la
misma manera que para un patrón simple, con modificaciones menores en el
estado después de que se haya producido el primer patrón
$\small{\Lambda_{1}}$.

**Ejemplo 4.5** Consideremos una secuencia de $\small{n=5}$ ensayos
*i.i.d.* de tres estados extraídos de $\small{\mathscr{S}=\{a,b,c\}}$, y
el patrón de serie $\small{\Lambda}=ab\ast cc$ generado por los dos
patrones simples $\small{\Lambda_{1}=ab}$ y $\small{\Lambda_{2}=cc}$.
Definiendo el conjunto de bloques finales
$\small{\mathscr{E}=\{a,\bar{a},ab\ast,ab{\ast}c,ab{\ast}cc\}}$ y el
espacio de estados

<!----Ecuación 4.21.4--->

::: math
```{=tex}
\begin{equation}
\Omega=\{\emptyset,(0,a),(0,\bar{a}),(0,ab{\ast}),(0,ab{\ast}c),(1,ab{\ast}cc),(1,a),(1,\bar{a})\}
\end{equation}
```
:::

donde $\small{\bar{a}}$ representa $\small{b}$ o $\small{c}$, y
$\small{ab{\ast}}$ representa $\small{ab{\ast}a}$ o $\small{ab{\ast}b}$.
La correspondiente cadena de Markov incrustada $\small{\{Y_t\}}$ tiene
la matriz de probabilidad de transición $\small{\boldsymbol{M}}$ dada
por:

<!----Ecuación 4.21.5--->

::: math
```{=tex}
\begin{equation}
\boldsymbol{M}=
\begin{array}{cc}&
\begin{array}{c}
\emptyset\\
(0,a)\\
(0,\bar{a})\\
(0,ab{\ast})\\
(0,ab{\ast}c)\\
(1,ab{\ast}cc)\\
(1,a)\\
(1,\bar{a})\\
\end{array}
&
\left(
\begin{array}{cccccccc}
0&p_{a}&p_{b}+p_{c}&0&0&0&0&0\\
0&p_{a}&p_{c}&p_{b}&0&0&0&0\\
0&p_{a}&p_{b}+p_{c}&0&0&0&0&0\\
0&0&0&p_{a}+p_{b}&p_{c}&0&0&0\\
0&0&0&p_{a}+p_{b}&0&p_{c}&0&0\\
0&0&0&0&0&0&p_{a}&p_{b}+p_{c}\\
0&0&0&0&0&0&1&0\\
0&0&0&0&0&0&0&1\\
\end{array}
\right)
\end{array}
\end{equation}
```
:::

Por lo tanto:

<!---Ecuación 4.21.6 ---->

::: math
```{=tex}
\begin{equation}
\mathbb{P}\big(X_{n}(\Lambda)=x\big)=\boldsymbol{\xi}_{0}\boldsymbol{M}^{5}\boldsymbol{U}(C_{x}),\,x=0,1.
\end{equation}
```
:::

Obsérvese que si $\small{\{Y_t\}}$ está en el estado
$\small{(0, ab{\ast})}$ o $\small{(0,ab{\ast}c)}$, significa que el
patrón $\small{\Lambda_{1}=ab}$ ha ocurrido antes o en el
$\small{t-}$ésimo ensayo. Ahora bien, si la realización de
$\small{X_{t+1}}$ es $\small{a}$ o $\small{b}$ , entonces
$\small{Y_{t+1}}$ tiene que estar en el estado $\small{(0, ab{\ast})}$,
suceso que ocurre con probabilidad de transición $\small{p_{a}+p_{b}}$ ,
y si la realización de $\small{X_{t+1}}$ es $\small{c}$, entonces
$\small{Y_{t+1}}$ avanza al estado $\small{(0, ab{\ast}c)}$ o
$\small{(1, ab{\ast}cc)}$, respectivamente, sucesos que ocurren con
probabilidad de transición $\small{p_{c}}$.

El ejemplo anterior pone de manifiesto las diferencias entre los
patrones en series y los patrones simples en lo que respecta a sus
matrices de probabilidad de transición de las cadenas de Markov
incrustadas. Ampliando ligeramente el espacio de estados
$\small{\Omega}$, sustituyendo $\small{(i,\bar{a}),\, i=0,1}$, por
$\small{(i,b)}$ y $\small{(i, c)}$, y sustituyendo
$\small{(0, ab{\ast})}$ por $\small{(0, ab{\ast}a)}$ y
$\small{(0, ab{\ast}b)}$, el ejemplo anterior puede ampliarse fácilmente
al caso de ensayos de tres estados Markov-Dependientes.

#### 4.5 Distribución conjunta

Hallar la distribución conjunta de dos números de rachas, digamos
$\small{X_n(\Lambda_{1})}$ y $\small{X_n(\Lambda_{2})}$ , en una
secuencia de ensayos de dos o varios estados $\small{\{X_t\}}$
utilizando la técnica de incrustación de cadenas de Markov finitas es
similar a hallar la distribución exacta de $\small{X_n(\Lambda)}$
introducida en la *Sección 4.2.* En general, la cadena de Markov
incrustada $\small{\{Y_t\}}$ asociada a la distribución conjunta de
$\small{X_n(\Lambda_{1})}$ y $\small{X_n(\Lambda_{2})}$ tiene la forma

<!---Ecuación 4.22 ---->

::: math
```{=tex}
\begin{equation}
Y_{t}=\big(X_{t}(\Lambda_{1}),X_{t}(\Lambda_{2}),E_{t}\big),\,t=1,2,\ldots,n.
\end{equation}
```
:::

El espacio de estados $\small{\Omega}$ y el bloque final $\small{E_{t}}$
para $\small{\{Y_t\}}$ dependen en gran medida de la estructura de los
patrones $\small{\Lambda_{1}}$ y $\small{\Lambda_{2}}$. Las matrices de
probabilidad de transición $\small{\boldsymbol{M}_{t}}$ de la cadena de
Markov inscrustada pueden construirse utilizando los mismos principios
descritos en secciones anteriores. A continuación, damos un ejemplo para
demostrar el procedimiento para encontrar la distribución conjunta.

**Ejemplo 4.6** Sea $\small{X_{n}}$ el número total de rachas de éxito
$\small{X_{n}(S)}$ y de fracaso $\small{X_{n}(S)}$ en una secuencia de
$\small{n}$ ensayos de dos estados. Para cada
$\small{X_{n} = X_{n}(S) + X_{n}(F)}$, y los números de rachas
$\small{X_{n}(S)}$ y $\small{X_{n}(F)}$ están relacionados de la
siguiente manera: si hay $\small{x}$ rachas de éxito, entonces sólo
puede haber $\small{x+1, x}$, o $\small{x-1}$ rachas de fracaso. De ello
se deduce que sólo puede haber cuatro tipos de estados
$\small{Y_{t}=(X_{t}(S), X_{t}(F), E_{t})}$, donde el bloque final
$\small{E_{t}}$ es $\small{S}$ o $\small{F}$ : (i)
$\small{(x, x-1, S)}$, (ii) $\small{(x, x + 1, F)}$, (iii)
$\small{(x, x, S)}$ y (iv) $\small{(x, x, F)}$.

Consideremos los resultados de diez ensayos de dos estados
$\small{w = (SSFFSFSSSF)}$. La realización de la cadena de Markov
imbricada $\small{\{Y_t\}}$ es
$\small{\{Y_{1}=(1,0, S), Y_{2}=(1,0,S), Y_{3}=(1,1,F), Y_{4}=(1,1,F), Y_{5}=(2,1,S), Y_{6}= (2,2,F),Y_{7}=(3,2,S),Y_{8}=(3,2, S),Y_{9}=(3,2,S), Y_{10} = (3,3, F)\}}$.
El espacio de estados $\small{\Omega}$ tiene la forma
$\small{\Omega=\{(1,0,S), (0,1,F), (1,1,S), (1,1,F),\ldots, (l_{n},l_{n}S), (l_{n}, l_{n},F)\}}$,
donde $\small{l_{n}=[(n+1)/2]}$. Para el caso de ensayos de dos estados
independientes pero no idénticamente distribuidos, la definición de
$\small{Y_{t}}$ da como resultado las matrices de probabilidad de
transición, para $\small{t=2,3,\ldots,n,}$

<!----Ecuación 4.21.5--->

::: math
```{=tex}
\begin{equation}
\boldsymbol{M_{t}}=
\begin{array}{cc}&
\begin{array}{c}
(1,0,S)\\
(0,1,S)\\
(1,1,S)\\
(1,1,S)\\
\cdot\\
\cdot\\
\cdot\\
(l_{n},l_{n}-1,S)\\
(l_{n}-1,l_{n},F)\\
(l_{n},l_{n},S)\\
(l_{n},l_{n},F)\\
\end{array}
&
\left(
\begin{array}{ccccccccccc}
p_{t}&0&0&q_{t}&&&&&&&\\
&q_{t}&p_{t}&0&0&&&&&&\\
&&p_{t}&0&0&q_{t}&&&&&\\
&&&q_{t}&p_{t}&0&0&&&&\\
&&&&\ddots&\ddots&\ddots&\ddots&&&\\
&&&&&\cdot&\cdot&\cdot&\cdot&&\\
&&&&&&\ddots&\ddots&\ddots&\ddots&\\
&&&&&&&p_{t}&0&0&q_{t}\\
&&&&&&&&q_{t}&p_{t}&0\\
&&&&&&&&&1&0\\
&&&&&&&&&&1\\
\end{array}
\right)
\end{array}
\end{equation}
```
:::

Dado $\small{\boldsymbol{\xi}_{1}=(p_{1},q_{1},0,\ldots,0)}$ , se deduce
que la distribución conjunta de $\small{X_n(S)}$ y $\small{X_n(F)}$ está
dada por:

<!----Ecuación 4.24--->

::: math
```{=tex}
\begin{equation}
\small{\mathbb{P}\big( X_{n}(S)=x,X_{n}(F)=y\mid \boldsymbol{\xi}_{1}\big)=\boldsymbol{\mathbf{\xi}}_{1} \Big(\prod_{t=1}^{n}\boldsymbol{M}_{t}\Big)\boldsymbol{\mathbf{U}'}(\mathbf{C}_{(x,y)})},
\end{equation}
```
:::

donde, si $\small{y= x+1}$, entonces
$\small{C_{(x,x+1)}=\{{(x, x + 1, F)}\}}$, si $\small{y=x-1}$, entonces
$\small{C_{(x, x-1)}=\{(x, x-1, S)\}}$, si $\small{y=x}$ entonces
$\small{C_{(x,x)}=\{(x, x, S), (x, x, F)\}}$, y
$\small{C_{(x,y)}=\{\emptyset\}}$ en cualquier otro caso.

Una vez más, con algunas modificaciones sencillas de las matrices de
probabilidades de transición, los resultados anteriores también son
válidos tanto para ensayos de dos estados *i.i.d.*, como
Markov-Dependientes homogéneos y no homogéneos. Las distribuciones
marginales de $\small{X_{n}(S)}$ y $\small{X_{n}(F)}$ pueden obtenerse
proyectando la distribución conjunta sobre las particiones generadas por
las variables aleatorias $\small{X_{n}(S)}$ y $\small{X_{n}(F)}$,
respectivamente. De forma más general, la distribución conjunta de
$\small{l>2}$ variables aleatorias
$\small{X_{n}(\Lambda_{1}),X_{n}(\Lambda_{2}),\ldots,X_{n}(\Lambda_{l})}$
puede obtenerse del mismo modo con una cadena de Markov
$\small{(l+1)-}$dimensional
$\small{\{Y_{t} = \big(X_{t}(\Lambda_{1}),\cdots, X_{t}(\Lambda_{l}), E_{t}\big)\}}$.

Fin 05 de Nov

### Capitulo 5: Distribucines de tiempo de espera

### Bibliografia:

Abramson, M. and Moser, W. O. J. (1967). Permutations without rising or
falling w-sequences. Annals of Mathematical Statistics 38, 1245-1254.

Aki, S. (1985). Discrete distributions of order k on a binary sequence.
Annals of the Institute of Statistical Mathematics 37, 205-224.

Aki, S. (1997). On sooner and later problems between success and failure
runs.Advances in Combinatorial Methods and Applications to Probability
and Statistics (ed. N. Balakrishnan), Birkhäuser, Boston, 385-400.

Aki, S. (1999). Distributions of runs and consecutive systems on
directed trees. Annals of the Institute of Statistical Mathematics 51,
1-15.

Aki, S., Balakrishnan, N. and Mohanty, S. G. (1996). Sooner and later
waiting time problems for success and failure runs in higher order
Markov dependent trials. Annals of the Institute of Statistical
Mathematics 48, 773-787.

Aki, S. and Hirano, K. (1988). Some characteristics of the binomial
distribution of order k and related distributions. Statistical Theory
and Data Analysis II (ed. K. Matusita), North-Holland, Amsterdam,
211-222.

Aki, S. and Hirano K. (1999). Sooner and later waiting time problems for
runs in Markov dependent bivariate trials. Annals of the Institute of
Statistical Mathematics 51, 17-29.

Aki, S. and Hirano K. (2000). Numbers of success-runs of specified
length until certain stopping time rules and generalized binomial
distributions of order k. Annals of the Institute of Statistical
Mathematics 52, 767-777.

Aki, S., Kuboki, H. and Hirano, K. (1984). On discrete distributions of
order k. Annals of the Institute of Statistical Mathematics 36, 431-440.

Antzoulakos, D. L. (1999). On waiting time problems associated with runs
in Markov dependent trials. Annals of the Institute of Statistical
Mathematics 51, 323-330.

Antzoulakos, D. L. (2001). Waiting times for patterns in a sequence of
multistate trials. Journal of Applied Probability 38, 508-518.

Balakrishnan, N. and Koutras, M. V. (2002). Runs and Scans with
Applications, Wiley, New York

Balasubramanian, K., Viveros, R. and Balakrishnan, N. (1993). Sooner and
later waiting time problems for Markovian Bernoulli trials. Statistics
and Prob- ability Letters 18, 153--161.}

Barnard, G. A. (1959). Control charts and stochastic processes. Journal
of the Royal Statistical Society, Series B 21, 239-271.

Barton, D. E. and David, F. N. (1958). Non-randomness in a sequence of
two alternatives: II. Runs test. Biometrika 45, 253-256.

Bateman, G. (1948). On the power function of the longest run as a test
for randomness in a sequence of alternatives. Biometrika 35, 97-112.

Boutsikas, M. V. and Koutras, M. V. (2000a). Generalized reliability
bounds for coherent structures. Journal of Applied Probability 37,
778-794.

Boutsikas, M. V. and Koutras, M. V. (2000b). Reliability approximation
for Markov chain imbeddable systems. Methodology and Computing in
Applied Probability 2, 393-411.

Brook, D. and Evans, D. A. (1972). An approach to the probability
distribution of cusum run length. Biometrika 59, 539-549.

Cai, J. (1994). Reliability of a large consecutive-k-out-of-r-from-n:F
system with unequal component-reliability. IEEE Transactions on
Reliability 43, 107-- 111.

Carlitz, L. (1964). Extended Bernoulli and Eulerian numbers. Duke
Mathematical Journal 31, 667-689.

Chao, M. T. (1999). Applications of Markov chains in quality-related
matters. Statistical Process Monitoring and Optimization (eds. S. H.
Park and G. G. Vining), Marcel Dekker, New York, 175-188.

Chao, M. T. and Fu, J. C. (1989). A limit theorem of certain repairable
systems. Annals of the Institute of Statistical Mathematics 41,
809--818.

Chao, M. T. and Fu, J. C. (1991). The reliability of large series system
under a Markovian structure. Advances in Applied Probability 23,
894-908.

Chao, M. T., Fu, J. C. and Koutras, M. V. (1995). Survey of reliability
stud- ies of consecutive-k-out-of-n: F and related systems. IEEE
Transactions on Reliability 44, 120-127.

Chao, M. T. and Lin, G. D. (1984). Economical design of large
consecutive-k- out-of-n:F systems. IEEE Transactions on Reliability 33,
411-413.

Chen, J. and Glaz, J. (1997). Approximations and inequalities for the
distribution of a scan statistic for 0-1 Bernoulli trials. Advances in
the Theory and Practice of Statistics (eds. N. L. Johnson and N.
Balakrishnan), Wiley, New York, 285-298.

Chen, J. and Glaz, J. (1999). Approximations for the distribution and
the moments of discrete scan statistics. Scan Statistics and
Applications (eds. J. Glaz and N. Balakrishnan), Birkhäuser, Boston,
27-66.

Cheung, L. K. W. (2002). Statistical Pattern Recognition in Genomic DNA
Sequences. Ph.D. Dissertation, Department of Statistics, University of
Manitoba, Canada.

Chiang, D. T. and Niu, S. C. (1981). Reliability of
consecutive-k-out-of-n:F sys- tems. IEEE Transactions on Reliability 30,
87-89.

Chrysaphinou, O. and Papastavridis, S. (1988). A limit theorem on the
number of overlapping appearances of a pattern in a sequence of
independent trials. Probability Theory and Related Fields 79, 129-143.

Cochran, W. G. (1938). An extension of Gold's method for examining the
apparent persistence of one type of weather. Quarterly Journal of the
Royal Meteorological Society 64, 631-634.

Csörgö, S. (1979). Erdös-Rényi laws. Annals of Statistics 7, 772-787.
David, F. N. (1947). A power function for tests of randomness in a
sequence of alternatives. Biometrika 34, 335-339.

David, F. N. and Barton, D. E. (1962). Combinatorial Chance, Hafner, New
York. Derman, G., Lieberman, G. J. and Ross, S. M. (1982). On the
consecutive-k-out- of-n:F system. IEEE Transactions on Reliability 31,
57-63.

Dillon, J. F. and Roselle, D. P. (1969). Simon Newcomb's problem. SIAM
Journal on Applied Mathematics 17, 1086-1093.

Doi, M. and Yamamoto, E. (1998). On the joint distribution of runs in a
sequence of multi-state trials. Statistics and Probability Letters 39,
133-141.

Dwass, M. (1973). The number of increases in a random permutation.
Journal of Combinatorial Theory, Series A 15, 192-199.

Ebneshahrashoob, M. and Sobel, M. (1990). Sooner and later problems for
Bernoulli trials: frequency and run quotas. Statistics and Probability
Letters 9, 5-11.

Erdös, P. and Rényi, A. (1970). On a new law of large numbers. Journal
d'Analyse Mathématique 23, 103-111.

Erdös, P. and Révész, P. (1975). On the length of the longest head-run.
Topics in Information Theory, Colloquia Mathematica Societatis János
Bolyai, 16 (eds. I. Csiszar and P. Elias; Keszthely, Hungary),
North-Holland, Amster- dam, 219-228.

Ewan, W. D. and Kemp, K. W. (1960). Sampling inspection of continuous
pro- cesses with no autocorrelation between successive results.
Biometrika 47, 363-380.

Feller, W. (1968). An Introduction to Probability Theory and Its
Applications (Vol. I, 3rd ed.), Wiley, New York.

Fu, J. C. (1985). Reliability of consecutive-k-out-of-n:F system. IEEE
Transac- tions on Reliability 34, 127-130.

Fu, J. C. (1986). Reliability of consecutive-k-out-of-n:F systems with
(k-1) step Markov dependence. IEEE Transactions on Reliability 35,
602-606.

Fu, J. C. (1995). Exact and limiting distributions of the number of
successions in a random permutation. Annals of the Institute of
Statistical Mathematics 47, 435-446.

Fu, J. C. (1996). Distribution theory of runs and patterns associated
with a sequence of multi-state trials. Statistica Sinica 6, 957-974.

Fu, J. C. (2001). Distribution of scan statistics for a sequence of
bi-state trials Journal of Applied Probability 38, 1-9.

Fu, J. C. and Chang, Y. M. (2002). On probability generating functions
for wait- ing time distributions of compound patterns in a sequence of
multistate trials. Journal of Applied Probability 39, 70-80.

Fu, J. C. and Hu, B. (1987). On reliability of a large
consecutive-k-out-of-n:F sys- tem with k-1 step Markov dependence. IEEE
Transactions on Reliability 36, 75-77.

Fu, J. C. and Koutras, M. V. (1994). Distribution theory of runs: a
Markov chain approach. Journal of the American Statistical Association
89, 1050-1058.

Fu, J. C. and Lou, W. Y. W. (1991). On reliabilities of certain large
linearly connected engineering systems. Statistics and Probability
Letters 12, 291-296.

Fu, J. C. and Lou, W. Y. W. (2000a). On the exact distribution of SECON
and its application. Statistica Sinica 10, 999-1010.

Fu, J. C. and Lou, W. Y. W. (2000b). Joint distribution of rises and
falls. Annals of the Institute of Statistical Mathematics 52, 415-425.

Fu, J. C., Lou, W. Y. W., Bai, Z. D. and Li, G. (2002). The exact and
limiting distributions for the number of successes in success runs
within a sequence of Markov-dependent two-state trials. Annals of the
Institute of Statistical Mathematics 54, 719-730.

Fu, J. C., Lou, W. Y. W. and Chen, S. C. (1999). On the probability of
pattern matching in nonaligned DNA sequences: a finite Markov chain
imbedding approach. Scan Statistics and Applications (eds. J. Glaz and
N. Balakrish- nan), Birkhäuser, Boston, 287-302.

Fu, J. C., Lou, W. Y. W. and Wang, Y. J. (1999). On the exact
distributions of Eulerian and Simon Newcomb numbers associated with
random permuta- tions. Statistics and Probability Letters 42, 115--125.

Fu, J. C., Shmueli, G. and Chang, Y. M. (2002). A unified Markov chain
approach for computing the run length distribution for control charts
with simple or compound rules. Technical Report, Department of
Statistics, University of Manitoba.

Fu, J. C., Spiring, F. A. and Xie, H. (2002). On the average run lengths
of quality control schemes using a Markov chain approach. Statistics and
Probability Letters 56, 369-380.

Glaz, J. (1989). Approximations and bounds for the distribution of the
scan statistic. Journal of the American Statistical Association 84,
560-566.

Glaz, J. (1992). Approximations for tail probabilities and moments of
the scan statistic. Computational Statistics and Data Analysis 14,
213-227.

Glaz, J., Naus, J. I. and Wallenstein, S. (2001). Scan Statistics,
Springer-Verlag, New York.

Godbole, A. P. (1990). Specific formulae for some success run
distributions. Statistics and Probability Letters 10, 119-124.

Godbole, A. P. (1991). Poisson approximations for runs and patterns of
rare events. Advances in Applied Probability 23, 851-865.

Goncharov, V. L. (1944). On the field of combinatory analysis. Isvestija
Akad. Nauk. SSSR. Ser. Math. 8, 3-48 (in Russian); English translation:
Translations of the AMS Ser. Math. 19 (1962), 1-46.

Goodman, L. A. (1958). Simplified runs tests and likelihood ratio tests
for Markoff chains. Biometrika 45, 181-197.

Han, Q. and Aki, S. (1998). Formulae and recursions for the joint
distributions of success runs of several lengths in a two-state Markov
chain. Statistics and Probability Letters 40, 203-214.

Han, Q. and Aki, S. (2000a). Sooner and later waiting time problems
based on a dependent sequence. Annals of the Institute of Statistical
Mathematics 52, 407-414.

Han, Q. and Aki, S. (2000b). Waiting time problems in a two-state Markov
chain. Annals of the Institute of Statistical Mathematics 52, 778-789.

Hirano, K. (1986). Some properties of the distributions of order k.
Fibonacci Numbers and Their Applications (eds. A. N. Philippou, G. E.
Bergum, and A. F. Horadam), Reidel, Dordrecht, 43-53.

Hirano, K. and Aki, S. (1987). Properties of the extended distributions
of order k. Statistics and Probability Letters 6, 67-69.

Hirano, K. and Aki, S. (1993). One number of occurrences of success runs
of specified length in a two-state Markov chain. Statistica Sinica 3,
313-320.

Huntington, R. J. and Naus, J. I. (1975). A simpler expression for kth
nearest neighbor coincidence probabilities. Annals of Probability 3,
894-896.

Hwang, F. K. (1982). Fast solutions for consecutive-k-out-of-n:F system.
IEEE Transactions on Reliability 31, 447-448.

Hwang, F. K. (1986). Simplified reliabilities for consecutive-k-out-of-n
systems.SIAM Journal on Algebraic and Discrete Methods 7, 258-264.

Jackson, D. M. and Reilly, J. W. (1976). Permutations with a prescribed
number of p-runs. Ars Combinatoria 1, 297-305.

Johnson, B. C. (2001). Distribution of increasing l-sequences in a
random permutation. Methodology and Computing in Applied Probability 3,
35-49.

Johnson, B. C. (2002). The distribution of increasing 2-sequences in
random per- mutations of arbitrary multi-sets. Statistics and
Probability Letters 59, 67-74.

Johnson, B. C and Fu, J. C. (2000). The distribution of increasing
l-sequences in random permutations: A Markov chain approach. Statistics
and Probability Letters 49, 337-344.

Kaplansky, I. (1944). Symbolic solution of certain problems in
permutations. Bul- letin of the American Mathematical Society 50,
906-914.

Karlin, S. and McGregor, J. (1959). Coincident probabilities. Pacific
Journal of Mathematics 9, 1141-1164.

Kontoleon, J. M. (1980). Reliability determination of a
r-successive-out-of-n:F system. IEEE Transactions on Reliability 29,
437.

Kossow, A. and Preuss, W. (1989). Reliability of
consecutive-k-out-of-n:F system with nonidentical component
reliabilities. IEEE Transaction on Reliability 38, 229-233.

Koutras, M. V. (1996a). On a Markov chain approach for the study of
reliability structures. Journal of Applied Probability 33, 357-367.

Koutras, M. V. (1996b). On a waiting time distribution in a sequence of
Bernoulli trials. Annals of the Institute of Statistical Mathematics 48,
789-806.

Koutras, M. V. (1997a). Waiting time distributions associated with runs
of fixed length in two-state Markov chains. Annals of the Institute of
Statistical Mathematics 49, 123-139.

Koutras, M. V. (1997b). Waiting times and number of appearances of
events in a sequence of discrete random variables. Advances in
Combinatorial Meth- ods and Applications to Probability and Statistics
(ed. N. Balakrishnan), Birkhäuser, Boston, 363-384.

Koutras, M. V. (2003). Applications of Markov chains to the distribution
the- ory of runs and patterns. Handbook of Statistics 21: Stochastic
Processes, Modeling and Simulation (eds. D. N. Shanbhag and C. R. Rao),
Elsevier, Amsterdam, in press.

Koutras, M. V. and Alexandrou, V. (1995). Runs, scans and urn model
distributions: a unified Markov chain approach. Annals of the Institute
of Statistical Mathematics 47, 743-766.

Koutras, M. V. and Alexandrou, V. (1997a). Non-parametric randomness
tests based on success runs of fixed length. Statistics and Probability
Letters 32, 393-404.

Koutras, M. V. and Alexandrou, V. (1997b). Sooner waiting time problems
in a sequence of trinary trials. Journal of Applied Probability 34,
593--609.

Koutras, M. V. and Papastavridis, S. G. (1993). Application of the
Stein-Chen method for bounds and limit theorems in the reliability of
coherent struc- tures. Naval Research Logistics 40, 617-631.

Ling, K. D. (1992). A generalization of the sooner and later waiting
time problems for Bernoulli trials: frequency quota. Statistics and
Probability Letters 14, 401-405.

Ling, K. D and Low, T. Y. (1993). On the soonest and the latest waiting
time distributions: succession quotas. Communications in Statistics
Theory and Methods 22, 2207-2221.

Lou, W. Y. W. (1996). On runs and longest run tests: method of finite
Markov chain imbedding. Journal of the American Statistical Association
91, 1595-- 1601.

Lou, W. Y. W. (1997). An application of the method of finite Markov
chain imbedding to runs tests. Statistics and Probability Letters 31,
155--161.

Lou, W. Y. W. (2000). The exact distribution of the continuity of care
measure NOP. Statistics and Probability Letters 48, 361--368.

Lou, W. Y. W. (2001). The distribution of the usual provider continuity
index under Markov dependence. Statistics and Probability Letters 54,
269--276.

Lou, W. Y. W. (2003). The exact distribution of the K-tuple statistic
for sequence homology. Statistics and Probability Letters 1, 51-59.

Lucas, J. M. and Crosier, R. B. (1982). Fast initial response for CUSUM
quality control schemes: Give your CUSUM a head start. Technometrics 24,
199-205.

MacMahon, P. A. (1915). Combinatory Analysis, Cambridge University
Press, London.

Mohanty, S. G. (1994). Success runs of length k in Markov dependent
trials. Annals of the Institute of Statistical Mathematics 46, 777-796.

Montgomery, D. C. (2001). Introduction to Statistical Quality Control
(4th ed.). Wiley, New York.

Mood, A. M. (1940). The distribution theory of runs. Annals of
Mathematical Statistics 11, 367--392.

Mosteller, F. (1941). Note on an application of runs to quality control
charts. Annals of Mathematical Statistics 12, 228-232.

Muselli, M. (2000). Useful inequalities for the longest run
distribution. Statistics and Probability Letters 46, 239-249.

Nagaev, S. V. (1957). Some limit theorems for stationary Markov chains.
Theory of Probability and its Applications 2, 378-406.

Naus, J. I. (1965). The distribution of the size of the maximum cluster
of points on a line. Journal of the American Statistical Association 60,
532-538.

Naus, J. I. (1974). Probabilities for a generalized birthday problem.
Journal of the American Statistical Association 69, 810-815

Naus, J. I. (1982). Approximations for distributions of scan statistics.
Journal of the American Statistical Association 77, 177-183.

Nishimura, K. and Sibuya, M. (1997). Extended Stirling family of
discrete probability distributions. Communications in Statistics Theory
and Methods 26, 1727-1744.

Papastavridis, S. G. (1988). A Weibull limit for the reliability of a
consecutive k-within-m-out-of-n system. Advances in Applied Probability
20, 690-692.

Papastavridis, S. G. and Koutras, M. V. (1993). Bounds for reliability
of consec- utive k-within-m-out-of-n:F systems. IEEE Transactions on
Reliability 42, 156-160.

Philippou, A. N. (1986). Distributions and Fibonacci polynomials of
order k, longest runs, and reliability of consecutive-k-out-of-n:F
systems. Fibonacci Numbers and Their Applications (eds. A. N. Philippou,
G. E. Bergum and A. F. Horadam), Reidel, Dordrecht, 203-227.

Philippou, A. N., Georghiou, C. and Philippou, G. N. (1983). A
generalized geometric distribution and some of its properties.
Statistics and Probability Letters 1, 171--175.

Philippou, A. N. and Makri, F. S. (1986). Success runs and longest runs.
Statistics and Probability Letters 4, 211--215.

Pyke, R. (1961). Markov renewal processes: definitions and preliminary
proper- ties. Annals of Mathematical Statistics 32, 1231-1242.

Reilly, J. W. and Tanny, S. M. (1979). Counting successions in
permutations. Studies in Applied Mathematics 61, 73-81.

Rényi, A (1970). Probability Theory, American Elsevier Publishing
Company Inc., New York.

Riordan, J. (1958). An Introduction to Combinatorial Analysis, Wiley,
New York.

Roselle, D. P. (1968). Permutations by number of rises and successions.
Proceed- ings of the American Mathematical Society 19, 8-16. Ross, S. M.
(2000). Introduction to Probability Models (7th ed.), Academic Press,
San Diego.

Rubin, G., McCulloch, C. E. and Shapiro, M. A. (1990). Multinomial runs
tests to detect clustering in constrained free recall. Journal of the
American Sta- tistical Association 85, 315-320.

Saperstein, B. (1972). The generalized birthday problem. Journal of the
American Statistical Association 67, 425-428.

Schilling, M. F. (1990). The longest run of heads. The College
Mathematics Jour- nal 21, 196-207.

Seneta, E. (1981). Non-negative Matrices and Markov Chains (2nd ed.),
Springer- Verlag, New York.

Sheng, K. N. and Naus, J. I. (1994). Pattern matching between two
non-aligned random sequences. Bulletin of Mathematical Biology 56,
1143-1162.

Steinwachs, D. M. (1979). Measuring provider continuity in ambulatory
care. Medical Care 17, 551-565.

Swed, F. S. and Eisenhart, C. (1943). Tables for testing randomness of
grouping in a sequence of alternatives. Annals of Mathematical
Statistics 14, 66-87.

Tanny, S. (1973). A probabilistic interpretation of Eulerian numbers.
Duke Math- ematical Journal 40, 717-722.

Tanny, S. M. (1976). Permutations and successions. Journal of
Combinatorial Theory, Series A 21, 196-202.

Vaggelatou, E. (2003). On the length of the longest run in a multi-state
Markov chain. Statistics and Probability Letters 62, 211--221.

Uchida, M. and Aki, S. (1995). Sooner and later waiting time problems in
a two- state Markov chain. Annals of the Institute of Statistical
Mathematics 47, 415-433

Wald, A. and Wolfowitz, J. (1940). On a test whether two samples are
from the same population. Annals of Mathematical Statistics 11, 147-162.

Wigle, D. T. (1982). Prevalence of selected chronic diseases in Canada,
1978-1979. Chronic Disease in Canada 3, 9.

Wishart, J. and Hirshfeld, H. O. (1936). A theorem concerning the
distribution of joins between line segments. Journal of the London
Mathematical Society 11, 227-235.

Wolfowitz, J. (1943). On the theory of runs with some applications to
quality control. Annals of Mathematical Statistics 14, 280-288.

Worpitzky, J. (1883). Studien über die Bernoullischen und Eulerschen
Zahlen. Journal für die reine und angewandte Mathematik 94, 203-232.




## Rachas y Escaners con Aplicaciones

### Prefacio

El concepto de rachas se entiende fácilmente y los procedimientos
inferenciales basados en rachas son a menudo heurísticamente simples de
seguir e implementar. Sin embargo, un estudio teórico de rachas requiere
cuidado y uso de una amplia gama de técnicas especiales. Este volumen
proporciona una descripción completa y exhaustiva de varios desarrollos
teóricos y aplicados sobre problemas que involucran rachas y escaners

Este volumen contiene doce capítulos y puede clasificarse en términos
generales en tres partes: la **Parte A**, que comprende los *Capítulos 2
y 3*, y se ocupa principalmente del tiempo de espera para la primera
aparición de rachas y sus aplicaciones; La **Parte B**, que comprende
los *Capítulos 4 a 8*, se ocupa del tiempo de espera para la ocurrencia
múltiple de rachas, el número de ocurrencia de rachas, problemas de
tiempo de espera tardia y temprana relacionados con rachas,
distribuciones de rachas multivariadas y sus aplicaciones; y la **Parte
C**, que comprende los *Capítulos 9 a 12*, y se ocupa principalmente del
tiempo de espera para el primer escaner, escaners múltiples, el número
de escaners y sus aplicaciones.

La extensión de este volumen, así como la extensa bibliografía al final
del mismo (la mayor parte de los últimos veinte años) proporciona un
amplio testimonio del notable crecimiento que este tema de investigación
ha experimentado en el pasado reciente. Aunque hemos analizado varias
aplicaciones diferentes de estadistícas de rachas y escaneo (con tres
capítulos dedicados a ellas),creemos que hay mucho más potencial para
muchas más aplicaciones diversas y espero sinceramente que este volumen
permita y anime a los investigadores aplicados en esta dirección. Para
ayudar a los lectores interesados en este proceso, también hemos
incluido en la Bibliografía algunas referencias adicionales que se
relacionan con esta área de investigación pero que no han sido citadas
directamente en el texto.

En un volumen de esta naturaleza y tamaño, inevitablemente habrá omisión
de algunos resultados que deberían haberse incluido en este volumen.
Aseguramos que tal omisión es sólo accidental y de ninguna manera se
debe a una antipatía personal no científica.

Alentamos a los lectores a comentar sobre el contenido de este volumen y
les agradecemos de antemano por informarnos sobre cualquier error,
tergiversación u omisión.

Nos complace reconocer el apoyo y el aliento del *Sr. Steve Quigley* de
*John Wiley & Sons, Inc.*, durante todo el transcurso de este proyecto.
Se agradece la ayuda administrativa y editorial brindada por la *Sra.
Heather Haselkorn* y el *Sr. Andrew Prince* de *John Wiley & Sons, Inc*.
También agradecemos a la *Sra. Debbie Iscoe (Mississauga, Ontario,
Canadá)* por componer todo el volumen, a la *Sra. Roza Garden (Atenas,
Grecia)* por mecanografiar algunas partes del volumen y al *Dr. Michael
Boutsikas* por ayudarnos a la preparación de figuras.

La redacción de este volumen comenzó en 1995 y concluyó en el verano de
2001. Durante este período bastante largo, disfrutamos del apoyo, la
cooperación y la inmensa paciencia de nuestras familias. A todos ellos
va nuestro agradecimiento muy especial.

### Introducción y comentarios históricos

#### ¿QUÉ SON LAS RACHAS?

El concepto y el uso potencial de las rachas se pueden explicar incluso
a un principiante en estadística en términos simples, ya que el término
*racha* se usa en el campo de la probabilidad y la estadística de la
misma manera que se usa en el lenguaje común. Un significado no técnico
comúnmente entendido del término *racha* es una *sucesión
ininterrumpida* y así es exactamente como definiremos y usaremos las
*rachas* en el libro. Concretamente, en un experimento que involucra
diferentes elementos (o resultados), una *racha* de un determinado tipo
de elemento(s) es una sucesión ininterrumpida de dichos elementos
delimitada en cada extremo por otros tipos de elementos o por el
principio o el final de la sucesión completa. Por ejemplo, en la
secuencia binaria $\small{1100011101}$, primero tenemos una racha de dos
$\small{1}'$s, luego una racha de tres $\small{0}'$s, una racha de tres
$\small{1}'$s, una racha de un $\small{0}$ y finalmente una racha de un
$\small{1}$. Por tanto, tenemos cinco rachas en esa sucesión binaria.

Aunque aquí hemos ilustrado el número de rachas como una estadística, es
posible, por supuesto, definir algunas otras estadísticas basadas en las
rachas. Por ejemplo, podemos considerar la longitud máxima de racha (que
es $\small{3}$), o la longitud mínima de rachas (que es $\small{1}$), o
la diferencia entre el número de rachas de $\small{1}'$s y de
$\small{0}'$s (que es $\small{3 - 2 = 1}$)

La definición anterior de racha es simple y fácil de introducir con una
sola forma de contar. Sin embargo, si consideramos rachas de una
longitud específica (digamos, $\small{2}$), es posible introducir
diferentes formas de contar. Por ejemplo, si permitimos el conteo
superpuesto, entonces la segunda racha de tres $\small{0}'$s en la
anterior sucesión binaria puede considerarse como dos rachas de dos
$\small{0}'$s. Por otro lado, si utilizamos un conteo no superpuesto,
entonces la segunda rachas de tres $\small{0}'$s puede considerarse como
una única racha de $\small{0}'$s.

#### ¿POR QUÉ RACHAS?

Las rachas y los problemas asociados siempre han atraído la atención de
probabilistas y estadísticos desde el principio. Ya en $\small{1738}$,
*De Moivre* discutió el siguiente problema: *¿Cuál es la probabilidad de
obtener una racha de longitud* ${r}$ o más en $n$ ensayos? Sin embargo,
hubo un error en la fórmula de *De Moivre (*$\small{1738}$, Doctrine of
Chance, Problema 88); pero *De Moivre* había utilizado la fórmula
correcta en sus ejemplos numéricos. *Simpson (1740), Laplace (1812)* y
*Todhunter (1865)* realizaron más debates sobre este problema.
Curiosamente, *Marbe (1916, 1934)* utilizó observaciones sobre rachas
para respaldar la teoría que propuso de que si una moneda da "cara" con
mucha frecuencia, entonces la probabilidad de obtener "cruz" en el
lanzamiento disminuye.

A pesar de que los problemas relacionados con las rachas se estaban
discutiendo en probabilidad y combinatoria desde la publicación de
*Doctrine of Chance* por *De Moivre* en $\small{1738}$, se necesitaron
más de dos siglos para desarrollar una buena aplicación de las rachas en
estadística. *Wald* y *Wolfowitz (1940)* utilizaron rachas para
establecer una prueba de dos muestras que es intuitivamente simple y
puede explicarse fácilmente de la siguiente manera.

Sea $\small{X_1,X_2,\ldots, X_m}$ una muestra aleatoria de una población
con función de distribución acumulativa $\small{F_X(x)}$, y sea
$\small{Y_1, Y_2,..., Y_n}$ otra muestra aleatoria independiente de una
población con función de distribución acumulativa $\small{F_Y(x)}$. El
problema inferencial de interés es contrastar las hipótesis
$\small{H_0 : F_X(x) = F_Y(x)}$ para todo $x$, frente a la alternativa
$\small{H_a: F_X(x) \neq F_Y(x)}$ para algún $x$. *Wald* y *Wolfowitz
(1940)* luego sugirieron combinar las dos muestras, organizar las
observaciones $\small{m+n}$ en orden creciente de magnitud, reemplazar
los valores ordenados por $\small{0}$ o $1$ dependiendo de si se
originaron a partir de la muestra $\small{X}$ o la muestra $\small{Y}$,
respectivamente, y utilizar el número total de rachas en esa sucesión
binaria como estadística de prueba. Dado que se espera que los valores
de $\small{X}$ y $\small{Y}$ estén completamente mezclados entre sí bajo
la hipótesis nula, lo que resulta en un valor grande para el número
total de racha, Wald y Wolfowitz (1940) propusieron rechazar la
hipótesis nula para valores pequeños del número total de rachas; los
valores críticos se pueden determinar fácilmente para los valores dados
de los tamaños de muestra $m$ y $n$ y el nivel deseado de significancia
$\small{\alpha}$. *Wald* y *Wolfowitz (1940)* lograron demostrar que
esta prueba de rachas de dos muestras es, de hecho, consistente, lo que
significa que la potencia de la prueba tiende a $\small{1}$ cuando los
tamaños de muestra $m$ y $n$ tienden a $\infty$.

Desde entonces, se han desarrollado con éxito una variedad de
aplicaciones diferentes de rachas y estadísticas basadas en rachas en
una amplia gama de áreas de la estadística, así como en disciplinas
aplicadas. En este libro, nuestro objetivo es reunir varios desarrollos
teóricos que se han realizado sobre rachas y estadísticas relacionadas y
muchas aplicaciones diferentes de estos resultados. Una aplicación
estadística significativa de las rachas, anterior al trabajo de *Wald y
Wolfowitz (1940)*, se debe a *De Forest (1876)*, quien sugirió usar
rachas en la sucesión de signos de los residuos para evaluar la
adecuación de una curva ajustada a un conjunto de datos observados;
Véase *Stigler (1978)* para algunos detalles sobre este tema.

Aunque esta sección ha proporcionado una breve reseña histórica del
trabajo sobre rachas y sus aplicaciones, se presentarán más detalles en
varios lugares pertinentes de este libro. Los lectores interesados
también pueden consultar el artículo de *Weiss (1985)* y los libros de
*Stigler (1986)* y *Hald (1990)* para obtener información adicional.

### ¿Para qué sirven las rachas?

Siguiendo la línea de la prueba de rachas de dos muestras descrita en la
última sección, el número de rachas también se puede utilizar para
desarrollar algunas pruebas de aleatoriedad. Específicamente, sean
$\small{X_1,X_2,\ldots,X_n}$, $n$ variables aleatorias con una función
de distribución acumulativa conjunta $\small{F(x_2,x_2,\ldots, x_n)}$.
El problema de interés es probar la hipótesis $\small{H_0: X_i's}$ son
independientes y están distribuidas idénticamente (i.i.d.), es decir,
$\small{F(x_1, ...,x_n) = \displaystyle\prod_{i=1}^{n}F ^{*}_i(x)}$,
donde $\small{F^{*}_i(x)}$ es una función de distribución acumulativa
univariada continua. Podemos considerar la secuencia de signos de las
diferencias $\small{X_2-X_2, X_3 - X_2,\ldots, X_n - X_{n-1}}$ y definir
una *racha positiva* como una racha de signos correspondientes a
diferencias sucesivas positivas y una *racha negativa* como una racha de
signos correspondientes a diferencias sucesivas negativas. Ahora se
pueden proponer diferentes procedimientos de prueba en función del
número de rachas positivas y negativas o de la longitud de estas.
Dependiendo de la alternativa considerada, se puede elegir una región
crítica apropiada. Por ejemplo, si el problema es probar la aleatoriedad
frente a la alternativa de que hay una tendencia en
$\small{X_1, X_2,\ldots, X_n}$, será razonable rechazar $\small{H_0}$ si
los números de rachas positivas y negativas son demasiado pequeñas. Si
la alternativa fuera especificar la dirección de la tendencia, entonces
podríamos optar por utilizar una de ellas (la que sea apropiada). Por
otro lado, si el problema es probar la aleatoriedad frente a la
alternativa de que hay muchos ciclos cortos presentes en
$\small{X_1,X_2,\ldots, X_n}$, entonces será razonable rechazar
$\small{H_0}$ si el número de racahs positivas y negativas son demasiado
grandes.

Otra aplicación de similar naturaleza surge en el control estadístico de
calidad o monitoreo de procesos. Aquí, asumimos que tenemos una
característica medible en los artículos que se producen y que esta
característica tiene límites de control superior e inferior (a veces,
solo uno de esos límites). Se supone que el proceso de producción está
*bajo control* si produce muchos artículos conformes y se declara *fuera
de control* si en cualquier momento se produce una cantidad inusualmente
grande de artículos no conformes. En concreto, podemos considerar que el
proceso de producción está fuera de control si, entre las mediciones
realizadas en $n$ artículos consecutivos, la longitud máxima de racha
positiva o negativa es demasiado grande. Por ejemplo, *Deming (1972)* ha
sugerido una tolerancia hasta una longitud máxima de $\small{6}$ y más
allá para concluir que el proceso de producción se está saliendo de
control. *Deming (1972)* también ha planteado otro esquema de monitoreo
de procesos en el que observamos la longitud máxima de la racha positiva
y negativa respecto de la media, es decir, longitud de racha por encima
y por debajo de la media, respestivamente. De manera similar, *Kitagawa*
y *Seguchi* *(1956, 1957)* han señalado la importancia del estudio de
las distribuciones relacionadas con rachas múltiples en relación con los
métodos de control estadístico.

Con base en ideas similares, también se han utilizado el número y la
longitud de las rachas para desarrollar pruebas no paramétricas de
simetría de la distribución de la cual se obtuvieron datos de muestra;
véanse, por ejemplo, *Cohen* y *Menjoge (1988)*, *McWilliams (1990)*,
*Henze (1993)* y *Modarres* y *Gastwirth (1996, 1998)*. En este
contexto, suponiendo que se conoce la **mediana** poblacional
$\small{\mu}$ (y se toma como cero, sin pérdida de generalidad), los
valores absolutos de las observaciones negativas y positivas se juntan,
se hace un recuento de las rachas de valores de un mismo lado y luego se
proponen las estadísticas de prueba en función de estas rachas. Sin
embargo, observe una diferencia clave en este problema: el número de
valores a un lado de la mediana es una variable aleatoria aunque el
tamaño de la muestra $n$ en sí sea fijo. El trabajo de *Balakrishnan* y
*Frattina (2000)* y *Balakrishnan* y *Ng (2001)* sobre pruebas de
*precedencia máxima*, en las que dos muestras de unidades se someten a
una prueba de vida útil y sólo se observan unos pocos fallos tempranos
de las unidades en ambas muestras, también utilizan de manera similar el
longitud máxima de racha (correspondiente a fallas de la muestra
"control") como estadística de prueba.

Las rachas también desempeñan un papel fundamental en las *pruebas de
demostración iniciales* (start-up demonstration testing, en ingles). En
esta experimentación, un dispositivo (como un generador de energía, una
cortadora de césped o una batería de automóvil) se prueba repetidamente
y después de cada ensayo simplemente se observa si ha tenido un aranque
exitoso o no. El plan/diseño de muestreo de aceptación utilizado por el
minorista (o el consumidor) puede aceptar ese equipo si se logra un
número prescrito de arranques exitosos consecutivos (es decir, una
rachas de éxitos) antes de una cierta cantidad de pruebas, y rechazar
ese equipo en caso contrario; véase, por ejemplo, *Hahn* y *Gage
(1983*).

Nuestra aplicación final es en sistemas de confiabilidad. Así como las
estadísticas de orden son fundamentales para los *sistemas*
$k$-out-of-$n:F$, las rachas(de hecho, la longitud de la racha más
larga) son fundamentales para los sistemas $k$-out-of-$n:F$
consecutivos. Imaginemos que tenemos un sistema que consta de $n$
componentes y todos los $n$ componentes funcionan de forma
independiente. En cualquier momento sólo existen dos estados posibles
para los componentes y para todo el sistema: operativo o averiado. Así,
se dice que dicho sistema es un *sistema* $k$-out-of-$n:F$, consecutivo
si falla sólo cuando al menos $k$ componentes consecutivos han fallado,
y funcionará mientras no hayan fallado $k$ componentes sucesivos; véase,
por ejemplo, *Chiang* y *Niu (1981)* o el artículo de revisión de *Chao,
Fu* y *Koutras (1995)*.

#### DE LAS RACHA A LOS ESCANERS

En el análisis de ensayos experimentales cuyos resultados pueden
clasificarse en dos categorías exclusivas, una pregunta que surge
naturalmente es si se podrían establecer criterios razonables que
proporcionen evidencia de agrupamiento de cualquiera de las dos
categorías. Estos criterios podrían luego usarse para detectar cambios
en el proceso subyacente que genera la serie de resultados.

Consideremos una sucesión $\small{X_1,\cdots, X_n}$ de $n=lm$
$\small{(m \geq 2)}$ y $\small{l > 1}$ enteros) resultados binarios. El
problema de interés es nuevamente probar la hipótesis nula de que
$\small{X_i}$ son independientes con probabilidad de éxito constante. Un
criterio simple y comúnmente utilizado es dividir los $n$ ensayos en $l$
grupos separados de $m$ ensayos consecutivos cada uno y observar el
número de éxitos dentro de cada grupo. Si algún grupo tiene "demasiados"
éxitos (digamos, $k$ o más), se recibirá una señal de que se ha
producido un cambio en el proceso subyacente. Si $k$ es cercano a $m$,
entonces podemos denominar al grupo de $m$ ensayos consecutivos una
racha de éxitos "casi perfecta".

Otro criterio muy utilizado se basa en la superposición de grupos de $m$
ensayos sucesivos. Con esta configuración, en cada ensayo contamos el
número de éxitos en los últimos $m$ ensayos, y la frecuente aparición de
ventanas de rachas "casi perfectas" podría servir como un indicio de un
cambio en el proceso subyacente. Es claro que el caso aquí discutido
consiste en una generalización natural del concepto de racha; Además,
ofrece una estadística de prueba alternativa eficiente y fascinante en
una variedad de campos donde tradicionalmente se han utilizado los
criterios clásicos de rachas.

Consideremos, por ejemplo, el siguiente modelo que tiene su origen en la
biología molecular. Al estudiar secuencias de aminoácidos se utilizan
varios esquemas de clasificación, incluido un alfabeto químico de ocho
letras, un alfabeto funcional de cuatro letras, un alfabeto de carga de
tres letras, etc.; véase, por ejemplo, *Karlin* y *Ghandour (1985)*,
*Karlin* y *MacKen (1991)*, *Karlin* y *Altschul (1993)*, *Karlin* y
*Cardon (1994)* y *Waterman (2000)*. Con el fin de desarrollar medidas
cuantitativas para evaluar e interpretar las heterogeneidades genómicas
entre diferentes especies o unidades sujetas a diferentes químicos
infecciosos y/o varios niveles de corrupción, los biólogos moleculares
comparan sus secuencias de ADN y buscan subsecuencias alineadas largas
que coincidan en la mayoría de sus posiciones. Aparentemente, una
coincidencia inusualmente larga, es decir, la ocurrencia de una racha
"casi perfecto" o escaner, ofrece una fuerte evidencia de similitud
entre los sujetos bajo inspección.

Con el objetivo de establecer un modelo matemático para aplicaciones de
esta naturaleza, denotemos por $\small{Z_{i1}, Z_{i2}, i = 1,2,\ldots}$,
dos secuencias de aminoácidos de un alfabeto finito. Se dirá que las dos
secuencias coinciden en posición ($i\geq 1$) si
$\small{Z_{i1}= Z_{i1}}$, en cuyo caso dejamos que $\small{X_i}$ sea
$\small{1}$ (y $\small{0}$ en caso contrario). Entonces, el número de
coincidencias en una ventana de longitud $m$ se describe mediante el
proceso de sumas móviles
$\small{S_i =}\tiny{\displaystyle\sum_{j=1}^{i+m-1}X_i}$ con
$\small{i \in\{1,2,\ldots\}}$ y la coincidencia "casi perfecta" en la
posición $\small{i}$ se puede describir mediante el evento
$\small{S_i \geq k}$ ($\small{k}$ es un número entero, lo
suficientemente cercano a $\small{m}$).

Los resultados teóricos sobre el tiempo de espera para la primera (o más
generalmente, la $r$-ésima) ocurrencia de tal evento, o el número de
ocurrencias de ellos en una secuencia de tamaño dado, son de gran
importancia práctica para establecer e investigar pruebas estadísticas
apropiadas que detectarían la hipótesis nula de que las dos secuencias
son idénticas; véanse, por ejemplo, *Karlin* y *Ost (1988)*, *Glaz* y
*Naus (1991)* y *Glaz* y *Balakrishnan (1999)*.

Los escaners también desempeñan un papel fundamental en varias otras
áreas científicas. Por ejemplo, en un modelo de confiabilidad que se
introdujo recientemente con el nombre de sistema
$k-within-consecutive-out-of-n$, la ocurrencia de un escaner (ejecución
"casi perfecta" de componentes fallidos) indica una falla del sistema;
véase *Papastavridis* y *Koutras (1994)*. En la teoría del control de
calidad estadístico, un modelo más sensible (en comparación con el
modelo basado en rachas descrito anteriormente en la `Sección 1.3`) se
obtiene al declarar que un proceso está fuera de control siempre que
$\small{k}$ de $\small{n}$ puntos consecutivos caigan en la zona
crítica; ver *Greenberg (1970)* y *Saperstein (1973)*. Del mismo modo,
en las pruebas de demostración de inicio ( *startup demonstration
testing*, en ingles), el concepto de escaner puede explotarse para
establecer procedimientos eficientes de aceptación/rechazo para la
unidad bajo inspección.

En este libro, además de presentar todos los detalles teóricos
relacionados con rachas, escaners y estadísticas relacionadas, también
consideraremos todas estas aplicaciones, elaboraremos metodologías
apropiadas y las ilustraremos con muchos ejemplos numéricos. Mientras lo
hacemos, también discutiremos algunas modificaciones, extensiones y
generalizaciones de estos problemas que pueden hacerlos más útiles y
aplicables a situaciones prácticas de la vida real.

#### QUE ESPERAR

Aunque todas las aplicaciones citadas en las dos últimas secciones se
basan en rachas de diferentes maneras, está bastante claro que algunos
problemas de tiempo de espera están asociados con todas ellas. También
es evidente que las distribuciones de probabilidad de la variable tiempo
de espera (hasta que ocurran algunas rachas de cierto tipo, por ejemplo)
y el número de rachas están bastante relacionadas. Por lo tanto, es útil
y revelador estudiar las distribuciones de los tiempos de espera
asociados con las rachas y luego utilizar estas distribuciones para
abordar los diversos problemas aplicados mencionados en las dos últimas
secciones. Éste es precisamente el objetivo y propósito de este libro.
Para facilitar la presentación de todos los desarrollos relevantes, el
resto de este libro se ha dividido en tres partes naturales de la
siguiente manera:

-   **Parte A**: incluye los *Capítulos 2* y *3* que se ocupa
    principalmente del tiempo de espera para la primera aparición de
    rachas y su aplicación a una variedad de problemas. En el *Capítulo
    3* se detallan varias aplicaciones interesantes en áreas tan
    diversas como confiabilidad, control de calidad, estadística no
    paramétrica, meteorología y ciencias ambientales.

-   **Parte B**: incluye los *Capítulos 4* a *8* y se centra
    principalmente en algunas extensiones y generalizaciones de los
    resultados discutidos en la *Parte A*. Específicamente, incluye
    discusiones detalladas sobre el tiempo de espera para la ocurrencia
    múltiple de rachas, sobre el número de ocurrencias de rachas, sobre
    problemas de tiempo de espera tardia y temprana que involucran racha
    y sobre distribuciones multivariadas relacionadas con la ocurrencia
    de rachas. Finalmente, se describen algunas aplicaciones diversas de
    estos resultados.

-   **Parte C**: incluye los *capítulos 9* a *12* y se ocupa de las
    distribuciones relacionadas con las estadísticas de escaneo, que son
    generalizaciones naturales del principio de rachas. La organización
    de la *Parte C* es similar a la utilizada para la *Parte B*, es
    decir, comenzamos nuestra discusión con la distribución del tiempo
    de espera para la primera ocurrencia de escaners, procedemos a los
    problemas de tiempo de espera de múltiples escaners y finalmente
    discutimos la distribución del número de ocurrencias de escaners en
    un número fijo de resultados. El libro concluye con el *Capítulo
    12*, donde se describen las aplicaciones de escaners a una variedad
    de problemas.
